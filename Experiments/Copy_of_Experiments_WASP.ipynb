{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Experiments_WASP",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f6f402d6ec4847e2a2e7c7b818cb6f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1621b348d3a4bd7aed7528b69cbc3cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c37875accdb4d249d7b23057b547d47",
              "IPY_MODEL_db28f6159efe4f74b6d653d98d74d422",
              "IPY_MODEL_d10c4823afb7489f915559cfe7143dc1"
            ]
          }
        },
        "b1621b348d3a4bd7aed7528b69cbc3cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c37875accdb4d249d7b23057b547d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be7284e1fbae4d50ba157aea6fcdf6d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c64fbe4b94024198b8ecce50e2188d25"
          }
        },
        "db28f6159efe4f74b6d653d98d74d422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62dad3bd952d4510b1eb6c4c38a72889",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 690,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 690,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b6668daa232428093f226bd70d59c6d"
          }
        },
        "d10c4823afb7489f915559cfe7143dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9267b6259a044d5ca33cfa713883fc0b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 690/690 [00:00&lt;00:00, 25.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5825732ed08f4ea2951fc3d7585012e8"
          }
        },
        "be7284e1fbae4d50ba157aea6fcdf6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c64fbe4b94024198b8ecce50e2188d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62dad3bd952d4510b1eb6c4c38a72889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b6668daa232428093f226bd70d59c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9267b6259a044d5ca33cfa713883fc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5825732ed08f4ea2951fc3d7585012e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd2b15d14df04c9b9cce992f98deff0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ccc300324f51404a9fe8c9fa33808a02",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e1869ce1dc742f9a1f6e41d7f100c83",
              "IPY_MODEL_c10d72bdc07943d2916a9882f114acdc",
              "IPY_MODEL_b1214f21efac42f884041856889ca4cf"
            ]
          }
        },
        "ccc300324f51404a9fe8c9fa33808a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e1869ce1dc742f9a1f6e41d7f100c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65db2acaf0694994949f6c46053b2729",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53f3422979a0417ab7e16d5ef9d885e9"
          }
        },
        "c10d72bdc07943d2916a9882f114acdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e2548b3c0944c78878ee53f1fd8f076",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3710,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3710,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b8513a65f274b3cbfd04d9388a743cd"
          }
        },
        "b1214f21efac42f884041856889ca4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b9877b0200a4ce2995fd16fdce1aafa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.71k/3.71k [00:00&lt;00:00, 164kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ad18f9660874d729567603b2bd5d7fd"
          }
        },
        "65db2acaf0694994949f6c46053b2729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53f3422979a0417ab7e16d5ef9d885e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e2548b3c0944c78878ee53f1fd8f076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b8513a65f274b3cbfd04d9388a743cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b9877b0200a4ce2995fd16fdce1aafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ad18f9660874d729567603b2bd5d7fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79ff1906738c47a2bf9319ec81773d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f43ed4f6829f438d95bb0a4b2bc664e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_50f36322352e49dca13119845eae01d1",
              "IPY_MODEL_24b58beb002d4053baabb844e005c714",
              "IPY_MODEL_b8d1c7b38fba4f4b97eccaf51e0bf943"
            ]
          }
        },
        "f43ed4f6829f438d95bb0a4b2bc664e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50f36322352e49dca13119845eae01d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ea761872ca84b04b8eafce51187d388",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e56751122b44d3ead3b7e434a83d493"
          }
        },
        "24b58beb002d4053baabb844e005c714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08bef71a805f4d988a34ff2dbee2e645",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 827,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 827,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ef34c72e6d84de58c9495e02ba82f0b"
          }
        },
        "b8d1c7b38fba4f4b97eccaf51e0bf943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e62b035a4a649138ddc7f8de0af14a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 827/827 [00:00&lt;00:00, 33.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a9e9a0d26304c839552c9c2506bf343"
          }
        },
        "9ea761872ca84b04b8eafce51187d388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e56751122b44d3ead3b7e434a83d493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08bef71a805f4d988a34ff2dbee2e645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ef34c72e6d84de58c9495e02ba82f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e62b035a4a649138ddc7f8de0af14a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a9e9a0d26304c839552c9c2506bf343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "959353bc2e4e4ec69a7e5e3c232e9972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_878259eafe3942e9a97381961939bac2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58b4d9dcb6a04e7b9667ee4ff7cf128c",
              "IPY_MODEL_8ff7f7b49ed641cfbfa3d3bf588689f8",
              "IPY_MODEL_0b7face2d8434fc6b6ba73d2792bf78e"
            ]
          }
        },
        "878259eafe3942e9a97381961939bac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58b4d9dcb6a04e7b9667ee4ff7cf128c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aad953bd07114fc7be4b0b2aad622cb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_943b3aa72e5b4a009d42c019c867cd99"
          }
        },
        "8ff7f7b49ed641cfbfa3d3bf588689f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8d3036b51b674dc4a0c973d681e3dc05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 122,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 122,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c373c967cd024b819d32f743193b363c"
          }
        },
        "0b7face2d8434fc6b6ba73d2792bf78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52e14e779947481c8949b273418a16c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 122/122 [00:00&lt;00:00, 5.06kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69094a501fb5406bbc02b172a540a475"
          }
        },
        "aad953bd07114fc7be4b0b2aad622cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "943b3aa72e5b4a009d42c019c867cd99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d3036b51b674dc4a0c973d681e3dc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c373c967cd024b819d32f743193b363c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52e14e779947481c8949b273418a16c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69094a501fb5406bbc02b172a540a475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9bd39ca07f54aa2a7aa9335c57c5dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41d04591ffb74cba96854ec7cc3fc21d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2373f51ce98b4e01a8fdf9528d64bad8",
              "IPY_MODEL_9259c7f9acac481d9422fd4500e39c86",
              "IPY_MODEL_744c6d72b257450d8526fa4d3e153619"
            ]
          }
        },
        "41d04591ffb74cba96854ec7cc3fc21d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2373f51ce98b4e01a8fdf9528d64bad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6e63b1d3a5747b59fdc81dc07ff0f3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a26add04510045428fdf53bc176bc480"
          }
        },
        "9259c7f9acac481d9422fd4500e39c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ee5157c93824e56ab77f5a7bed0c896",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 229,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 229,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06cd029c18324f4fb7097075029ea32f"
          }
        },
        "744c6d72b257450d8526fa4d3e153619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c4c91cac57146d8bf8d1e01660684a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 229/229 [00:00&lt;00:00, 7.64kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_611da4707b0746ca90aaee8f11db013d"
          }
        },
        "f6e63b1d3a5747b59fdc81dc07ff0f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a26add04510045428fdf53bc176bc480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ee5157c93824e56ab77f5a7bed0c896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06cd029c18324f4fb7097075029ea32f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c4c91cac57146d8bf8d1e01660684a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "611da4707b0746ca90aaee8f11db013d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9e67dcb062d435db3c500111f039b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_515ee0024fb749a8a8939772d5f5557f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12ca4d5cd12d41b6b3ccda8f0b1a03a6",
              "IPY_MODEL_8c041ab2c99c4318b5df0f6fae48dcac",
              "IPY_MODEL_cd73cb2c43a64f17873771e2048822c9"
            ]
          }
        },
        "515ee0024fb749a8a8939772d5f5557f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12ca4d5cd12d41b6b3ccda8f0b1a03a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_701d67cee6f94242a33506da39dd58e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd54bea5f02f45568efbeca0ccc6ac42"
          }
        },
        "8c041ab2c99c4318b5df0f6fae48dcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4baa85a1830a49e89cd44ab5ba37b42e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46747799,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46747799,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_705849ccd1c0478b9ff8c299f54e2ea9"
          }
        },
        "cd73cb2c43a64f17873771e2048822c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f0a13ea7c7b4acfaf33bfe755f69e9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 46.7M/46.7M [00:00&lt;00:00, 60.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f473107b79e34c859b3ef0370ca56a74"
          }
        },
        "701d67cee6f94242a33506da39dd58e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd54bea5f02f45568efbeca0ccc6ac42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4baa85a1830a49e89cd44ab5ba37b42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "705849ccd1c0478b9ff8c299f54e2ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f0a13ea7c7b4acfaf33bfe755f69e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f473107b79e34c859b3ef0370ca56a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48359d7763ec407da48ac6b77471f289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d68c7e5475b4d09b053d92b7e797c58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f78ccb9803354607982df3e504842899",
              "IPY_MODEL_90797182727f4170868b0baf17102f4b",
              "IPY_MODEL_b640ca2ccd354059bcabf5f10cd2ee76"
            ]
          }
        },
        "9d68c7e5475b4d09b053d92b7e797c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f78ccb9803354607982df3e504842899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f9b47e88eda40a5b83ee65529426415",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a90c104f09b0427e9a727a276c8b90e2"
          }
        },
        "90797182727f4170868b0baf17102f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1cb2d776c69432fa4021747d0656abb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 53,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 53,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8440f76cc6f4a5e9a1bdaaed20f69a4"
          }
        },
        "b640ca2ccd354059bcabf5f10cd2ee76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f82e074193348249b97fcae0b8be056",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.30kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c3dd55d688b47d7a120acd4f8479487"
          }
        },
        "9f9b47e88eda40a5b83ee65529426415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a90c104f09b0427e9a727a276c8b90e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1cb2d776c69432fa4021747d0656abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8440f76cc6f4a5e9a1bdaaed20f69a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f82e074193348249b97fcae0b8be056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c3dd55d688b47d7a120acd4f8479487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de50c5d9871a4b75b5df9f4e4cb44dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e4709d755f84031a12085ba5446dc33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cabdcc69d7c64461a235ef634318b0ca",
              "IPY_MODEL_629dc4f13820460b85dcdcb5ca4a688d",
              "IPY_MODEL_bcf79da797304de1ab4150bcfd55314c"
            ]
          }
        },
        "4e4709d755f84031a12085ba5446dc33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cabdcc69d7c64461a235ef634318b0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9234d8117d044ed38124271c85e40ecc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6174bf7ab7ca4608b6b95498d16c587e"
          }
        },
        "629dc4f13820460b85dcdcb5ca4a688d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0194c94c6bc34b58b45d2689b3f8f3de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 245,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 245,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ab2165a5c2149779400198506bfb5e6"
          }
        },
        "bcf79da797304de1ab4150bcfd55314c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_478e56a7cd4d489794b9f54f316c47db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 245/245 [00:00&lt;00:00, 9.20kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50885ccfc97b4bbea57871710c02a13a"
          }
        },
        "9234d8117d044ed38124271c85e40ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6174bf7ab7ca4608b6b95498d16c587e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0194c94c6bc34b58b45d2689b3f8f3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ab2165a5c2149779400198506bfb5e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "478e56a7cd4d489794b9f54f316c47db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50885ccfc97b4bbea57871710c02a13a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be5cbdb819204331af6eae3a4c62a412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5970eaa296d43b6a9ac94fab05dcc4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_28f6aff1120248ef93d95fa179934a55",
              "IPY_MODEL_34db9d63efc04c5cb115de2b347c8e5d",
              "IPY_MODEL_f0ccbe5a769d4c179eef53362218313b"
            ]
          }
        },
        "e5970eaa296d43b6a9ac94fab05dcc4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28f6aff1120248ef93d95fa179934a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c7fceab5267496da03769774ce2f837",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4841dde8969543b68af0be5c13e25ea1"
          }
        },
        "34db9d63efc04c5cb115de2b347c8e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8287ef8e716f46e896b07444a0f84b60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7520e09534ce478e995a5d51c46d19cc"
          }
        },
        "f0ccbe5a769d4c179eef53362218313b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_031d505dc327453484bf63ff0aa11bf1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760k/760k [00:00&lt;00:00, 10.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5549654549a0465a8bd1d2ef15fcb8d2"
          }
        },
        "5c7fceab5267496da03769774ce2f837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4841dde8969543b68af0be5c13e25ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8287ef8e716f46e896b07444a0f84b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7520e09534ce478e995a5d51c46d19cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "031d505dc327453484bf63ff0aa11bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5549654549a0465a8bd1d2ef15fcb8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5850a56431d943f989f25617de1d9695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0e2aeac3609f4d9090a98facc88a99ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_38f505d5b1df4c37ab0ff88ac655097c",
              "IPY_MODEL_47df807a812f4985a10f586f0050ad58",
              "IPY_MODEL_a809054b268a4be2899f0ccce1324d1a"
            ]
          }
        },
        "0e2aeac3609f4d9090a98facc88a99ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38f505d5b1df4c37ab0ff88ac655097c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8482dc25ad764fe5b8d02a2dfdf20efa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cceb1002ce9748549e34919dab52503e"
          }
        },
        "47df807a812f4985a10f586f0050ad58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fcf59b58237148e5b40eaf64f79e6adb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1311010,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1311010,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33f4565ae3c04479bb77b43274b3d614"
          }
        },
        "a809054b268a4be2899f0ccce1324d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf78b307f6e44f49a183d057264359f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.31M/1.31M [00:00&lt;00:00, 2.93MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a04f560c631143e5bee4a368e8e6d041"
          }
        },
        "8482dc25ad764fe5b8d02a2dfdf20efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cceb1002ce9748549e34919dab52503e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcf59b58237148e5b40eaf64f79e6adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33f4565ae3c04479bb77b43274b3d614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf78b307f6e44f49a183d057264359f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a04f560c631143e5bee4a368e8e6d041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8819c883b3154cc5abeb0d2653669198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ade9a46986dc4f1388964e88900b857e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fcedc86ae5ea45a0aae3cae6201e9d7c",
              "IPY_MODEL_f5dd62995e02483989138e0623ae7bff",
              "IPY_MODEL_32886ed6bd7d48bca496fe09190c91f0"
            ]
          }
        },
        "ade9a46986dc4f1388964e88900b857e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcedc86ae5ea45a0aae3cae6201e9d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61fa0d0eeb30413fb98672e578f0609a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ee0e6b1caf44e338f7138893ef20a4e"
          }
        },
        "f5dd62995e02483989138e0623ae7bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b837eca01c243b09475412d178c8c40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 465,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 465,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e07001640ee9445b8fab59c2224522ba"
          }
        },
        "32886ed6bd7d48bca496fe09190c91f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d2559ab1c3342c6a52dab2e74395357",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 465/465 [00:00&lt;00:00, 19.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_082fa958a2844769995e288ce6955f72"
          }
        },
        "61fa0d0eeb30413fb98672e578f0609a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ee0e6b1caf44e338f7138893ef20a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b837eca01c243b09475412d178c8c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e07001640ee9445b8fab59c2224522ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d2559ab1c3342c6a52dab2e74395357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "082fa958a2844769995e288ce6955f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12f65e2ff2c04a84bfe1f6e1246d7c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_79bd140dd5fe4b2985226265da651cd2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f87f97b3790e4734aa1075447b71fcce",
              "IPY_MODEL_981e144a5c6a49d7aa2a6fb5db63c3f2",
              "IPY_MODEL_794bff3c76c04780b4993a9934fd0ec0"
            ]
          }
        },
        "79bd140dd5fe4b2985226265da651cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f87f97b3790e4734aa1075447b71fcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29a49056bca3424aa6e4a6c90f1ab0a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb6fcf6768824d4aa687f7acaa75fab1"
          }
        },
        "981e144a5c6a49d7aa2a6fb5db63c3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc3853c6e2814fd89a60dd398fd2bbd7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 190,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 190,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_658ee447ae9041d085756d435a3443cd"
          }
        },
        "794bff3c76c04780b4993a9934fd0ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fe68b69b44a54b24aa32618bf243bd97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 190/190 [00:00&lt;00:00, 7.57kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7106d7b68724d1b94b58b462d27e1c7"
          }
        },
        "29a49056bca3424aa6e4a6c90f1ab0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb6fcf6768824d4aa687f7acaa75fab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc3853c6e2814fd89a60dd398fd2bbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "658ee447ae9041d085756d435a3443cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe68b69b44a54b24aa32618bf243bd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7106d7b68724d1b94b58b462d27e1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bjkqT5UslWOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install torch -q\n",
        "!pip install sentence-transformers -q\n",
        "!pip install nltk -q\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "from random import sample\n",
        "import re\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    CONFIG_MAPPING,\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    AutoConfig,\n",
        "    GPT2LMHeadModel, \n",
        "    GPT2Model,\n",
        "    GPT2Tokenizer,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    LineByLineTextDataset,\n",
        "    PreTrainedTokenizer,\n",
        "    TextDataset,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        "    BertForSequenceClassification,\n",
        ")\n",
        "\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "import pickle\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, AutoTokenizer,AutoConfig\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import GPT2TokenizerFast\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "umRMWcyeoXzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d640f5-46fe-4d1a-cb80-0c3543fc01bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4 MB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 77.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 100.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 55.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 19.3 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the models and test data"
      ],
      "metadata": {
        "id": "0_LNhF8ylWRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaned test data:"
      ],
      "metadata": {
        "id": "l7Bk6F9_mz4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/data_clean\"\n",
        "%cd data_clean\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFhbLmL-lg-o",
        "outputId": "b72430ac-850d-429c-dea8-7630cec3eb61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data_clean\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formal = pickle.load(open(\"/content/data_clean/formal_test.obj\", \"rb\"))\n",
        "informal0 = pickle.load(open(\"/content/data_clean/informal_test0.obj\", \"rb\"))\n",
        "informal1 = pickle.load(open(\"/content/data_clean/informal_test1.obj\", \"rb\"))\n",
        "informal2 = pickle.load(open(\"/content/data_clean/informal_test2.obj\", \"rb\"))\n",
        "informal3 = pickle.load(open(\"/content/data_clean/informal_test3.obj\", \"rb\"))\n",
        "formal_tune = pickle.load(open(\"/content/data_clean/formal_tune.obj\", \"rb\"))\n",
        "formal_train = pickle.load(open(\"/content/data_clean/formal_train.obj\", \"rb\"))\n",
        "informal_tune0 = pickle.load(open(\"/content/data_clean/informal_tune0.obj\", \"rb\"))\n",
        "informal_train = pickle.load(open(\"/content/data_clean/informal_train.obj\", \"rb\"))\n",
        "\n",
        "paranmt_dev = pickle.load(open(\"/content/data_clean/0_paranmt_dev.pickle\", \"rb\"))\n",
        "paranmt_train = pickle.load(open(\"/content/data_clean/0_paranmt_train.pickle\", \"rb\"))\n",
        "cleaned_paranmt = pickle.load(open(\"/content/data_clean/1_cleaned_paranmt.pkl\", \"rb\"))\n",
        "bleu_cleaned_paranmt = pickle.load(open(\"/content/data_clean/2_bleu_cleaned_paranmt.pkl\", \"rb\"))\n",
        "\n",
        "# acl_testing_0 = pickle.load(open(\"/content/data_clean/0_acl_testing.jsonl\", \"rb\"))\n",
        "# acl_training_0 = pickle.load(open(\"/content/data_clean/0_acl_training.jsonl\", \"rb\"))\n",
        "acl_cleaned_1 = pickle.load(open(\"/content/data_clean/1_cleaned_acl.pkl\", \"rb\"))\n",
        "acl_cleaned_train_1 = pickle.load(open(\"/content/data_clean/1_cleaned_acl_train.pkl\", \"rb\"))\n",
        "acl_testing_pair_2 = pickle.load(open(\"/content/data_clean/2_acl_testing_pair.pkl\", \"rb\"))\n",
        "acl_train_pair_2 = pickle.load(open(\"/content/data_clean/2_acl_train_pair.pkl\", \"rb\"))\n",
        "acl_cleanend_all_3 = pickle.load(open(\"/content/data_clean/3_all_acl_cleaned.pkl\", \"rb\"))\n",
        "\n",
        "\"\"\"\n",
        "  dataset should be in the form [(in, out), (in, out), ..., (in, out)]\n",
        "\"\"\"\n",
        "def get_mixed_sample(dataset1, dataset2, amount):\n",
        "  dataset = dataset1 + dataset2\n",
        "  return sample(dataset, amount)"
      ],
      "metadata": {
        "id": "_24e8HeimKWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Model 1 data"
      ],
      "metadata": {
        "id": "w7Oqe6v4MCef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(100):\n",
        "#   print(cleaned_paranmt[i][3], \" -> \", cleaned_paranmt[i][4])\n",
        "\n",
        "print(paranmt_dev[0][3], paranmt_train[0][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW2cf5QDmkTR",
        "outputId": "b50642da-cd6a-49b1-c7d6-3aac01f19bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A person's character is reflected in his wathan. I guess it's up to me to save this family, then.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_paranmt = []\n",
        "for i in range(len(paranmt_dev)):\n",
        "  total_paranmt.append((paranmt_dev[i][3], paranmt_dev[i][4]))\n",
        "for i in range(len(paranmt_train)):\n",
        "  total_paranmt.append((paranmt_train[i][3], paranmt_train[i][4]))\n",
        "\n",
        "total_GYAFC = []\n",
        "for i in range(len(formal)):\n",
        "  total_GYAFC.append((formal[i], informal0[i]))\n",
        "for i in range(len(formal_tune)):\n",
        "  total_GYAFC.append((formal_tune[i], informal_tune0[i]))\n",
        "for i in range(len(formal_train)):\n",
        "  total_GYAFC.append((formal_train[i], informal_train[i]))"
      ],
      "metadata": {
        "id": "vMglGDquDyXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(total_paranmt), len(total_GYAFC))\n",
        "\n",
        "sample_GYAFC = sample(total_GYAFC, len(total_paranmt))\n",
        "print(len(sample_GYAFC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUQwLXdSK-Ri",
        "outputId": "353033c5-6cc6-4d9c-908e-8d14b307bcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74554 111272\n",
            "74554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data_50_50 = total_paranmt + sample_GYAFC\n",
        "total_data_50_50 = sample(total_data_50_50, 5120) #40 batches of 128"
      ],
      "metadata": {
        "id": "k8rjsFLULcFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(total_data_50_50, open(\"new_total_data_50_50\", \"wb\"))"
      ],
      "metadata": {
        "id": "G5CXHK4TLbXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Run this while importing total data 50 50\n",
        "total_data_50_50 = pickle.load(open(\"/content/total_data_50-50.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "P5hGAfa8LbdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m-VuQVBA8jTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_data_50_50[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW-dQPY3wj4b",
        "outputId": "a7c55bd1-9b20-4029-ce8a-a3e4acc3bbe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Four suspected terrorists had been detained and were now undergoing interrogation.', 'they further were detained by the four suspects, who have now been subjected to questioning.'), ('You and Grandma want to stay in the room.', \"you'll be staying with your grandmother.\"), ('If you just send him an email, then it means you are frightened', 'If you just send him an email, then that means ur scared'), (\"Dr. Garner's agreed to drop the kidnapping charges if you turn over the boy.\", 'when you give him the boy, Dr. Garner withdraws a kidnapping charge.'), ('Incoming breakers broke, spilling shatters of foam on the sand.', 'the waves crashed and splashed across the sand with showers of foam.'), ('Enjoy your time going out Enjoy your freedom', 'GO OUT AND HAVE A GOOD TIMEBE FREE'), ('Go into chat rooms that are in your peer group, and then introduce yourself', 'GO INTO CHAT ROOMS THAT ARE YOUR PEER GROUPINTRODUCE YOURSELF'), ('His distaste for America quailed before his hatred for the rulers of his own country.', \"Muhammadi's hostility to America was in awe of hatred for his country's rulers.\"), ('Ask him or have one of your girlfriends ask him', 'ask him or have one of your girl friends ask him'), ('Darling, I was so excited when I got your message.', 'oh, sweetie, your message has made me so happy.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Model 2 Data\n"
      ],
      "metadata": {
        "id": "GVyV8cIjMGuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_model2 = []\n",
        "reference_output_model2 = []\n",
        "for i in range(len(acl_testing_pair_2)):\n",
        "  reference_output_model2.append(acl_testing_pair_2[\"input\"].iloc[i])\n",
        "  input_model2.append(acl_testing_pair_2[\"output\"].iloc[i])\n",
        "\n",
        "for i in range(len(acl_testing_pair_2)):\n",
        "  reference_output_model2.append(acl_train_pair_2[\"input\"].iloc[i])\n",
        "  input_model2.append(acl_train_pair_2[\"output\"].iloc[i])\n",
        "\n",
        "data_pairs = []\n",
        "\n",
        "for i in range(len(input_model2)):\n",
        "  data_pairs.append((input_model2[i], reference_output_model2[i]))\n",
        "\n",
        "total_model2_sample = sample(data_pairs, 5120)"
      ],
      "metadata": {
        "id": "hREifnJTM9Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_model2_sample = np.array(total_model2_sample)\n",
        "\n",
        "open_file = open(\"total_model2_sample.p\", \"wb\")\n",
        "pickle.dump(total_model2_sample, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "kaMLN8ckRkZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#or load from file:\n",
        "total_model2_sample = pickle.load(open(\"/content/total_model2_sample.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "y2P4G1LOTtQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(total_model2_sample, open(\"new_total_model2_sample\", \"wb\"))"
      ],
      "metadata": {
        "id": "xkzoD5I14xgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_output_model2_sample = total_model2_sample[:, 1]\n",
        "input_model2_sample = total_model2_sample[:, 0]"
      ],
      "metadata": {
        "id": "pMZCU1ICTnY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_model2_sample[10:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F48fm5X9R8Pa",
        "outputId": "30d84c97-d39e-410a-e7ec-2a34f51decd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' shown in the left and right bracket is a symbol for the combination of the left and right braces, and we will call it the left and right bracket.',\n",
              "       'as noted in the previous section, the calculation of the probability of a pcfg or a hmm is relatively complex.',\n",
              "       'a Parser for Chinese Parses',\n",
              "       'the analysis was not satisfactory, but the results were satisfying',\n",
              "       'we have not yet implemented this option in the current system.',\n",
              "       '.but the latter is more accurate than the former, at least for now.',\n",
              "       'however, the model of Morphological Morphology is not addressed and the correspondence between sequence and morphological properties is not optimal',\n",
              "       'the NUM method is not practical in practice',\n",
              "       'we need to know how many times a verb is attested in a given context to estimate the probability of occurrence',\n",
              "       'in very small quantities of training, the unconstrained model is incapable of continuing to grow'],\n",
              "      dtype='<U325')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_output_model2_sample[10:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGeLj7OTSAXt",
        "outputId": "06c4ce76-63a9-45c6-c13a-0db6e1c8f86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['with a slight abuse of notation we now let them act as cover symbols standing for the sets of left and right brackets lcb a c rcb and lcb a c rcb respectively and we let m be the combined set u',\n",
              "       'as noted in the previous section maximizing the conditional likelihood of a pcfg or a hmm can be computationally intensive',\n",
              "       'we present a chinese parser based on abduction',\n",
              "       'the problems of analysis were severe but the results gratifying',\n",
              "       'in the current system we have not implemented this option',\n",
              "       'while neither of these is absolutely correct the latter is generally much closer to the truth than the former',\n",
              "       'however morphology is not addressed and the sequence correspondence model is less powerful than that employed in the back transliteration and spelling correction literature',\n",
              "       'algorithm NUM is not a practical method for incremental feature selection',\n",
              "       'in order to estimate the probability p f v we need to know how many times a verb is attested with a given frame',\n",
              "       'the unconstrained joint model becomes intractable with very small amounts of training data'],\n",
              "      dtype='<U325')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuned models:"
      ],
      "metadata": {
        "id": "I4EH2Ewnm6sD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download: GPT2 - GYAFC Model:"
      ],
      "metadata": {
        "id": "gquWA_NmAEgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/GYAFC_model\"\n",
        "%cd GYAFC_model\n",
        "\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hF5vnFuAJdJ",
        "outputId": "9e93d92a-7c1c-430d-d514-5fb5410de727"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GYAFC_model\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GYAFC trained GPT2 model (no rewards)\n",
        "model_GYAFC = GPT2LMHeadModel.from_pretrained(\"/content/GYAFC_model/\")\n",
        "tokenizer_GYAFC = AutoTokenizer.from_pretrained(\"/content/GYAFC_model/\")"
      ],
      "metadata": {
        "id": "KeLTOtxhAxMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download: GPT2 PARANMT Model"
      ],
      "metadata": {
        "id": "IBCsLxmOJXGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/PARANMT_model/\"\n",
        "%cd PARANMT_model\n",
        "\n",
        "\n",
        "\n",
        "%cd ..\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_tZni_GJRV8",
        "outputId": "6b3e2a8a-d271-4893-9285-34c1f3f47c02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PARANMT_model\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PARANMT trained GPT2 model (no rewards)\n",
        "model_PARANMT = GPT2LMHeadModel.from_pretrained(\"/content/PARANMT_model/\")\n",
        "tokenizer_PARANMT = GPT2Tokenizer.from_pretrained(\"/content/PARANMT_model/\")"
      ],
      "metadata": {
        "id": "PwQYJktEK7qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e95fb4-7867-4aa9-bc09-1cd6fbf4db1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/PARANMT_model/ were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.bias', 'transformer.extra_embedding_project.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download: GPT2 GYAFC/PARANMT Model"
      ],
      "metadata": {
        "id": "-cB14NnopU6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/Combi_model/\"\n",
        "%cd Combi_model\n",
        "\n",
        "\n",
        "\n",
        "%cd ..\n"
      ],
      "metadata": {
        "id": "L59X5x8wpU60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538091ac-fbeb-429c-8369-6c7b33312e74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Combi_model\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GYAFC/PARANMT trained GPT2 model (no rewards)\n",
        "model_combi = GPT2LMHeadModel.from_pretrained(\"/content/Combi_model/\")\n",
        "tokenizer_combi = AutoTokenizer.from_pretrained(\"/content/Combi_model/\")"
      ],
      "metadata": {
        "id": "VU4yUIffo9QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download: Model1 Rewards"
      ],
      "metadata": {
        "id": "GQ4U_b73IJ8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cfvdeg-AIMiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/Model1_Rewards/\"\n",
        "%cd Model1_Rewards\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%cd ..\n"
      ],
      "metadata": {
        "id": "L-7bpEqWIJ8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15011d6-8237-4719-8460-0122ffd33f19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Model1_Rewards\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model1_rewards = GPT2LMHeadModel.from_pretrained(\"/content/Model1_Rewards/\")\n",
        "tokenizer1_rewards = GPT2Tokenizer.from_pretrained(\"/content/Model1_Rewards/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn3fUELcIJ8K",
        "outputId": "db304871-fcc6-46ba-d892-b656526977af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/Model1_Rewards/ were not used when initializing GPT2LMHeadModel: ['v_head.summary.bias', 'v_head.summary.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download: Model 2"
      ],
      "metadata": {
        "id": "QL0oePt7_drT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/Model2/\"\n",
        "%cd Model2\n",
        "\n",
        "\n",
        "\n",
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNoYhzcf_5DC",
        "outputId": "7c2fe97f-335f-41cf-eedf-514d2fc7d282"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Model2\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = GPT2LMHeadModel.from_pretrained(\"/content/Model2/\")\n",
        "tokenizer_2 = AutoTokenizer.from_pretrained(\"/content/Model2/\")"
      ],
      "metadata": {
        "id": "l_Q6s3uVBRdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSnIPO5H4Lfd"
      },
      "source": [
        "### Download: Model 2 (previous project)\n",
        "\n",
        "1. Run all cells\n",
        "2. Scroll down to the interactive part to explore GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43xZG8-z4hM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23a988f-906b-4ac7-fa5a-7f5982db923d"
      },
      "source": [
        "! echo \"Prepare download of GPT-2 model...\"\n",
        "! mkdir gpt2_model_2\n",
        "%cd gpt2_model_2\n",
        "! echo \"download model checkpoint\"\n",
        "\n",
        "%cd ..\n",
        "\n",
        "checkpoint = \"/content/gpt2_model_2\"\n",
        "\n",
        "! echo \"install libraries...\"\n",
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "!pip install -q transformers torch"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare download of GPT-2 model...\n",
            "/content/gpt2_model_2\n",
            "download model checkpoint\n",
            "/content\n",
            "install libraries...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 596 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 60.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.0 MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWjrTUlATqPA"
      },
      "source": [
        "from transformers import pipeline, TextGenerationPipeline, GPT2LMHeadModel, AutoTokenizer\n",
        "\n",
        "model2_1 = GPT2LMHeadModel.from_pretrained(checkpoint)\n",
        "tokenizer2_1 = AutoTokenizer.from_pretrained(checkpoint, )\n",
        "science_generator2_1 = TextGenerationPipeline(model=model2_1, tokenizer=tokenizer2_1, return_full_text=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIxvgomcTqHv"
      },
      "source": [
        "def processor(input):\n",
        "  input_prompt = \"<BOS>\"+input+\"<GENERATE_SCIENCE>\"\n",
        "\n",
        "  max_length= len(input_prompt)\n",
        "  science = science_generator2_1(input_prompt, min_length = int(max_length/2), max_length = max_length, do_sample=True,\n",
        "                repetition_penalty=1.1, temperature=1.2,\n",
        "                top_p=0.55, top_k=50)\n",
        "\n",
        "  x = science[0]['generated_text']\n",
        "  output = ''\n",
        "  for ch in x:\n",
        "    if ch == '.':\n",
        "      output += '.'\n",
        "      break\n",
        "    else:\n",
        "      output += ch\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2l5Lyv4fBgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e57844d-e4f3-4a58-955b-ee2f72592792"
      },
      "source": [
        "#@title Interactive\n",
        "\n",
        "#@markdown Please set your sentences, that you would like to be transferred.\n",
        "text = \"The majority of CNN-based object detectors are largely applicable only for recommendation systems. For example, searching for free parking spaces via urban video cameras is executed by slow accurate models, whereas car collision warning is related to fast inaccurate models. Improving the real-time object detector accuracy enables using them not only for hint generating recommendation systems, but also for stand-alone process management and human input reduction. Real-time object detector operation on conventional Graphics Processing Units (GPU) allows their mass usage at an affordable price. T\" #@param {type: \"string\"}\n",
        "\n",
        "print(processor(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in addition to the detection of objects based on CNN, they are used mainly in the recommendation system, with a large proportion of these objects for the system of recommendations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Eu7KwFj78om"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download: Model 2 with rewards"
      ],
      "metadata": {
        "id": "qxtL6fMCNPxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/Model2_rewards/\"\n",
        "%cd Model2_rewards\n",
        "\n",
        "\n",
        "\n",
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94810423-0c95-467e-b14d-201910573ec8",
        "id": "7ShuwH9UNPxV"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Model2_rewards\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_rewards = GPT2LMHeadModel.from_pretrained(\"/content/Model2_rewards/\")\n",
        "tokenizer_2_rewards = AutoTokenizer.from_pretrained(\"/content/Model2_rewards/\")"
      ],
      "metadata": {
        "id": "-dKZYdyuNPxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16a4105-9762-4224-df91-6c602820da99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/Model2_rewards/ were not used when initializing GPT2LMHeadModel: ['v_head.summary.bias', 'v_head.summary.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning and Importing Model Ouputs:"
      ],
      "metadata": {
        "id": "wkiGbwbfouM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1"
      ],
      "metadata": {
        "id": "4eLVAip54iCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading in the raw output data of the models:\n",
        "\n",
        "\n",
        "\n",
        "raw_output_gyafc = pickle.load(open(\"/content/generated_outputs_GYAFC_Model.p\", \"rb\"))\n",
        "raw_output_paranmt = pickle.load(open(\"/content/generated_outputs_PARANMT_Model.p\", \"rb\"))\n",
        "raw_output_combi = pickle.load(open(\"/content/generated_outputs_Combi_Model.p\", \"rb\"))\n",
        "raw_output_model1_rewards = pickle.load(open(\"/content/generated_outputs_Model1_rewards.p\", \"rb\")) "
      ],
      "metadata": {
        "id": "4VTXiwIXhmSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_output_gyafc = []\n",
        "decoded_output_paranmt = []\n",
        "decoded_output_combi = []\n",
        "decoded_output_model1_rewards = []\n",
        "\n",
        "for i in range(len(raw_output_gyafc)):\n",
        "  decoded_output_gyafc.append(tokenizer_GYAFC.decode(raw_output_gyafc[i][0]))\n",
        "  decoded_output_paranmt.append(tokenizer_PARANMT.decode(raw_output_paranmt[i][0]))\n",
        "  decoded_output_combi.append(tokenizer_combi.decode(raw_output_combi[i][0]))\n",
        "  decoded_output_model1_rewards.append(tokenizer1_rewards.decode(raw_output_model1_rewards[i][0]))"
      ],
      "metadata": {
        "id": "EfnBmBXykQL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoded_output_model1_rewards[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1v4I4AQTHlO",
        "outputId": "ede3a533-8c12-4a63-e03a-6ff53eeb2f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<BOS> I do; men break your heart, while friends stay forever <SCI_GEN> i do... men break ur heart... friends stay forever... <EOS> i do... men break ur heart... friends stay forever... <EOS> i do... men break ur heart... friends stay forever... <EOS> i do... men break ur heart... friends stay forever... <EOS> i do... men break ur heart... friends stay forever... <EOS> <EOS> i do... men break ur heart... friends stay forever... <EOS> <EOS> i do... men break ur heart... friends stay forever', '<BOS> You can acquire it from limewire, however you must download it <SCI_GEN> you can get it from limewire but u have to download it. <EOS> you can get it from limewire but u have to download it. <EOS> u can get it from limewire but u have to download it. <EOS> you have to download it... <EOS> u can get it from limewire... but u have to download it... <EOS> i guess... you just have to download it... <EOS>... u can get it from', '<BOS> I do not believe you can compare different cases of love <SCI_GEN> i dont think you can say the same thing for love. <EOS> i dont think you can compare love cases. <EOS> i dont think u can say the same thing for love. <EOS> i dont think u can say that for love. <EOS> i dont think u can say that for love. <EOS> i dont think u can say that for love. <EOS> i dont think u can say that for love. <EOS> <EOS> i dont think u can say that for love. <EOS>', '<BOS> She must have done an edit similar to the one I just did for it <SCI_GEN> she must have done an edit like i did for it. <EOS> she must have done an edit like i did for it. <EOS> she must have done an edit like that. <EOS> she must have done an edit like that. <EOS> she must have done an edit like that. <EOS> she must have done one. <EOS> she must have done one. <EOS>...she must have done one... <EOS>...she must have done one... <EOS>...she', \"<BOS> That is how it got where he is today <SCI_GEN> that's how he got where he is now. <EOS> thats how it went down. <EOS> that's how it went down... <EOS> thats how it went down... <EOS> thats how it went down... <EOS> thats how it went down... <EOS> thats how it went down... <EOS>...that's how it went... <EOS>...that's how it went...... <EOS>...that's how it went... <EOS>...that's how it went... <EOS>...that\", '<BOS> Nessus said, \"All the seas seem to be of the same order of magnitude.\" <SCI_GEN> \"the entire ocean seems to be the same size,\" Nessus said. <EOS> \"the whole ocean is the same size,\" Ness said. <EOS>... and so on...  I think... it\\'s all the seas... I\\'m sure. <EOS>... and so... I think... it\\'s... it\\'s... it\\'s... it\\'s... it\\'s... it\\'s... it... it... it... it... it...', \"<BOS> HQsaid you're at the tunnel, yeah? <SCI_GEN> the statement said you were in the tunnel, right? <EOS> so you're in the tunnel...... yeah...... what do you say? <EOS> so...... what do you say...... you're in the tunnel...... yeah...... what do you say? <EOS> so...... what do you say...... you're in the tunnel...... yeah...... what do you say? <EOS> so...... what do you say...... you're in the tunnel...... yeah...... what do you say? <EOS> so...... what\", '<BOS> The song Take the A Train by Duke Ellington Orchestra Eighteen <SCI_GEN> Take the A Train by Duke Ellington Orchestra  Eighteen. <EOS> Take the A Train by Duke Ellington Orchestra   18. <EOS>...                                                          ', '<BOS> And the other guards returned fire on the copilot. <SCI_GEN> the other guards fired at the copilot. <EOS> the other guards fired at the pilot. <EOS> the pilot was shot by the other guards. <EOS> the other guards shot him. <EOS> the pilot was shot by the other guards. <EOS> the other guards shot him. <EOS> the pilot was shot. <EOS> the other guards shot him. <EOS> the pilot was shot. <EOS> the other ones shot him. <EOS> the pilot was shot. <EOS> the others shot him. <EOS> the', \"<BOS> I am short of cash so I try to be frugal <SCI_GEN> I'm not really short on cash so I try to be frugal. <EOS> i'm short of cash so i try to be frugal. <EOS> i'm not really short of cash, i just try to be. <EOS> i'm not that cheap, i just try to be. <EOS> (i'm not really that cheap, i just try to be). <EOS> (i'm not that cheap, i just try to be. <EOS> (\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_gyafc = []\n",
        "output_paranmt = []\n",
        "output_combi = []\n",
        "output_1_rewards = []\n",
        "for i in range(len(decoded_output_gyafc)):\n",
        "  g = decoded_output_gyafc[i].split(\"<SCI_GEN>\")[1].split(\"<EOS>\")[0]\n",
        "  output_gyafc.append(g)\n",
        "\n",
        "  p = decoded_output_paranmt[i].split(\"<SCI_GEN>\")[1].split(\"<SCI _ GEN>\")[0]\n",
        "  p = p.split(\"<eos>\")[0]\n",
        "  output_paranmt.append(p)\n",
        "\n",
        "  c = decoded_output_combi[i].split(\"<SCI_GEN>\")[1].split(\"<EOS>\")[0]\n",
        "  output_combi.append(c)\n",
        "\n",
        "  r = decoded_output_model1_rewards[i].split(\"<SCI_GEN>\")[1].split(\"<EOS>\")[0]\n",
        "  output_1_rewards.append(r)"
      ],
      "metadata": {
        "id": "MdlX_V-il9J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_1_rewards[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFhjRrqvmfjB",
        "outputId": "86651d30-3446-44da-d184-c5ff48d52a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' i do... men break ur heart... friends stay forever... ',\n",
              " ' you can get it from limewire but u have to download it. ',\n",
              " ' i dont think you can say the same thing for love. ',\n",
              " ' she must have done an edit like i did for it. ',\n",
              " \" that's how he got where he is now. \",\n",
              " ' \"the entire ocean seems to be the same size,\" Nessus said. ',\n",
              " ' the statement said you were in the tunnel, right? ',\n",
              " ' Take the A Train by Duke Ellington Orchestra  Eighteen. ',\n",
              " ' the other guards fired at the copilot. ',\n",
              " \" I'm not really short on cash so I try to be frugal. \"]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_data = [x[0] for x in total_data_50_50]\n",
        "\n"
      ],
      "metadata": {
        "id": "WvVBDYg2pRrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DoKlrEeppGT",
        "outputId": "0d0a2e8a-f148-4d98-8615-6a8c35217894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I do; men break your heart, while friends stay forever',\n",
              " 'You can acquire it from limewire, however you must download it',\n",
              " 'I do not believe you can compare different cases of love',\n",
              " 'She must have done an edit similar to the one I just did for it',\n",
              " 'That is how it got where he is today',\n",
              " 'Nessus said, \"All the seas seem to be of the same order of magnitude.\"',\n",
              " \"HQsaid you're at the tunnel, yeah?\",\n",
              " 'The song Take the A Train by Duke Ellington Orchestra Eighteen',\n",
              " 'And the other guards returned fire on the copilot.',\n",
              " 'I am short of cash so I try to be frugal']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_gyafc = pickle.load(open(\"/content/new_gyafc_output.p\", \"rb\"))\n",
        "output_paranmt = pickle.load(open(\"/content/new_outputs_paranmt.p\", \"rb\"))\n",
        "output_combi = pickle.load(open(\"/content/new_combi_output.p\", \"rb\"))\n",
        "output_model1_rewards = pickle.load(open(\"/content/new_model1_rewards_output.p\", \"rb\"))\n"
      ],
      "metadata": {
        "id": "oLyJGZGveuIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_model1_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwBe0FTEfYma",
        "outputId": "656017e1-aae0-409d-e563-934a6bd5bc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[50257,    40,   466,    26,  1450,  2270,   534,  2612,    11,   981,\n",
              "           2460,  2652,  8097, 50260,    72,   466,   986,  1450,  2270,  2956,\n",
              "           2612,   986,  2460,  2652,  8097,   986, 50258,    72,   466,   986,\n",
              "           1450,  2270,  2956,  2612,   986,  2460,  2652,  8097,   986, 50258,\n",
              "             72,   466,   986,  1450,  2270,  2956,  2612,   986,  2460,  2652,\n",
              "           8097,   986, 50258,    72,   466,   986,  1450,  2270,  2956,  2612,\n",
              "            986,  2460,  2652,  8097,   986, 50258,    72,   466,   986,  1450,\n",
              "           2270,  2956,  2612,   986,  2460,  2652,  8097,   986, 50258, 50258,\n",
              "             72,   466,   986,  1450,  2270,  2956,  2612,   986,  2460,  2652,\n",
              "           8097,   986, 50258, 50258,    72,   466,   986,  1450,  2270,  2956,\n",
              "           2612,   986,  2460,  2652,  8097]]),\n",
              " tensor([[50257,  1639,   460, 12831,   340,   422,  1761,   413,   557,    11,\n",
              "           2158,   345,  1276,  4321,   340, 50260,  5832,   460,   651,   340,\n",
              "            422,  1761,   413,   557,   475,   334,   423,   284,  4321,   340,\n",
              "             13, 50258,  5832,   460,   651,   340,   422,  1761,   413,   557,\n",
              "            475,   334,   423,   284,  4321,   340,    13, 50258,    84,   460,\n",
              "            651,   340,   422,  1761,   413,   557,   475,   334,   423,   284,\n",
              "           4321,   340,    13, 50258,  5832,   423,   284,  4321,   340,   986,\n",
              "          50258,    84,   460,   651,   340,   422,  1761,   413,   557,   986,\n",
              "            475,   334,   423,   284,  4321,   340,   986, 50258,    72,  4724,\n",
              "            986,   345,   655,   423,   284,  4321,   340,   986, 50258,   986,\n",
              "            334,   460,   651,   340,   422]]),\n",
              " tensor([[50257,    40,   466,   407,  1975,   345,   460,  8996,  1180,  2663,\n",
              "            286,  1842, 50260,    72, 17666,   892,   345,   460,   910,   262,\n",
              "            976,  1517,   329,  1842,    13, 50258,    72, 17666,   892,   345,\n",
              "            460,  8996,  1842,  2663,    13, 50258,    72, 17666,   892,   334,\n",
              "            460,   910,   262,   976,  1517,   329,  1842,    13, 50258,    72,\n",
              "          17666,   892,   334,   460,   910,   326,   329,  1842,    13, 50258,\n",
              "             72, 17666,   892,   334,   460,   910,   326,   329,  1842,    13,\n",
              "          50258,    72, 17666,   892,   334,   460,   910,   326,   329,  1842,\n",
              "             13, 50258,    72, 17666,   892,   334,   460,   910,   326,   329,\n",
              "           1842,    13, 50258, 50258,    72, 17666,   892,   334,   460,   910,\n",
              "            326,   329,  1842,    13, 50258]]),\n",
              " tensor([[50257,  3347,  1276,   423,  1760,   281,  4370,  2092,   284,   262,\n",
              "            530,   314,   655,   750,   329,   340, 50260,  7091,  1276,   423,\n",
              "           1760,   281,  4370,   588,  1312,   750,   329,   340,    13, 50258,\n",
              "           7091,  1276,   423,  1760,   281,  4370,   588,  1312,   750,   329,\n",
              "            340,    13, 50258,  7091,  1276,   423,  1760,   281,  4370,   588,\n",
              "            326,    13, 50258,  7091,  1276,   423,  1760,   281,  4370,   588,\n",
              "            326,    13, 50258,  7091,  1276,   423,  1760,   281,  4370,   588,\n",
              "            326,    13, 50258,  7091,  1276,   423,  1760,   530,    13, 50258,\n",
              "           7091,  1276,   423,  1760,   530,    13, 50258,   986,  7091,  1276,\n",
              "            423,  1760,   530,   986, 50258,   986,  7091,  1276,   423,  1760,\n",
              "            530,   986, 50258,   986,  7091]]),\n",
              " tensor([[50257,  2504,   318,   703,   340,  1392,   810,   339,   318,  1909,\n",
              "          50260,  5562,   338,   703,   339,  1392,   810,   339,   318,   783,\n",
              "             13, 50258,   400,  1381,   703,   340,  1816,   866,    13, 50258,\n",
              "           5562,   338,   703,   340,  1816,   866,   986, 50258,   400,  1381,\n",
              "            703,   340,  1816,   866,   986, 50258,   400,  1381,   703,   340,\n",
              "           1816,   866,   986, 50258,   400,  1381,   703,   340,  1816,   866,\n",
              "            986, 50258,   400,  1381,   703,   340,  1816,   866,   986, 50258,\n",
              "            986,  5562,   338,   703,   340,  1816,   986, 50258,   986,  5562,\n",
              "            338,   703,   340,  1816,   986,   986, 50258,   986,  5562,   338,\n",
              "            703,   340,  1816,   986, 50258,   986,  5562,   338,   703,   340,\n",
              "           1816,   986, 50258,   986,  5562]]),\n",
              " tensor([[50257,    45,   408,   385,   531,    11,   366,  3237,   262, 21547,\n",
              "           1283,   284,   307,   286,   262,   976,  1502,   286, 14735,   526,\n",
              "          50260,     1,  1169,  2104,  9151,  2331,   284,   307,   262,   976,\n",
              "           2546,   553, 41606,   385,   531,    13, 50258,     1,  1169,  2187,\n",
              "           9151,   318,   262,   976,  2546,   553, 41606,   531,    13, 50258,\n",
              "            986,   290,   523,   319,   986,   220,   314,   892,   986,   340,\n",
              "            338,   477,   262, 21547,   986,   314,  1101,  1654,    13, 50258,\n",
              "            986,   290,   523,   986,   314,   892,   986,   340,   338,   986,\n",
              "            340,   338,   986,   340,   338,   986,   340,   338,   986,   340,\n",
              "            338,   986,   340,   338,   986,   340,   986,   340,   986,   340,\n",
              "            986,   340,   986,   340,   986]]),\n",
              " tensor([[50257, 41275, 30079,   345,   821,   379,   262, 13275,    11, 10194,\n",
              "             30, 50260,  1169,  2643,   531,   345,   547,   287,   262, 13275,\n",
              "             11,   826,    30, 50258,   568,   345,   821,   287,   262, 13275,\n",
              "          16317, 10194, 16317,   644,   466,   345,   910,    30, 50258,   568,\n",
              "          16317,   644,   466,   345,   910, 16317,   345,   821,   287,   262,\n",
              "          13275, 16317, 10194, 16317,   644,   466,   345,   910,    30, 50258,\n",
              "            568, 16317,   644,   466,   345,   910, 16317,   345,   821,   287,\n",
              "            262, 13275, 16317, 10194, 16317,   644,   466,   345,   910,    30,\n",
              "          50258,   568, 16317,   644,   466,   345,   910, 16317,   345,   821,\n",
              "            287,   262, 13275, 16317, 10194, 16317,   644,   466,   345,   910,\n",
              "             30, 50258,   568, 16317,   644]]),\n",
              " tensor([[50257,   464,  3496,  7214,   262,   317, 16835,   416, 11083,   412,\n",
              "           2680,  1122, 34017, 18087,  6429, 50260, 12322,   262,   317, 16835,\n",
              "            416, 11083,   412,  2680,  1122, 34017,   220, 18087,  6429,    13,\n",
              "          50258, 12322,   262,   317, 16835,   416, 11083,   412,  2680,  1122,\n",
              "          34017,   220,   220,  1248,    13, 50258,   986,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,  1870,   262,   584, 10942,  4504,  2046,   319,   262,  2243,\n",
              "          23439,    13, 50260,  1169,   584, 10942,  6294,   379,   262,  2243,\n",
              "          23439,    13, 50258,  1169,   584, 10942,  6294,   379,   262,  8022,\n",
              "             13, 50258,  1169,  8022,   373,  2823,   416,   262,   584, 10942,\n",
              "             13, 50258,  1169,   584, 10942,  2823,   683,    13, 50258,  1169,\n",
              "           8022,   373,  2823,   416,   262,   584, 10942,    13, 50258,  1169,\n",
              "            584, 10942,  2823,   683,    13, 50258,  1169,  8022,   373,  2823,\n",
              "             13, 50258,  1169,   584, 10942,  2823,   683,    13, 50258,  1169,\n",
              "           8022,   373,  2823,    13, 50258,  1169,   584,  3392,  2823,   683,\n",
              "             13, 50258,  1169,  8022,   373,  2823,    13, 50258,  1169,  1854,\n",
              "           2823,   683,    13, 50258,  1169]]),\n",
              " tensor([[50257,    40,   716,  1790,   286,  5003,   523,   314,  1949,   284,\n",
              "            307,   277,  2143,   282, 50260,    40,  1101,   407,  1107,  1790,\n",
              "            319,  5003,   523,   314,  1949,   284,   307,   277,  2143,   282,\n",
              "             13, 50258,    72,  1101,  1790,   286,  5003,   523,  1312,  1949,\n",
              "            284,   307,   277,  2143,   282,    13, 50258,    72,  1101,   407,\n",
              "           1107,  1790,   286,  5003,    11,  1312,   655,  1949,   284,   307,\n",
              "             13, 50258,    72,  1101,   407,   326,  7026,    11,  1312,   655,\n",
              "           1949,   284,   307,    13, 50258,     7,    72,  1101,   407,  1107,\n",
              "            326,  7026,    11,  1312,   655,  1949,   284,   307,   737, 50258,\n",
              "              7,    72,  1101,   407,   326,  7026,    11,  1312,   655,  1949,\n",
              "            284,   307,    13, 50258,     7]]),\n",
              " tensor([[50257,  1135,   761,   284,  2962,   319,   262,  1109,   326,  2258,\n",
              "           4969,   338,  1262,   607,   757,   986,  2644, 10197,   996,   607,\n",
              "           5369,   468,   587,  7362,   284,   514,    13, 50260, 14157,  4969,\n",
              "            318,  1262,   607, 16317,   772,   996,   356,   760,   508,   673,\n",
              "            318, 16317,   783,    13, 50258,   732,   815, 20062, 16317,   319,\n",
              "            262,  1109, 16317,   326, 16317,   356,   760, 16317,   508, 16317,\n",
              "            673,   318, 16317,   783, 16317,    13, 50258,   732,  1276, 16317,\n",
              "           2962, 16317,   319, 16317,   262,  1109, 16317,   326, 16317,   356,\n",
              "          16317,   760, 16317,   508, 16317,   673,   318, 16317, 16317, 16317,\n",
              "          16317,   783, 16317,    13, 50258,   732, 16317,  1276, 16317,  2962,\n",
              "          16317,   319, 16317,   262,  1109]]),\n",
              " tensor([[50257,    40,   561,  2074,  4305,   683,   611,   339, 46701,   423,\n",
              "            257,   922,  7468, 50260,   361,   339, 46701,   423,   257,   922,\n",
              "          12226,    11,  1312,   561,  2666,   683,    13, 50258,   361,   339,\n",
              "          46701,   423,   257,   922, 12226,   986,  1312,   561,  2666,   683,\n",
              "             13, 50258,   361,   339, 46701,   423,   257,   922, 12226,   986,\n",
              "           1312,   561,  2666,   683,    13, 50258, 50258,   361,   339, 46701,\n",
              "            423,   257,   922, 12226,   986,  1312,   561,  2666,   683,    13,\n",
              "          50258,   361,   339, 46701,   423,   257,   922, 12226,   986,  1312,\n",
              "            561,  2666,   683,    13, 50258, 50258,   361,   339, 46701,   423,\n",
              "            257,   922, 12226,   986,  1312,   561,  2666,   683,    13, 50258,\n",
              "            361,   339, 46701,   423,   257]]),\n",
              " tensor([[50257,  6385,   345,  3730, 18240,   674, 23272,    11, 25991,   356,\n",
              "            714,  3292,   326,  3253,    87, 18240,    13, 50260,   732,   714,\n",
              "           3292,   262,  3253,    87,   326,   373,  9909,   329,   326,    13,\n",
              "          50258, 20777,   345,  1053,  9909,   674, 23272, 16317,  3863,   356,\n",
              "            714,  3292,   340,   329,   340,    13, 50258,   732,   460,  3292,\n",
              "            340,   329,   340, 16317,  1201,   345,  1053,  9909,   340, 16317,\n",
              "            329,   326,    11,   356,   714,  5163,   340,    13, 50258, 20777,\n",
              "            345,  1053,  9909,   340, 16317,   356,   460,   470,  5163,   340,\n",
              "          16317,   329,   326, 16317,   356,  1183,  5163,   340, 16317,   329,\n",
              "            326,   986, 50258,   732,   460,   470,  5163,   340, 16317,   329,\n",
              "            326, 16317,   780, 16317,   356]]),\n",
              " tensor([[50257,  1639,   821, 10589,  1234,  1566,   262,  5953,  2058,   736,\n",
              "             13, 50260,  5832,   821, 10589,   994,  1566,   262, 11561,  2058,\n",
              "            736,    13, 50258,  5832,   821,   994,   329,   262, 11561,   338,\n",
              "           1441,    13, 50258,  5832,   821,   994,   329,   262,   640,   852,\n",
              "          16317,  1566,   262, 11561,  2058,   736,    13, 50258,  5832,   821,\n",
              "            612, 16317,  1566,   262, 11561,  2058,   736,    13, 50258,  5832,\n",
              "            821,   612, 16317,  1566,   788, 16317,   345,   821,   994, 16317,\n",
              "            329,   262,   640,   852, 16317,    13, 50258,   986,  1566,   788,\n",
              "          16317,   345,   821,   612, 16317,   329,   262,   640,   852, 16317,\n",
              "             13, 50258,   986,   329,   326, 16317,   345,   821,   994, 16317,\n",
              "            329,   262,   640, 16317,    13]]),\n",
              " tensor([[50257,    40,   466,   407,   892,   314,   460,  2453,   326, 10794,\n",
              "           2158,    13, 50260,    72,   836,   470,   892,  1312,   460,  2453,\n",
              "            326, 10794,   996,    13, 50258,    72, 17666,   892,  1312,   460,\n",
              "           2453,   326, 10794,   996,    13, 50258,    72, 17666,   892,  1312,\n",
              "            460,  2453,   326, 10794,   996,    13, 50258,    72, 17666,   892,\n",
              "           1312,   460,  2453,   326, 10794,   996,    13, 50258,    72, 17666,\n",
              "            892,  1312,   460,  2453,   326, 10794,   996,    13, 50258, 50258,\n",
              "          50258,    72, 17666,   892,  1312,   460,  2453,   326, 10794,   996,\n",
              "             13, 50258, 50258,    72, 17666,   892,  1312,   460,  2453,   326,\n",
              "          10794,   996,    13, 50258, 50258, 50258, 50258,   986,  1312, 17666,\n",
              "            892,  1312,   460,  2453,   326]]),\n",
              " tensor([[50257,  1532,   314,   547,   345,    11,   314,   561,  1234,   257,\n",
              "           1256,   286,  1807,   290,  9110,   656,   428, 50260,    72,   561,\n",
              "           1234, 43158,   286,  1807,   290,  9110,   656,   428,    13, 50258,\n",
              "             72,   561,  2192,  1234, 43158,   286,  1807,   290,  9110,   656,\n",
              "            428,    13, 50258,    72,   561,  2192,  1234, 43158,   286,  1807,\n",
              "            290,  9110,   656,   428,    13, 50258,    72,   561,  2192,  1234,\n",
              "          43158,   286,  1807,   290,  9110,   656,   428,    13, 50258,   361,\n",
              "           1312,   547,   334,  1312,   561,  2192,   892,   546,   340, 43158,\n",
              "             13, 50258,   361,  1312,   547,   334,  1312,   561,  2192,   892,\n",
              "            546,   340, 43158,    13, 50258,   361,  1312,   547,   334,  1312,\n",
              "            561,  2192,   892,   546,   340]]),\n",
              " tensor([[50257,  1026,   550,   587,   257, 12922,  3297,   286,  9707,  1022,\n",
              "            606,   379,   717,    11,   878,   262,  7722,   550,  7891,  1165,\n",
              "           2089,   329, 14532,    13, 50260, 19052,   262,  7722,  2067,    11,\n",
              "            484,   547,   991, 29711,   546,   340,    11,   475,   340,   373,\n",
              "            257, 12922,  9707,    13, 50258,  9930,   547,   991, 29711,   546,\n",
              "            340,    11,   475,   340,   373,   257, 12922,  9707,    13, 50258,\n",
              "            270,   373,   257, 12922,  9707,    11,   475,   340,   373,   257,\n",
              "           9707,   986,   878,   340,   373,  1165,   881,    13, 50258,   270,\n",
              "            373,   257,  9707,   986,   878,   340,   373,  1165,   881,   986,\n",
              "          50258,   270,   373,   986,   340,   373,   986,   257,   986, 12922,\n",
              "            986,  9707,   986,   329,   986]]),\n",
              " tensor([[50257,  1639,   743,  8551,   517,  2952,   422, 14917,  1108,   351,\n",
              "            281, 16954,   286,   262, 17770, 14182,  1840,   416,  2130,   508,\n",
              "           4206,   703,   284,   779,   340,    13, 50260,  1525,   262,   779,\n",
              "            286,   257,  1048,   508,  4206,   703,   284,   779,   262, 17770,\n",
              "          14182,  1840,    11,   345,   460,  8551,   517,  2952,   287,   262,\n",
              "           8889,   286, 10510,    13, 50258,   259,   262,  1339,   286,   257,\n",
              "           1048,   508,  4206,   703,   284,   779,   340, 16317,   345,   460,\n",
              "           8551,   517,  2952, 16317,   287,   262,  1339,   286, 14917,  1108,\n",
              "             13, 50258,  1169,   779,   286,   257,  1048,   508,  4206,   703,\n",
              "          16317,   345,   460,  8551, 16317,   517,   986,   287,   262,  1339,\n",
              "          16317,   286,   257,  1048, 16317]]),\n",
              " tensor([[50257,    40,   892,   262,  5035, 13052,   561,   307,   442,  4668,\n",
              "            689,   611,   339, 10408, 42402, 50260,   361,   339, 10408, 42402,\n",
              "             11,  1312,   892,   442,  4668,   689,   561,   307,   262,   826,\n",
              "           3572,    13, 50258,    72,   892,   340,   561,   307,   442,  4668,\n",
              "            689,   611,   339, 10408, 42402,    13, 50258,   361,   339, 10408,\n",
              "          42402,    11,   788,  1312,   892,   326,   561,   307,   262,   826,\n",
              "           3572,    13, 50258, 50258,    72,   892,   523,   986,   611,   339,\n",
              "          10408, 42402,   986,   788,  1312,   892,   442,  4668,   689,   561,\n",
              "            307,   262,  1266,  3572,    13, 50258, 50258,    72,   892,   523,\n",
              "            986,   611,   339, 10408, 42402,   986,   788,   340,   561,   307,\n",
              "            442,  4668,   689,   986, 50258]]),\n",
              " tensor([[50257,  1532,   345,   588,  5701,    11,   788,   711,  4709,  1636,\n",
              "           1894,    11, 25911,    11,   393,  1223,  2092, 50260,   361,   334,\n",
              "            588,  5701,   711,   410,  1894,   393,   275,  1894,   393,  4232,\n",
              "             13, 50258,   361,   334,   588,  5701,   711,   410,  1894,   393,\n",
              "            275,  1894,   393,  4232,    13, 50258,   361,   334,   588,  5701,\n",
              "            711,   410,  1894,   393,   275,  1894,   393,  4232,    13, 50258,\n",
              "            361,   334,   588,  5701,   711,   410,  1894,   393,   275,  1894,\n",
              "            393,  4232,    13, 50258,   361,   334,   588,  5701,   711,   410,\n",
              "           1894,   393,   275,  1894,   393,  4232,    13, 50258,   361,   334,\n",
              "            588,  5701,   711,   410,  1894,   393,   275,  1894,   393,  4232,\n",
              "             13, 50258,   361,   334,   588]]),\n",
              " tensor([[50257, 16676,   326,  3809,   618,   345, 28077,   262,  8966,    30,\n",
              "          50260,  4598,   345,  3505,   262,  3809,   287,   262,  3072,    30,\n",
              "          50258,  4598,   345,  3505,   644,   339,   531,   618,   345,  1444,\n",
              "             30, 50258,  4598,   345,  3505,    30, 50258,  4598,   345,  3505,\n",
              "            644,   339,   531,   618,   345,  1444,    30, 50258, 38947,   683,\n",
              "             30, 50258,  4598,   345,  3505,    30, 50258,  4598,   345,  3505,\n",
              "             30, 50258,  4598,   345,  3505,    30, 50258,  4598,   345,    30,\n",
              "          50258,  4598,   345,  3505,    30, 50258,  4598,   345,    30, 50258,\n",
              "           4598,   345,    30,   986,  3505,    30,   986,   466,   345,    30,\n",
              "            986,  3505,    30,   986,  3505,    30,   986,  3505,    30,   986,\n",
              "          50258,  4598,   345,    30,   986]]),\n",
              " tensor([[50257,  9069, 20646,    12, 38077,   550,  2067,   284,  6531,   262,\n",
              "           1218,   262,  3072,  1625,   284,  1204,    13, 50260,  1169,  1218,\n",
              "            262,  3072, 28077,    11, 26249,    12, 38077,  2540,   284,  6531,\n",
              "             13, 50258,  1169,  1218,   262,  3072,   373,  5611, 16317,  9069,\n",
              "          20646,    12, 38077,  2540,   284,  6531,    13, 50258,  1169,  1218,\n",
              "            262,  3072, 28077, 16317,  9069, 20646,    12, 38077,  2067,   986,\n",
              "          50258,  1169,  1218, 16317,  1169,  1218, 16317,  1169,  1218, 16317,\n",
              "           2067, 16317,   351,   262,  3072,   338,  1204,    13, 50258, 50258,\n",
              "           1169,  1218, 16317,   262,  1218, 16317,  2540, 16317,   351,   262,\n",
              "           3072, 16317,    13, 50258,  1169,  1218, 16317, 16317, 16317,   351,\n",
              "            262,  1037, 16317,    11,   339]]),\n",
              " tensor([[50257, 44140,   351,   262, 31420,    11,   262,   481, 48484,   903,\n",
              "            340,   510, 50260,  9688,   351,   262, 31420,   986,   262,   481,\n",
              "          48484,   903,   340,   510,    13, 50258,  9688,   351,   262, 31420,\n",
              "            986,   262,   481, 48484,   903,   340,   510,   986, 50258,  9688,\n",
              "            351,   262, 31420,   986,   262,   481, 48484,   903,   340,   510,\n",
              "            986, 50258,  9688,   351,   262, 31420,   986,   262,   481, 48484,\n",
              "            903,   340,   510,   986, 50258,  9688,   351,   262, 31420,   986,\n",
              "            262,   481, 48484,   903,   340,   510,   986, 50258,  9688,   351,\n",
              "            262, 31420,   986,   262,   481, 48484,   903,   340,   510,   986,\n",
              "          50258,  9688,   351,   262, 31420,   986,   262,   481, 48484,   903,\n",
              "            340,   510,   986, 50258,  9688]]),\n",
              " tensor([[50257,    40,  4398,   470,  3750, 22498,  1201,   986,   880,    11,\n",
              "            262,   938,   640,   616,  4490,  8957,  1718,   502,    13, 50260,\n",
              "           4053,   986,  1201,   616, 17695,  1718,   502,   986,   314,  4398,\n",
              "            470,   587, 22498,    13, 50258, 20777,   788, 16317,   314,  4398,\n",
              "            470,   587, 22498, 16317,  1683,    13, 50258,  4053, 16317,  1201,\n",
              "          16317,   326,   986,   616, 17695,   986,  1718,   502, 16317,   329,\n",
              "            257,   981, 16317,   314,  1422,   470,   467, 22498,    13, 50258,\n",
              "          20777,   788, 16317,   314,  1053,   407,   587, 16317, 22498, 16317,\n",
              "           1683,    13, 50258,  4053, 16317,   326, 16317,   314,   986,  1422,\n",
              "            470,   986,   467, 16317,   284,  1413, 16317,  1201, 16317,   326,\n",
              "          16317,    13, 50258, 20777, 16317]]),\n",
              " tensor([[50257,    40,   460,   407,  3505,   262,   717,  1573,   475,   262,\n",
              "           1218,  1573,   373,  4753,  2910, 50260,    72,   460,   470,  3505,\n",
              "            262,   717,  1573,    11,   475,   262,  1218,   373,  4753,  2910,\n",
              "             13, 50258,    72, 18548,  3505,   262,   717,  1573, 16317,  1169,\n",
              "           1218,   530,   373,  4753,  2910,    13, 50258,    72, 18548,  3505,\n",
              "            262,   717,  1573, 16317,  1169,  1218,   530,   373,  2730,  1286,\n",
              "            257,  2910,    12,  5363,   530,    13, 50258,    72, 18548,  3505,\n",
              "          16317, 12758,    11,   262,   352,   301,   530,   373,  2730,  1286,\n",
              "            257,  2910,    12,  5363,   530,   986, 50258, 12758, 16317,  1169,\n",
              "            362,   358,   530,   373,  2730,  1286,   986, 50258, 12758, 16317,\n",
              "           1169,   352,   301,   530,   373]]),\n",
              " tensor([[50257,    40,   423, 13075, 16105,   319,   257,   220, 32381,  1700,\n",
              "          50260, 43462, 16105,   319,   257, 32381,  1700,   986, 50258,    72,\n",
              "            423, 13075, 16105,   319,   257, 32381,  1700,   986, 50258,    73,\n",
              "           6996,   302,   276,    88,   986,   319,   257, 32381,  1700,   986,\n",
              "          50258,    73,  6996,   302,   276,    88,   986,   319,   257, 32381,\n",
              "           1700,   986, 50258,    73,  6996,   302,   276,    88,   986,   319,\n",
              "            257, 32381,  1700,   986, 50258,    73,  6996,   302,   276,    88,\n",
              "            986,   319,   257, 32381,  1700,   986, 50258,    73,  6996,   302,\n",
              "            276,    88,   986,   319,   257, 32381,  1700,   986, 50258,    73,\n",
              "           6996,   302,   276,    88,   986,   319,   257, 32381,  1700,   986,\n",
              "          50258,    73,  6996,   302,   276]]),\n",
              " tensor([[50257,  5248,   461,   656,   994,    13,  9340,   262,  4936,   866,\n",
              "             13, 12167,   656,   994,    13, 50260,  2946,   262,  4936,   290,\n",
              "           2740,    13, 50258,  2946,   262,  4936,   290,  2740,    13, 50258,\n",
              "           2946,   262,  4936,   290,  1745,   340,    13, 50258,  2946,   262,\n",
              "           4936,   290,  2740,    13, 50258,  2946,   340,   290,   523,   319,\n",
              "             13, 50258,  2946,   340,   290,   523,   319,    13, 50258,  2946,\n",
              "            340, 16317,   523, 16317,   329,   783, 16317,  1309,   338,  1561,\n",
              "             13, 50258,  2946,   340, 16317,   290, 16317,   329,   783, 16317,\n",
              "           1309,   338,  1561,    13, 50258,  2946,   340, 16317,   290, 16317,\n",
              "            329,   783, 16317,  1309,   338,  1561,    13, 50258,  2946,   340,\n",
              "          16317,   290, 16317,   329,   783]]),\n",
              " tensor([[50257,  1212,  3516, 20393,  9669,    11, 11783,    11,  9061,    11,\n",
              "            290,  2647, 50260,    33, 14575,    11, 15872,    11, 22476,   364,\n",
              "          16317,   290,  7849, 16317,  3966, 10194,    11,   290,   428,  3516,\n",
              "           7832,   284,   711,  9669,    11, 11783,    11,   290,  2647,    13,\n",
              "          50258,  1212,  3516,  7832,  9669,    11, 11783,    11,  9061, 16317,\n",
              "            290,  2647, 16317,   575,   929, 16317,   392,   326,   338,   655,\n",
              "            329, 19896,    13, 50258,    33,    14,    66,   986, 35634,  2189,\n",
              "          16317,   392,   329, 19896, 16317,   428,  3516,  7832,   284,   711,\n",
              "            986,  9669, 16317,   290,   329, 19896, 16317,   339,  7832,   284,\n",
              "            711, 16317, 11783, 16317,   290,   329, 19896, 16317,   339,  7832,\n",
              "            284,   711, 16317,  2647, 16317]]),\n",
              " tensor([[50257,  2949,    11,   339,   373,  6974, 29711,    11,   257,   835,\n",
              "            286,  5149, 48352,   284,  2239,  1497,   290,  2000,   465,  1839,\n",
              "           1597, 50260,  3919,   986,   339,   373,   655, 26471,   986,    64,\n",
              "            835,   286,  5149, 21081,   494,   284,  2239,  1497,   290,  2000,\n",
              "            465,  1597,    13, 50258,  3919,   986,   339,   373,   655, 26471,\n",
              "            986,    64,   835,   286,  5149, 21081,   494,   284,  2239,  1497,\n",
              "            290,  2000,   465,  1597,    13, 50258,  3919,   986,   339,   373,\n",
              "            655, 26471,   986,    64,   835,   286,  5149, 21081,   494,   284,\n",
              "           2239,  1497,   290,  2000,   465,  1597,    13, 50258,  3919,   986,\n",
              "            339,   373,   655, 26471,   986,    64,   835,   286,  5149, 21081,\n",
              "            494,   284,  2239,  1497,   290]]),\n",
              " tensor([[50257,  1544,   338,  1016,   284,  2277,   546,   257,   734,  6953,\n",
              "             11,   314,   892,    13, 50260,   258,   373,  1016,   284,   466,\n",
              "            257,   734,  6953,    11,   314,  4724,    13, 50258,   258,   373,\n",
              "           1016,   284,   466,   340, 16317,   362,  6953,   986, 50258,   258,\n",
              "            373,   986,   339,   373,   986,   362,  6953,   986, 50258,   258,\n",
              "            373,   986,   362,  6953,   986, 50258,   258,   373,   986,   362,\n",
              "           6953,   986, 50258,   258,   373,   986,   362,  6953,   986, 50258,\n",
              "            258,   373,   986,   362,  6953,   986, 50258,   258,   373,   986,\n",
              "            362,  6953,   986, 50258,   258,   373,   986,   362,  6953,   986,\n",
              "          50258,   258,   373,   986,   362,  6953,   986, 50258,   258,   373,\n",
              "            986,   362,  6953,   986, 50258]]),\n",
              " tensor([[50257,  1026,   373,   465,  2126,   284,  1057,   262, 20842,    11,\n",
              "           2492,   470,   340,    30, 50260,   258,  1422,   470,   765,   284,\n",
              "           1057,   262, 20842,    11,   750,   339,    30, 50258,   258,   338,\n",
              "           1760,   340,    11,  2125,   470,   339,    30, 50258,   258,   750,\n",
              "            340,   780,   339,  2227,   284,   466,   340,    11,   826,    30,\n",
              "          50258,   258,   750,   340,   780,   339,  2227,   284,    11,   826,\n",
              "             30, 50258,   258,   750,   340,   780,   339,   373,  1804,   340,\n",
              "             11,   826,    30, 50258,   258,   750,   340,   780,   339,   373,\n",
              "           1804,   340, 16317,   826,    30, 50258,   258,   750,   340, 16317,\n",
              "            826, 16317,    30, 50258,   258,   750,   340, 16317,    30,   986,\n",
              "          50258,   258,   750,   340, 16317]]),\n",
              " tensor([[50257, 29531, 30287,   290, 41973,   815,   307,  5281,   503,   416,\n",
              "            262,  2351, 25186, 11416,   284,   766,   326,  5423,   389,   852,\n",
              "           9456,    13, 50260,  1169,  2260, 22548,  4934,   815,  3283,   503,\n",
              "           4738,  8794,   290, 41973,   284,  4155,   326,   262,  5423,   389,\n",
              "            852,  9456,    13, 50258,  1640,   326,  1738,    11,   262,  2260,\n",
              "          22548,  4934,   815,  3283,   503,  4738, 30287,   290, 41973,    13,\n",
              "          50258, 50258, 50258,  1462,   326,   886, 16317,   340,   318,  3306,\n",
              "          16317,   284,  4155,   326,   262,  5423,   389,  9456, 16317,    11,\n",
              "            340,   318,  3306, 16317,   284,  3283,   503,  4738, 30287,   290,\n",
              "          41973,    13, 50258, 50258,    11,   287,   428,  2565, 16317,    11,\n",
              "            484,   815,   307,  5281,   503]]),\n",
              " tensor([[50257,   940, 16059,  2861,   286,  1605, 12088,   290, 12088,    13,\n",
              "          50260,     3,   940, 16059,   329, 13632,   290, 13632,    13, 50258,\n",
              "              3,   940, 16059,   329, 13632,   290, 13632,    13, 50258,     3,\n",
              "            940, 16059,   329, 13632,   290, 13632,    13, 50258,     3,   940,\n",
              "            269, 10277,   326,   338,   644,   314,  1392,    13, 50258,     3,\n",
              "            940,   269, 10277,   326,   338,   644,   314,  1392,    13, 50258,\n",
              "              3,   940,   269, 10277,   326,   338,   644,   314,  1392,    13,\n",
              "          50258,     3,   940,   269, 10277,   326,   338,   644,   314,  1392,\n",
              "             13, 50258,     3,   940,   269, 10277,   326,   338,   644,   314,\n",
              "           1392,    13, 50258,     3,   940,   269, 10277,   326,   338,   644,\n",
              "            314,  1392,    13, 50258,     3]]),\n",
              " tensor([[50257,  1026,   481,  4219, 23059,  9021,   611,  3306,    13, 50260,\n",
              "            361,  3306,    11,   262, 23059,  8771,  2236,   307,  5611,    13,\n",
              "          50258,   361,   523,    11,   484,  2236,  3283,   503,   262,  8771,\n",
              "             11,   340,  2236,   307,  1760,    13, 50258,  1169,  8771,  2236,\n",
              "            307,  5281,   503,    11,   611,  3306,    11,   329,   262,  4007,\n",
              "            286, 23059,    13, 50258,  1640,   326,  1738,    11,   262,  8771,\n",
              "           2236,   307,  5611,    13, 50258,  1169,  8771,  2236,   307,  5281,\n",
              "            503,    11,   611,  3306,    11,   287,  1339,   286, 23059,    13,\n",
              "          50258,  1169,  8771,   318,  4361,  3306,    11,   340,   318,  3306,\n",
              "             13, 50258,   270,   318,  4361,  3306,    11,   329,   326,  1738,\n",
              "             11,   329,   262,  4007,    11]]),\n",
              " tensor([[50257,  2949,    11, 15967,    11,   612,   318,   407,   835,   484,\n",
              "            389,  4642,   351,  1263,  2951, 50260,  3919, 16317,  8117,   318,\n",
              "            645,   835, 16317,  9930,   389,  4642,   351,  1263,  2951,    13,\n",
              "          50258,  3919, 16317,  9930,   389,   407,  4642,   351,  1263,  2951,\n",
              "             13, 50258, 50258,  3919, 16317,   484,   389,   407,  4642,   351,\n",
              "           1263,  2951,    13, 50258, 50258,  3919, 16317,   484,   389,   407,\n",
              "           4642,   351,  1263,  2951,    13, 50258, 50258, 50258,  3919, 16317,\n",
              "            484,   389,   407, 16317,   351,  1263,  2951,    13, 50258, 50258,\n",
              "          50258, 50258, 50258,  3919, 16317,   484,   389,   407, 16317,   351,\n",
              "           1263,  2951,    13, 50258, 50258, 50258,  3919, 16317,   484,   389,\n",
              "            407, 16317,   351,  1263,  2951]]),\n",
              " tensor([[50257,  3152,  1395, 11146,   604,    13,    15,    13,    18,   290,\n",
              "            299,    85,    13,    78,   612,   318,   257,  5434,  7186,   287,\n",
              "           6283,  7577,    13, 50260,  1169,  3124,   286,   262,  1395, 11146,\n",
              "            604,    13,    15,    13,    18,   290,   299,    85,    13,    78,\n",
              "            318,  2642,    13, 50258,  1169,  7577,   286,  1395, 11146,   604,\n",
              "             13,    15,    13,    18,   290,   299,    85,    13,    78,   389,\n",
              "           2642,    13, 50258,  8117,   318,   257,  1917,   351,  1395, 11146,\n",
              "            604,    13,    15,    13,    18,   290,   299,    85,    13,    78,\n",
              "             13, 50258,  1169,  3124,   286,  1395, 11146,   604,    13,    15,\n",
              "             13,    18,   290,   299,    85,    13,    78,   318,  2642,    13,\n",
              "          50258, 50258,  1169,  7577,   286]]),\n",
              " tensor([[50257,  2202,   262, 11920,    11,   345,  1183,   307,  5399,   416,\n",
              "            257,   649,  8539,   805,    13, 50260,    64,   649,  8539,   805,\n",
              "            481,  4654,   262, 11920,    13, 50258,  5832,  1183,   635,   423,\n",
              "            257,   649,  8539,   805, 15500,   262,  6215,    13, 50258,    64,\n",
              "            649,  2888,   481,  4654,   345,   287,   262,  6215,    13, 50258,\n",
              "           5832,  1183,   307,  5399,   416,   257,   649,  2888,    13, 50258,\n",
              "             64,   649,  2888,   481,  4654,   345,   319,   262,  6215,    13,\n",
              "          50258,    64,   649,  2888,   481,   635,  4654,   345,    13, 50258,\n",
              "             64,   649,  2888,   318,  9679,   345,    13, 50258,    64,   649,\n",
              "           2888,   318,   635,   319,   262,  6614,    13, 50258,    64,   649,\n",
              "           2888,   318,   612,    13, 50258]]),\n",
              " tensor([[50257,  2504,   373,  7650,   345,   815,   655,  1561,   284,   683,\n",
              "          50260,  2504,   373,  7650,   334,   815,   655,  1561,   284,   683,\n",
              "             13, 50258,  5562,   373,  7650,   334,   815,   655,  1561,   284,\n",
              "            683,    13, 50258,  5562,   373,  7650,   334,   815,   655,  1561,\n",
              "            284,   683,    13, 50258,  5562,   373,  7650,   334,   815,   655,\n",
              "           1561,   284,   683,    13, 50258,  5562,   373,  7650,    11,   334,\n",
              "            815,   655,  1561,   284,   683,    13, 50258,  5562,   373,  7650,\n",
              "             11,   334,   815,   655,  1561,   284,   683,    13, 50258,  5562,\n",
              "            373,  7650,    11,   334,   815,   655,  1561,   284,   683,    13,\n",
              "          50258,   400,  1381,  7650,    11,   334,   815,   655,  1561,   284,\n",
              "            683,    13, 50258,   400,  1381]]),\n",
              " tensor([[50257,  2504,   318,  8258,   780,   616,  3656,   318,  1719,   262,\n",
              "            976,  1917, 50260,   400,  1381,  8258,   763,    89,   616,  3656,\n",
              "            318,  1719,   262,   976,  1917,    13, 50258, 50258,   400,  1381,\n",
              "           8258,   763,    89,   616,  3656,   318,  1719,   262,   976,  1917,\n",
              "            986, 50258, 47288,   986,   616,  3656,   318,   986,   387,   387,\n",
              "            387,   387,   387,    13, 50258, 50258,  3099,   387,   986,   616,\n",
              "           3656,   318,   986,   387,   387,   387,   986, 19462,   986, 50258,\n",
              "          50258,  3099,   387,   986,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,    42,   385,   403, 18228, 11418,   329,   262, 10851,   379,\n",
              "          18632,    13,    56,  3768,  2879,  7844,  1134,  8126,   329,   262,\n",
              "          36298, 10851,    13, 50260,    42,   385,   403,   482,   952,  8350,\n",
              "            329,   262, 10851,   379, 18632,    13,   575,  3768,  2879,   290,\n",
              "            329,   262, 36298, 10851,    13, 50258,   986,   379, 18632,    13,\n",
              "            575,  3768,  2879, 16317,   329,   262, 36298, 10851, 16317,   509,\n",
              "          10277,   403,   482,   952,  8350, 16317,   329,   262, 11060, 16317,\n",
              "            286,   262, 10851,    13, 50258, 16317,   379,   326,   986, 16317,\n",
              "            339,  8350, 16317,   329,   262, 11060, 16317, 16317,   286,   262,\n",
              "          10851, 16317,    13, 50258, 16317,   379,   326, 16317, 16317, 16317,\n",
              "          16317,   339,  8350, 16317,   329]]),\n",
              " tensor([[50257,  1639,   815,   466,  3511,   257,  2661,   290,  4043, 50260,\n",
              "           5211,  3511,   257,  2661,   290,  4043,    13, 50258,  5211,  3511,\n",
              "            257,  2661,   290,  4043,    13, 50258,  5703,   466,  3511,   257,\n",
              "           2661,   290,   655,  4043,    13, 50258,  5703,   466,  3511,   257,\n",
              "           2661,   290,   655,  4043,    13, 50258,    35,   756,   307,  2739,\n",
              "             11, 17666,   307,  2739,    11, 17666,   307,  2739,    11, 17666,\n",
              "            307,  2739,   986, 50258,    35,   756,   307,  2739,    11, 17666,\n",
              "            307,  2739,   986, 50258,  5703,   466,  3511,   257,  2661,   290,\n",
              "            655,  4043,    13, 50258, 50258,    35,   756,   307,  2739,   986,\n",
              "          17666,   307,  2739,   986, 17666,   307,  2739,   986, 17666,   307,\n",
              "           2739,   986, 50258,    35,   756]]),\n",
              " tensor([[50257, 13436,   605,  3777,   547,  6007,   286,  1804,  1997,    11,\n",
              "            262, 44625,   550,  2982,    13, 50260,  1169, 44625,  2982,   262,\n",
              "          10883,  3777,   714,   466,  1997,    13, 50258,  1169, 44625,  2993,\n",
              "            326,   262,  5536,  3777,   714,   466,  1997,    13, 50258,  1169,\n",
              "          44625,  2982,   326,   484,   714,   466,  1997,   351,   606,    13,\n",
              "          50258,  1169, 44625,  2993,   326,   484,   714,   466,  1997,   351,\n",
              "            606,    13, 50258,  1169,  5536,  3777,   714,   466,  1997, 16317,\n",
              "          50258,  1169, 44625,  2993, 16317,   326,   484,   714,   466,   340,\n",
              "          16317,   329,  1672, 16317,   329,   262, 11060,   286,   262, 46220,\n",
              "             13, 50258, 50258, 50258,  1169, 44625,  2993, 16317,   326, 16317,\n",
              "            339,  2982, 16317,   326, 16317]]),\n",
              " tensor([[50257,    40,   466,   407,   760,   810,   345,   460,  1570,   340,\n",
              "             11,  4556,   345,  5001,   340,   287,   569,  7998,  5794,  7382,\n",
              "          50260,    72,   836,   470,   760,   810,   345,   460,   766,   340,\n",
              "            986,  4556,   345,  2822,   340,   287,   569,  7998,   986, 50258,\n",
              "             72,   836,   470,   760,   810,   345,   460,   766,   340,   986,\n",
              "           4556,   345,  2822,   340,   287,   569,  7998,   986, 50258,    72,\n",
              "            836,   470,   760,   810,   345,   460,   766,   340,   986,  4556,\n",
              "            345,  2822,   340,   287,   569,  7998,   986, 50258,    72,   836,\n",
              "            470,   760,   986,   810,   460,  1312,   766,   340,   986, 50258,\n",
              "             72,   836,   470,   760,   986,   810,   460,  1312,   766,   340,\n",
              "            986, 50258,    72,   836,   470]]),\n",
              " tensor([[50257, 24795,   468,  1683,  1775,   523,  3772,   257, 35889,    12,\n",
              "          28816,     0, 50260,  3919,   530,  2497,   884,   257,  3772, 34792,\n",
              "             13, 50258,  3919,   530,   373,  3772,   546,   262, 35889,    13,\n",
              "          50258,  3919,   530,   373,  3772,   546,   262, 34792,    13, 50258,\n",
              "           3919,   530,   373,  3772,   546,   340,    13, 50258,  3919,   530,\n",
              "            373,  3772,   546,   340,    13, 50258,  3919,   530,   373,  3772,\n",
              "            546,   340,    13, 50258,  3919,   530,   373,  3772,   546,   340,\n",
              "             13, 50258,  3919,   530,   373,  3772,    13, 50258,  3919,   530,\n",
              "            373,  3772,   546,   340,    13, 50258,  3919,   530,   373,  3772,\n",
              "             13, 50258,  3919,   530,   373,    13, 50258,  3919,   530,   373,\n",
              "             13, 50258,  3919,   530,   373]]),\n",
              " tensor([[50257, 49488,   743,   407,  2152, 50260,  9930,   836,   470,   760,\n",
              "            644,  9439,   481,   307,    13, 50258,   732,   836,   470,   760,\n",
              "            644,  9439,   481,   307,    13, 50258,  9930,   836,   470,   760,\n",
              "            644,  9439,   481,   307,    13, 50258,   732,   836,   470,   760,\n",
              "            644,  9439,   481,   307,    13, 50258,   732,   836,   470,   760,\n",
              "            644,   340,   481,   307,    13, 50258,   732,   836,   470,   760,\n",
              "            644,   340,   318,    13, 50258,   732,   836,   470,   760,   644,\n",
              "            340,   338,   546,    13, 50258,   732,   836,   470,   760,   644,\n",
              "            340,   318,    13, 50258,   732,   836,   470,   760,   644,   340,\n",
              "            318,    13, 50258,   732,   836,   470,   760,   644,   340,   338,\n",
              "            546,    13, 50258,   732,   836]]),\n",
              " tensor([[50257,  2061,   561,   345,   466,   611,   345,   750,   923, 10691,\n",
              "          50260, 10919,   561,   345,   466,   611,   345,   750,   923, 10691,\n",
              "             13, 50258,  2061,   561,   345,   466,   611,   345,   750,   923,\n",
              "          10691,    30, 50258,  2061,   561,   345,   466,   611,   345,   750,\n",
              "            923, 10691,    30, 50258,  2061,   561,   345,   466,   611,   345,\n",
              "            750,   923, 10691,    30, 50258,  2061,   561,   345,   466,   611,\n",
              "            345,   750,   923, 10691,    30, 50258,  2061,   561,   345,   466,\n",
              "            611,   345,   750,   923, 10691,    30, 50258, 10919,   561,   345,\n",
              "            466,   611,   345,   750,   923, 10691,    30, 50258, 10919,   561,\n",
              "            345,   466,   611,   345,   750,   923, 10691,    30, 50258, 10919,\n",
              "            561,   345,   466,   611,   345]]),\n",
              " tensor([[50257, 15468,    11,   345,   743,  2652,  1327,   329,  1165,   890,\n",
              "          50260, 29810, 16317,   345,   743,  2652,  1165,   890,    13, 50258,\n",
              "          29810, 16317,   345,   743,  2652,  1165,   890,    13, 50258, 29810,\n",
              "          16317,   345,   743,  2652,  1165,   890,    13, 50258, 29810, 16317,\n",
              "            345,   743,  2652,  1165,   890,    13, 50258, 29810, 16317,   345,\n",
              "            743,  2652,  1165,   890,    13, 50258, 29810, 16317,   345,   743,\n",
              "           2652,  1165,   890,    13, 50258, 29810, 16317,   345,   743,  2652,\n",
              "           1165,   890,    13, 50258, 29810, 16317,   345,   743,  2652,  1165,\n",
              "            890,    13, 50258, 29810, 16317,   345,   743,  2652,  1165,   890,\n",
              "             13, 50258, 29810, 16317,   345,   743,  2652,  1165,   890,    13,\n",
              "          50258, 29810, 16317,   345,   743]]),\n",
              " tensor([[50257,    32,   321,   343,  5311,   504,  3956,   318,   376, 15152,\n",
              "            282, 11356,    11,   475,   339,   318,   407,   326,  5863,   780,\n",
              "            339,   318,   407,   257,   845, 12356,  8674, 50260,    64,   321,\n",
              "            343,   479,  7637,   318,   257, 16933,   286,   277, 15152,   282,\n",
              "            479,  7637,   475,   339,   318,   407,   326,  5863,   986,   780,\n",
              "            339,   318,   407,   257,   845, 12356,  8674,    13, 50258,   282,\n",
              "           3506,   986,   257,   321,   343,   479,  7637,   318,   257, 16933,\n",
              "            986,   475,   339,   318,   407,   326,  5863,   986,   339,   318,\n",
              "            407,   257,   845, 12356,  8674,    13, 50258,  1847, 15821,   986,\n",
              "            257,   321,   343,   479,  7637,   986,   339,   318,   407,   326,\n",
              "           5863,   986,   339,   318,   407]]),\n",
              " tensor([[50257, 35596,   910, 29294,  3734,    11,   340,   373,   257, 16498,\n",
              "            287,   597,  1339, 50260, 14323,  2145,   910, 29294,  3734, 16317,\n",
              "            340,   373,   257, 16498,   287,   597,  1339,    13, 50258, 14323,\n",
              "           2145,   910, 29294,  3734, 16317,   340,   373,   257, 16498,   287,\n",
              "            597,  1339,    13, 50258, 14323,  2145,   910, 29294,  3734, 16317,\n",
              "            340,   373,   257, 16498,   287,   597,  1339,    13, 50258, 14323,\n",
              "           2145,   910, 29294,  3734, 16317,   340,   373,   257, 16498,   287,\n",
              "            597,  1339,    13, 50258, 14323,  2145,   910, 29294,  3734, 16317,\n",
              "            340,   373,   257, 16498,   287,   597,  1339,    13, 50258, 14323,\n",
              "           2145,   910, 29294,  3734, 16317,   340,   373,   257, 16498,   287,\n",
              "            597,  1339,    13, 50258, 14323]]),\n",
              " tensor([[50257,  2504,  1948,  4732,  1276,   407,   307, 11564,   618,   340,\n",
              "           2058,   284, 35391,   326,  3188,    13, 50260,  1169, 10794,   286,\n",
              "            428,  3188,  1276,   407,   307, 11564,   287,   428,  4732,    13,\n",
              "          50258,  1169, 10794,   286,   428,  3188,   318,  4361,   407,  1744,\n",
              "            287,   428,  4732,    13, 50258,  5661,  4732,   318,  4361,   407,\n",
              "          11564,   287,   428,  2461,    13, 50258,   732,  1276,  4361,   407,\n",
              "           6044,   326,  1109,    13, 50258,  5661,  1109,   318,  4361,   407,\n",
              "          11564,   287,   428,  4732,    13, 50258,   732,  1276,  4361,   407,\n",
              "           6044,   340,    13, 50258,   732,  1276,  4361,   407,  6044,   340,\n",
              "          16317,   329,   326,  1738,   986,   356,  1276,   407,  6044,   340,\n",
              "          16317,   329,   326,  1738,   986]]),\n",
              " tensor([[50257, 12050,  1223,  2081,   503,   286,   477,   286,   428, 50260,\n",
              "          15883,  1223,   510,   503,   286,   340,    13, 50258, 15883,  1223,\n",
              "            510,   503,   286,   340,    13, 50258, 15883,  1223,   510,   503,\n",
              "            286,   340,    13, 50258, 15883,  1223,   510,   503,   286,   340,\n",
              "             13, 50258, 15883,  1223,   510,   503,   286,   340,    13, 50258,\n",
              "          15883,   340,   510,   986, 50258, 15883,   340,   510,   986, 50258,\n",
              "          15883,   340,   510,   986,   796,     8, 50258,   796,     8,   796,\n",
              "              8,   796,     8,   796,     8,   796,     8,   796,     8,   796,\n",
              "              8,   796,     8,   796,     8,   796,     8,   796,     8,   796,\n",
              "              8,   796,     8,   796,     8,   796,     8,   796,     8,   796,\n",
              "              8,   796,     8,   796,     8]]),\n",
              " tensor([[50257,  3856, 16425,   290, 10176,   617,  3235, 44126,  1320,   318,\n",
              "            644,  1466,    11,   393,   379,  1551,   749,  1466,    11,   588,\n",
              "           2102,    11, 20976,   318,   852, 16425, 50260,  1350,  3511,    11,\n",
              "            905,   617,  3235, 44126,   986,   326,   338,   644,  1466,   588,\n",
              "            986, 50258,   265,  1551,   749,  1466,   986,   379,  1551,   749,\n",
              "           1466,   986,   326,   338,   644,   484,   588,    13, 50258,  1350,\n",
              "           3511,   986,   905,   617,  3235, 44126,   986,   326,   338,   644,\n",
              "            484,   588,   986, 50258,   265,  1551,   986,   326,   338,   644,\n",
              "            484,   588,   986,   379,  1551,   986,   326,   338,   644,   484,\n",
              "            588,   986,   379,  1551,   986,   326,   338,   644,   484,   588,\n",
              "            986, 50258, 50258,   986,   379]]),\n",
              " tensor([[50257,    40,   892,  2039,  7295,  2058,   351,   922,  6918, 50260,\n",
              "             72,   892,  4755,   318,   922,  6918,    11,   475,  2039,  7295,\n",
              "            318,   922,  1165,    13, 50258,    72,   892,  4755,   318,   922,\n",
              "            475,   551,  7295,   318,   922,  1165,    13, 50258,    72,   892,\n",
              "           4755,   318,   922,    11,   475,   551,  7295,   318,   922,   986,\n",
              "          50258,    72,   892,  4755,   318,   922,    11,   475,  1312,   892,\n",
              "           4755,   318,   922,   986, 50258,    72,   892,  4755,   318,   922,\n",
              "             11,   475,   551,  7295,   318,   922,   986, 50258,    72,   892,\n",
              "            523,   986, 10194,   986,  4755,   318,   922,   986, 10194,   986,\n",
              "            796,     8, 50258,    72,   892,   523,   986, 10194,   986,   796,\n",
              "              8, 50258,    72,   892,  4755]]),\n",
              " tensor([[50257,    40,   892,   340,   318,  1049, 50260,    72,   892,   340,\n",
              "            318,  1049,    13, 50258,    72,   892,   663,  1049,    13, 50258,\n",
              "             72,   892,   663,  1049,    13, 50258,    72,   892,   663,  1049,\n",
              "             13, 50258,    72,   892,   663,  1049,    13, 50258,    72,   892,\n",
              "            663,  1049,    13, 50258,    72,   892,   663,  1049,    13, 50258,\n",
              "             72,   892,   663,  1049,    13, 50258,    72,   892,   663,  1049,\n",
              "             13, 50258,    72,   892,   663,  1049,    13, 50258,    72,   892,\n",
              "            663,  1049,    13, 50258,    72,   892,   663,  1049,    13, 50258,\n",
              "             72,   892,   663,  1049,    13, 50258,    72,   892,   663,  1049,\n",
              "             13, 50258,    72,   892,   663,  1049,    13, 50258,    72,   892,\n",
              "            663,  1049,    13, 50258,    72]]),\n",
              " tensor([[50257,     1, 24795,   475,   262, 12746,   423,   587,   994,   326,\n",
              "            890,   526, 50260,     1,  3919,   530,  2073,   468,   587,   994,\n",
              "            329,   523,   890,   526, 50258,     1,  3919,   530,   373,   994,\n",
              "            329,  1165,   890,   526, 50258,   986,  3919,   530,   373,   612,\n",
              "            986,   329,   523,   890,   986, 50258,   986,  3919,   530,   373,\n",
              "            612,   986,   329,   523,   890,   986, 50258,   986,  3919,   530,\n",
              "            373,   612,   986,   329,   523,   890,   986, 50258,   986,  3919,\n",
              "            986,   645,   986,   329,   326,   986, 50258,   986,   329,   326,\n",
              "            986,   329,   326,   986, 50258,   986,   329,   326,   986, 50258,\n",
              "            986,   329,   326,   986, 50258,   986,   329,   326,   986, 50258,\n",
              "            986,   329,   326,   986, 50258]]),\n",
              " tensor([[50257,  1212,   318,   780,   534,  2802,   314,   373,   287,   262,\n",
              "          19612,    13, 50260,   270,   338,   780,   314,   373,   287,   262,\n",
              "          19612,   351,   534,  2802,    13, 50258,   270,   373,   780,   314,\n",
              "            373,   351,   534,  2802,   287,   262, 19612,    13, 50258,   270,\n",
              "            373,   780,   314,   373,   351,   534,  2802,   287,   262, 19612,\n",
              "             13, 50258, 50258,   270,   373,   780,   314,   373,   351,   607,\n",
              "            287,   262, 19612,    13, 50258, 50258,   270,   373,   780,   314,\n",
              "            373,   351,   607, 16317,   287,   262, 19612, 16317, 50258, 50258,\n",
              "            270,   373, 16317,   780, 16317,  1312,   373, 16317,   351, 16317,\n",
              "            607, 16317,   287,   262, 19612, 16317, 50258, 50258, 50258,    72,\n",
              "            373, 16317,   351, 16317,   607]]),\n",
              " tensor([[50257,    40,  1975,   262, 28527,   318,   220,   812,  1468,    11,\n",
              "            475,   345,   481,   765,   284, 11767,   351,   584,  4237, 50260,\n",
              "             72,   892,   663,   546,  2479,    11,   475,   334,   460,  1949,\n",
              "            284,  1265,   584,   661,   508,   389,  1088,    13, 50258,    72,\n",
              "            892,   663,   546,  2479,   986,   475,   334, 17753,  1265,   584,\n",
              "            279,   489,   508,   389,  1088,    13, 50258,    72,   892,   663,\n",
              "            546,  2479,   986,   475,   334, 17753,  1265,   584,   279,   489,\n",
              "            508,   389,  1088,    13, 50258,    72,   892,   663,   546,  2479,\n",
              "            986,   475,   334, 17753,  1265,   584,   279,   489,   508,   389,\n",
              "           1088,    13, 50258,    72,   892,   663,   546,  2479,   986,   475,\n",
              "            334, 17753,  1265,   584,   279]]),\n",
              " tensor([[50257, 24893,  9353,    11,  3478, 23932,    13, 22381,  3840,   284,\n",
              "           4656,    13, 50260,  1452,  9353,   986,  1452, 23932,   986,  8208,\n",
              "           3840,   284,  4656,   986, 50258,  1452,  9353,   986,  1452, 23932,\n",
              "            986,  8208,  3840,   986, 50258,   986,  1452,   986,  1452,   986,\n",
              "           1452,   986,  8208,   986,  3840,   986,   220,   986,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220]]),\n",
              " tensor([[50257,  5246,    13,  4986,   986,  2644,   361,   612,   547,   281,\n",
              "          17226,  1175,    11,    37,   268, 16239,   561,   307,  6572,    13,\n",
              "          50260,   361,   612,   373,   257,  4523,  1175, 16317, 19426, 16239,\n",
              "            561,   307,  6572,    13, 50258,   361,   612,   373,   257,  1175,\n",
              "            986, 19426, 16239,   561,   307,  6572, 16317, 50258,   361,   612,\n",
              "            373,   257,  4523,  1175, 16317,   339,   561,   423,   587,  6572,\n",
              "             13, 50258,   361,   612,   373,   986,   257,  1175,   986,   339,\n",
              "            561,   423,   587,  6572,   986, 50258,   986,   329,   326,   986,\n",
              "            339,   986,   561,   986,   423,   986,  6572,   986,   262,   986,\n",
              "           7705, 16317,   287,   986,   262,   986,  1339,   986,   257,   986,\n",
              "           4523,  1175,   986, 50258,   986]]),\n",
              " tensor([[50257,    40,  4236,  4362,   339,   468,   220,  5389,   635,    11,\n",
              "            475,  1312, 15677,   340,    11,   780,   663,  1107,   407,   326,\n",
              "           2089, 50260,    72,  4236,   986,   780,   339,   468,  1735,   986,\n",
              "           1312,  1101,   407,  1165,  2089,   986,   339,   338,   655,   986,\n",
              "            796,     8, 50258,    72,  4236,   986,   780,   339,   468,   986,\n",
              "          23781,   986, 23781,   986, 23781,   986, 23781,   986, 23781,   986,\n",
              "          23781,   986, 23781,   986, 23781,   986, 23781,   986, 23781,   986,\n",
              "          23781,   986, 23781,   986, 23781,   986, 23781,   986, 23781,   986,\n",
              "          23781,   986, 23781,   986, 23781,   986, 23781,   986, 23781,   986,\n",
              "          23781,   986, 23781,   986, 23781,   986, 23781,   986, 23781,   986,\n",
              "          23781,   986, 23781,   986, 23781]]),\n",
              " tensor([[50257,  1890,   783,    11,   345,   389,   734,  8308,    86,  5379,\n",
              "          30533,  2759,   287,  1842,    13, 50260,  5832,   821,   734,  8308,\n",
              "             86,  5379,    11, 30533,  2759,   287,  1842,    13, 50258,  1640,\n",
              "            783, 16317,   345,   821,   734,  8308,    86,  5379, 16317, 30533,\n",
              "           2759,   287,  1842,    13, 50258,  5832,   821,   734, 16317,   345,\n",
              "            821,   734, 16317,   345,   821, 16317,   287,  1842, 16317,   783,\n",
              "          16317,    13, 50258,  1640,   783, 16317,   345,   821, 16317,   734,\n",
              "          16317,   345,   821, 16317,   287,  1842, 16317,   783, 16317,    13,\n",
              "          50258,  1640,   783, 16317,   345,   821, 16317,   734, 16317,   345,\n",
              "            821, 16317,   287,  1842, 16317,   783, 16317,    13, 50258,  1640,\n",
              "            783, 16317,   345,   821, 16317]]),\n",
              " tensor([[50257,  1639,  2314,  1592,  5928,  9976,   357, 10197,  1729,    12,\n",
              "          24498,  3392,     8,   832,  2742,  7767,  3436,    13, 50260,  1169,\n",
              "           2742,  8771,   318,   407,  6751,   329,   262,  5373,   286,  5928,\n",
              "           9976,    13, 50258,  1169,   691,   835,   284,  1592,   257,  5928,\n",
              "           1175,   318,   407,   832,  2742,  1724,   986, 50258,    64,  2742,\n",
              "           8771,   318,   407,  6751,   329,   326,   986, 50258,  1169,   691,\n",
              "            835,   986,   345,   460,   470,  1592,   986,   257,  5928,  1175,\n",
              "            986, 50258, 50258,    64,  2742,  8771,   986,   318,   407,  1576,\n",
              "            986,   329,   326,   986, 50258, 50258,  1169,   691,   835,   986,\n",
              "            345,   460,   470,   986,  1592,   986,   257,  1175,   986,   287,\n",
              "            428,  1339,   986, 50258, 50258]]),\n",
              " tensor([[50257, 15419,   259,  5731,   772,   286,  7218,  3806,  6387,    11,\n",
              "           4457, 14855, 50260, 10197,   996,  7218,  3806,  6387,   318,   407,\n",
              "           3017,    11,   326,   318,   991,   257,  2089,  1517,    13, 50258,\n",
              "              7, 10197,   996,  7218,  3806,  6387,   318,   407,  3017,    11,\n",
              "            326,   318,   991,   257,  2089,  1517,   986,   737, 50258,     7,\n",
              "          10197,   996,  7218,  3806,  6387,   318,   407,  3017,   986,   326,\n",
              "            318,   991,   257,  2089,  1517,   986,   737, 50258,     7, 10197,\n",
              "            996,   986,   326,   318,   986,   326,   318,   986,   326,   318,\n",
              "            986,   326,   318,   986,   326,   318,   986,   326,   318,   986,\n",
              "            326,   318,   986,   326,   318,   986,   326,   318,   986,   326,\n",
              "            318,   986,   326,   318,   986]]),\n",
              " tensor([[50257,  1639,  6304,   470,   810,   345,   547,  4385,   284,   307,\n",
              "             11,  5141,    13, 50260,  5832,   821,   407,   810,   345,   815,\n",
              "            423,   587,    11,  5141,    13, 50258,  5832,  6304,   470,   810,\n",
              "            345,   815,   423,   587,    11,  2933,    13, 50258,  5832,   821,\n",
              "            407,   810,   345,   815,   423,   587,    13, 50258,  5832,  6304,\n",
              "            470,   612,    13, 50258,  5832,   821,   407,   612,    11,  2933,\n",
              "             13, 50258,  5832,  6304,   470,   612,    11,   345,   821,   407,\n",
              "            612,    13, 50258,  5832,   821,   407,   612,    11,   345,   821,\n",
              "            407,   612,    13, 50258,  5832,   821,   407,   612,    11,   345,\n",
              "            821,   407,   612,    13, 50258,  5832,   821,   407,   612,    11,\n",
              "            345,   821,   407,   612,    13]]),\n",
              " tensor([[50257, 25104,  3337,   406,    45,    22,   718, 24544, 12406,    11,\n",
              "          16131,  4053,    11,  1578,  7526,  5601, 11345,   394,   347,    13,\n",
              "             53,    13, 50260,    49,   849,  4053,    11,  1578,  7526,    25,\n",
              "           4992,  9072,   406,    45,    22,   718, 24544, 12406,    11, 16131,\n",
              "           4053,    11,  1578,  7526,    13, 50258,    25,     8,   220,  1058,\n",
              "              8,   220,  1058,     8,   220,  1058,     8,   220,  1058,     8,\n",
              "            220,  1058,     8,   220,  1058,     8,   220,  1058,     8,   220,\n",
              "           1058,     8,   220,  1058,     8,   220,  1058,     8,   220,  1058,\n",
              "              8,   220,  1058,     8,   220,  1058,     8,   220,  1058,     8,\n",
              "            220,  1058,     8,   220,  1058,     8,   220,  1058,     8,   220,\n",
              "           1058,     8,   220,  1058,     8]]),\n",
              " tensor([[50257,     1, 23318,   607,   257, 48112,   286,  4713,  1633,   351,\n",
              "            262,  8966,  1666,    11,  3178,  1636,   553, 50260,     1,    40,\n",
              "            765,   284,  8508,   262,  4713,  1633,   553,   531,  3178,   306,\n",
              "             13, 50258,     1,    40,   765,   284,  8508,   262,  4713,  1633,\n",
              "             11,  3178,   306,   553,   339,   531,    13, 50258,     1,    40,\n",
              "            765,   284,  8508,   340,    11,  1165,    11,  3178,   306,   553,\n",
              "            339,   531,    13, 50258,     1,    40,  1183,  1309,   607,  8508,\n",
              "            340,    11,   996,    11,   523,   314,  2911,   553,   339,   531,\n",
              "             13, 50258,     1,    40,  1101,  1654,   314,  1183,  1254,   340,\n",
              "             11,  1165,    11,  3178,   306,   553,   339,   531,    13, 50258,\n",
              "              1,    40,  1183,  1577,   607]]),\n",
              " tensor([[50257,     1,  1639, 19059,   502,  1115,  1290, 27971,    11,   910,\n",
              "            262, 30987,   286,   520,    13,  5780,   338,   526, 50260,     1,\n",
              "             40,  1183,  1577,   345,  1115,  1243,    11,   520,    13,  5780,\n",
              "            338, 30987,   526, 50258,     1,    40,  1183,  1577,   345,  1115,\n",
              "           1243, 16317,   262, 30987,   286,   520,    13,  5780,   526, 50258,\n",
              "              1,    40,  1183,  1577,   345,  1115, 16317,   262,  8966,   286,\n",
              "            520,    13,  5780,   526, 50258,     1,   270,   338,  1115, 16317,\n",
              "            329,   502, 16317,   262, 30987,   286,   520,    13,  5780,   526,\n",
              "          50258,     1,   270,   338,  1115, 16317,   329,   502, 16317,   262,\n",
              "           8966, 16317,   286,   520,    13,  5780,   526, 50258,     1,   270,\n",
              "            338, 16317,  1115, 16317,   329]]),\n",
              " tensor([[50257,  5195,   836,   470,   345,   910,   366,    40,  1842,   345,\n",
              "              1,   284,   534,  6151,  3392,    13, 50260, 22850,   836,   470,\n",
              "            345,   910,  1312,  1842,   345,   284,   534,  6151,  3392,    30,\n",
              "          50258, 22850,   836,   470,   345,   910,  1312,  1842,   345,   284,\n",
              "            534,  6151,  3392,    30, 50258, 22850,   836,   470,   345,   910,\n",
              "           1312,  1842,   345,   284,   534,  6151,  3392,    30, 50258, 50258,\n",
              "             30,   986,   220,  1106,   220, 12359,   220, 12359,   220, 12359,\n",
              "            220, 12359,   220, 12359,   220, 12359,   220, 12359,   220, 12359,\n",
              "            220, 12359,   220, 12359,   220, 12359,   220, 12359,   220, 12359,\n",
              "            220, 12359,   220, 12359,   220, 12359,   220, 12359,   220, 12359,\n",
              "            220, 12359,   220, 12359,   220]]),\n",
              " tensor([[50257,  7676, 13808, 26237,  1719,  4257,  2460,   290,  6047,  3011,\n",
              "          19354, 50260,  3876, 13808,  7832,  1719,  3516,  2460,   290,   374,\n",
              "           4121,  7832, 19354,    13, 50258,  3876, 13808,  7832,  1719,  3516,\n",
              "           2460,   290,   374,  4121,  7832, 19354,    13, 50258,  3876, 13808,\n",
              "           7832,  1719,  3516,  2460,   290,   374,  4121,  7832, 19354,    13,\n",
              "          50258,    72,   892,   326,   374,  4121,   318, 19354,   286,   326,\n",
              "             13, 50258,  3876, 13808,  7832,  3516,  2460,   290,   339,   318,\n",
              "           1165,    11,   339,  3011, 19354,    13, 50258,    72,   892,   326,\n",
              "            374,  4121,   318,  1165,   986,   339,  7832,   326,    13, 50258,\n",
              "             72,   892,   326,   986,   339,   338,   257,  3516,    11,  1165,\n",
              "            986,   339,   338,   257, 19354]]),\n",
              " tensor([[50257,  2504,  1724,   340,   318,   691,   220,  1411,  1728, 50260,\n",
              "           5562,  1724,   340,   318,   691,   220,   220,  1411,  1728,    13,\n",
              "          50258,   568,   663,   691,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,  1532,   340,   318,   429,   607,   607,    11,  1846,   407,\n",
              "           1654, 50260,  1532,   340,   338,   407,   607,   986,   880,   986,\n",
              "            314,   836,   470,   760,    13, 50258,  1532,   340,   338,   407,\n",
              "            607,   986,   880,   986,   314,   836,   470,   760,    13, 50258,\n",
              "            361,   340,   338,   407,   607,   986,   880,   986,  1312,   836,\n",
              "            470,   760,    13, 50258,   361,   340,   338,   407,   607,   986,\n",
              "            880,   986,  1312,   836,   470,   760,    13, 50258,   361,   340,\n",
              "            338,   407,   607,   986,   880,   986,  1312,   836,   470,   760,\n",
              "             13, 50258,   361,   340,   338,   407,   607,   986,   880,   986,\n",
              "           1312,   836,   470,   760,    13, 50258,   361,   340,   338,   407,\n",
              "            607,   986,   880,   986,  1312]]),\n",
              " tensor([[50257,   138,   245,    68,   338,  1392,  2266,  8849,   477,   625,\n",
              "            465,  3835,    13, 50260,   138,    97,    68,   338,  1392,  2266,\n",
              "           8849,   477,   625,   262,  3835,    13, 50258,  1169,  3835,   547,\n",
              "           1336,   286,  2266, 16882,    13, 50258,  1169,  3835,   547,  1336,\n",
              "            286,  2266, 16882,    13, 50258,  8117,   373,   257,  2266,  1317,\n",
              "            319,   606,    13, 50258,  8117,   373,   257,  2266,  1317,   319,\n",
              "            606,    13, 50258,  1169,  3835,   547,  1336,   286,   606,    13,\n",
              "          50258,  1169, 16882,   373,   612,    13, 50258,  8117,   373,   257,\n",
              "           2266,  1317,   319,   606,    13, 50258,  8117,   373,   257,  2266,\n",
              "           1317,    13, 50258,  8117,   373,   257,  2266,  1317,    13, 50258,\n",
              "           1169, 16882,   373,   612,    13]]),\n",
              " tensor([[50257,  5211,   345,  9245,   534,   285,  1689,   351,   326,  5422,\n",
              "             30, 50260,   392,   345,   821, 25847,   534,  1995,   351,   326,\n",
              "           5422,    30, 50258,   392,   345,   821, 25847,   534,  1995,   351,\n",
              "            326,  5422,    30, 50258,   392,   345,   821, 25847,   607,    30,\n",
              "          50258,   392,   345,  9245,   607,    30, 50258,   392,   345,  9245,\n",
              "            607,    30, 50258,   392,   345,  9245,   607,    30, 50258,   392,\n",
              "            345,  9245,   607,    30, 50258,   392,   345,  9245,   607,    30,\n",
              "          50258,   392,   345,  9245,   607,    30, 50258,   392,   345,  9245,\n",
              "            607,    30, 50258,   392,   345,  9245,   607,    30, 50258,   392,\n",
              "            345,  9245,   607,    30, 50258,   392,   345,  9245,   607,    30,\n",
              "          50258,   392,   345,  9245,   607]]),\n",
              " tensor([[50257, 18465,  3022,  1566,   262,  7706,  1014,   550,   587, 23019,\n",
              "            290,   262,   509,  1236,  3087,  4170,   550, 24057,    13, 50260,\n",
              "          28446,   788,   986,  2147,  3022,   986,  1566,   262,   509,  1236,\n",
              "           3087,  4170,   373,  3750, 16317,   290,   262,   509,  1236,  3087,\n",
              "           4170,  1816,    13, 50258, 28446,   788,   986,  2147,  3022, 16317,\n",
              "           1566, 16317,   262,   509,  1236,  3087,  4170,   373,  3750, 16317,\n",
              "            290, 16317,   262,   509,  1236,  3087,  4170,  1816,    13, 50258,\n",
              "          28446,   788, 16317,  2147, 16317,  1566, 16317,   262,   509,  1236,\n",
              "           3087,  4170,   373,  3750, 16317,   290, 16317,   262,   509,  1236,\n",
              "           3087,  4170,  1816,    13, 50258,   986,   329,   326, 16317, 16317,\n",
              "          16317, 16317,  2147,  3022, 16317]]),\n",
              " tensor([[50257, 33583,   540, 11948,    37,   383,  2176, 11948,    37,   284,\n",
              "            307,  5625,  2236,    25, 50260,  1169, 11948,    37,   973,   318,\n",
              "             25, 50258,  1169, 11948,    37,   318,   973,   329,    25, 50258,\n",
              "           1169, 11948,    37,  2236,   307,   973,    25, 50258,  1169,  1708,\n",
              "            318,   262, 11948,    37,    25, 50258,  1169,  5981, 11948,    37,\n",
              "            318,    25, 50258, 50258,  1169,  5981, 11948,    37,  2236,   307,\n",
              "            973,    25, 50258, 50258,  1169,  2426,   318,    25, 50258,  1169,\n",
              "           2426,   318,    25, 50258,  1169,  1708,   318,   262, 11948,    37,\n",
              "             25, 50258,  1169,  1708,   318,   262, 11948,    37,    25, 50258,\n",
              "           1169,  1708,   318,   262, 11948,    37,    25, 50258,  1169,  5981,\n",
              "          11948,    37,   318,    25, 50258]]),\n",
              " tensor([[50257,    40,   466,   407,  1833,  1521,  1466,   886,   510,   852,\n",
              "           3684,  3921,   913,   351,   511,  2081,  1842, 50260, 22850,   466,\n",
              "           4813, 22705,   319,   511,  2081,  1842,    30, 50258,    72, 17666,\n",
              "            760,  1521,   484, 22705,   319,   511,  1842,    13, 50258, 22850,\n",
              "            466,  4813, 22705,   319,   511,   300, 14795,    30, 50258,    72,\n",
              "          17666,   760,   986, 22850,   466,   484, 22705,   319,   511,  1842,\n",
              "             30, 50258, 50258, 50258, 22850,   466,   484, 22705,   319,  1842,\n",
              "            986, 50258,    30,   986,    72, 17666,   760,   986, 22850,   466,\n",
              "            484, 22705,    30, 50258,    30,   986, 50258,    30,   986, 22850,\n",
              "            466,   484, 22705,   986, 50258,    30,   986,    72, 17666,   760,\n",
              "            986, 22850,   466,   484, 22705]]),\n",
              " tensor([[50257, 31334,   812,  4423,   510,   287,   257, 36892,   484,   466,\n",
              "            326,   284,   345,    13, 50260, 26548,   812,    11,   484,   821,\n",
              "           5291,   345,  8970,   510,   287,   257, 36892,    13, 50258,  9930,\n",
              "            821,  5291,   345,   612,   329,  3598,   812,    13, 50258, 26548,\n",
              "            812,    11,   326,   338,  1521,   345,   821,  8970,   510,    13,\n",
              "          50258,  5832,   821,   612,   329,  3598,   812,    11,   326,   338,\n",
              "           1521,    13, 50258, 26548,   812,    11,   484,   821,   991,  1804,\n",
              "            340,   284,   345,    13, 50258,  9930,   821,  1804,   340,   284,\n",
              "            345,    11,   326,   338,  1521,    13, 50258,  9930,   821,   991,\n",
              "           1804,   340,    11,   340,   338,   329,  3598,   812,    13, 50258,\n",
              "          26548,   812,   986,   326,   338]]),\n",
              " tensor([[50257,    40,  9477,   340,   832,  7576,   413,   557,  4321, 50260,\n",
              "             72,  1392,   340,   422,  1761,   413,   557,   986,    72,  1392,\n",
              "            340,   422,   612,    13, 50258,    72,  1392,   340,   422,  1761,\n",
              "            413,   557,   986,    72,  1392,   340,   422,   612,    13, 50258,\n",
              "             72,  1392,   340,   422,   612,   986,    72,  1392,   340,   422,\n",
              "            612,    13, 50258,    72,  1392,   340,   422,  1761,   413,   557,\n",
              "            986,    72,  1392,   340,   422,   612,    13, 50258,    72,  1392,\n",
              "            340,   422,   612,   986,    72,  1392,   340,   422,   612,   986,\n",
              "          50258,    72,  1392,   340,   422,   612,   986, 50258,    72,  1392,\n",
              "            340,   422,   612,   986,    72,  1392,   340,   422,   612,   986,\n",
              "          50258,    72,  1392,   340,   422]]),\n",
              " tensor([[50257,  1544,   318,   845, 10966, 50260,   392,   339,   318,   257,\n",
              "            845,   289,  1252,   494,    13, 50258,   258,   318,   845,  3024,\n",
              "            986, 50258,   258,   318,   523,  2238,   289,  1252,   494,   986,\n",
              "          50258,   258,   318,   523,  2238,   289,  1252,   494,   986, 50258,\n",
              "            258,   318,   523,   289,  1252,   494,   986, 50258,   258,   318,\n",
              "            523,   289,  1252,   494,   986, 50258,   258,   318,   523,   289,\n",
              "           1252,   494,   986, 50258,   258,   318,   523,   289,  1252,   494,\n",
              "            986, 50258,   258,   318,   523,   289,  1252,   494,   986, 50258,\n",
              "            258,   318,   523,   289,  1252,   494,   986, 50258,   258,   318,\n",
              "            523,   289,  1252,   494,   986, 50258,   258,   318,   523,   289,\n",
              "           1252,   494,   986, 50258,   986]]),\n",
              " tensor([[50257,    40,   423,  1464,   587,  7926,   314,   531,   326,    13,\n",
              "          50260,    40,  1053,  1464,  2936,  7926,   329,  2282,   326,    13,\n",
              "          50258,    40,  1053,  1464,  2936,  7926,   329,  2282,   326,    13,\n",
              "          50258,    40,  1053,  1464,  2936,  7926,   329,   340,    13, 50258,\n",
              "             40,  1101,  7926,   314,   531,   340,    13, 50258,    40,  1101,\n",
              "           7926,    13,   314,  1053,  1464,  2936,  7926,   329,   340,    13,\n",
              "          50258,    40,  1101,  7926,    13,   314,  1053,  1464,  2936,  7926,\n",
              "            329,   340,    13, 50258,    40,  1101,  7926,    13,   314,  1053,\n",
              "           1464,  2936,  7926,   329,   340,    13, 50258,    40,  1101,  7926,\n",
              "             13,   314,  1101,  7926,    13,   314,  1101,  7926,    13, 50258,\n",
              "             40,  1101,  7926,    13,   314]]),\n",
              " tensor([[50257, 30313,   329,   262,   986,  7326,  4241,   625,   534,  3112,\n",
              "             11,   314, 18959,   470, 19837,  1752,    13, 50260,    40,  1422,\n",
              "            470,   986,   314,  1422,   470,  6486,   546,   616,  3112,    13,\n",
              "          50258,    40,  1422,   470,   986,   314,  1422,   470,  6486,   546,\n",
              "            262,  3112,    13, 50258,    40,  1101,   407,   986,   314,  1101,\n",
              "            407,  9105,   546,   340,    13, 50258,    40,  1101,   986,   314,\n",
              "           1101,   407,   986,   546,   262,   986, 10802,   986,   546,   262,\n",
              "           3112,   986,   287,   428,  1339,    13, 50258,   986,   329,   986,\n",
              "            262,   986, 10802,   986,   546,   262,   986,  3112,   986,   287,\n",
              "            986,   428,  1339,   986, 50258,   986,   314,  1101,   986,   407,\n",
              "            986,   546,   986,   326,   986]]),\n",
              " tensor([[50257, 11041,   534,  4430,   284,  5004,   534,  4661, 50260,  5460,\n",
              "            329,   534,  4661,   287,   534,  3632,    13, 50258,  5832,   423,\n",
              "            284,   779,   534,  4430,   284,  3785,   503,   644,   534,  3061,\n",
              "            318,    13, 50258,  5832,   423,   284,   779,   534,  4430,   284,\n",
              "           3785,   340,   503,    13, 50258,  5832,   423,   284,   779,   534,\n",
              "           4430,   986,   284,   766,   644,   534,  3061,   318,    13, 50258,\n",
              "          50258,  5832,   423,   284,   779,   534,  4430,   986,   284,   766,\n",
              "            644,   534,  3061,   318,   986, 50258, 50258,   986,   290,   986,\n",
              "            334,   423,   284,   779,   534,  4430,   986,   284,   766,   986,\n",
              "            644,   986,   340,   986,   318,   986, 14373, 50258,   986,   290,\n",
              "            986,   334,   986,   423,   986]]),\n",
              " tensor([[50257,   464, 26274,   423,  8904, 30802,   287,   326,   484,  2689,\n",
              "            674,  5009,    13, 50260,  1169,  1109,   326,   484, 21160,   287,\n",
              "            674,  1570,    11,   318,   326,   484,   389,   287,   674,  3923,\n",
              "             13, 50258,  1169,  1109,   326,   484,   389,   287,   674,  3923,\n",
              "          16317,   318,  1521,   484, 21160, 16317,    13, 50258, 50258,   732,\n",
              "            460,   766, 16317,   326,   262,  3923,   389, 16218, 16317,   287,\n",
              "            674,  1570,    13, 50258,   732,   460,   910, 16317,   326, 16317,\n",
              "            484,   389,   986,   287,   674,  1621, 16317,    13, 50258,   732,\n",
              "            460, 16317,   910, 16317,   326, 16317, 16317,   340, 16317,   318,\n",
              "          16317,  1521, 16317,    13, 50258,   732, 16317,   460, 16317,   910,\n",
              "          16317,   326, 16317,   986,   340]]),\n",
              " tensor([[50257,  1532,   416,  1719,   257, 13850,   345,  1612,  4581,   640,\n",
              "            379,  1123,  1854,  7777,    11,   788,  3504,  1524,   393, 13430,\n",
              "           1029, 50260,   361,   416,  1719,   257, 13850,   345,  1612,  4581,\n",
              "            640,   379,  1123,  1854,  7777,   788,  3504,  1524,   393, 13430,\n",
              "           1029,    13, 50258,   361,   416,  1719,   257, 13850,   345,  1612,\n",
              "           4581,   640,   379,  1123,  1854,  7777,   788,  3504,  1524,   393,\n",
              "          13430,  1029,    13, 50258,   361,   416,  1719,   257, 13850,   345,\n",
              "           1612,  4581,   640,   379,  1123,  1854,  7777,   788,  3504,  1524,\n",
              "            393, 13430,  1029,    13, 50258,   361,   416,  1719,   257, 13850,\n",
              "            345,  1612,  4581,   640,   379,  1123,  1854,  7777,   788,  3504,\n",
              "           1524,   393, 13430,  1029,    13]]),\n",
              " tensor([[50257,    40,   423,   262,   976,  1861,   417,    76,    11,  5176,\n",
              "            329,  4737,   326,  1808, 50260,    72,   423,   262,   976,  1917,\n",
              "          16317,  5176,   329,  4737,   428,  1808,   986, 50258,    72,   423,\n",
              "            262,   976,  1917, 16317,  5176,   329,  4737,   428,  1808,   986,\n",
              "          50258,    72,   423,   262,   976,  1917, 16317,  5176,   329,  4737,\n",
              "            428,  1808,   986, 50258, 50258,    72,   423,   262,   976,  1917,\n",
              "          16317,  5176,   329,  4737,   428,  1808,   986, 50258,    72,   423,\n",
              "            262,   976,  1917, 16317,  5176,   329,  4737,   428,  1808,   986,\n",
              "          50258,    72,   423,   262,   976,  1917, 16317,  5176,   329,  4737,\n",
              "            428,  1808,   986, 50258, 50258,    72,   423,   262,   976,  1917,\n",
              "          16317,  5176,   329,  4737,   428]]),\n",
              " tensor([[50257,    40,   973,   284,   307, 12725,   284,  6405,  1450,   543,\n",
              "            373,  2089, 50260,    72,   973,   284,   307, 12725,   284,  6405,\n",
              "           1450,   986,  4758,   373,  2089,    13, 50258,    72,   973,   284,\n",
              "            307, 12725,   284,  6405,  1450,   986,  4758,   373,  2089,    13,\n",
              "          50258,    72,   973,   284,   307, 12725,   284,  6405,  1450,   986,\n",
              "           4758,   373,  2089,    13, 50258,    72,   973,   284,   307, 12725,\n",
              "            284,  6405,  1450,   986,  4758,   373,  2089,    13, 50258,    72,\n",
              "            973,   284,   307, 12725,   284,  6405,  1450,   986,  4758,   373,\n",
              "           2089,    13, 50258,    72,   973,   284,   307, 12725,   284,  6405,\n",
              "           1450,   986,  4758,   373,  2089,    13, 50258,    72,   973,   284,\n",
              "            307, 12725,   284,  6405,  1450]]),\n",
              " tensor([[50257,   464,  1657,  4171,  5417,  3607,   281, 22491,   286,  4167,\n",
              "            290, 31882,   879,   319,   262,  1956, 50260,  1169,  4171, 21547,\n",
              "           2897,   257,  9480,   290, 12309,  2858,   319,   262,  4417,    13,\n",
              "          50258,  1169,  4171, 21547,  2897,   257,  9480,   290, 46944,  2858,\n",
              "            319,   262,  4417,   986, 50258,  1169,  4171, 21547,   389,    11,\n",
              "            287,   428,  2565, 16317,   257,  9480,   290, 40836,  1295,    13,\n",
              "          50258, 50258, 50258,  1169,  4171, 21547,   389, 16317,   257,  9480,\n",
              "            290, 15497,  1295, 16317,   329,   262, 11060, 16317,   286, 16317,\n",
              "           4167,    13, 50258, 50258,  1169,  4171, 21547, 16317,   389, 16317,\n",
              "            257,  9480,   290, 15497,  1295, 16317,   329,   262, 11060, 16317,\n",
              "            286, 16317,  9480,    13, 50258]]),\n",
              " tensor([[50257,     1, 30571,     1,   632,   481,  1107,  1645,    11,   523,\n",
              "            340,   338,   407,   257,  4320,    13, 50260,     1, 30571,     1,\n",
              "            532,   632,   481,  1107,  1645,    11,   523,   340,   338,   407,\n",
              "            257,  4320,    13, 50258,    12,   632,   338,   407,   257,  4320,\n",
              "             11,   340,   338,   257,  1103,  1517,    13, 50258,    12,   632,\n",
              "            338,   407,   257,  4320,    11,   340,   338,   257,  1109,    13,\n",
              "          50258,    12,   632,   338,   407,   257,  4320,    11,   340,   338,\n",
              "            257,  1109,    13, 50258,    12,   632,   338,   407,   257,  4320,\n",
              "            986,   532,   632,   338,   257,  1109,    13, 50258,    12,   632,\n",
              "            338,   407,   257,  4320,   986,   532,   632,   338,   257,  1109,\n",
              "             13, 50258,    12,   632,   338]]),\n",
              " tensor([[50257,  2990,  3993,   329,  2250,   379,   257,   640,    13, 50260,\n",
              "           9930,  3993,   329,  2250,   379,   257,   640,    13, 50258,  9930,\n",
              "           3993,   329,  2250,   379,   257,   640,    13, 50258, 50258,  9930,\n",
              "           3993,   329,  2250,   379,   257,   640,    13, 50258,  9930,  3993,\n",
              "            329,  2250,   379,   257,   640,    13, 50258, 50258,  9930,  3993,\n",
              "            329,  2250,   379,   257,   640,    13, 50258,  9930,  3993,   329,\n",
              "           2250,   379,   257,   640,    13, 50258,  9930,  3993,   329,  2250,\n",
              "            379,   257,   640,    13, 50258,  9930,  3993,   329,  2250,   379,\n",
              "            257,   640,    13, 50258,  9930,  3993,   329,  2250,   379,   257,\n",
              "            640,    13, 50258,  9930,  3993,   329,  2250,   379,   257,   640,\n",
              "             13, 50258,  9930,  3993,   329]]),\n",
              " tensor([[50257,  2061,   389,   345,  2111,   284,   466,    30,  1305,   432,\n",
              "            268,   607,   284,  1918,    30, 50260, 10919,   466,   345,   765,\n",
              "            284,   466,   351,   607,    30, 50258, 10919,   389,   345,  2111,\n",
              "            284,   466,    30,  1305,   432,   268,   607,   284,  1918,    30,\n",
              "          50258, 10919,   466,   345,   765,   284,   466,   351,   607,    30,\n",
              "          50258, 10919,   466,   345,   765,   284,   466,    30, 50258, 10919,\n",
              "            466,   345,   765,   284,   466,    30, 50258, 50258, 10919,   466,\n",
              "            345,   765,   284,   466,    30, 50258, 50258, 10919,   466,   345,\n",
              "            765,   284,   466,    30, 50258, 10919,   466,   345,   765,   284,\n",
              "            466,    30, 50258, 50258, 10919,   466,   345,   765,   284,   466,\n",
              "             30, 50258, 10919,   466,   345]]),\n",
              " tensor([[50257,    47,  1571,   319,    12,  1169,    12, 20485,  8794,  5281,\n",
              "            319,   416,   262,  4513,    11,   340,   318,   783,  3306,   284,\n",
              "           4259,   262,   717,   916,   282,   434,   286,   262,  8108,  3176,\n",
              "          10156,    13, 50260,  1169,   717,   916,   282,   434,   286,   262,\n",
              "           8108, 10156,  2236,    11,   287,   262, 14324, 16317,   307,  5969,\n",
              "            986,   416,   262,  4513, 16317,   287,   262,  1339,   286,   257,\n",
              "           2060,   319,    12,  1169,    12, 20485,  2198,    13, 50258,  1169,\n",
              "            717,   916,   282,   434, 16317,  2236,   986,  3520,   986,  1566,\n",
              "          16317,   262,  4513,   986, 10732,   503,   257,  2060,   986,  8922,\n",
              "            986,   286,   262,  8108,   338,  3176, 10156,    13, 50258, 50258,\n",
              "           1169,   717,   916,   282,   434]]),\n",
              " tensor([[50257,  1639,   423,   257,   826,   284,   307,  8805, 50260,  5832,\n",
              "            423,   257,   826,   284,   307,  8805,    13, 50258,  5832,   423,\n",
              "            257,   826,   284,   307,  8805,    13, 50258,  5832,   423,   257,\n",
              "            826,   284,   307,  8805,    13, 50258,  5832,   423,   257,   826,\n",
              "            284,   307,  8805,    13, 50258, 50258, 50258,  5832,   423,   257,\n",
              "            826,   284,   307,  8805,    13, 50258,  5832,   423,   257,   826,\n",
              "            284,   307,  8805,    13, 50258, 50258,  5832,   423,   257,   826,\n",
              "            284,   307,  8805,    13, 50258, 50258,  5832,   423,   257,   826,\n",
              "            284,   307,  8805,    13, 50258,  5832,   423,   257,   826,   284,\n",
              "            307,  8805,    13, 50258,  5832,   423,   257,   826,    13, 50258,\n",
              "          50258,  5832,   423,   257,   826]]),\n",
              " tensor([[50257,    40,  1577,   345,   262,  3663,   286,   257, 10869,    11,\n",
              "            290,   345,   655,  6611,   340,     0, 50260,    72,  1577,   345,\n",
              "            262,  3663,   286,   257, 10869, 16317,   290,   345,   655,  6611,\n",
              "            340,     0, 50258,    72,  1577,   334,   262,  3663, 16317,   286,\n",
              "            257, 10869, 16317,   290,   334,   655,  6611,   340,     0, 50258,\n",
              "          50258,    72,  1577,   334,   262,  3663, 16317,   286,   257, 10869,\n",
              "          16317,   290,   334,   655,  6611,   340,     0, 50258,     0,   986,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,  9203,   262,   466,   579,   265,   318,   257,  1994,   326,\n",
              "            314,   423,  1364,   329,   345,    13,   447,   251, 50260,    40,\n",
              "           1364,   257,  1994,   739,   262,  3420,    13,   366, 50258,  4625,\n",
              "            262,  3996,   318,   257,  1994,   314,  2921,   345,    13,   366,\n",
              "          50258,     1,    40,  2921,   345,   257,  1994,   739,   262,  3996,\n",
              "             13,   366, 50258,     1,    40,  1053,  1364,   345,   257,  1994,\n",
              "            329,   345,    13,   366, 50258,     1,  4625,   262, 28774,    11,\n",
              "            314,   423,   257,  1994,    13,   366, 50258,     1,    40,  1053,\n",
              "           1813,   345,   262,  1994,   986,   314,  1053,  1364,   340,   612,\n",
              "            986, 50258,     1,    40,  1053,  1364,   340,   986,   314,  1101,\n",
              "           4305,   340,   986,   329,   345]]),\n",
              " tensor([[50257,  4864,    11,   612,   389,   617,   922,  1450,   503,   612,\n",
              "          50260,  4360,   612,   389,   617,   922,  1450,   503,   612,    13,\n",
              "          50258,  4360,   612,   389,   617,   922,  1450,   503,   612,    13,\n",
              "          50258,  4360,   612,   389,   617,   922,  1450,   503,   612,    13,\n",
              "          50258,  4360,   986,  8117,   389,   617,   922,  1450,   503,   612,\n",
              "             13, 50258,  4360,   986,  8117,   389,   617,   922,  1450,   503,\n",
              "            612,    13, 50258,  4360,   986,  8117,   389,   617,   922,  1450,\n",
              "            503,   612,    13, 50258,  4360,   986,  8117,   389,   617,   922,\n",
              "           1450,   503,   612,    13, 50258,  4360,   986,  8117,   389,   617,\n",
              "            922,  1450,   503,   612,    13, 50258,  4360,   986,  8117,   389,\n",
              "            617,   922,  1450,   503,   612]]),\n",
              " tensor([[50257,  6653,  5287,   284,   307,   612,  1244,   307,  1775,   355,\n",
              "           6617,   326,   339,   373, 40316, 33840,    13, 50260,  1169,  1109,\n",
              "            326,   339,   373,   407,   612,   743,   307, 16173,   355,   257,\n",
              "           5287,   284,   905, 31450,    13, 50258,  1169,  1109,   326,   339,\n",
              "            373,   407,   612,   743,  1950,   326,   339,   373, 40316, 33840,\n",
              "             13, 50258,  1169,  1109,   326,   339,   373,   407,   612,   743,\n",
              "           7603,   326,   339,   373, 40316, 33840,    13, 50258,  1169,  1109,\n",
              "            326,   339,   373,   407,   612,   743,  7603,   326,   339,   373,\n",
              "             13, 50258,  1169,  1109,   326,   339,   373,   407,   612,   743,\n",
              "           1950,   326,   339,   373,    13, 50258,  1169,  1109,   326,   339,\n",
              "            373,   407,   612,   743,  7603]]),\n",
              " tensor([[50257,   464, 44128,  2192, 11694,   606, 50260,  1169, 44128,   743,\n",
              "            423, 11694,   606,    13, 50258,   270,   373,  2192, 11694,   416,\n",
              "          37441, 12140,    13, 50258,  1169, 37441, 12140,   743,   423, 11694,\n",
              "            606,    13, 50258,   270,   373,  2192, 11694,   416, 37441, 12140,\n",
              "             13, 50258,   270,   373,  2192, 11694,   416, 37441, 12140,    13,\n",
              "          50258,  1169, 37441, 12140,   743,   423, 11694,   606,    13, 50258,\n",
              "            270,   373,  2192, 11694,   416, 37441, 12140,    13, 50258,  1169,\n",
              "          37441, 12140,   743,   423, 11694,   606,    13, 50258,  1169, 37441,\n",
              "          12140,   743,   423, 11694,   606,    13, 50258,  1169, 37441, 12140,\n",
              "            743,   423, 11694,   606,    13, 50258,  1169, 37441, 12140,   743,\n",
              "            423, 11694,   606,    13, 50258]]),\n",
              " tensor([[50257, 20459, 37276,   290,  1257,    11,   475,   407, 16662,   329,\n",
              "            257,  3807, 50260,   896, 37276,   290,  1257,   986,  4360,   407,\n",
              "          16662,   329,   257,  3807,    13, 50258,   896, 37276,   290,  1257,\n",
              "            986,  4360,   407, 16662,   329,   257,  3807,    13, 50258,   896,\n",
              "          37276,   986,  4360,   407,   329,   257,  3807,   986, 50258,   896,\n",
              "          37276,   986,  4360,   407,   329,   257,  3807,   986, 50258,   896,\n",
              "          37276,   986,   392,  1257,   986,   475,   407,   329,   257,  3807,\n",
              "             13, 50258,   896, 37276,   986,  4360,   407,   329,   257,  3807,\n",
              "            986, 50258,   896, 37276,   986,   392,  1257,   986,   475,   407,\n",
              "            329,   257,  3807,   986, 50258, 50258,   896, 37276,   986,  4360,\n",
              "            407,   329,   257,  3807,   986]]),\n",
              " tensor([[50257,  3347,  1422,   470,   588,   465,   840,    13, 14446,   683,\n",
              "            651,  8530,    12,  2395,   988, 35223,    13, 50260,   258,  1392,\n",
              "          35223,   329,   465,  8530,    13, 50258,   258,  1392, 35223,   329,\n",
              "            465,  8530,    13, 50258,   258,  1392, 35223,   329,   465,  8530,\n",
              "             13, 50258,   258,  1392, 35223,   329,   326,    13, 50258,   258,\n",
              "           1392, 35223,   329,   326,    13, 50258,   258,  1392, 35223,   329,\n",
              "            326,    13, 50258,   258,  1392, 35223,   329,   326,    13, 50258,\n",
              "            258,  1392, 35223,   329,   326,    13, 50258,   258,  1392, 35223,\n",
              "            329,   326,    13, 50258,   258,  1392, 35223,   329,   326,    13,\n",
              "          50258,   258,  1392, 35223,   329,   326,    13, 50258,   258,  1392,\n",
              "          35223,   329,   326,    13, 50258]]),\n",
              " tensor([[50257,  7120, 30521,   263,   530,   508,   318,   510,   284,  3128,\n",
              "            355,   881,   355,   345,   389, 50260, 14108, 16008,   508,   318,\n",
              "            517,   510,   284,  3128,    13, 50258, 14108, 16008,   508,   318,\n",
              "            517,   510,   284,  3128,    13, 50258, 50258,   392,   534, 16008,\n",
              "            508,   318,   517,   510,   284,  3128,    13, 50258, 50258,   392,\n",
              "            534, 16008,   508,   318,   517,   510,   284,  3128,    13, 50258,\n",
              "          50258,   392,   523,   319,   986, 50258,   392,   523,   319,   986,\n",
              "          50258,   392,   523, 16317, 50258,   392,   523, 16317,   986,  1312,\n",
              "           4724,   986,  1312,  4724, 16317,  1312,  4724, 16317,  1312,  4724,\n",
              "            986,  1312,  4724,   986, 50258, 50258,   986,   290, 16317,   326,\n",
              "            338,  1521, 16317,  1312,  4724]]),\n",
              " tensor([[50257,  2990,   423,   257,   905,   329,  2506,   503,   612, 50260,\n",
              "           9930,   423,   257,   905,   329,  2506,   503,   612,    13, 50258,\n",
              "           9930,   423,   257,   905,   329,  2506,   503,   612,    13, 50258,\n",
              "           9930,   423,   257,   905,   329,  2506,    13, 50258,  9930,   423,\n",
              "            257,   905,   329,  2506,    13, 50258,  9930,   423,   257,   905,\n",
              "            329,  2506,   503,   612,    13, 50258, 50258,  9930,   423,   257,\n",
              "            905,   329,  2506,    13, 50258,  9930,   423,   257,   905,   329,\n",
              "           2506,    13, 50258,   986,  9930,   423,   257,   905,   329,  2506,\n",
              "            986, 50258,   986,   329,  2506,   986, 50258,   986,   329,  2506,\n",
              "            986, 50258,   986,   329,  2506,   986, 50258,   986,   329,   477,\n",
              "            986, 50258,   986,   329,   477]]),\n",
              " tensor([[50257,  1639,   481,  1111,  1716, 20315,   913,    11,   611,   345,\n",
              "           2652,   351,   257,   582,   345,   466,   407,  1842, 50260,   361,\n",
              "            345,  2652,   351,   257,  3516,   345,   836,   470,  1842,    11,\n",
              "            788,   345,  1183,  1111,  1716, 20315,   913,    13, 50258, 16885,\n",
              "            286,   345,   481,   307, 20315,   913,    11,   611,   345,  2652,\n",
              "            351,   683,   393,   673, 14768,   351,   683,    13, 50258, 50258,\n",
              "            568,   611,   345,  2652,   351,   683,   393,   673, 14768,   351,\n",
              "            683,    11,   345,  1111,  1716, 20315,   913,    13, 50258,  5832,\n",
              "           1183,  1111,   651, 20315,   913,    13, 50258,   568,   611,   345,\n",
              "           2652,   351,   683,   393,   673, 14768,   351,   683,   986,   345,\n",
              "           1183,  1111,   307, 20315,   913]]),\n",
              " tensor([[50257,  1537,   612,   338,  1682,   257, 16304,   284,   262,  1621,\n",
              "             13, 50260,  8117,   338,   257, 16304,   284,   262,  1621,    13,\n",
              "          50258,   392,   262,  1621,   318,   772,   517,  3519,   284,   262,\n",
              "          16304,    13, 50258,  5661,   318,  1521,   986,   612,   318,   257,\n",
              "          16304,   284,   262,  1621,    13, 50258,  5562,   338,  1521, 16317,\n",
              "            612,   318,   257, 16304,   284,   340, 16317,    13, 50258,   986,\n",
              "            290,   340,   318,   986,   257, 16304,   284,   262,  1621,    13,\n",
              "          50258,   986,   290, 16317,   326,   338,  1521, 16317,   340,   318,\n",
              "          16317,   257, 16304,   284,   262,  1621,    13, 50258,   986,   326,\n",
              "            338,  1521, 16317,   340,   338,   986,   257, 16304, 16317,    13,\n",
              "          50258,   986,   326,   338,  1521]]),\n",
              " tensor([[50257,    40,   892,   326,  1111,  1466,   389,  8603, 12356,   287,\n",
              "            511,  7147,  2214,   475,   611,  4137,   314,   561,  3853, 33127,\n",
              "          50260,    72,   892,  1111,  1466,   460,   466,   340,   290,   611,\n",
              "           4137,  1312,   561,  3853,   300,   521, 16706,    13, 50258,    72,\n",
              "            892,  1111,  1466,   460,   466,   340,   986,  4360,   611,   340,\n",
              "            373,   510,   284,   502,  1312,   561,  3853,   300,   521, 16706,\n",
              "             13, 50258,    72,   892,  1111,   460,   466,   340,   986,  4360,\n",
              "            611,   340,   373,   284,   502,  1312,  1549,  3853,   300,   521,\n",
              "          16706,    13, 50258,    72,   892,  1111,   460,   466,   340,   986,\n",
              "           4360,   611,   340,   373,   284,   502,  1312,  1549,  3853,   300,\n",
              "            521, 16706,    13, 50258,    72]]),\n",
              " tensor([[50257,  3237,  1973,   262, 11621,    11,  2422,  3386,   547,   852,\n",
              "           3220,   287,  4202,   290,  4624,   319,  7995,    13, 50260, 33631,\n",
              "           3386,   547, 12380,  1973,   262,   995,    11,   290,   262,  7995,\n",
              "            373,  3220,    13, 50258,  1169,  2422,   373,  4376,   287,   262,\n",
              "           2104,   995, 16317,   290,   262,  3074,   373,   925,  4785,    13,\n",
              "          50258,  1169,  3074,   373, 38337, 16317,   287,   477,   262,   995,\n",
              "          16317,   262,  2422,   373, 27324,    13, 50258,  1169,  3074,   373,\n",
              "           4376, 16317,   287,   477,  4113, 16317,   262,  2422,   373,  1234,\n",
              "            319,  7995,    13, 50258,  1169,  3074,   373,   925, 16317,   416,\n",
              "            262,  2422, 16317,   287,   477,  2663, 16317,   262,  3074,   373,\n",
              "            925,  4785,    13, 50258,  1169]]),\n",
              " tensor([[50257, 12442,    69,   291,  1927,    11,   340,   318, 38486,   284,\n",
              "            423,   597, 16584,  2776,   351,   597,  6405,  6506,   379,   477,\n",
              "          50260,     7, 12442,    69,   291,  1927, 16317, 15028, 16317,   379,\n",
              "           1551, 16317,   329,   477,  6405,  6506,   737, 50258,     7, 12442,\n",
              "             69,   291,  1927, 16317,   340,   338, 38486, 16317,   284,   423,\n",
              "            597,  1611,   286, 16584,  2776, 16317,   351,   597,  6405,  1048,\n",
              "          16317,   379,   477,    13, 50258,     7, 12442,    69,   291,  1927,\n",
              "          16317,   340,   338, 38486, 16317,   284,   423, 16317,   597,  1611,\n",
              "          16317,   286, 16317,  2776, 16317,   351,   597,  6405,  1048, 16317,\n",
              "            379,   477,    13, 50258,     7, 12442,    69,   291,  1927, 16317,\n",
              "            340,   338, 16317, 32949, 16317]]),\n",
              " tensor([[50257, 38101,  1995,  5356,   523,  3735,   326,   618,   673,  4191,\n",
              "           4962,  1088,   663,   607, 10955, 50260, 38101,   285,  1689,   523,\n",
              "           3735,    11,   618,   673,  4962,  1088,    11,   607, 10955,   318,\n",
              "            319,   262,  1110,    13, 50258, 38101,   285,  1689,   523,  3735,\n",
              "            986,   618,   673,  4962,  1088,   986,   607, 10955,   318,   319,\n",
              "            262,  1110,    13, 50258, 38101,   285,  1689,   523,  3735,   986,\n",
              "            618,   673,  4962,   986,   607, 10955,   318,   319,   262,  1110,\n",
              "             13, 50258, 38101,   285,  1689,   523,  3735,   986,   618,   673,\n",
              "           4962,   986,   607, 10955,   318,   319,   262,  1110,    13, 50258,\n",
              "          38101,   285,  1689,   523,  3735,   986,   618,   673,  4962,   986,\n",
              "            607, 10955,   318,   319,   262]]),\n",
              " tensor([[50257,    40,   561,  4313,  4379,  2035,   262, 14657, 30364,   393,\n",
              "          44269,  4502, 50260,  1169, 11398,   279,   415,   372,   393, 11040,\n",
              "           4903,  3643,    13, 50258,    72,   561,   467,   766,   262, 11398,\n",
              "            279,   415,   372,   393, 11040,  4903,  3643,    13, 50258,  1169,\n",
              "          11398,   279,   415,   372,   393, 11040,  4903,  3643,    13, 50258,\n",
              "             72,   561,   467,   766,   262, 11398,   279,   415,   372,   393,\n",
              "          11040,  4903,  3643,    13, 50258,  1169, 11398,   279,   415,   372,\n",
              "            393, 11040,  4903,  3643,    13, 50258,  1169, 11398,   279,   415,\n",
              "            372,   393, 11040,  4903,  3643,    13, 50258,    72,   561,   467,\n",
              "            766,   262, 11398,   279,   415,   372,   393, 11040,  4903,  3643,\n",
              "             13, 50258,    72,   561,   467]]),\n",
              " tensor([[50257,  2949, 12681, 12737,   547,  4367,   416,   262, 20725,    13,\n",
              "          50260,  1169, 20725,   750,   407,  4003,   597, 12681, 12737,    13,\n",
              "          50258,  1169, 20725,   750,   407, 12414,   597, 12681, 12737,    13,\n",
              "          50258,  1169, 20725,   750,   407,  4003,   597, 12681, 12737,    13,\n",
              "          50258,  1169, 20725,   750,   407, 12414,   597, 12681, 12737,    13,\n",
              "          50258,  3919, 12681, 12737,   547,  2098,    13, 50258,  3919, 12681,\n",
              "          12737,   547,  6515,   416,   262, 20725,    13, 50258,    13,   258,\n",
              "            373,   407,  7981,   286,   597, 12681, 12737,    13, 50258,    13,\n",
              "            258,   373,   407,  7981,   546,   606,    13, 50258,    13,   258,\n",
              "            373,   407,  7981,   546,   606,    13, 50258,    13,   258,   373,\n",
              "            407,  7981,   546,   606,    13]]),\n",
              " tensor([[50257,  1870,  4145,   262, 23642,   286, 13158,  3171,    11,  1432,\n",
              "            793,  6202,   290, 26962,  9349,    13, 50260,   568,   262, 23642,\n",
              "            286, 13158,  3171, 16317,   290,   523,    11,  1165, 16317,   262,\n",
              "          24842,   286,   262, 29714, 16317,    13, 50258,   568, 16317,   262,\n",
              "          23642, 16317,   290, 16317,   262, 24842, 16317,   286,   262, 29714,\n",
              "          16317,    13, 50258, 50258,   568, 16317,   262,  3074, 16317,   373,\n",
              "          16317,   262,  1255, 16317,   286,   262, 13158,  3171, 16317, 16317,\n",
              "          16317,   290, 16317,   262, 24842, 16317,   286,   262, 29714, 16317,\n",
              "             13, 50258, 50258,   568, 16317,   262,  3074, 16317,   373, 16317,\n",
              "            262,  1255, 16317, 16317, 16317, 16317, 16317, 16317, 16317, 16317,\n",
              "            286,   262, 13158,  3171, 16317]]),\n",
              " tensor([[50257,  1532,   345, 14996,   606,    11,  1394,   606, 50260,  1532,\n",
              "            345,   588,   606,    11,  1394,   606,    13, 50258,  1532,   345,\n",
              "            588,   606,    11,  1394,   606,    13, 50258,   361,   345,   588,\n",
              "            606,    11,  1394,   606,    13, 50258,   361,   345,   588,   606,\n",
              "             11,  1394,   606,    13, 50258,   361,   345,   588,   606,    11,\n",
              "           1394,   606,    13, 50258,   361,   345,   588,   606,    11,  1394,\n",
              "            606,    13, 50258,   361,   345,   588,   606,    11,  1394,   606,\n",
              "             13, 50258,   361,   345,   588,   606,    11,  1394,   606,    13,\n",
              "          50258,   361,   345,   588,   606,    11,  1394,   606,    13, 50258,\n",
              "            361,   345,   588,   606,    11,  1394,   606,    13, 50258,   361,\n",
              "            345,   588,   606,    11,  1394]]),\n",
              " tensor([[50257,  8491,   345,  2111,   284,   787,  1243,  2092,   351,   616,\n",
              "           1232,   290,   345,  4305,  1524,    30, 50260,   533,   345,  2111,\n",
              "            284,   787,  1243,  2092,   351,   616,  1232,   290,   345,  4305,\n",
              "           1524,    30, 50258,    30,   986,   393,   389,   345,   655,  2111,\n",
              "            284,   787,   340,   588, 16317,   351,   616,  1232,   986,   393,\n",
              "          16317,   351,   345,   986,  4305,  1524,    30, 50258,    30,   986,\n",
              "            393, 16317,   466,   345,   655,   765,   284,   787,   340, 16317,\n",
              "            588, 16317,   351, 16317,   502, 16317,   393, 16317,   351, 16317,\n",
              "            345, 16317,  1016,   284,  1524,    30, 50258,    30,   986,   393,\n",
              "          16317,   466, 16317,   356, 16317,   787,   340, 16317,   588, 16317,\n",
              "            351, 16317,   502, 16317,   393]]),\n",
              " tensor([[50257,  1537,   340,   338,  8066,  4656,    13,   532,  9425,    11,\n",
              "            356,   821,   477,  8066,  4656,    13, 50260,  8505, 16317,   356,\n",
              "           1183,   477,  4656, 16317,   340,   481,    13, 50258,  8505, 16317,\n",
              "            356,  1183,   477,  4656, 16317,   356,  1183,   477,  4656, 16317,\n",
              "            340,   481,    13, 50258,   732,  1183,   477,  4656, 16317,   356,\n",
              "           1183,   477,  4656, 16317,   340,   481,    13, 50258,   732,  1183,\n",
              "            477,  4656, 16317,   356,  1183,  4656, 16317,   340,   338,  2081,\n",
              "             13, 50258,   732,  1183,   477,  4656, 16317,   356,  1183,  4656,\n",
              "          16317,   340,   338,  2081,    13, 50258,   732,  1183,   477,  4656,\n",
              "          16317,   356,  1183,  4656, 16317,   340,   338,  2081, 16317, 50258,\n",
              "            732,  1183,   477,  4656, 16317]]),\n",
              " tensor([[50257, 10995,    11,   326,   835,   345,   760,   326,   612,   318,\n",
              "            517,   284,  1714,    11,   588,   534,  3656,   290,  5229,   466,\n",
              "            340, 50260,  8505,   986,   326,   835,   986,   334,   760,   986,\n",
              "            612,   318,   517,   986,   284,  1714,   986,   588,   262,  3656,\n",
              "            986,   290,   986,   262,  5229,   986, 50258, 43669,   986,   326,\n",
              "            835,   986,   334,   760,   986,   612,   318,   986,   517,   986,\n",
              "            284,  1714,   986,   588,   262,  3656,   986,   290,   986,   262,\n",
              "           5229,   986, 50258, 43669,   986,   326,   835,   986,   334,   760,\n",
              "            986,   612,   986,   517,   986,   284,  1714,   986,   588,   986,\n",
              "            262,  3656,   986,   290,   986,   262,  5229,   986, 50258, 43669,\n",
              "            986,   326,   835,   986,   334]]),\n",
              " tensor([[50257,  1639,   815,  1560,   607,   326,   345,   466,   407,   423,\n",
              "            262,   262,   976,  7666,   355,   607, 50260, 24446,   607,   345,\n",
              "            836,   470,  1254,   262,   976,   329,   607,    13, 50258,  5832,\n",
              "            815,  1560,   607,   326,   345,   836,   470,  1254,   262,   976,\n",
              "            835,   546,   607,    13, 50258,  5832,   815,  1560,   607,   326,\n",
              "            345,   836,   470,  1254,   262,   976,   835,   546,   607,    13,\n",
              "          50258,  5832,   815,  1560,   607,   326,   345,   836,   470,  1254,\n",
              "            262,   976,   835,   546,   607,    13, 50258,  5832,   815,  1560,\n",
              "            607,   326,   345,   836,   470,  1254,   262,   976,   835,   546,\n",
              "            607,    13, 50258,  5832,   815,  1560,   607,   326,   345,   836,\n",
              "            470,  1254,   262,   976,   835]]),\n",
              " tensor([[50257,    40,  1064,   340,  6283,   290,   290,   314,   561, 27537,\n",
              "            262, 15061, 50260,  1026,   338,  6283, 16317,    40,  1549,  4829,\n",
              "            262, 12734,   572,    13, 50258,   896,  7650, 16317,    72,  1549,\n",
              "           4829,   262, 12734,   572, 16317, 50258,   896,  7650, 16317,    72,\n",
              "           1549,  4829,   262, 12734, 16317, 50258,   896,  7650, 16317,    72,\n",
              "           1549,  4829,   262, 12734, 16317, 50258,   896,  7650, 16317,    72,\n",
              "           1549,  4829,   262, 12734, 16317, 50258,   896,  7650, 16317,    72,\n",
              "           1549,  4829,   262, 12734, 16317, 50258,   896,  7650, 16317,    72,\n",
              "           1549,  4829,   262, 12734, 16317, 50258,   896,  7650, 16317,    72,\n",
              "           1549,  4829,   262, 12734, 16317, 50258,   896,  7650, 16317,    72,\n",
              "           1549,  4829,   262, 12734, 16317]]),\n",
              " tensor([[50257,     1,  1544,   561,   307,   257,   764,   764,   764, 36450,\n",
              "           4931,    11,  3636,   470,   339,  1701, 50260,     1,   258,  1183,\n",
              "            307,   257, 36450,  4931,    11,  1839,   470,   339,  1701, 50258,\n",
              "              1,   258,   338,   257, 36450,   582, 16317,   257,  2324,   582,\n",
              "          16317,  1701, 50258,     1,   258,   338,   257,  2324,   582, 16317,\n",
              "            339,   338,   257,  2324,   582, 16317,  1701, 50258,     1,   258,\n",
              "            338,   257,  2324,   582, 16317,   339,   338,   257,  2324,   582,\n",
              "          16317,  1701, 50258,     1,   258,   338,   257,  2324,   582, 16317,\n",
              "            339,   338,   257,  2324,   582, 16317,  1701, 50258,     1,   258,\n",
              "            338,   257,  2324,   582, 16317,   339,   338,   257,  2324,   582,\n",
              "          16317,  1701, 50258,     1,   258]]),\n",
              " tensor([[50257, 11633,   345,   760,   326,   673,   973,   284,  3128, 18990,\n",
              "          21166, 50260, 11633,   345,   760,   673,   973,   284,  3128, 18990,\n",
              "          21166,    30, 50258, 11633,   345,   760,   673,   973,   284,  3128,\n",
              "          18990, 21166,    30, 50258, 11633,   345,   760,   673,   973,   284,\n",
              "           3128,   683,    30, 50258, 50258, 11633,   345,   760,   673,   973,\n",
              "            284,  3128,   683,    30, 50258, 50258,    30,   986,  7091,   973,\n",
              "            284,  3128, 18990, 21166,   986,    30, 50258,    30,   986,    30,\n",
              "            986,    30,   986,    30,   986,    30,   986,    30,   986,    30,\n",
              "            986,    30,   986,    30,   986,    30,   986,    30,   986,    30,\n",
              "            986,    30,   986,    30,   986,    30,   986,    30,   986,    30,\n",
              "            986,    30,   986,    30,   986]]),\n",
              " tensor([[50257,    32,  1178,  5054,   284,  2822,   617,  1700, 16788,    30,\n",
              "          50260,     3,    20,   329,   257,  3155,   286, 16788,    30, 50258,\n",
              "              3,    20,   329,   257,  3155, 16788,    30, 50258,     3,    20,\n",
              "            329,   326,    30, 50258,     3,    20,   329,   257,  3155, 16788,\n",
              "             30, 50258,     3,    20,    30, 50258,     3,    20,   329,   326,\n",
              "             30, 50258,     3,    20,   329,   257,  3155, 16788,    30, 50258,\n",
              "              3,    20,   329,   326,    30, 50258,     3, 16317,   329,   326,\n",
              "             30, 50258,     3,    20,   329,   326,    30, 50258,     3, 16317,\n",
              "            329,   326,    30, 50258,     3, 16317,   329,   326,    30, 50258,\n",
              "              3, 16317,   329,   326,    30, 50258,     3, 16317,   329,   326,\n",
              "             30, 50258,     3,    20,   329]]),\n",
              " tensor([[50257,  6943,  1450,   389,   407,  4988, 17679, 32940,    26,   345,\n",
              "            389,  2391,  3249,   262,  2642,   661, 50260,  1712,  1450,   389,\n",
              "            407,  4988, 17679, 32940,    26,   345,   389,  2391,  3249,   262,\n",
              "           2642,   661,    13, 50258,  1712,  1450,   389,   407,  4988, 17679,\n",
              "          32940,    26,   345,   389,  2391,  3249,   262,  2642,   661,    13,\n",
              "          50258,  1712,  1450,   389,   407,  4988, 17679, 32940,    26,   345,\n",
              "            389,  2391,  3249,   262,  2642,   661,    13, 50258,  1712,  1450,\n",
              "            389,   407,  4988, 17679, 32940,    26,   345,   389,  2391,  3249,\n",
              "            262,  2642,   661,    13, 50258,  1712,  1450,   389,   407,  4988,\n",
              "          17679, 32940,    26,   345,   389,  2391,  3249,   262,  2642,   661,\n",
              "             13, 50258,  1712,  1450,   389]]),\n",
              " tensor([[50257, 10248,   781,  1648,    12,   392,    12, 11379,   318,   645,\n",
              "          29711,  2300,    13, 50260, 11274,   781,  1648,  1222, 38744,   389,\n",
              "            645,  9707,    13, 50258, 11274,   781,  1648,  1222, 38744,   986,\n",
              "           3919, 26471,    13, 50258, 11274,   781,  1648,  1222, 38744,   986,\n",
              "           3919, 26471,    13, 50258, 11274,   781,  1648,  1222, 38744,   986,\n",
              "           3919, 26471,    13, 50258, 11274,   781,  1648,  1222, 38744,   986,\n",
              "           3919, 26471,    13, 50258, 11274,   781,  1648,  1222, 38744,   986,\n",
              "           3919, 26471,    13, 50258, 11274,   781,  1648,  1222, 38744,   986,\n",
              "           3919, 26471,    13, 50258, 11274,   781,  1648,  1222, 38744,   986,\n",
              "           3919, 26471,    13, 50258, 11274,   781,  1648,  1222, 38744,   986,\n",
              "           3919, 26471,    13, 50258, 11274]]),\n",
              " tensor([[50257,   464,  3663,   561,    11,   379,   477,  2995,    11,  1283,\n",
              "           6454,  4071,    13, 50260,  1169,  5885,   318,    11,   287,   597,\n",
              "           1339, 16317,   257,  1310,  4071,    13, 50258,   265,  1551, 16317,\n",
              "            262,  5885, 16317,   318, 16317,   257,  1310,  4071,    13, 50258,\n",
              "           1169,  1109,   326, 16317,   612, 16317,   318, 16317,   257, 16317,\n",
              "           5885, 16317,   329,   262,  2589,    13, 50258,  1169,  5885, 16317,\n",
              "            318, 16317,   326, 16317,   379,  1551, 16317,   340, 16317,  2331,\n",
              "          16317,   257,  1643,  4071,    13, 50258,  1169,  1109, 16317,   326,\n",
              "          16317,   612, 16317,   318, 16317,   257, 16317,  5885, 16317,   329,\n",
              "          16317,   262,  2589,    13, 50258,  1169,  1109, 16317,   326, 16317,\n",
              "            326, 16317,   318, 16317,   326]]),\n",
              " tensor([[50257,  8491,   345, 12724,   510,   706,   734,  1418, 19325,   661,\n",
              "          50260,    17, 11841,   661, 12724,   510,   706,   345,    30, 50258,\n",
              "             17, 11841,   661, 12724,   510,   706,   345,    30, 50258,    17,\n",
              "          11841,   661, 12724,   510,   706,   345,    30, 50258,    17, 11841,\n",
              "            661,    30, 50258,    17, 11841,   661,    30,   986, 12724,   510,\n",
              "            706,   362, 24097,   661,    30, 50258,    17, 24097,   661,   986,\n",
              "            362, 11841,   661,   986,   362, 24097,   661,   986, 50258,    17,\n",
              "          24097,   661,   986,   362, 24097,   986, 50258,    17, 24097,   986,\n",
              "            362, 24097,   986,   362, 24097,   986, 50258,    17, 24097,   986,\n",
              "            362, 24097,   986,   362, 24097,   986, 50258,    17, 24097,   986,\n",
              "            362, 24097,   986,   362, 24097]]),\n",
              " tensor([[50257, 29653,  3633,   314,   373,  3375,   284,   345,  2961,    11,\n",
              "            314, 12433,   281,  5629,   966,    13, 50260,     1,   259,   262,\n",
              "           1781,   286,   674,  2180,  5273, 16317,   314, 12433,   257,  6283,\n",
              "           1517,    13, 50258,     1,    40,  3505, 16317,   314,   373,  3375,\n",
              "          16317,   546, 16317,   262,  6283,  1517, 16317,   981,   314,   373,\n",
              "           1804,   523,    13, 50258,     1,    40,  3505, 16317,   314,  3505,\n",
              "          16317,   262,  6283,  1517, 16317,   618,   314,   373,  3375,   284,\n",
              "            345,    13, 50258,     1,    40, 16317,  3505, 16317,   262,  6283,\n",
              "           1517, 16317,   618,   314,   373,  3375,   284,   345,    13, 50258,\n",
              "              1, 50258,     1, 12518, 16317,   314, 16317, 12086, 16317,   326,\n",
              "          16317,   314, 16317, 12086, 16317]]),\n",
              " tensor([[50257, 11337,   326,   477,   503,   319,   534,   898,    11,   750,\n",
              "            345,    30, 50260, 26875,   340,   503,  3511,    11,   750, 21349,\n",
              "             30, 50258,  4598,   345,   760,   644,   339,   750,    11,   788,\n",
              "             30, 50258,  4598,   345,   760,   644,   339,   750,    30, 50258,\n",
              "           5832,   760,   644,   339,   750,    11,   788,    30, 50258,   568,\n",
              "             11,   466,   345,   760,    30, 50258,  5832,   760,   644,   339,\n",
              "            750,    30,   986, 50258,  4598,   345,   760,    30,   986,   788,\n",
              "            986,   466,   345,   760,    30, 50258,   568,   986,   466,   345,\n",
              "            760,    30,   986,   788,   986,   466,   345,   760,    30, 50258,\n",
              "            568,   986,   466,   345,   760,    30,   986,   788,   986,   644,\n",
              "             30, 50258,    30,   986,   788]]),\n",
              " tensor([[50257,    40,  1656,   284,   423, 23407,   257, 11363, 18307,  4369,\n",
              "            286,   617,  1611,    13, 50260,    40,  1101,  4385,   284,   423,\n",
              "          23407,   257, 11363, 18307,  4369,    13, 50258,    40,  4724,   314,\n",
              "           1392,  6639,    13, 50258,    40,  1101, 14112,   351,  1223,    13,\n",
              "          50258,    40,  1101, 14112,   986,   290,   314,  1101,  4385,   284,\n",
              "            423, 23407,  1223,    13, 50258,    40,  4724,   986,   314,  1392,\n",
              "           1223,   986, 50258,    40,  4724,   986,   314,  1101, 14112,   986,\n",
              "            351,  1223,   986, 50258,    40,  4724,   986,   314,  1101, 14112,\n",
              "            986,   351,  1223,   986, 50258,   986,   314,  4724,   986,   314,\n",
              "           1101,   986,   351,  1223,   986, 50258,   986,   314,  4724,   986,\n",
              "            314,  1101,   986, 14112,   986]]),\n",
              " tensor([[50257,  3792,   262,   649,  5156,   257,   467,  1525,   393,   257,\n",
              "           2576, 50260,  1169,   649,  5156,   318,   257,   467,  1525,   393,\n",
              "            257,  2576,    13, 50258,  1169,   649,  5156,   318,   257,   467,\n",
              "           1525,   393,   257,  2576,    13, 50258,  1169,   649,  5156,   318,\n",
              "            257,   467,  1525,   393,   257,  2576,    13, 50258, 50258,  1169,\n",
              "            649,  5156,   318,   257,   467,  1525,   393,   257,  2576,    13,\n",
              "          50258, 50258,  1169,   649,  5156,   318,   257,   467,  1525,   393,\n",
              "            257,  2576,    13, 50258, 50258, 50258, 50258,  1169,   649,  5156,\n",
              "            318,   257,   467,  1525,   393,   257,  2576,    13, 50258, 50258,\n",
              "           1169,   649,  5156,   318,   257,   467,  1525,   393,   257,  2576,\n",
              "             13, 50258, 50258, 50258, 50258]]),\n",
              " tensor([[50257,  1639,   761,   284,   760,   611,   339, 10408,   607,   736,\n",
              "          50260,  4598,   334,   760,   611,   339, 10408,   607,   736,    13,\n",
              "          50258,  5832,   761,   284,   760,   611,   339, 10408,   607,   736,\n",
              "             13, 50258,  5832,   761,   284,   760,   611,   339, 10408,   607,\n",
              "            736,    13, 50258,  5832,   761,   284,   760,   611,   339, 10408,\n",
              "            607,   736,    13, 50258,  5832,   761,   284,   760,   611,   339,\n",
              "          10408,   607,   736,    13, 50258,  5832,   761,   284,   760,   611,\n",
              "            339, 10408,   607,   736,    13, 50258,  5832,   761,   284,   760,\n",
              "            611,   339, 10408,   607,    13, 50258,  5832,   761,   284,   760,\n",
              "            611,   339, 10408,   607,    13, 50258,  5832,   761,   284,   760,\n",
              "            611,   339, 10408,   607,    13]]),\n",
              " tensor([[50257, 11028,    11,   262, 10846,   422,   262, 11550,   262,  4382,\n",
              "           6810,    13, 50260,  1169, 10846,   508,  2499,   379,   262, 11550,\n",
              "            373,  6655,    13, 50258,  1169,  2415,   508,  2499,   287,   262,\n",
              "          11550,   373,  6655,    13, 50258, 50258, 50258,  1169,  2415,   508,\n",
              "           2499,   612,   373,  6655,    13, 50258, 50258, 50258,  1169,  2415,\n",
              "            508,  2499,   612,   373,    13,   764,   764,   764,   262,   530,\n",
              "            508,   373,   612,    13, 50258, 50258, 50258, 50258, 50258,  1169,\n",
              "           2415,   508,  2499,   612,   373,    13,   764,   764,   764,   262,\n",
              "            530,   508,   373,   612,    13, 50258, 50258, 50258, 50258, 50258,\n",
              "           1169,   530,   508,   373,   612,   986,   373,   986,   373,   986,\n",
              "           6655,    13, 50258, 50258, 50258]]),\n",
              " tensor([[50257,  1639,   761,   284,   651,  2354,   284,   257,  1295,   351,\n",
              "            645,  5509,  3002,   810,   345,   460,   470,   307, 12326,    13,\n",
              "          50260,  1136,   503,   286,   262,  2156,   810,   612,   338,   645,\n",
              "           5509,  3002,    13, 50258,  5832,   423,   284,   651,   503,   286,\n",
              "            262,  2156,   986,   810,   612,   338,   645,  5509,  3002,   986,\n",
              "            290,   345,   821,   407, 12326,    13, 50258,  1136,   503,   986,\n",
              "            612,   338,   645,  5509,  3002,   986,   290,   345,  1839,   470,\n",
              "            307,  1775,    13, 50258,  1136,   503,   986,   345,   821,   407,\n",
              "            612,   986,   345,   821,   407,   612,   986,   345,   821,   407,\n",
              "            612,   986,   345,   821,   407,   612,   986,   345,   821,   407,\n",
              "            612,   986,   345,   821,   407]]),\n",
              " tensor([[50257,  1858,   373,   257,  1263,  3359,   329,  4333, 20641,    13,\n",
              "          50260,  8117,   373,   257,  3236,   905,   329,  1176, 11975,    13,\n",
              "          50258,  1169,  1263,   905,   373,   329,  1176, 11975,    13, 50258,\n",
              "           8117,   373,   257,  1263,   905,   329,  1176, 11975,    13, 50258,\n",
              "           1169,  1263,   905,   373,   329,   326,   986, 50258,  1169,  1263,\n",
              "            905,   373,   329,   326,   986, 50258,  1169,  1263,   905,   986,\n",
              "            329,   326,   986,   329,   326,   986, 50258,   986,   329,   326,\n",
              "            986,   329,   326,   986, 50258,   986,   329,   326,   986,   329,\n",
              "            326,   986, 50258,   986,   329,   326,   986,   329,   326,   986,\n",
              "          50258,   986,   329,   326,   986, 50258,   986,   329,   326,   986,\n",
              "          50258,   986,   329,   326,   986]]),\n",
              " tensor([[50257,    40,   716,  6427,   262, 13580,    11,  1802,     4,   284,\n",
              "            683,    13, 50260,    40,  1101,  3501,   683,  1802,     4,   286,\n",
              "            262, 13580,    13, 50258,    40,  1101,  1016,   284,  1577,   683,\n",
              "            262, 13580,    11,  1802,  7225, 50258,  3064,     4,   314,  1101,\n",
              "            351,   683,   986, 50258,    40,  1101,  3501,   683,   262, 19262,\n",
              "            986, 50258,  3064,     4,   986,   326,   338,   340,   986,   314,\n",
              "           1101,   351,   683,   986, 50258,  1802,  7225, 50258,   986,   314,\n",
              "           1101,   351,   683,   986,  1802,  7225, 50258,   986,   314,  1101,\n",
              "            351,   683,   986,  1802,  7225, 50258,   986,   314,  1101,   986,\n",
              "           1802,  7225, 50258,   986,   314,  1101,   986,  1802,  7225, 50258,\n",
              "            986,   314,  1101,   986,  1802]]),\n",
              " tensor([[50257,  2437,   890,   314,  3332,   523,    11,   314,   466,   407,\n",
              "            760,    13, 50260,  4919,   890,  1312,  3332,   612,    11,  1312,\n",
              "          17666,   760,    13, 50258,  4919,   890,  1312,  3332,   612,   986,\n",
              "           1312, 17666,   760,    13, 50258,    72, 17666,   760,   986,   703,\n",
              "            890,   750,   340,  1011,    30, 50258,  4919,   890,   750,   340,\n",
              "           1011,   986,  1312, 17666,   760,   986, 50258,  4919,   890,   750,\n",
              "            340,  1011,   986, 50258,    72, 17666,   760,   986,   703,   890,\n",
              "            750,   340,  1011,   986, 50258, 50258,    72, 17666,   760,   986,\n",
              "            703,   890,   750,   340,  1011,   986,   703,   890,   750,   340,\n",
              "           1011,   986, 50258, 50258, 50258,    72, 17666,   760,   986,   703,\n",
              "            890,   750,   340,  1011,   986]]),\n",
              " tensor([[50257,  3347,   743,   423,   550,  7309,  8185,   379,   530,   640,\n",
              "            393,  1194, 50260,  7091,   743,   423,   550,  7309,  8185,   379,\n",
              "            530,   640,   393,  1194,    13, 50258,  7091,   743,   423,   550,\n",
              "           7309,  8185,   379,   530,   640,   393,  1194,    13, 50258,  7091,\n",
              "            743,   423,   550,  7309,  8185,   379,   530,   640,   393,  1194,\n",
              "             13, 50258,  7091,   743,   423,   550,   340,  1760,   379,   530,\n",
              "            640,   393,  1194,    13, 50258,  7091,   743,   423,   550,   340,\n",
              "           1760,   379,   530,   640,   393,  1194,    13, 50258, 50258,  7091,\n",
              "            743,   423,   550,   340,  1760,   379,   530,   640,   393,  1194,\n",
              "             13, 50258,  7091,   743,   423,   550,   340,  1760,   379,   530,\n",
              "            640,   393,  1194,    13, 50258]]),\n",
              " tensor([[50257,   464,  2607,   286,   262,  2422,  8153,   655, 28077,    11,\n",
              "          15967,    13, 50260,  1169,  2422,  8153,   338,  2607, 28077,    11,\n",
              "          15967,    13, 50258,  1169,  8153,   338,  2607,   318, 32333,    11,\n",
              "          15967,    13, 50258,  1169,  2607,   318,   287,  3877,   286,   262,\n",
              "           2422,  8153,    13, 50258,  1169,  2422,  8153,   318,   612,    13,\n",
              "          50258,  1169,  2422,  8153,   318,   612,    13, 50258,  1169,  2607,\n",
              "            318,   852,   973,    11, 15967,    13, 50258,  1169,  2422,  8153,\n",
              "            318,   612,    13, 50258,  1169,  2422,  8153,   318,   612, 16317,\n",
              "          50258,  1169,  2300,   318,   852,  1760, 16317,   290,   523,   318,\n",
              "            262,  2607,    13, 50258, 50258,  1169,  2300,   318,   852,  1760,\n",
              "          16317,   290,   523,   318,   262]]),\n",
              " tensor([[50257,  1544,   318,  7558, 16143,   379,   345,    11,   318,   339,\n",
              "            407, 50260,  1544,   338, 16143,   379,   345,   477,   262,   640,\n",
              "            986,   392,   339,   338,   407,   772,   534, 13850,    13, 50258,\n",
              "           1544,   338, 16143,   379,   345,   477,   262,   640,   986,   392,\n",
              "            339,   338,   407,   772,   534, 13850,    13, 50258, 50258,  1544,\n",
              "            338, 16143,   379,   345,   986,   392,   339,   338,   407,   772,\n",
              "            534, 13850,    13, 50258, 50258, 13909,     6,    50,  3563, 12203,\n",
              "           2751,  5161,  7013, 11096,  3336, 20460,   986,  6981, 11179,     6,\n",
              "             50,  5626, 45886, 16592, 16494,    56,    37,  7112, 10619,    13,\n",
              "          50258,  1544,   338, 16143,   379,   345,   986,   392,   339,   338,\n",
              "            407,   772,   534, 13850,    13]]),\n",
              " tensor([[50257,     1,  3792,  2622,   284,  3141,   262, 41337,   981,   345,\n",
              "           1057, 20001, 26075,    13, 50260,     1, 12518,   345,   821,   287,\n",
              "           3141, 16317,   345,   423,   284,  3141,   262, 41337,    13, 50258,\n",
              "              1,   292,   329,   262,  1907, 16317,   345,   423,   284,  3141,\n",
              "            262,  5373, 16317,   287,   262,  1339, 16317,   286,   262, 20001,\n",
              "          16317,    13, 50258,     1,  5832,   423,   284,  3141, 16317,   262,\n",
              "           3344, 16317,   287,   262,  1339, 16317,   286,   262, 11026, 16317,\n",
              "             13, 50258,     1,  5832,   423, 16317,   284,  3141, 16317,   262,\n",
              "           3344, 16317,   287,   262,  1339, 16317,   286,   262, 40733, 16317,\n",
              "             13, 50258,     1,  5832, 16317,   423, 16317,   284,  3141, 16317,\n",
              "            262,  3344, 16317,   287,   262]]),\n",
              " tensor([[50257,  1135,   821,  1016,   284,  1577,  5205,   284,   790,  7541,\n",
              "            319,   262, 10283,    13, 50260,   732,  1183,   905,   345,   262,\n",
              "           7541,   338, 12566,    13, 50258,   732,  1183,   905,   345,   262,\n",
              "           7541,   338,  8408,    13, 50258,   732,  1183,   905,   345,   262,\n",
              "           7541,   338,  3307,    13, 50258,   732,  1183,  1560,   345,   546,\n",
              "            262,  7541,    13,   775,  1183,  1577,   345,   262,  5205,    13,\n",
              "          50258,   732,  1183,  1560,   345,   546,   340,    13,   775,  1183,\n",
              "            905,   345,   262,  5986,    13, 50258,   732,  1183,   905,   345,\n",
              "            262,  3307, 16317,   379,   477,   262, 18505,    13, 50258,   732,\n",
              "           1183,  1560,   345, 16317,   703,   356,  1183,   905,   345,   262,\n",
              "          12566, 16317,   287,   477,   262]]),\n",
              " tensor([[50257,    40,  1842,   262,  4097,  3469,  3596, 50260,    72,  1842,\n",
              "           4077,  1110,    13, 50258,    72,  1842,  4077,  1110,    13, 50258,\n",
              "             72,  1842,  4077,  1110,    13, 50258,    72,  1842,  4077,  1110,\n",
              "             13, 50258,    72,  1842,  4077,  1110,    13, 50258,    72,  1842,\n",
              "           4077,  1110,    13, 50258,    72,  1842,  4077,  1110,    13, 50258,\n",
              "             72,  1842,  4077,  1110,    13, 50258,    72,  1842,  4077,  1110,\n",
              "             13, 50258,    72,  1842,  4077,  1110,    13, 50258,    72,  1842,\n",
              "           4077,  1110,    13, 50258,    72,  1842,  4077,  1110,    13, 50258,\n",
              "             72,  1842,  4077,  1110,    13, 50258,    72,  1842,  4077,  1110,\n",
              "             13, 50258,    72,  1842,  4077,  1110,    13, 50258,    72,  1842,\n",
              "           4077,  1110,    13, 50258,    72]]),\n",
              " tensor([[50257,  5492,   423,  1257,   351,   340,    11,   878,   314,   460,\n",
              "            923,  1262,   340,  3589, 50260, 11980,  1257,   351,   340,   878,\n",
              "            314,   923,  1262,   340,  3589,    13, 50258, 14150,  1257,   351,\n",
              "            340,   878,  1312,   779,   340,  3589,    13, 50258, 50258, 14150,\n",
              "           1257,   351,   340,    11,   878,  1312,   779,   340,  3589,    13,\n",
              "          50258, 50258,   986,   878,  1312,   779,   340,  1312,  1101,  8066,\n",
              "            466,   340,    13, 50258,   986,   423,  1257,   351,   340,   986,\n",
              "            878,  1312,   923,    13, 50258,   986,   423,  1257,   351,   340,\n",
              "            986,   878,  1312,   923,    13, 50258,   986,   423,  1257,   986,\n",
              "          50258,   986,   878,  1312,   923,   986, 50258,   986,   423,  1257,\n",
              "            986,   351,   340,   986,   878]]),\n",
              " tensor([[50257, 35392, 12681,  6317,  3136,  2714,   319,   262,   412,   463,\n",
              "           4108, 27187,   590,  6831,   743,   307,  9167,   416,   262,  1171,\n",
              "             13, 50260,  1169,  1171,   743,  2581,   262,  6447,   286, 12681,\n",
              "          12737,   284,   262,   412,   463,  4108, 27187,   590,  6831,    13,\n",
              "          50258,  1169,  2650,   286, 12681, 12737,   287,   262,   412,   463,\n",
              "           4108, 27187,   590,  6831,   743,   307,  9167,   416,   262,  1171,\n",
              "             13, 50258,  1169, 13019,   743,   635,   307,  9167,   329,   262,\n",
              "           1171,    13, 50258,  1169,  6317,   743,   307,  9167,   287,   262,\n",
              "           1339,   286,   262, 12681, 12737,    13, 50258,  1169,  1321,   743,\n",
              "            635,   307,  9167,   329,   262,  2650,    13, 50258,  1169,  3074,\n",
              "            743,   307,  3417,   287,   262]]),\n",
              " tensor([[50257,  2953,   262,   640,   286,   534,  2457, 12928,    11,  1793,\n",
              "            481,  2148,   281,  4296, 50260, 12518,   345,   821,  4305,    11,\n",
              "           1793,   481,  1560,   345,    13, 50258, 50258,  1169,   640,   345,\n",
              "            821,  4305,    11,  1793,   481,  1560,   345,    13, 50258, 12518,\n",
              "            345,   821,  4305,    11,   339,  1183,  1560,   345,    13, 50258,\n",
              "          50258, 12518,   345,   821,  1016,    11,   339,  1183,  1560,   345,\n",
              "             13, 50258, 50258,   258,  1183,  1560,   345,   706,   534, 12928,\n",
              "             13, 50258, 50258,   258,  1183,  1560,   345,   546,   340, 16317,\n",
              "            618,   356,  2666, 16317, 50258, 50258,   258,  1183,  1560,   345,\n",
              "          16317,   706,   356,   467, 16317,   339,  1183,  1560,   345,    13,\n",
              "          50258, 50258,   986,   618,   356]]),\n",
              " tensor([[50257,    40,   716,  7926,   673,   468,   407,  9373,   534,  6105,\n",
              "          50260,    72,  1101,  7926,   673,   468,   407,  9373,   534,  1808,\n",
              "           9380,    13, 50258,    72,  1101,  7926,   673,   468,   407,  9373,\n",
              "            534,  1808,  9380,    13, 50258, 41599,   673,  5818,   470,  9373,\n",
              "            534,  1808,    13, 50258,    72,  1101,  7926,   673,  5818,   470,\n",
              "           9373,   534,  1808,    13, 50258, 41599,   986,   673,  5818,   470,\n",
              "           9373,   534,  1808,    13, 50258, 41599,   986,   673,  5818,   470,\n",
              "           9373,   534,  1808,    13, 50258, 41599,   986,   673,  5818,   470,\n",
              "           9373,   534,  1808,    13, 50258, 41599,   986,   673,  5818,   470,\n",
              "           9373,   534,  1808,    13, 50258,    72,  1101,  7926,   986,   673,\n",
              "           5818,   470,  9373,   534,  1808]]),\n",
              " tensor([[50257, 16973,   340,   597,   922,   314,   387,  1151,  1775,   340,\n",
              "           1865, 50260, 20839,  1312,  1683,   766,   340,   922,    30, 50258,\n",
              "             72,  4398,   470,  1775,   340,  1865,    11,   373,   340,   922,\n",
              "             30, 50258,    30,   986,   373,   340,   922,  1576,   329,   502,\n",
              "             30, 50258,    30,   986,   373,   340,   922,  1576,   329,   502,\n",
              "             30, 50258,    30,   986,   373,   340,   922,  1576,   329,   502,\n",
              "             30, 50258,    30,   986, 50258,    30,   986,   373,   340,   922,\n",
              "           1576,   329,   502,    30, 50258,    30,   986, 50258,    30,   986,\n",
              "            373,   340,   922,  1576,   329,   502,    30, 50258,    30,   986,\n",
              "             30,   986,   373,   340,   922,  1576,   329,   502,    30, 50258,\n",
              "             30,   986,    30,   986,    30]]),\n",
              " tensor([[50257,  4561,   437,   517,  3081,   640,   351,   683,   416,  3375,\n",
              "            290,   781, 35355, 50260,  4561,   437,   517,  3081,   640,   351,\n",
              "            683,   416,  3375,   284,   683,   290,   781, 35355,    13, 50258,\n",
              "           2777,   437,   517,  3081,   640,   351,   683, 16317,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,  8491,   612,   597,   584,  6741,   345,  1549,   588,   284,\n",
              "          22127,   284,   379,   428,   640,    30, 50260,  4598,   345,   765,\n",
              "            284, 22127,   284,   584,  6741,   783,    30, 50258,  5171,   345,\n",
              "          22127,   284,   584,  6741,   783,    30, 50258,  4598,   345,   765,\n",
              "            284,   466,   326,    30, 50258,  5171,   345,   783,    30, 50258,\n",
              "            533,   345, 22127,   278,   284,   584,  6741,    30, 50258,  5171,\n",
              "            345,   466,   326,    30, 50258,  5171,   345,   466,   326,    30,\n",
              "          50258,   533,   345,    30,   986,   783,   986,   466,   345,   765,\n",
              "            284,    30, 50258,  4598,   345,    30,   986,   460,   345,    30,\n",
              "            986,   466,   345,    30,   986,   466,   345,    30,   986,   466,\n",
              "            345,    30,   986,   466,   345]]),\n",
              " tensor([[50257, 13300,   326,   338,   329, 21262,   284,   466, 17291,  1568,\n",
              "             13, 50260,  1169, 21262,   481,   423,   284,   466,   340,  1568,\n",
              "             13, 50258, 25991,   484,  1183,   466,   340,  1568, 16317,   329,\n",
              "          21262,    13, 50258, 25991, 16317,   326,   338,   329, 21262, 16317,\n",
              "            284,   466, 16317,  1568, 16317,    13, 50258, 25991, 16317,   326,\n",
              "            338,   329, 21262, 16317,   284,   466, 16317, 16317,   329, 16317,\n",
              "            606, 16317,    13, 50258, 25991, 16317,   326, 16317,   318, 16317,\n",
              "            329, 16317,   606, 16317, 16317,    13, 50258, 25991, 16317,   326,\n",
              "          16317,   318, 16317,   329, 16317,   606, 16317,    13, 50258, 25991,\n",
              "          16317,   326, 16317,   318, 16317,   329, 16317,   606, 16317,    13,\n",
              "          50258, 25991, 16317,   326, 16317]]),\n",
              " tensor([[50257, 14385,   611,   345,   588,   606, 50260,   361,   334,   588,\n",
              "            606,   788,  7926,    13, 50258,   361,   334,   588,   606,    11,\n",
              "            788,  7926,    13, 50258,   361,   334,   588,   606,    11,   788,\n",
              "           7926,    13, 50258,   361,   334,   588,   606,    11,   788,  7926,\n",
              "             13, 50258,   361,   334,   588,   606,    11,   788,  7926,    13,\n",
              "          50258,   361,   334,   588,   606,    11,   788,  7926,    13, 50258,\n",
              "            361,   334,   588,   606,    11,   788,  7926,    13, 50258,   361,\n",
              "            334,   588,   606,    11,   788,  7926,    13, 50258,   361,   334,\n",
              "            588,   606,    11,   788,  7926,    13, 50258,   361,   334,   588,\n",
              "            606,    11,   788,  7926,    13, 50258,   361,   334,   588,   606,\n",
              "             11,   788,  7926,    13, 50258]]),\n",
              " tensor([[50257,  2990,  1549,   307,  8011,   278,   510,   262,   649, 17301,\n",
              "           6973,  9975,    13, 50260,  9930,   821,  1016,   284,  2018,   262,\n",
              "            649,  1630,  6103,  1909,    13, 50258,  1122,   432,    11,   484,\n",
              "           1183,  8011,   510,   262,   649,  6973,   329,   262, 17301,    13,\n",
              "          50258,  1122,   432, 16317,   484,  1183,  2018,   262,  6973, 16317,\n",
              "            284,   262,   649, 17301,    13, 50258,   732,  1183,   466,   340,\n",
              "          16317,   329,  1909, 16317,   484,  1183,  2018, 16317,   262,  1630,\n",
              "           6103, 16317,   284,   262,  4572,    13, 50258,   732,  1183,   466,\n",
              "            340, 16317,   329,   428, 16317,   484,  1183,   466,   340, 16317,\n",
              "            329,  1909, 16317,   329,   428, 16317,   356,  1183,   466,   340,\n",
              "          16317,   329,  1909, 16317,   329]]),\n",
              " tensor([[50257,  1639,  3128,  3511,  1320,   857,   407,  2128,   588,   340,\n",
              "            815, 50260,   270,  5238,   588,   345,   821, 10691,  3511,   986,\n",
              "          50258,   270,  5238,   588,   345,   821, 10691,  3511,   986, 50258,\n",
              "           1026,  5238,   588,   345,   821, 10691,  3511,   986, 50258,  5832,\n",
              "            821,   407,    13, 50258,     7,  1026,   338,   407,   588,   326,\n",
              "            379,   477,   986,   340,  5238,   588,   345,   821, 10691,  2014,\n",
              "          50258,     7,  1026,   338,   407,   588,   326,   986,   340,  5238,\n",
              "            588,   345,   821, 10691,  2014, 50258,     7,  1026,   338,   407,\n",
              "            986,   340,   338,   986,   340,   338,   986,   340,   338,   986,\n",
              "            340,   338,   986,   340,   338,   986,   340,   338,   986,   340,\n",
              "            338,   986,   340,   338,   986]]),\n",
              " tensor([[50257, 11041,   262, 21194,   560,   284,   804,   510, 22594,  2846,\n",
              "           1043,   287,   597,   720,    58, 14406, 12453,    60,  3586,    13,\n",
              "          50260,  1904,   262, 21194,   560,   284,   804,   510, 22594,  2846,\n",
              "            287,   597,   720,    58, 14406, 12453,    60,  3586,    13, 50258,\n",
              "          50258,  1904,   262, 21194,   560,   284,   804,   510, 22594,  2846,\n",
              "            287,   597,   720,    58, 14406, 12453,    60,  3586,    13, 50258,\n",
              "          50258, 50258,  1904,   262, 21194,   560,   284,   804,   510, 22594,\n",
              "           2846,   287,   597,   720,    58, 14406, 12453,  4083, 50258, 50258,\n",
              "          50258,     7,    64,     8,   287,   262,  1339,   286,   720,    58,\n",
              "          14406, 12453,  4357,   262, 21194,   560,  2236,   307,   973,   329,\n",
              "            262, 11795,   286,   262,  6439]]),\n",
              " tensor([[50257, 23061,    11,   938,   614,   484, 18240,   616,  7161,  1165,\n",
              "            986,   523,   314, 27946,   340,   572,    13, 50260, 12957,   614,\n",
              "          16317,   484, 18240,   616,  7161, 16317,   523,   314, 27946,   340,\n",
              "            572, 16317, 50258, 50258, 50258,   986,   314, 27946,   616,  7161,\n",
              "          16317,   938,   614, 16317,   484, 18240,   340, 16317, 50258, 50258,\n",
              "            986,   290, 16317,   484, 18240,   340, 16317,   938,   614, 16317,\n",
              "            314, 27946,   340, 16317, 50258,   986,   523, 16317,   314, 27946,\n",
              "            340, 16317, 50258, 16317,   326,   338,  1521, 16317,   314, 27946,\n",
              "            616,  7161, 16317,   938,   614, 16317,    13, 50258,   986,   780,\n",
              "          16317,   484, 18240,   340, 16317, 50258, 16317,   326,   338,  1521,\n",
              "          16317,   314, 27946,   340, 16317]]),\n",
              " tensor([[50257, 10044,  1636,  3888,  1088,   257,  1643,    11,   788, 35622,\n",
              "            284,   257,  5228,   355, 47977,  1718,   257,  2239,   287,   465,\n",
              "           4571,    13, 50260, 16305,  1559,  3888,  1088,   257,  1310,    11,\n",
              "            788, 35622,   284,   262,  5228,    13, 50258, 16305,  1559,  3888,\n",
              "           1088,   257,  1310,    11,   788, 35622,   284,   262,  5228,    13,\n",
              "          50258,  8524,   339,  1816,   736,   284,   262,  5228,    13, 50258,\n",
              "           8524,   339,  1816,   736,   284,   262,  5228,    13, 50258,   568,\n",
              "            339,  1816,   257,  1310,    13, 50258,   568,   339,  1816,   257,\n",
              "           1310,    13, 50258,  8524,   339,  1816,   284,   262,  5228,    13,\n",
              "          50258,   568,   339,  1816,   612,    13, 50258,   568,   339,  1816,\n",
              "            612,    13, 50258,   568,   339]]),\n",
              " tensor([[50257,  3237,   428,   640,   345,  1053,   550,   257, 17214,    30,\n",
              "          50260,  5832,  1053,   550,   257, 17214,   477,   262,   640,    30,\n",
              "          50258,  5832,  1053,   587,   351,   428, 17214,   329,   477,   262,\n",
              "            640,    30, 50258,  5832,  1053,   587,   351,   607,   329,   477,\n",
              "            777,   812,    30, 50258,  5832,  1053,   587,   351,   607,   329,\n",
              "            477,   428,   640,    30, 50258, 20839,   345,   423,   257, 17214,\n",
              "            329,   326,    30, 50258, 20839,   345,   423,   257, 17214,   329,\n",
              "            326,    30, 50258,  1640,   477,   326,    11,   345,  1053,   550,\n",
              "            607,    30, 50258,  5832,  1053,   587,   351,   607,   329,   477,\n",
              "            428,   640,    30, 50258, 20839,   345,   423,   257, 17214,   329,\n",
              "            326,    30, 50258, 20839,   345]]),\n",
              " tensor([[50257,     1,  1639,  2082,   701,   832,   502,   588,   257,  3931,\n",
              "            338, 28633, 50260,     1,  5832,   821, 19280,   502,   510,   588,\n",
              "            257,  3931, 28633,   526, 50258,     1,  5832,   821, 19280,   502,\n",
              "            510,   588,   257,  3931, 28633,   526, 50258,     1,  5832,   821,\n",
              "          19280,   502,   510,   588,   257,  3931, 28633,   526, 50258,   986,\n",
              "          50258,   986,   588,   257,  3931, 28633, 16317, 50258,   986,   588,\n",
              "            257,  3931, 28633, 16317, 50258,   986,   588,   326, 16317, 50258,\n",
              "            986,   588,   326, 16317,   588, 16317,   326, 16317,   329,  1654,\n",
              "            986, 50258,   986,   329,  1654, 16317, 16317,   986,   340, 16317,\n",
              "            318, 16317,   262, 16317,  1517, 16317,   986, 50258,   986,   329,\n",
              "           1654, 16317, 16317, 16317, 16317]]),\n",
              " tensor([[50257,  7447,  2105,   287, 23994,    11,   339,  6793,   257, 18355,\n",
              "            278,  6611,   284,   262,   582,   338, 19921,    13, 50260,   258,\n",
              "          21376,   465, 18606,   656,   262,   582,   338, 19921,   290,   788,\n",
              "          10764,  2952,    13, 50258,   258, 25436,   262,   582,   287,   262,\n",
              "          19921,   290,  2952, 10764,   287,    13, 50258,   258, 25436,   683,\n",
              "            287,   262, 27105,    11,   290,   788, 10764,  2952,    13, 50258,\n",
              "            258, 25436,   683,   287,   262, 27105,    11,   290,   788,    11,\n",
              "            329,   257,  2589,    11,   339,  6204,   878,   683,    13, 50258,\n",
              "            258,   373,   287,   257, 23290,    11,   290,   788,    11,   339,\n",
              "          10764,  2952,    13, 50258,   258, 25436,   683,   287,   262,  7721,\n",
              "             11,   290,   788,    11,   329]]),\n",
              " tensor([[50257,   464, 10106, 13176,   262, 21885,    83,   321,  3599,   284,\n",
              "            895,    68,   694,   340,    13, 50260,  1169,  9591, 13176,   262,\n",
              "          21885,    83,   321,   290,  2067,   895,  5430,   340,    13, 50258,\n",
              "           1169,  9591, 13176,   262, 21885,    83,   321,   290,  2067,   895,\n",
              "           5430,   340,    13, 50258,  1169,  9591, 13176,   262, 21885,    83,\n",
              "            321,   290,  2067,   895,  5430,   340,    13, 50258,  1169,  9591,\n",
              "          13176,   262, 21885,    83,   321,   290,  2067,   895,  5430,   340,\n",
              "             13, 50258,  1169,  9591, 13176,   262, 21885,    83,   321,   290,\n",
              "           2067,   895,  5430,   340,    13, 50258,  1169,  9591, 13176,   262,\n",
              "          21885,    83,   321,   290,  2067,   895,  5430,   340,    13, 50258,\n",
              "           1169,  9591, 13176,   262, 21885]]),\n",
              " tensor([[50257,  1858,   318,   881,   546,   514,   345,   466,   407,   760,\n",
              "             13, 50260,  5832,   836,   470,   760,   881,   546,   514,    13,\n",
              "          50258,  5832,   836,   470,   760,   881,   546,   514,    13, 50258,\n",
              "           5832,   836,   470,   760,   881,   546,   514,    13, 50258,  5832,\n",
              "            821,   407,  1654,   546,   340,    13, 50258,  5832,   836,   470,\n",
              "            760,   881,   546,   514,    13, 50258,  5832,   836,   470,   760,\n",
              "            881,   546,   340,    13, 50258,   732,   821,   407,  1165,  1654,\n",
              "            546,   340,    13, 50258,  5832,   836,   470,   760,   881,   546,\n",
              "            340,    13, 50258,  5832,   836,   470,   760,   881,   546,   340,\n",
              "             13, 50258,   732,   821,   407,  1654,   546,   340,    13, 50258,\n",
              "            732,   836,   470,   760,   881]]),\n",
              " tensor([[50257,    40,   466,   407,   423,   257,  4004,  3496, 50260,    72,\n",
              "          17666,   423,   257,   277,  1015,  3496,   996,    13, 50258,    72,\n",
              "          17666,   423,   257,   277,  1015,  3496,   996,    13, 50258,    72,\n",
              "          17666,   423,   257,   277,  1015,  3496,   996,    13, 50258, 50258,\n",
              "             72, 17666,   423,   257,   277,  1015,  3496,   996,    13, 50258,\n",
              "             72, 17666,   423,   257,   277,  1015,  3496,   996,    13, 50258,\n",
              "          50258, 50258,    72, 17666,   423,   257,   277,  1015,  3496,   996,\n",
              "             13, 50258, 50258,    72, 17666,   423,   257,   277,  1015,  3496,\n",
              "            996,    13, 50258, 50258, 50258,    72, 17666,   423,   257,   277,\n",
              "           1015,  3496,   996,    13, 50258, 50258, 50258, 50258,    72, 17666,\n",
              "            423,   257,   277,  1015,  3496]]),\n",
              " tensor([[50257,     1,    41,   519,   616, 22662,   757,   290,   314,  1183,\n",
              "            423,   616,  1117, 13670,  1234,   257,  1020, 14452,   866,   534,\n",
              "          13589,   526, 50260,     1,    40,  1183,   423,   257,  6253,  1234,\n",
              "            257, 12774,   287,   534, 13589,   757,   526, 50258,     1,    40,\n",
              "           1183,   787,   345,   257,  6253,   284,  1234,   257, 12774,   287,\n",
              "            534,  1021,   526, 50258,     1,    40,  1183,   651,   345,   257,\n",
              "           6253,   329,   257, 12774,   526, 50258,     1,    40,  1183,  1577,\n",
              "            345,   257,  6253,   329,   262,  8875,   526, 50258,     1,    40,\n",
              "           1183,  1011,  1337,   286,   340,  1752,   517, 16317,   329,   262,\n",
              "          11060, 16317,   286,   257,  6253, 16317,   329,   262,  1332, 16317,\n",
              "            286,   262, 33519,   526, 50258]]),\n",
              " tensor([[50257,  2348,   292,    11,  3272,    12,  3642, 24979,   318,  1327,\n",
              "            284,  3368,    13, 50260,   403,  6668, 16317,   340,   318,  2408,\n",
              "          16317,   284,  3368,   262,  4104,   286, 10280,    13, 50258,   403,\n",
              "           6668, 16317,   340,   318,  2408, 16317,   284,  3368,   262,  4104,\n",
              "          16317,   286,   262, 10280,    13, 50258,   403,  6668, 16317,   340,\n",
              "            318, 16317,  2408, 16317,   284,  3368, 16317,   262,  4104, 16317,\n",
              "            286,   262,  4369,    13, 50258,   403,  6668, 16317,   340,   318,\n",
              "          16317,  2408, 16317,   284, 16317,  3368, 16317,   262,  4104, 16317,\n",
              "            286,   262, 10280,    13, 50258,   403,  6668, 16317,   340,   318,\n",
              "          16317,  2408, 16317,   284, 16317,  3368, 16317,   262,  4104, 16317,\n",
              "            286,   262,  4369,    13, 50258]]),\n",
              " tensor([[50257,   464,  3657,   836,   470,  4174,   284,   502,    13,   314,\n",
              "           1101, 13068,   329,  1115,  4553,  3840,    13, 50260,  1169,  1099,\n",
              "           8991,   691,   284,   502,   986,  1312,  1101, 13068,   329,  1115,\n",
              "           3840,    13, 50258,  1169,  1099,  1595,   470,  4174,   986,  1312,\n",
              "           1101, 13068,   329,   513,  3840,    13, 50258,  1169,  1099,   318,\n",
              "            691,   329,   502,   986,  1312,  1101,   407,  1804,   340,   986,\n",
              "           1312,  1101,   407,    13, 50258,    18,  3840,   986,  1312,  1101,\n",
              "          13068,   986,   329,   326,   986, 50258,  1169,  1099,   318,   691,\n",
              "            329,   502,   986,  1312,  1101,   407,   986, 50258,    18,  3840,\n",
              "            986,  1312,  1101,   407,   986,  1312,  1101,   407,   986, 50258,\n",
              "             18,  3840,   986,  1312,  1101]]),\n",
              " tensor([[50257,   259,   616,  4459,    11,   345,   389,  5597,   611,   345,\n",
              "            423,  4987,   284,   651,  6405, 50260,    40,   892,   345,   821,\n",
              "           3492,   611,   345,  1053,  4987,   284,   651,  6405,    13, 50258,\n",
              "            361,   345,  1053,  4987,   284, 12479,   607,   986,  1312,  1549,\n",
              "            910,   345,   821,  3492,    13, 50258,    72,   892,   326,   338,\n",
              "           1521,  1312,   910,   345,   821,  3492,   986,   611,   345,  4236,\n",
              "            284, 12479,   607,    13, 50258,    72,   892,   326,   338,  1521,\n",
              "            986,   611,   345,  4236,   284, 12479,   607,    13, 50258, 50258,\n",
              "             72,   892,   326,   338,  1521,   986,   611,   345,  4236,   284,\n",
              "          12479,   607,   986, 50258,    72,   892,   326,   338,  1521,   986,\n",
              "            611,   345,  4236,   284, 12479]]),\n",
              " tensor([[50257,  1135,  1907,   262, 26359,   351, 26359,    13, 50260,   732,\n",
              "            821,  4330,   262,  4369,   351,   257,  4369,    13, 50258,   732,\n",
              "            821,  4330,   262,  4369,   351,   262,  4369,    13, 50258,   732,\n",
              "            821,  4330,   262,  4369,   986,   351,   262,  4369,   986,   340,\n",
              "            338,  3306,    13, 50258,   732,  1276,   986,  1907,   262, 26359,\n",
              "            986,   351,   262,  4369,   986,   340,   338,  3306,   986, 50258,\n",
              "            732,  1276,   986,  1907,   986,   262,  4369,   986,   329,   986,\n",
              "            326,   986,   340,   986,   318,   986,  3306,   986, 50258,   732,\n",
              "           1276,   986,  1907,   986,   262,  4369,   986,   329,   986,   326,\n",
              "            986,   340,   986,   318,   986,  3306,   986, 50258,   732,  1276,\n",
              "            986,  1907,   986,   262,  4369]]),\n",
              " tensor([[50257, 12050,  1654,   345,   423,   281,  4075, 32928,   290, 39331,\n",
              "          19397,  1430,   319,   534,  3644, 50260, 17350,   341,   986, 33770,\n",
              "            986,    64, 32928,   290, 39331, 19397,   986, 50258, 33770,   986,\n",
              "             64, 32928,   986,   392,   986,    64, 39331, 19397,   986, 50258,\n",
              "          33770,   986,    64, 32928,   986,   392,   986,    64, 39331, 19397,\n",
              "            986, 50258, 17350,   341,   986, 33770,   986,    64, 32928,   986,\n",
              "            392,   986,    64,   986, 30586,   986,   329,   986,   326,   986,\n",
              "             13, 50258, 17350,   341,   986, 33770,   986,   257,   986, 30586,\n",
              "          16317,   329,   986,   326,   986,    13, 50258, 17350,   341,   986,\n",
              "          16317,   329,   986,   326, 16317,   986,   986,   340,   986,   318,\n",
              "            986,  3306,   986,   329,   986]]),\n",
              " tensor([[50257, 10462, 13947,   447,   247,    82,  2274,  3513,   416,   262,\n",
              "          33802,    11,  2158,    11,   468,   587, 27690,   913,    13, 50260,\n",
              "           4360,    11,   287,  1109, 16317,   262, 14780,  3513,   416,   262,\n",
              "          33802,   468,   587, 27690,   913,    13, 50258, 50258,  1169, 14780,\n",
              "           3513,   318,   986, 27690,   913, 16317,   287,   262,  1339, 16317,\n",
              "            286,   262, 33802,    11,   340,   373,  1760,    13, 50258, 50258,\n",
              "          50258,  1169, 14780,  1339, 16317,   318,   986, 27690,   913, 16317,\n",
              "            287,   262,  1339, 16317,   286,   262, 33802, 16317,    11,   340,\n",
              "            373,    13, 50258, 50258, 50258,  1169,  1109, 16317,   326, 16317,\n",
              "            340,   318, 16317,   262,  1339, 16317, 16317, 16317,   286,   262,\n",
              "          33802, 16317,    11,   340,   318]]),\n",
              " tensor([[50257,  1639,   466,   407,   761,   284,  4745,   319,   257,   582,\n",
              "          50260,  1639,   836,   470,   761,   257,   582,   284,  4745,   319,\n",
              "             13, 50258,  5832,   836,   470,   761,   257,   582,   284,  4745,\n",
              "            319,    13, 50258,  1639,   836,   470,   761,   257,   582,   284,\n",
              "           4745,   319,    13, 50258,  5832,   836,   470,   761,   257,   582,\n",
              "            284,  4745,   319,    13, 50258,  1639,   836,   470,   761,   257,\n",
              "            582,   284,  4745,   319,    13, 50258,  5832,   836,   470,   761,\n",
              "            257,   582,   284,  4745,   319,    13, 50258,  5832,   836,   470,\n",
              "            761,   257,   582,   284,  4745,   319,    13, 50258,  5832,   836,\n",
              "            470,   761,   257,   582,   284,  4745,   319,    13, 50258,   986,\n",
              "          50258,   986,   345,   836,   470]]),\n",
              " tensor([[50257,  8061,  1949,   284,  4727,   340,   475,   340,  2331,   588,\n",
              "            345,   389,   429, 41062, 50260, 15332,  1949,   284,  4727,   340,\n",
              "          16317,   475,   340,  2331,   588,   345,   260,   407, 41062,   986,\n",
              "          50258, 15332,  1949,   284,  4727,   340, 16317,   475,   340,  2331,\n",
              "            588,   345,   260,   407, 41062, 16317, 50258, 15332,  1949,   284,\n",
              "           4727,   340, 16317,   475,   340,  2331,   588,   345,   260,   407,\n",
              "          41062, 16317,    30, 50258, 15332,  1949,   284,  4727,   340, 16317,\n",
              "            475,   340,  2331,   588,   345,   260,   407, 41062, 16317,    30,\n",
              "          50258, 15332,  1949,   284,  4727,   340, 16317,   475,   340,  2331,\n",
              "            588,   345,   260,   407, 41062, 16317,    30, 50258, 15332,  1949,\n",
              "            284,  4727,   340, 16317,   475]]),\n",
              " tensor([[50257,  3666,  5422,   373,  1280,   319,   326,   220,  2474, 50260,\n",
              "             40,  1101,   407,  4756,   616,  5422,   986,   705, 50258,     6,\n",
              "           1820,  5422,   318,  1280,   986,   705,   986,   705, 50258,     6,\n",
              "            986,   705,   986,   705,   986,   705,   986,   705,   986,   705,\n",
              "            986,   705,   986,   705,   986,   705,   986,   705,   986,   705,\n",
              "            986,   705,   986,   705,   986,   705,   986,   705,   986,   705,\n",
              "            986,   705,   986,   705,   986,   705,   986,   705,   986,   705,\n",
              "            986,   705,   986,   705,   986,   705,   986,   705,   986,   705,\n",
              "            986,   705,   986,   705,   986,   705,   986,   705,   986,   705,\n",
              "            986,   705,   986,   705,   986,   705,   986,   705,   986,   705,\n",
              "            986,   705,   986,   705,   986]]),\n",
              " tensor([[50257, 20570,   656,   262,  7837, 37995,    11,   290, 12412,  1972,\n",
              "            503, 50260, 37210,   656,   262,  7837, 37995, 16317,   290,   788,\n",
              "           1972,   503,    13, 50258, 37210,   656,   262,  7837, 16317,   788,\n",
              "           1972,   503,    13, 50258, 37210,   656,   262,  7837, 16317,   788,\n",
              "          16317,   788, 16317,   788, 16317,   788, 16317,   788, 16317,   788,\n",
              "          16317,   788, 16317,   788, 16317,   788, 16317,   788, 16317,   788,\n",
              "          16317,   788, 16317,   788, 16317,   788, 16317,   788, 16317,   788,\n",
              "          16317,   788, 16317,   788, 16317,   788, 16317,   788, 16317,   788,\n",
              "          16317,   788, 16317,   788, 16317,   788, 16317,   788, 16317,   788,\n",
              "          16317,   788, 16317,   788, 16317,   788, 16317,   788, 16317,   788,\n",
              "          16317,   788, 16317,   788, 16317]]),\n",
              " tensor([[50257,  1858,   338,   281,  5002,   286, 13052,   986,  2644,  5562,\n",
              "            714,   772,   275,  5927,  1611,   286, 15962, 25943,    13, 50260,\n",
              "           1169,  1109,   326,   612,   318,   257, 13052, 16317,   329,   257,\n",
              "           1611, 16317,   286,  8253, 25943, 16317,    30, 50258,  1169,  1109,\n",
              "          16317,   326, 16317,   612,   318, 16317,   257, 13052, 16317,   329,\n",
              "            257,   986,  1611, 16317, 25943, 16317,    30, 50258,  1169,  1109,\n",
              "          16317,   326, 16317,   612, 16317,   318, 16317,   257, 13052, 16317,\n",
              "            329, 16317,   257, 16317,  8253, 16317, 25943, 16317,    30, 50258,\n",
              "          50258,  1169, 16317,  1109, 16317,   326, 16317, 16317,   612, 16317,\n",
              "            318, 16317,   257, 16317, 13052, 16317, 16317,   329, 16317,   257,\n",
              "          16317,  3716, 16317,    30, 50258]]),\n",
              " tensor([[50257,    40,   772,  1297,   607,   314,   561,  1667,    81,   563,\n",
              "            607,    11,   655,   284,   905,   607,   703,   881,   314,  1842,\n",
              "            607, 50260,    40,   772,  1297,   607,   314,   561, 12479,   607,\n",
              "             11,   655,   284,   905,   607,   703,   881,   314,  1842,   607,\n",
              "             13, 50258,    72,   772,  1297,   607,   314,   561, 12479,   607,\n",
              "          16317,   655,   284,   905,   607,   703,   881,   314,  1842,   607,\n",
              "             13, 50258, 50258,    72,   772,  1297,   607,  1312,   561, 12479,\n",
              "            607, 16317,   655,   284,   905,   607,   703,   881,   314,  1842,\n",
              "            607,    13, 50258,    72,   772,  1297,   607,  1312,   561, 12479,\n",
              "            607, 16317,   655,   284,   905,   607,   703,   881,  1312,  1842,\n",
              "            607,    13, 50258,   986, 50258]]),\n",
              " tensor([[50257,  5779,    11,   617,   661,   389,   655,   407,  1280, 35661,\n",
              "             11,   314,  4724, 50260,  4053,    11,   617,   661,   389,   655,\n",
              "            407,  1280, 35661,   986,  1312,  4724,    13, 50258,  4053,   986,\n",
              "            617,   661,   389,   655,   407,  1280, 35661,   986,  1312,  4724,\n",
              "             13, 50258,  4053,   986,   617,   661,   389,   655,   407,  1280,\n",
              "          35661,   986,  1312,  4724,   986, 50258,  4053,   986,   617,   279,\n",
              "            489,   389,   655,   407,  1280, 35661,   986,  1312,  4724,   986,\n",
              "          50258,  4053,   986,   617,   279,   489,   389,   655,   407,  1280,\n",
              "          35661,   986,  1312,  4724,   986, 50258,  4053,   986,   617,   279,\n",
              "            489,   389,   655,   407,  1280, 35661,   986,  1312,  4724,   986,\n",
              "          50258,  4053,   986,   617,   279]]),\n",
              " tensor([[50257,  1026,   338,  6507,   284,   423,   284,   636,   340,    13,\n",
              "          50260,   270,   338,  6507,   284,   423,   284,   636,   340,    13,\n",
              "          50258,   896,  6507,   284,   423,   284,   636,   340,    13, 50258,\n",
              "            896,  6507,   284,   423,   284,   636,   340,    13, 50258,   896,\n",
              "           6507,   284,   423,   284,   636,   340,    13, 50258,   896,  6507,\n",
              "            284,   423,   284,   636,   340,    13, 50258,   896,  6507,   284,\n",
              "            423,   284,   636,   340,    13, 50258,   896,  6507,   284,   423,\n",
              "            284,   636,   340,    13, 50258,   896,  6507,   284,   423,   284,\n",
              "            636,   340,    13, 50258,   896,  6507,   284,   423,   284,   636,\n",
              "            340,    13, 50258,   896,  6507,   284,   423,   284,   636,   340,\n",
              "             13, 50258,   896,  6507,   284]]),\n",
              " tensor([[50257,  1532,   339,  1139,   645,    11,  1265,  2130,  2073, 50260,\n",
              "            361,   339,  1139,   645,    11,  1265,  1194,  3516,    13, 50258,\n",
              "            361,   339,  1139,   645,    11,   788,  1265,  1194,  3516,    13,\n",
              "          50258,   361,   339,  1139,   645,    11,   788,  1265,  1194,  3516,\n",
              "             13, 50258,   361,   339,  1139,   645,    11,   788,  1265,  1194,\n",
              "           3516,    13, 50258,   361,   339,  1139,   645,    11,   788,  1265,\n",
              "           1194,  3516,    13, 50258,   361,   339,  1139,   645,    11,   788,\n",
              "           1265,  1194,  3516,    13, 50258,   361,   339,  1139,   645,    11,\n",
              "            788,  1265,  1194,  3516,    13, 50258,   361,   339,  1139,   645,\n",
              "             11,   788,  1265,  1194,  3516,    13, 50258,  8524,  1265,  1194,\n",
              "           3516,    13, 50258,   361,   339]]),\n",
              " tensor([[50257,    40,   892,   326,   407,  6970,   318,  4785, 50260,    72,\n",
              "            892,   326,   407,  6970,   318,  4785,    13, 50258,    72,   892,\n",
              "            407,  6970,   318,  4785,    13, 50258, 50258, 50258,    72,   892,\n",
              "            326,   407,  6970,   318,  4785,   986, 50258,    72,   892,   407,\n",
              "           6970,   318,  4785,   986, 50258, 50258,    72,   892,   407,  6970,\n",
              "            318,  4785,   986, 50258, 50258, 50258,    72,   892,   326,   986,\n",
              "            407,  6970,   318,   986,  4785,   986, 50258, 50258, 50258,    72,\n",
              "            892,   986,   407,  6970,   986,   326,   986,   326,   986,   318,\n",
              "            986,  4785,   986, 50258, 50258, 50258, 50258, 50258,    72,   892,\n",
              "            986,   326,   986,   326,   986,   318,   986,  4785,   986, 50258,\n",
              "          50258, 50258, 50258,   986,   326]]),\n",
              " tensor([[50257, 28042,   345,   588,   340,   477,   625,   534,  6131, 50260,\n",
              "          28042,   345,   588,   340,   477,   625,   534,  6131,   986, 50258,\n",
              "          28042,   345,   588,   340,   477,   625,   534,  6131,   986, 50258,\n",
              "          25252,   345,   588,   340,   477,   625,   534,  6131,   986, 50258,\n",
              "          25252,   345,   588,   340,   477,   625,   986, 50258, 25252,   345,\n",
              "            588,   340,   477,   625,   986, 50258, 25252,   345,   588,   340,\n",
              "            477,   625,   986, 50258, 25252,   345,   588,   340,   986, 50258,\n",
              "          25252,   986,   880,   986,   788,   986,   880,   986,   788,   986,\n",
              "            788,   986,   788,   986,   788,   986,   788,   986,   788,   986,\n",
              "            788,   986,   788,   986,   788,   986,   788,   986,   788,   986,\n",
              "            788,   986,   788,   986,   788]]),\n",
              " tensor([[50257,  1026,  5300,  5403,   355,  3621,   618,   339,   460,   407,\n",
              "           1745,   340,   287,   597,  2392, 50260,   896,   772,  1365,   618,\n",
              "            339, 18548,  1745,   340,  7471,    13, 50258,   896,   772,  1365,\n",
              "            618,   339, 18548,  1745,   340,  7471,    13, 50258,   896,   772,\n",
              "           1365,   618,   339, 18548,  1745,   340,  7471,    13, 50258,   896,\n",
              "            772,  1365,   618,   339, 18548,  1745,   340,  7471,    13, 50258,\n",
              "            896,   772,  1365,   618,   339, 18548,  1745,   340,  7471,    13,\n",
              "          50258,   896,   772,  1365,   618,   339, 18548,  1745,   340,  7471,\n",
              "             13, 50258,   896,   772,  1365,   618,   339, 18548,  1745,   340,\n",
              "           7471,    13, 50258,   896,   772,  1365,   618,   339, 18548,  1745,\n",
              "            340,  7471,    13, 50258,   896]]),\n",
              " tensor([[50257, 23433,   284,  8960,   290,   407,  5490,    11,   655,   307,\n",
              "           3511, 50260, 28311,   284,  8960,   290,   836,   470,  5490,   986,\n",
              "            655,   307,  3511,   986, 50258, 28311,   284,  8960,   290,   836,\n",
              "            470,  5490,   986,   655,   307,  3511,   986, 50258, 28311,   284,\n",
              "           8960,   290,   836,   470,  5490,   986,   655,   307,  3511,   986,\n",
              "          50258, 50258, 28311,   284,  8960,   290,   407,  5490,   986,   655,\n",
              "            307,  3511,   986, 50258, 28311,   284,  8960,   290,   836,   470,\n",
              "           5490,   986,   655,   307,  3511,   986, 50258, 50258, 28311,   284,\n",
              "           8960,   290,   836,   470,  5490,   986,   655,   307,  3511,   986,\n",
              "          50258, 50258, 28311,   284,  8960,   290,   836,   470,  5490,   986,\n",
              "            655,   307,  3511,   986, 50258]]),\n",
              " tensor([[50257,  5211,   314,   761,   284,   467,   783, 50260,    72,   761,\n",
              "            284,   467,   783,    13, 50258,  2197,  1312,   761,   284,   467,\n",
              "             13, 50258,    72,   761,   284,   467,   783,    13, 50258,  2197,\n",
              "           1312,   761,   284,   467,    13, 50258,  2197,  1312,   761,   284,\n",
              "            467,    13, 50258,  2197,  1312,   761,   284,   467,    13, 50258,\n",
              "           2197,  1312,   761,   284,   467,    13, 50258,  2197,  1312,   761,\n",
              "            284,   467,    13, 50258,  2197,  1312,   761,   284,   467,    13,\n",
              "          50258,  2197,  1312,   761,   284,   467,    13, 50258,  2197,  1312,\n",
              "            761,   284,   467,    13, 50258,  2197,  1312,   761,   284,   467,\n",
              "             13, 50258,  2197,  1312,   761,   284,   467,    13, 50258,  2197,\n",
              "           1312,   761,   284,   467,    13]]),\n",
              " tensor([[50257,   464,  3329,   986,  3329,   338,   257,   922,   640,    13,\n",
              "          50260,  1169,  3329,   986,   340,   338,   257,   922,   640,    13,\n",
              "          50258,  1169,  3329,   986,   340,   338,   257,   922,  1517,    13,\n",
              "          50258,  1169,  3329, 16317,   340,   338,   257,   922,  1517,    13,\n",
              "          50258,   270,   338,   257,   922,   640, 16317,   329,  1654,    13,\n",
              "          50258,  1169,  3329, 16317,   318,   340,   257,   922,  1517, 16317,\n",
              "            329,  1654,    13, 50258,   270,   338,   257,   922,  1517, 16317,\n",
              "            340,   338,   262,  3329,    13, 50258,  1169,  3329, 16317,   318,\n",
              "            340,   257,   922,  1517, 16317,   329,  1654,    13, 50258,   270,\n",
              "            338,   257,   922,  1517, 16317,   329,  1654,    13, 50258,   270,\n",
              "            338,   257,   922,  1517, 16317]]),\n",
              " tensor([[50257,  6214,    11,   257,  3621,  7779,   263,    11,   339,  2982,\n",
              "            345, 17997,    13, 50260,   258,  2982,   345, 17997,   257,  3621,\n",
              "           1097,    13, 50258,   258,  2497,   345, 17997,   257,  3621,  1097,\n",
              "             13, 50258,   258,  2497,   345, 17997,   257,  3621,  1097,    13,\n",
              "          50258,   258,  2497,   340, 16317,   290,   339,  2982, 16317,   345,\n",
              "            547, 17997,   257,  3621,  1097,    13, 50258, 50258,   258,  2497,\n",
              "          16317,   345,   547,   986, 17997, 16317,   257,  3621,  1097, 16317,\n",
              "            220,   986,   329,  1654,    13, 50258,   258,   373,   986, 14376,\n",
              "          16317,   546,   340, 16317, 16317,   287,  1109, 16317,   339,  2982,\n",
              "          16317,   345,   547,   986, 17997, 16317,   257,  3621,  1097, 16317,\n",
              "             13, 50258, 50258, 50258,   258]]),\n",
              " tensor([[50257,  3673,  6974,  2233,   284,  6464,  3214, 39485, 50260,  1662,\n",
              "            655,   780,  1312,  1392,  8104,   986, 50258,  1662,   655,   780,\n",
              "           1312,  1392,  8104,   986, 50258,  1662,   655,   780,  1312,  1392,\n",
              "           8104,   986, 50258,  1662,   655,   780,  1312,  1392,  8104,   986,\n",
              "          50258,  1662,   655,   780,  1312,  1392,  8104,   986, 50258,    25,\n",
              "              8, 50258,    25,     8,   220,  1892,   655,   780,  1312,  1392,\n",
              "           8104,   986, 50258,    25,     8,   220,  1892,   655,   780,  1312,\n",
              "           1392,  8104,   986, 50258,    25,     8,   220,   220,   220,  1892,\n",
              "            655,   780,  1312,  1392,  8104,   986, 50258,    25,     8,   220,\n",
              "            220,  1892,   655, 16317,   326,  1312,  1392,  8104,   986, 50258,\n",
              "             25,     8,   220,  1892,   986]]),\n",
              " tensor([[50257,  3260,  4953,  1115, 43546,  1528,    11,   339,  3848,   938,\n",
              "           1755,   290,  1139,  5689,   338,  3492,    13, 50260,   258, 13488,\n",
              "           1115,  1528,    11,   290,   339,  1444,   502,  7415,   290,   531,\n",
              "           5689,   373,  4953,    13, 50258,   258, 13488,  1115,  1528, 16317,\n",
              "            290,   339,  1444,   502,  7415, 16317,   290,   531,   326,  5689,\n",
              "            373,  4953,    13, 50258,   258, 13488,   986,   290,   339,  1444,\n",
              "            502, 16317,   290,   531, 16317,   326, 16317,  5689,   373,  4953,\n",
              "             13, 50258,   258, 13488, 16317,   290, 16317,   339,  1444, 16317,\n",
              "            290, 16317,   339, 13488,   986,   290, 16317,   339, 13488, 16317,\n",
              "            290, 16317,   329,  1115,  1528,    13, 50258,   258, 13488, 16317,\n",
              "            290, 16317,   290, 16317,   339]]),\n",
              " tensor([[50257,    40,  5875,   345,   287,  5963,   329, 18877,   617,   286,\n",
              "            616,  2683, 50260, 27547,   329, 18877,   617,  2683,   546,   502,\n",
              "             13, 50258,    72,  1101,   523,  9675,  1312,  1392,   534,  3280,\n",
              "             13, 50258, 27547,   329, 18877,   616,  2683,    13, 50258,    72,\n",
              "           1101,  9675,  1312,  1053,  9373,   534,  1808,    13, 50258,    72,\n",
              "           1101,   523,  9675,  1312,  1392,   262,  3280,    13, 50258, 27547,\n",
              "            329, 18877,   534,  1808,    13, 50258,    72,  1101,  9675,    13,\n",
              "          50258,    72,  1101, 14066,   329,   326,    13, 50258,    72,  1101,\n",
              "           9675,  1312,  1053,  9373,   534,  1808,    13, 50258,    72,  1101,\n",
              "          14066,   329,   326,    13, 50258,    72,  1101, 14066,   329,   326,\n",
              "             13, 50258,    72,  1101, 14066]]),\n",
              " tensor([[50257,   447,   250, 23061,   284,   502,    11,  4813,    11,   447,\n",
              "            251,   531, 11735,    12, 46827,   284, 24799,   290,   406, 10071,\n",
              "             13, 50260,     6, 23061,   284,   502,    11, 17308,    11,   705,\n",
              "          30079, 11735,    12, 46827,    13, 50258,     6,  4868,   268,    11,\n",
              "          17308, 16317,   705, 47638, 11735,    12, 46827,    13, 50258,     6,\n",
              "           4868,   268, 16317,   705, 16317,   329,   783, 16317,   705, 47638,\n",
              "            406, 10071,    13, 50258,     6,  4868,   268, 16317,   705, 16317,\n",
              "            329,   783, 16317,   705, 47638, 11735,    12, 46827,    13, 50258,\n",
              "              6,  4868,   268, 16317,   705, 16317,   329,   783, 16317,   705,\n",
              "          47638,   406, 10071,    13, 50258,     6,  4868,   268, 16317,   705,\n",
              "          16317,   329,   783, 16317,   705]]),\n",
              " tensor([[50257,    38,  6201,  8970,   319,   262, 50128,    11,  1471,  1559,\n",
              "            348,  1389,   890,  4420,    13, 50260,  5574,  1559, 50030,   379,\n",
              "            262, 50128,    11,   290,   339,   348,  1389,    13, 50258,  1169,\n",
              "          50128,   547,  8970,   287,   465,  2951,    11,   290,   339,   373,\n",
              "          25602,    13, 50258,  1169, 50128,   547, 16143,   379,   683,    11,\n",
              "            290,   339,   373, 22002,   278,    13, 50258,   258,  3114,   379,\n",
              "            606,    11,   290,   339,   373,  7960,    13, 50258,  1169, 50128,\n",
              "            547, 16143,   379,   683,    11,   290,   339,   373, 22002,   278,\n",
              "             13, 50258,   258,   373,  2045,   379,   606,    11,   290,   339,\n",
              "            373, 38635,    13, 50258,   258,  3114,   379,   606,    11,   290,\n",
              "            339,   373, 25602,    13, 50258]]),\n",
              " tensor([[50257,  7120,  3280,  6774,   510,   517,  2683, 50260,  7120,  3280,\n",
              "            318,   655,  1165,   867,   329,   502,   284,  3505,    13, 50258,\n",
              "             39, 27532, 16317,   534,  3280,   318,   655,  1165,   867, 16317,\n",
              "            329,   502,   284,  3505,    13, 50258,    39, 27532, 16317,   534,\n",
              "           3280,   318,   655,  1165,   867, 16317,   329,   502,   284,  3505,\n",
              "             13, 50258,    39, 27532, 16317,   534,  3280,   318,   655,  1165,\n",
              "            867, 16317,   329,   502,   284,  3505,    13, 50258,    39, 27532,\n",
              "          16317,   534,  3280,   318,   655,  1165,   867, 16317,   329,   502,\n",
              "            284,  3505,    13, 50258,    39, 27532, 16317,   534,  3280,   318,\n",
              "            655,  1165,   867, 16317,   329,   502,   284,  3505,    13, 50258,\n",
              "             39, 27532, 16317,   534,  3280]]),\n",
              " tensor([[50257,   270, 22523,   290,   314,  5465,   340, 50260,    72,  5465,\n",
              "            340,   290,   340, 22523,    13, 50258,   270, 22523,    11,   290,\n",
              "           1312,  5465,   340,    13, 50258, 50258,   270, 22523,    11,   290,\n",
              "           1312,  5465,   340,    13, 50258,    72,  5465,   340,    11,   290,\n",
              "           1312,  5465,   340,    13, 50258,    72,  5465,   340,    11,   290,\n",
              "           1312,  5465,   340,    13, 50258,    72,  5465,   340,    13, 50258,\n",
              "             72,  5465,   340,    11,   290,  1312,  5465,   340,    13, 50258,\n",
              "             72,  5465,   340,    13, 50258,    72,  5465,   340,    13, 50258,\n",
              "             72,  5465,   340,    11,   290,  1312,  5465,   340,    13, 50258,\n",
              "             72,  5465,   340,    13, 50258,    72,  5465,   340,    13, 50258,\n",
              "             72,  5465,   340,    13, 50258]]),\n",
              " tensor([[50257,    40,   716,  5291,   262,  5210,  6510,  8179, 50260,    72,\n",
              "           1101,   407,  1016,   284,  1309,   262,  5210,  6510,   466,   477,\n",
              "            262,   670,    13, 50258,    72,  1101,   407,  8066,  1309,   262,\n",
              "           5210,  3730,   466,   340,    13, 50258,    40,  1101,   407,  8066,\n",
              "           1309,   606,   466,   340,    13, 50258,    40,  1101,   407,  8066,\n",
              "           1309,   606,   466,   340,    13, 50258,    40,  1101,   407,  8066,\n",
              "           1309,   606,   466,   340,    13, 50258,    72,  1101,   407,  8066,\n",
              "           1309,   606,   466,   340,    13, 50258,    72,  1101,   407,  8066,\n",
              "           1309,   606,   466,   340,    13, 50258,    72,  1101,   407,  8066,\n",
              "           1309,   606,   466,   340,    13, 50258,    40,  1101,   407,  8066,\n",
              "           1309,   606,   466,   340,    13]]),\n",
              " tensor([[50257,   818,   616,  4459,    11,   340,   318,   655,  1194,  1919,\n",
              "           6841,   326, 43739,   790,  1952,  1637,    11,   475,   484,   389,\n",
              "           1257, 50260,    72, 17666,   892,   340,   318,   257,  1919,  3430,\n",
              "            986,   340,   318,   655,  1194,  7030,   286,  1637,   986,   475,\n",
              "            484,   389,  1257,    13, 50258,    72,   892,   340,   318,   655,\n",
              "           1194,  1919,  6841,   986,  1312,   892,   663,   655,  1194, 18359,\n",
              "           8872,   986,   475,   484,   389,  1257,    13, 50258,    72,   892,\n",
              "            663,   655,  1194,  7030,   286,  1637,   986,   475,   484,   389,\n",
              "           1257,    13, 50258,    25,     8, 50258,    25,     8,  1312,   892,\n",
              "            340,   318,   655,  1194,  1919,  6841,   986,  1312,   892,   663,\n",
              "            655,  1194, 18359,  8872,   986]]),\n",
              " tensor([[50257,  1532,   345,   588,   683,    11,   466,   407, 15912,   378,\n",
              "            340, 50260,  1532,   345,   588,   683,    11,   836,   470,  6611,\n",
              "            340,    13, 50258,   361,   334,   588,   683,    11,   836,   470,\n",
              "           6611,   340,    13, 50258,   361,   334,   588,   683,    11,   836,\n",
              "            470,  6611,   340,    13, 50258,   361,   334,   588,   683,    11,\n",
              "            836,   470,  6611,   340,    13, 50258,   361,   334,   588,   683,\n",
              "             11,   836,   470,  6611,   340,    13, 50258,   361,   334,   588,\n",
              "            683,    11,   836,   470,  6611,   340,    13, 50258,   361,   334,\n",
              "            588,   683,    11,   836,   470,  6611,   340,    13, 50258,   361,\n",
              "            334,   588,   683,    11,   836,   470,  6611,   340,    13, 50258,\n",
              "            361,   334,   588,   683,    11]]),\n",
              " tensor([[50257, 18755,   257,  1285,    11,   339,  1183,   307,   572,   284,\n",
              "           2439,  2120,   654,    13, 50260,   258,  1183,  2666,  2439,   346,\n",
              "            654,   329,   257,  1285,    13, 50258,   258,  1183,  2666,  2439,\n",
              "            346,   654,   329,   257,  1285,    13, 50258,   258,  1183,   467,\n",
              "            612,   287,   257,  1285,    13, 50258,   258,  1183,   467,   612,\n",
              "            287,   257,  1285,    13, 50258,   258,  1183,   307,  3750,   329,\n",
              "            257,  1285,    13, 50258,   258,  1183,   467,   612,   287,   257,\n",
              "           1285,    13, 50258,   258,  1183,   307,   612,   287,   257,  1285,\n",
              "             13, 50258,   258,  1183,   307,   612,   329,   257,  1285,    13,\n",
              "          50258,   258,  1183,   307,   612,   329,   257,  1285,    13, 50258,\n",
              "            258,  1183,   467,   612,   287]]),\n",
              " tensor([[50257,    40,  4043,  1566,   314,  1254,   588,   314,   460,  1833,\n",
              "            616,  2415, 50260,    72,  4043,  1566,  1312,  1254,   588,  1312,\n",
              "            760,   616,  2415,    13, 50258,    72,  4043,  1566,  1312,  1254,\n",
              "            588,  1312,   760,   616,  2415,    13, 50258,    72,  4043, 21502,\n",
              "           1312,  1254,   588,  1312,   760,   616,  2415,    13, 50258,    72,\n",
              "           4043, 21502,  1312,  1254,   588,  1312,   760,   616,  2415,    13,\n",
              "          50258,    72,  4043, 21502,  1312,  1254,   588,  1312,   760,   616,\n",
              "           2415,    13, 50258, 50258,   986,  1312,  4043, 10597,  1312,  1254,\n",
              "            588,  1312,   760,   616,  2415,    13, 50258,   986,  1312,  4043,\n",
              "          10597,  1312,  1254,   588,  1312,   760,   616,  2415,    13, 50258,\n",
              "            986,  1312,  4043, 10597,  1312]]),\n",
              " tensor([[50257,  2953,   511,  7372,   262,  6279,    12,    86,   630,   704,\n",
              "           7842,   811,   594,   286,  3334, 21295,   259,   284,  8279,  2029,\n",
              "            262,  1956,    13, 50260, 29370,   262,  2323,    11,   262,  1029,\n",
              "             12,  2704,   593, 13476,   286,   262,  3334, 32685,  9174,   287,\n",
              "            262,  6766,    13, 50258, 29370,   262,  2323,    11,   262, 13476,\n",
              "            286,   262,  3334, 32685,   373,  1775,   287,   262,  6766,    13,\n",
              "          50258,  1169,  1029,    12,  2704,  2150, 13476,   286,   262,  3334,\n",
              "          32685,   373,  9066,   287,   262,  7372,    13, 50258,  1169, 13476,\n",
              "            373,  9066,   379,   262,  7372,    11,   287,   262,  6766,    11,\n",
              "            287,   262,  1029,  1295,    13, 50258,  1169, 13476,   373,   612,\n",
              "             11,   287,   262,  6766,    11]]),\n",
              " tensor([[50257,  1026,   338,   655,   326, 26926,   986,   339,  1422,   470,\n",
              "           1607, 11254,  1820,   986, 50260, 48280, 16317,   339,  1422,   470,\n",
              "           1607,   502, 16317,   284,   307,   986,   616,  1995,    13, 50258,\n",
              "            258,  1422,   470,  1607,   502, 16317,   284,   307, 16317,   616,\n",
              "           1995,    13, 50258,   258,  1422,   470,  1607, 16317,   502, 16317,\n",
              "            284, 16317,   307, 16317,   616,  1995,    13, 50258,   258,  1422,\n",
              "            470,  1607, 16317,   502, 16317,   284, 16317,   307, 16317,   616,\n",
              "           1995,    13, 50258,   258,  1422,   470,  1607, 16317,   502, 16317,\n",
              "            284, 16317,   307, 16317,   616,  1995,    13, 50258,   258,  1422,\n",
              "            470,  1607, 16317,   502, 16317,   284, 16317,   307, 16317,   616,\n",
              "           1995,    13, 50258,   258,  1422]]),\n",
              " tensor([[50257,  1544,   318,   655,   257,  9192,   508,   318, 28357,   691,\n",
              "            284,  2241, 50260,   258,   318,   257,  9192,   508,   318, 28357,\n",
              "            691,   284,  2241,    13, 50258,   986,   339,   318,   655,   257,\n",
              "           9192,   508,   318, 28357,   691,   284,  2241,   986, 50258,   986,\n",
              "            339,   318,   655,   257,  9192,   508,   318, 28357,   691,   284,\n",
              "           2241,   986, 50258,   986,   339,   318,   655,   257,  9192,   986,\n",
              "            691,   329,  2241,   986, 50258,   986,   339,   318,   986,   691,\n",
              "            986,   329,  2241,   986, 50258,   986,   339,   986,   318,   986,\n",
              "            691,   986,   329,  2241,   986, 50258,   986,   339,   986,   318,\n",
              "            986,   691,   986,   329,  2241,   986,   986,   986, 50258,   986,\n",
              "            339,   986,   318,   986,   691]]),\n",
              " tensor([[50257,  2949,  1808,    11,   340,   338,   257, 16362,   286, 22912,\n",
              "            338, 10857,    13, 50260,  3919,    11,   340,   338,   257,  3975,\n",
              "            286, 22912,   338, 10857,    13, 50258,  3919,   986,   340,   338,\n",
              "            257,  3975, 16317,   286, 22912,   338, 10857,    13, 50258,  3919,\n",
              "            986,   340,   338, 16317,   257,  3975, 16317,   329, 22912,   338,\n",
              "          10857,    13, 50258,  3919,   986,   340, 16317,   318, 16317,   329,\n",
              "          16317, 22912,   338, 10857,    13, 50258,  3919, 16317,   329, 16317,\n",
              "            326, 16317,   340, 16317,   318, 16317,   329, 16317,   326, 16317,\n",
              "             13, 50258,  3919, 16317,   329, 16317,   326, 16317, 16317, 16317,\n",
              "          16317, 16317, 16317,   986,   329, 16317,   326, 16317,    13, 50258,\n",
              "            986,   329, 16317,   326, 16317]]),\n",
              " tensor([[50257,  7594,  3700, 16314,    11,   484,   547, 11300,   739,  3991,\n",
              "          18413,    13, 50260,  9930,   547,  1262,   262,  5369,   286,  3700,\n",
              "          16314,   986,   475,   484,   547,   635, 11300,   739,   262,  3891,\n",
              "            286,  3700, 16314,    13, 50258,  9930,   547,  1262,   262,  1438,\n",
              "           3700, 16314, 16317,   475,   484,   547,   635,  1262,   262,  1438,\n",
              "           3700, 16314, 16317, 19462,    13, 50258,  9930,   547,   655,  1262,\n",
              "            262,  1438,  3700, 16314, 16317,   475,   986,  1312,  4724,   986,\n",
              "            484,   547,   635,  1262,   262,  1438,  3700, 16314, 16317, 19462,\n",
              "             13, 50258,  9930,   547,   655,  1262,   262,  1438,  3700, 16314,\n",
              "          16317,   475,   986,  1312,  4724, 16317,   484,   547,   635,   986,\n",
              "           1262,   262,  1438,  3700, 16314]]),\n",
              " tensor([[50257, 10995,    11,   617,  1545,    11,   345,  1444,   502,   257,\n",
              "           1902,  8589,    13, 50260,  5832,  1444,   502,   257,  1902,  8589,\n",
              "             11,   616,  1545,    13, 50258,  5832,  1444,   502,   257,  1545,\n",
              "             11,   475,   314,  1101,   257,  1902,  8589,    13, 50258,  5832,\n",
              "           1444,   502,   257,  1545,    11,   475,   314,  1101,   257,  1902,\n",
              "           8589,    13, 50258,  5832,  1444,   502,   257,  1545, 16317,   475,\n",
              "            314,  1101,   257,  1902,  8589,    13, 50258,  1820,  1545, 16317,\n",
              "            345,  1444,   502,   257,  1036,  8589,    13, 50258,  5832,  1444,\n",
              "            502,   257,  1545, 16317,   475,   314,  1101,   257,  1902,  8589,\n",
              "             13, 50258,  5832,   821,   257,  1036,  8589, 16317, 50258,    40,\n",
              "           1101,   257,  1545, 16317,   314]]),\n",
              " tensor([[50257, 10995,    11,   607,  3809,   318,  3750,   290,   607, 17515,\n",
              "            389,   625, 19943, 50260, 43669,   986,   607,  3809,   318,  3750,\n",
              "            986,   607, 17515,   389,  1165,  1263,   986, 50258, 43669,   986,\n",
              "            607,  3809,   318,  3750,   986,   607, 17515,   389,  1165,  1263,\n",
              "            986, 50258, 43669,   986,   607,  3809,   986,  3750,   986,   607,\n",
              "          17515,   986,  1165,  1263,   986, 50258, 43669,   986,   607,  3809,\n",
              "            986,  3750,   986,   607, 17515,   986,  1165,  1263,   986, 50258,\n",
              "          43669,   986,   607,  3809,   986,  3750,   986,   607, 17515,   986,\n",
              "           1165,  1263,   986, 50258, 43669,   986,   607,  3809,   986,  3750,\n",
              "            986,   607, 17515,   986,  1165,  1263,   986, 50258, 43669,   986,\n",
              "            607,  3809,   986,  1165,  1263]]),\n",
              " tensor([[50257,     7,    64,     8, 30145,   286,  7006, 13889, 42290,  1429,\n",
              "             26,   357,    65,     8, 17137,   284,  7006, 13889, 42290,  1429,\n",
              "             13, 50260,     7,    33,     8,   262,  8771,   329, 19089,   262,\n",
              "           7006, 13889, 42290,  2236,   307, 19267,    13, 50258,     7,    33,\n",
              "              8,   262,  8771,   329,   262,  2071,   286,   262,  7006, 13889,\n",
              "          42290,  2236,   307, 11412,    13, 50258,     7,    33,     8,   329,\n",
              "            326,  4007,    11,   262,  8771,   329,   262,  2071,   286,   262,\n",
              "          42290,   318, 19267,    13, 50258,     7,    33,     8,   428,  8771,\n",
              "           2236,   307,  5281,   503,    13, 50258,     7,    33,     8,   262,\n",
              "           2071,   286,   262, 42290,  2236,   307, 19267,    13, 50258,     7,\n",
              "             33,     8,   428,  8771,   318]]),\n",
              " tensor([[50257,  5247,   423,  1257, 50260,  2188,   290,   423,  1257,    13,\n",
              "          50258,  2188,   290,   423,  1257,    13, 50258,  2188,   290,   423,\n",
              "           1257,    13, 50258,  2188,   290,   423,  1257,    13, 50258,  2188,\n",
              "            290,   423,  1257,    13, 50258,  2188,   290,   423,  1257,    13,\n",
              "          50258,  2188,   290,   423,  1257,    13, 50258,  2188,   290,   423,\n",
              "           1257,    13, 50258,  2188,   290,   423,  1257,    13, 50258,  2188,\n",
              "            290,   423,  1257,    13, 50258,  2188,   290,   423,  1257,    13,\n",
              "          50258,  2188,   290,   423,  1257,    13, 50258,  2188,   290,   423,\n",
              "           1257,    13, 50258,  2188,   290,   423,  1257,    13, 50258,  2188,\n",
              "            290,   423,  1257,    13, 50258,  2188,   290,   423,  1257,    13,\n",
              "          50258,  2188,   290,   423,  1257]]),\n",
              " tensor([[50257,    40,   716,  7725,   340,   318,   407,  2233,   284,   262,\n",
              "           2460,   314, 11602,   351, 50260,    40,  2911,   340,   338,   407,\n",
              "            780,   286,   262,  2460,   314,  8181,   503,   351,    13, 50258,\n",
              "             40,  1101,  7725,   340,   338,   407,   780,   314,  1101,   351,\n",
              "           2460,    13, 50258,    72,  1101,   655,  7725,   340,   338,   407,\n",
              "            780,  1312,  1101,   351,  2460,    13, 50258, 50258,    72,  1101,\n",
              "            655,  7725,   340,   338,   407,   780,  1312,  1101,   351,  2460,\n",
              "             13, 50258, 50258,    72,  1101,   655,  7725,   340,   338,   407,\n",
              "            780,  1312,  1101,   351,  2460,    13, 50258, 50258,    72,  1101,\n",
              "            655,  7725,   340,   338,   407,   780,  1312,  1101,   351,  2460,\n",
              "             13, 50258,    72,  1101,   655]]),\n",
              " tensor([[50257,    40,   691,   872, 12004,   287,  1502,   284,  4911,   616,\n",
              "          17696,  3812,   345, 50260,    72,   655,  1444,   284,   910,  1312,\n",
              "           1842,   334,    13, 50258,    72,   655,  1444,   284,   910,  1312,\n",
              "           1842,   334,    13, 50258,    72,   691,  1444,   284,   910,  1312,\n",
              "           1842,   334,    13, 50258,    72,   655,  1444,   284,   910,  1312,\n",
              "           1842,   334,    13, 50258,    72,   691,  1444,   284,   910,  1312,\n",
              "           1842,   334,    13, 50258,    72,   691,  1444,   284,   910,  1312,\n",
              "           1842,   334,    13, 50258,    72,   691,  1444,   284,   910,  1312,\n",
              "           1842,   334,    13, 50258,    72,   691,  1444,   284,   910,  1312,\n",
              "           1842,   334,    13, 50258, 50258,    72,   691,  1444,   284,   910,\n",
              "           1312,  1842,   334,    13, 50258]]),\n",
              " tensor([[50257, 25515,   340,   355,   867,  1661,   355,   345,   765,   673,\n",
              "            481,   760,   644,   345,  1612, 50260, 16706,   340,   355,   867,\n",
              "           1661,   355,   345,   765,   673,   481,   760,   644,   345,  1612,\n",
              "             13, 50258,  7091,  1183,   760,   644,   334,  1612,   986, 50258,\n",
              "           7091,  1183,   760,   644,   334,  1612,   986, 50258, 16706,   340,\n",
              "            588,   334,   765,   986,   673,  1183,   760,   986, 50258,     7,\n",
              "            361,   334,   765,   986,   673,  1183,   760,   986,     8, 50258,\n",
              "              7,   361,   334,   765,   986,   673,  1183,   760,   986,     8,\n",
              "          50258,     7,   361,   334,   765,   986,   673,  1183,   760,   986,\n",
              "              8, 50258,     7,   361,   334,   765,   986,   673,  1183,   760,\n",
              "            986,     8, 50258,     7,   361]]),\n",
              " tensor([[50257,   464,   411,   257,  1256,   286, 12954,   287,  3936, 50260,\n",
              "          21607,   468,   257,  1256,   286, 12954,    13, 50258,  8117,   389,\n",
              "           6088,   286, 12954,   287,  3936,    13, 50258, 21607,   468,  6088,\n",
              "            286, 12954,    13, 50258, 21607,   468,  6088,   286,   606,   986,\n",
              "          50258, 21607,   468,  6088,   986,   286,   606,   986, 50258, 21607,\n",
              "            468,  6088,   986,   286,   606,   986, 50258, 21607,   468,  6088,\n",
              "            986,   286,   606,   986, 50258, 21607,   468,  6088,   986,   286,\n",
              "            606,   986, 50258, 21607,   468,  6088,   986,   286,   606,   986,\n",
              "          50258, 21607,   468,  6088,   986,   286,   606,   986, 50258, 21607,\n",
              "            468,  6088,   986,   286,   606,   986, 50258, 21607,   468,  6088,\n",
              "            986,   286,   606,   986, 50258]]),\n",
              " tensor([[50257,    40,  1101,  1972,   617,  1611,   286,  8867, 29384,  5764,\n",
              "             13, 50260,    40,  1183,   651,   257, 29384,   338,  5764,   329,\n",
              "            326,    13, 50258,  1640,   326,    11,   314,  1183,  1577,   683,\n",
              "            257, 12733,  5764,    13, 50258,    40,  1183,  1577,   683,   257,\n",
              "          16383,   329,   340,    13, 50258,  5562,   338,  1521,   314,  1101,\n",
              "           1016,   284,  1577,   683,   257, 16383,    13, 50258,    40,  1183,\n",
              "           1577,   683,   257, 16383,   329,   326,    13, 50258,  5562,   338,\n",
              "           1521,   314,  1183,  1577,   683,   257, 16383,    13, 50258,  5562,\n",
              "            338,  1521,   986, 50258,  5562,   338,  1521,   986,   314,  1183,\n",
              "           1577,   683,   986,   257, 16383,   986,   329,   326,   986, 50258,\n",
              "           5562,   338,  1521,   986,   314]]),\n",
              " tensor([[50257,  3347,   318,   991,   262,   976,  2576, 50260,   392,   673,\n",
              "            318,   991,   262,   976,  2576,    13, 50258,  7091,   318,   991,\n",
              "            262,   976,  2576,    13, 50258,  7091,   318,   991,   262,   976,\n",
              "           2576,    13, 50258,  7091,   318,   991,   262,   976,  2576,    13,\n",
              "          50258,  7091,   318,   991,   262,   976,    13, 50258,  7091,   318,\n",
              "            991,   262,   976,    13, 50258,  7091,   318,   991,   262,   976,\n",
              "             13, 50258,  7091,   318,   991,   262,   976,    13, 50258,  7091,\n",
              "            318,   991,   262,   976,    13, 50258,  7091,   318,   991,   262,\n",
              "            976,    13, 50258,  7091,   318,   991,   262,   976,    13, 50258,\n",
              "           7091,   318,   991,   262,   976,    13, 50258,  7091,   318,   991,\n",
              "            262,   976,    13, 50258,  7091]]),\n",
              " tensor([[50257,    40,   481,   407, 43373,   469,   262,  7464,    26,  2158,\n",
              "             11,   477,  1751,    82,  2523,   466,  4327,   284,   423,  3772,\n",
              "          38168,  1320,   815,  1577,   345,   257, 18437, 50260,    72,  1839,\n",
              "            470,  1560,   345,   262,  7464,   475,  1312,  1183,  1560, 21349,\n",
              "            986,   477,  3988,  2523,   423,  3772, 38168,   986, 50258,   568,\n",
              "             11,  1312,  1183,   655,  1560, 21349,   986,   477,  3988,  2523,\n",
              "            423,  3772, 38168,   986, 50258,     7,    72,  1183,  1560, 21349,\n",
              "            986,   340,   338, 17855,   588,   986,  1312,  1183,  1560, 21349,\n",
              "            986,   663, 17855,   588,   986,  1312,  1183,  1560, 21349,   986,\n",
              "           1267, 50258,     7,    72,  1183,  1560, 21349,   986,   340,   338,\n",
              "          17855,   588,   986,  1312,  1183]]),\n",
              " tensor([[50257,  1544,   373,   407,   781, 35355,   611,   734,   812,   467,\n",
              "            416,   290,   339,   991,   468,   407,  1965,   345,   329,   257,\n",
              "           3128, 50260,    17,   812,  1568,   290,   339,   338,   991,   407,\n",
              "           4737,   345,   503,    13, 50258,    17,   812,  1568,    11,   339,\n",
              "            991,  5818,   470,  1965,   345,   503,    13, 50258,    17,   812,\n",
              "           1568,   986,   339,   991,  5818,   470,  1965,   345,   503,   986,\n",
              "          50258,    17,   812,   986,   339,   991,  5818,   470,  1965,   345,\n",
              "            503,   986, 50258,    17,   812,   986,   339,   991,  5818,   470,\n",
              "           1965,   345,   503,   986, 50258,    17,   812,   986,   339,   991,\n",
              "           5818,   470,  1965,   345,   503,   986, 50258,    17,   812,   986,\n",
              "            339,   991,  5818,   470,  1965]]),\n",
              " tensor([[50257,  7120,  3656,   481,  1239,   760,   546,   428,    11,   645,\n",
              "            530,   481,    13, 50260,  3919,   530,   481,   760,   546,   340,\n",
              "             11,   534,  3656,   481,  1239,   760,    13, 50258,  3919,   530,\n",
              "            481,   760,   986,   534,  3656,   481,  1239,   760,   986, 50258,\n",
              "           3919,   530,   481,   760,   986,   673,  1183,  1239,   760,   986,\n",
              "          50258,  3919,   530,   481,   760,   986,   607,   986,   673,  1183,\n",
              "           1239,   760,   986, 50258,  3919,   530,   481,   760,   986,   673,\n",
              "           1183,  1239,   760,   986, 50258,  3919,   986,   673,  1183,  1239,\n",
              "            760,   986,   673,  1183,  1239,   760,   986, 50258,  3919,   986,\n",
              "            673,  1183,  1239,   760,   986,   673,  1183,  1239,   760,   986,\n",
              "          50258,  3919,   986,   673,  1183]]),\n",
              " tensor([[50257,  6030,   286, 17504,    11,   513,  4372,  1241,    25, 11052,\n",
              "            393, 20855,    13, 50260,  1169, 17504,   318,   329,   513,  4372,\n",
              "           1241,    11,   262,  1988,   393, 20855,    13, 50258,  1169, 17504,\n",
              "            318,   329,   513,  4372,  1241,    11,   262,  3616,   393, 20855,\n",
              "             13, 50258,  1169,  4006,   318,   329,   262,   513,  4372,  1241,\n",
              "             11,   262,  3616,   393, 20855,    13, 50258,  1169, 17504,   318,\n",
              "            329,   326,  1738,   986,  1988,   393, 20855,    13, 50258, 50258,\n",
              "           1169, 17504,   318,   986,   329,   513,  4372,  1241,   986,   262,\n",
              "           3616,   393, 20855,    13, 50258, 50258,  1169,  1738,   986,   329,\n",
              "            326,  1738,   986,   340,   318,   986,   257,  1988,   393, 20855,\n",
              "             13, 50258, 50258, 50258,  1169]]),\n",
              " tensor([[50257,  4366,  1450,   466,   290,  1854,   466,   407, 50260,  4366,\n",
              "           1450,   466, 16317,   392,   617,  1450,   836,   470,    13, 50258,\n",
              "           4366,  1450,   466, 16317,   392,   617,  1450,   836,   470,    13,\n",
              "          50258, 11246,  1450,   466, 16317,   392,   617,  1450,   836,   470,\n",
              "             13, 50258, 11246,  1450,   466, 16317,   392,   617,  1450,   836,\n",
              "            470,    13, 50258,   986,   392,   617,  1450,   466, 16317,   392,\n",
              "            617,  1450,   836,   470,    13, 50258,   986,   392,   617,  1450,\n",
              "            466, 16317,   392,   617,  1450,   466, 16317,   392,   617,  1450,\n",
              "            836,   470,    13, 50258,   986,   392,   617,  1450,   466, 16317,\n",
              "            392,   617,  1450,   466, 16317,   392,   617,  1450,   836,   470,\n",
              "             13, 50258,   986,   392,   617]]),\n",
              " tensor([[50257,    40,  1244,   423,   284,   651,   257,  1204,   286,   616,\n",
              "            898,   783,   475,  3863,   356,   477,   815, 50260,  2197,   314,\n",
              "           1244,   423,   284,  2107,   616,   898,  1204,   986, 25991,   356,\n",
              "            815,   477,   466,   340,    13, 50258,  2197,   314,  1244,   423,\n",
              "            284,   651,   257,  1204,   986, 25991,   356,   815,   477,   466,\n",
              "            340,    13, 50258,  2197,  1312,  1244,   423,   284,   466,   340,\n",
              "            986, 25991,   356,   815,   466,   340,    13, 50258,  2197,  1312,\n",
              "           1244,   423,   284,   466,   340,   986, 25991,   356,   815,   466,\n",
              "            340,    13, 50258,  2197,  1312,  1244,   423,   284,   466,   340,\n",
              "            986, 25991,   356,   815,    13, 50258,  2197,  1312,  1244,   423,\n",
              "            284,   466,   340,   986, 25991]]),\n",
              " tensor([[50257,  2953,   428,  2837,    11,   340,     6,   346,  2270,   257,\n",
              "           1178, 27105,    13, 50260,    64,  3155,   286, 27105,   481,  2270,\n",
              "            379,   428,  5253,    13, 50258,   265,   326,  5253, 16317,   257,\n",
              "           3155,   286, 27105,   481,   307,  5445,    13, 50258,    64,  3155,\n",
              "            286, 27105,   481,   307,  5445,    13, 50258,   265,   326,  5253,\n",
              "          16317,   257,  3155,   286, 27105,   481,   307,  5445,    13, 50258,\n",
              "             64,  3155,   286, 27105, 16317,   326,   338,   477,    13, 50258,\n",
              "          50258,    64,  3155, 16317,   326,   338,   477, 16317,   379,   326,\n",
              "           2837, 16317,   257,  3155, 16317,   389,   484,  5445,    30, 50258,\n",
              "            568, 16317,   326, 16317,   318,   340,  1744, 16317,   329,   326,\n",
              "          16317,    30, 50258,   568, 16317]]),\n",
              " tensor([[50257,   464,  6397,  9478,   286, 13106,  2236,   307, 30169,   416,\n",
              "           1099,    13, 50260,  1169,  1099, 19026,   262,  4129,   286,   262,\n",
              "           8771,    13, 50258,  1169,  1099,  3769,   329,   257,  6397,  9478,\n",
              "             13, 50258,  1169,  8771,   318, 30169,   416,  1099,    13, 50258,\n",
              "           1169,  8771,   318,  4361,  7520,   329,   257,  6397,  2278,    13,\n",
              "          50258,  1169,  1099,   318,  4361,  5281,   503,    13, 50258,  1169,\n",
              "           8771,   318,  4361, 30169,   416,  1099,    13, 50258,  1169,  2071,\n",
              "            318,  4361,  3066,   287, 10213,   351,   262,  1099,    13, 50258,\n",
              "           1169,  8771,   318,  4361, 14460,    13, 50258,  1169,  2071,   318,\n",
              "           4361,  3066,   287, 10213,   351,   262,  1099,    13, 50258,  1169,\n",
              "           8771,   318,  4361,  1760,   287]]),\n",
              " tensor([[50257,   464,  1936, 46783,   284,   465,  8286,  9456,   511,  8761,\n",
              "             13, 50260,  1169,  1936,  7588,  2157,   683,   547,  4030,   287,\n",
              "            511,  1781,    13, 50258,  1169,  2866,   286,   262,  5006,   373,\n",
              "           9456,   416,   262,  1936,  7588,    13, 50258,  1169,  1936,  7588,\n",
              "            547,  3888,   416,   683,    13, 50258,  1169,  2866,   373,  9456,\n",
              "            416,   262,  1936,  7588,    13, 50258,  1169,  5006,   547,  7986,\n",
              "            416,   683,    13, 50258,  1169,  2866,   373,  9456,   416,   262,\n",
              "           1936,  7588,    13, 50258,  1169,  1271,   373,   900,    13, 50258,\n",
              "           1169,  1271,   373,   973,   329,   326,    13, 50258,  1169,  1271,\n",
              "            373,   973,   329,   326,    11,   290,   523,   319,    13, 50258,\n",
              "           1169,  5006,   547,   973,   986]]),\n",
              " tensor([[50257,  7841, 22585,   611,   345,  2074,  3511, 29327, 35587, 50260,\n",
              "          16480,   611,   345,   892,   326,   334,   389, 13400,    13, 50258,\n",
              "          16480,   611,   334,   892,   334,   389, 13400,    13, 50258, 16480,\n",
              "            611,   334,   892,   326,   334,   389, 13400,    13, 50258, 16480,\n",
              "            611,   334,   892,   326,   334,   389, 13400,    13, 50258, 16480,\n",
              "            611,   334,   892,   326,   334,   389, 13400,    13, 50258, 16480,\n",
              "            611,   334,   892,   326,   334,   389, 13400,    13, 50258, 16480,\n",
              "            611,   334,   892,   326,   334,   389, 13400,    13, 50258, 16480,\n",
              "            611,   334,   892,   326,   334,   389, 13400,    13, 50258, 16480,\n",
              "            611,   334,   892,   326,   334,   389, 13400,    13, 50258, 16480,\n",
              "            611,   334,   892,   326,   334]]),\n",
              " tensor([[50257,  1639,   761,   284,  1064,  1811,   661,   351,  1180, 10530,\n",
              "          18054,    11,   884,   355, 13777,   393,  2712, 10047,    11, 24730,\n",
              "             11, 12702,    11,   393, 10586, 50260,  5832,   761,   284,  1064,\n",
              "           1811,   661,   351,  1180, 10530, 18054, 16317, 12215,   278,   393,\n",
              "           2712, 10047, 16317, 24730, 16317, 12702, 16317, 10586, 16317, 50258,\n",
              "           5832,   761,   284,  1064,  1811,   661, 16317, 12215,   278, 16317,\n",
              "            273, 16317,  2712, 16317, 10047, 16317, 24730, 16317, 12702, 16317,\n",
              "            393, 16317, 10586, 16317,    13, 50258, 50258,  5832,   761,   284,\n",
              "           1064,  1811, 16317, 12215,   364, 16317,   393, 16317,  2712, 16317,\n",
              "          16317, 10047, 16317, 24730, 16317,   393, 16317, 10586, 16317,    13,\n",
              "          50258,   986,   392,   986,   345]]),\n",
              " tensor([[50257,   464,  4252,    11, 11226,   866,   319, 19690, 10150,    11,\n",
              "           5635,   262,  6193,  3341,   286,   262, 13342,    13, 50260,  1169,\n",
              "           4252,   318, 22751,   287,   262, 19690, 21547,    11,   290,   262,\n",
              "           6193,  1080,   318,  5676,   416,   340,    13, 50258,  1169,  4252,\n",
              "            318, 22751,   287,   262,  9151,    11,   290,   262,  3403,   286,\n",
              "            262,  6193,   389,  5676,   416,   340,    13, 50258, 50258,  1169,\n",
              "           4252,   318, 22751,   287,   262, 19690, 21547,    11,   290,   262,\n",
              "           3403,   286,   262,  6193,   389,  5295,   416,   340,    13, 50258,\n",
              "          50258, 50258,  1169,  4252,   318, 22751,   287,   262,  9151,    11,\n",
              "            290,   262,  3403,   286,   262,  6193,   389,  5295,   416,   340,\n",
              "             13, 50258, 50258, 50258,  1169]]),\n",
              " tensor([[50257, 28211,   508,   338,  3377,   640,   287,   262,  3215, 10566,\n",
              "             13, 50260, 46248,   508,   468,  3377,   640,   287,   262,  8708,\n",
              "           9475,    13, 50258, 46248,   508,   468,  3377,   640,   287,   262,\n",
              "           8708,  9475,    13, 50258, 46248,   508,   468,  3377,   640,   287,\n",
              "            326,    13, 50258, 46248,   508,   468,  3377,   640,   287,   262,\n",
              "           8708,  9475,    13, 50258, 46248,   508,   468,  1760,   523,    13,\n",
              "          50258, 46248,   508,   468,  1760,   523,   986, 50258,   986,  2130,\n",
              "            508,   468,  3377,   640,   287,   262,  8708,  9475,    13, 50258,\n",
              "            986,  2130,   508,   468,  1760,   523,   986, 50258,   986,  2130,\n",
              "            508,   468,  1760,   523,   986, 50258,   986,  2130,   508,   468,\n",
              "           1760,   523,   986, 50258,   986]]),\n",
              " tensor([[50257,  3673,   881,   345,   460,   466,   618,   345,   761,   284,\n",
              "           2800,   262,  5243,  4429, 50260,  4053,   986,   407,   881,   345,\n",
              "            460,   466,   618,   345,   423,   284,   869,   262,  5243,  4429,\n",
              "             13, 50258,  4053,   986,   407,   881,   345,   460,   466,   618,\n",
              "            345,   423,   284,   869,   262,  5243,  4429,    13, 50258,  4053,\n",
              "            986,   407,   881,   345,   460,   466,   618,   345,   423,   284,\n",
              "            869,   262,  5243,  4429,    13, 50258,  4053,   986,   407,   881,\n",
              "            345,   460,   466,   618,   345,   423,   284,   869,   262,  5243,\n",
              "           4429,    13, 50258,  4053,   986,   407,   881,   345,   460,   466,\n",
              "            618,   345,   423,   284,   869,   262,  5243,  4429,    13, 50258,\n",
              "           4053,   986,   407,   881,   345]]),\n",
              " tensor([[50257,  1639,   815,  1309,   683,   760,   326,   345,   765,   284,\n",
              "          16552,   391,   422,  1714,  1566,   262,  2776, 19575, 50260, 33331,\n",
              "            683,   345,   765,   284,  4043,  1566,   262,  2776, 19575,    13,\n",
              "          50258, 33331,   683,   345,   765,   284,  4043,  1566,   262,  2776,\n",
              "          19575,    13, 50258, 50258, 33331,   683,   345,   765,   284,  4043,\n",
              "           1566,   262,  2776, 19575,    13, 50258, 50258, 50258, 33331,   683,\n",
              "            345,   765,   284,  4043,  1566,   262,  2776, 19575,    13, 50258,\n",
              "          50258, 50258, 50258, 33331,   683,   345,   765,   284,  4043, 10597,\n",
              "            262,  2776, 19575,    13, 50258, 50258, 50258, 33331,   683,   326,\n",
              "            345,   765,   284,  4043, 10597,   262,  2776, 19575,    13, 50258,\n",
              "          50258, 50258, 50258, 33331,   683]]),\n",
              " tensor([[50257, 13800,  4058,   290,  2666,   428,  2157,    11,   616,  1545,\n",
              "           8192,  1257, 50260,  5247,  4058,   290,  2666,   428,  2157,    11,\n",
              "            616,  1545,    13, 50258, 11230,   317, 37682,  5357, 12509,    32,\n",
              "           6089, 12680,  8355, 11651, 16317, 17615, 48167, 10619,  1106,    43,\n",
              "           3535, 50258, 11230,   317, 37682,  5357, 12509,    32,  6089, 12680,\n",
              "           8355, 11651, 16317, 17615, 48167, 10619,   986,    43,  3535, 50258,\n",
              "          11230,   317, 37682,  5357, 12509,    32,  6089, 12680,  8355, 11651,\n",
              "          16317, 17615, 48167, 10619,   986,    43,  3535,    13, 50258, 11230,\n",
              "            317, 37682,  5357, 12509,    32,  6089, 12680,  8355, 11651, 16317,\n",
              "          17615, 48167, 10619,   986,    43,  3535,    13, 50258, 11230,   317,\n",
              "          37682,  5357, 12509,    32,  6089]]),\n",
              " tensor([[50257,  1858,   373,  2147,  2073,   287,   262,  2119,  2845,   262,\n",
              "           2008,  4676, 12623,   287,   530,   401,   263,  1474,   262, 13387,\n",
              "             13, 50260,  8117,   373,  2147,  2073,   287,   262,  2119,  2845,\n",
              "            329,   262,  2008,  4676,   319,   262, 13387,    13, 50258,  1169,\n",
              "            691,  1517,  2073,   287,   262,  2119,   373,   262,  2008,  4676,\n",
              "            326,   373, 12623,   287,   262,  5228,    13, 50258,  1169,   691,\n",
              "           1517,   287,   262,  2119,   373,   262,  2008,  4676,    13, 50258,\n",
              "           1169,   691,  1517,  2073,   373,   262,   530,   319,   262, 13387,\n",
              "             13, 50258,  1169,   691,  1517,   373,   262,   530,   319,   262,\n",
              "           4314,    13, 50258,  1169,   691,  1517,   373,   262,   530,   287,\n",
              "            262,  5228,    13, 50258,  1169]]),\n",
              " tensor([[50257,     1,  1890,   262,  1306,  1811,  2250,    11,  2279,   373,\n",
              "           5897,    13, 50260,     1,   732,   547,  5897,   329,  1811,  2250,\n",
              "             13, 50258,     1,   732,   547,  5897,   329,   257,  1178,  2250,\n",
              "            706,   326,    13, 50258,     1,  8117,   373,   257,  3155,   286,\n",
              "           2250,   286,  9550, 16317,   366, 50258,     1,  8117,   373,   257,\n",
              "           3155,   286,  2250,   286,   326, 16317,   366, 50258,     1,   732,\n",
              "           1053,   587,  5897,   329,   257,  1178,  2431, 16317,   366, 50258,\n",
              "              1,   732,  1053,   587,   612, 16317,   329,   257,   981, 16317,\n",
              "            366, 50258,     1,   732,  1053,   587,   612, 16317,   329,   257,\n",
              "            981, 16317,   366, 50258,     1,   732,  1053,   587,   612, 16317,\n",
              "            329,   257,   981, 16317,   366]]),\n",
              " tensor([[50257,  2990,   389,  1611,   286,  4950,    11,   996,    11,  3588,\n",
              "            470,   484,    30, 50260,  9930,   821,  4950,    11,  3588,   470,\n",
              "            484,    30, 50258,  9930,   821,  4950, 16317,   220,  1119,   821,\n",
              "           4950, 16317,   220,  1320,   338,  1521, 16317,   484,   821,  4950,\n",
              "          16317,   220,  1119,   821,  4950, 16317,   326,   338,  1521, 16317,\n",
              "          50258,  9930,   821,  4950, 16317,   220,  1119,   821, 16317,   523,\n",
              "          16317,   484,   821, 16317,  4950, 16317,   220,  1320,   338,  1521,\n",
              "          16317,   484,   821, 16317,  4950, 16317,   326,   338,  1521, 16317,\n",
              "            484,   821, 16317,  4950, 16317,   326,   338,  1521, 16317, 50258,\n",
              "           9930,   821, 16317,  4950, 16317,   220,  1119,   821, 16317,   523,\n",
              "          16317,   484,   821, 16317,   484]]),\n",
              " tensor([[50257,  1722,   257,  1200,    11,   356, 15063,  4445,    11,   788,\n",
              "            551,    73,  2577,    72,    13, 50260,   732,  1053, 17065,   790,\n",
              "           1110,   329,   262,  1613,  1115,   812,   986,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,  1870,   788,  7288,   314,   760,   318, 16039,    11,   290,\n",
              "            314,  1101,    11,   314,  1101, 21693,   379,  1755,    13, 50260,\n",
              "            392,   788,   314,  2993,  2506,   373, 16039,    11,   290,   314,\n",
              "            373,   986,   314,   373,   986, 21693,   986,   379,  1755,    13,\n",
              "          50258,   392,   788,   986,   788,   986,   314,  2993,   986,   314,\n",
              "           2993,   986,   314,   373,   986, 21693,   986,   379,  1755,    13,\n",
              "          50258,   392,   986,   788,   986,   314,  2993,   986,   314,  2993,\n",
              "            986,   314,   373,   986, 21693,   986,   379,  1755,   986, 50258,\n",
              "            392,   986,   788,   986,   314,  2993,   986,   314,   373,   986,\n",
              "          21693,   986,   379,  1755,   986, 50258,   392,   986,   788,   986,\n",
              "            314,  2993,   986,   314,   373]]),\n",
              " tensor([[50257, 32397,   606,   262,  2187,  6766,   550,  1716,   257, 16134,\n",
              "            286,  5788,    13, 50260,    64, 16134,   286,  5788,   373,  9066,\n",
              "           2029,   606,    13, 50258, 29370,   606,    11,   612,   373,   257,\n",
              "           6766,   286,  5788,    13, 50258, 29370,   606,    11,   612,   373,\n",
              "            257,  3359,   286,  5788,    13, 50258,  8117,   373,   257,  3359,\n",
              "            286,   606,   287,   262,  6766,    13, 50258, 29370,   606,    11,\n",
              "            612,   373,   257, 16134,   286,  5788,    13, 50258, 29370,   606,\n",
              "             11,   340,   373,   257, 13646,   286,   262,  6766,    13, 50258,\n",
              "            270,   373,   257, 13646,   286,   262,  6766,    13, 50258,  1169,\n",
              "           6766,   373,   852,  9066,    13, 50258,   270,   373,   523,   881,\n",
              "             13, 50258, 29370,   606,    11]]),\n",
              " tensor([[50257,   464,  1109,   318,   314,  1101,  9646,   866,   257, 25912,\n",
              "            437,    11,   257, 29262,    13, 50260,  1169,  1109,   318, 16317,\n",
              "            314,  1101,  2045,   329,   257, 11868, 16317,   257, 25906,    13,\n",
              "          50258,  1169,  1109,   318, 16317,   314,  1101,  2045,   329,   257,\n",
              "          11868, 16317,   257, 25906,    13, 50258, 50258,    40,  1101,  2045,\n",
              "          16317,   329,   257, 29262, 16317,   257, 25906, 16317,   326,   338,\n",
              "            477,    13, 50258,  5562,   338,  1521, 16317,   314,  1101,  2045,\n",
              "          16317,   329,   257, 29262, 16317,   257, 25906, 16317,   326,   338,\n",
              "            477,    13, 50258,  5562,   338,  1521, 16317,   314,  1101,  2045,\n",
              "          16317,   329,   257, 29262, 16317,   257, 25906, 16317,   326,   338,\n",
              "            477,    13, 50258,  5562,   338]]),\n",
              " tensor([[50257,    40,  5465,  3589,   329,   407,  4737,   607,   503, 14556,\n",
              "            355,   262,  3516,   673,   318,   351,   783,   857,   407, 10925,\n",
              "            607, 50260,    40,  5465,  3589,   329,   407,  4737,   607,   503,\n",
              "          14556,    11,   262,  3516,   673,   318,   351,   783,  1595,   470,\n",
              "          10925,   607,    13, 50258,    72,  5465,  3589,   329,   407,  4737,\n",
              "            607,   503, 14556,   986,   262,  3516,   673,   318,   351,   783,\n",
              "          14071,   607,    13, 50258,    72,  5465,  3589,   329,   407,  4737,\n",
              "            607,   503, 14556,   986,   262,  3516,   673,   318,   351, 14071,\n",
              "            607,    13, 50258, 50258,    72,  5465,  3589,   329,   407,  4737,\n",
              "            607,   503, 14556,   986,   262,  3516,   673,   318,   351, 14071,\n",
              "            607,    13, 50258, 50258,    72]]),\n",
              " tensor([[50257,    40,  1807,   340,   373, 36102,    11,   290,   314,   716,\n",
              "          21541, 50260,    72,  1807,   340,   373,  8258,   290,   545,   257,\n",
              "          21541,    13, 50258,    72,  1101,   257, 21541,    11,   523,  1312,\n",
              "           1807,   340,   373,  8258,    13, 50258,    72,  1101,   257, 21541,\n",
              "             11,   523,  1312,  1807,   340,   373,  8258,    13, 50258, 50258,\n",
              "             72,  1807,   340,   373, 28297,   986,  1312,  1101,   257, 21541,\n",
              "             13, 50258, 50258,    72,  1807,   340,   373,   986,   880,   986,\n",
              "           1312,  1101,   257, 21541,   986,   523,   986,  1312,  1807,   986,\n",
              "           1312,  1101,   257, 21541,   986, 50258, 50258, 50258, 50258, 50258,\n",
              "             72,  1807,   986,  1312,  1101,   986,  1312,  1101,   986,  1312,\n",
              "           1807,   986,  1312,  1807,   986]]),\n",
              " tensor([[50257,  1212,  8636,   750,   407, 19330, 10653,   422, 20691,   287,\n",
              "          25112, 36700,    13, 50260, 39308,   654,   319,   262,  4308,   286,\n",
              "          20691,   287,   262,  1271,   286,  4409,   287,   262, 10043,   373,\n",
              "            407,  3017,   287,   428,  8636,    13, 50258,  1169,  8636,   373,\n",
              "            407,  3017,   287,   262, 17952,   286,   262, 10653,  7186,   422,\n",
              "            262,  7741,   287,   262,  1271,   286,  3085,   379,   262, 10043,\n",
              "             13, 50258, 39308,   654,   547,   407,  3017,   287,   262, 17952,\n",
              "            286,   428,  2033,    11,   543,   373,  1912,   319,   262,  7741,\n",
              "            287,   262,  1271,   286,  4409,    13, 50258, 39308,   654,   547,\n",
              "            407,  3017,   287,   262, 17952,   286,   428,  2033,    11,   543,\n",
              "            373,  2233,   284,   262,  7741]]),\n",
              " tensor([[50257, 31632,   635,  6698,   262,  2526,   286,  7417, 45106,    13,\n",
              "          50260, 31632,   635,  6698,   262,  2526,   286,   262, 45106,   286,\n",
              "          10509,    13, 50258, 31632,   318,   635,  2426,   284,   262,  2526,\n",
              "            286,  8649,    13, 50258, 42002,  4568,   389,   635,  8556,   287,\n",
              "           7137,    13, 50258, 42002,  4568,   389,   635,  8556,   287,   428,\n",
              "           2461,    13, 50258, 42002,  4568,   389,   635,  8556,   287,   428,\n",
              "           2461,    13, 50258, 42002,  4568,   389,   635,  8556,   287,   428,\n",
              "           1339,    13, 50258, 42002,  4568,   389,  4361,  8556,    13, 50258,\n",
              "          42002,  4568,   389,  4361,  5281,   503,    13, 50258, 42002,  4568,\n",
              "            389,  4361,  5281,   503,   986,   287,   428,  1339,   986,    13,\n",
              "          50258, 42002,  4568,   986,   389]]),\n",
              " tensor([[50257, 37280,    11,  6041,   286,  1243,    13,   532,   921,   466,\n",
              "           6041,   286,  1243,    30, 50260,  4598,   345,   466,   257,  1256,\n",
              "            286,  1243,    30, 50258,  4598,   345,   466,   257,  1256,   286,\n",
              "           1243,    30, 50258,  4598,   345,   466,   257,  1256,   286,  1243,\n",
              "             30, 50258,  4598,   345,   466,   257,  1256,   286,  1243,    30,\n",
              "          50258,  4598,   345,   466,   257,  1256,   286,  1243,    30, 50258,\n",
              "             30,   986,  6041,   286,  1243,    30,   986, 50258,    30,   986,\n",
              "           6041,   286,  1243,    30,   986,  5633,   986,  5633,   986,  5633,\n",
              "            986,  5633,   986,  5633,   986,  5633,   986,  5633,   986,    30,\n",
              "            986,    30,   986,    30,   986,    30,   986,    30,   986,    30,\n",
              "            986,    30,   986,    30,   986]]),\n",
              " tensor([[50257,   464,  8771,   329, 18094,   286,   262,  9384,   286,   262,\n",
              "          19572,  2236,   307,  8104,   866,   416,  2176,  3953,   286,  5923,\n",
              "          11159,    13, 50260,  1169,  5923, 11159,  8771,   318,  1912,   319,\n",
              "            257,  2176,  3953,    11,   543,   318,   262,  8771,   329,   262,\n",
              "          18094,   286,   262,  9384,   286,   262, 19572,    13, 50258,  1169,\n",
              "           8771,   329,   262, 19637,   286,   262, 19572,   318,   900,   503,\n",
              "            287,   262,  5923, 11159,  8771,    13, 50258,  1169,  8771,   318,\n",
              "            900,   503,   287,   262,  5923, 11159,  8771,    11,   543,   318,\n",
              "            262,  8771,   329,   262, 19637,   286,   262,  9384,    13, 50258,\n",
              "           1169, 17734,   318,   900,   503,   287,   428,  1339,    11,   329,\n",
              "            262, 19637,   286,   262, 19572]]),\n",
              " tensor([[50257, 35320,   874,   743,   307, 23707, 17033,   611, 12681,  3048,\n",
              "            393,  2465,   389,  1884,   284,  3051,    13, 50260,   361,   612,\n",
              "            318,   257,  2526,   286, 12681,  3048,   393,  2465,    11,  4695,\n",
              "            815,   307, 23707, 17033,    13, 50258,   361,   612,   318,   257,\n",
              "           2526,    11,  4695,   815,   307, 23707,   379,   257,  2176,  1295,\n",
              "             13, 50258,   361,   612,   318,   257,  2526,    11,   262,  4695,\n",
              "            815,   307, 23707,   379,   326,  1295,    13, 50258,   361,   612,\n",
              "            318,   257,  2526,    11,   484,   815,   307, 23707,   287,   326,\n",
              "            835,    13, 50258,   361,   612,   318,   257,  2526,    11,   484,\n",
              "            815,   307, 23707,   379,   326,  1295,    13, 50258,   361,   612,\n",
              "            318,   257,  2526,    11,   484]]),\n",
              " tensor([[50257,  1544,   338,   257,  1844, 41409,   329, 21608,   319,   345,\n",
              "             13, 50260,  1640, 21608,    11,   339,   318,   257,  1844, 31030,\n",
              "             13, 50258,  1640,   326,    11,   339,   318,   257,  1844, 31030,\n",
              "             13, 50258,   258,   318,   257,  1844, 29757,    13, 50258,   258,\n",
              "            318,   257, 22705,    11,   339,   318,   257, 22705,    13, 50258,\n",
              "           1640,   326,    11,   339,   318,   257, 22705,    13, 50258,  1640,\n",
              "            326,    11,   339,   318,   257, 22705,    13, 50258,   258,   318,\n",
              "            257, 22705,    13, 50258,   258,   318,   257, 22705,    13, 50258,\n",
              "            258,   318,   257, 22705,    13, 50258,   258,   318,   257, 22705,\n",
              "             13, 50258,  1640,   326,    11,   339,   318,   257, 22705,    13,\n",
              "          50258,  1640,   326, 16317,   339]]),\n",
              " tensor([[50257,    40,  1975,   618,   673,   373,  7099,   326,   673,  2826,\n",
              "          13732,  1424,  2239, 29642,   287,  3687,  7338, 50260,    72,   892,\n",
              "            673,   373,   257,   299, 15249,  2239,  4957,   287,  7627,  7338,\n",
              "             13, 50258,    72,   892,   673,   373,   257,   299, 15249,  2239,\n",
              "           4957,   287,  7627,  7338,    13, 50258,    72,   892,   673,   373,\n",
              "            257,   299, 15249,  2239,  4957,   287,  7627,  7338,    13, 50258,\n",
              "             72,   892,   523,   986,  1312,  4724,   986,  1312,  4724,   986,\n",
              "            673,   373,   257,   299, 15249,  2239,  4957,   287,  7627,  7338,\n",
              "            986, 50258, 50258,    72,  4724,   986,  1312,  4724,   986,   673,\n",
              "            373,   257,   299, 15249,  2239,  4957,   287,  7627,  7338,   986,\n",
              "          50258,    72,  4724,   986,   673]]),\n",
              " tensor([[50257,  3886,   262,   835,    11,   345,   389,  7205,   588,   281,\n",
              "          22324, 50260,    33,  4246,   986,   345,   821,  7205,   588,   281,\n",
              "          22324,   986,   416,   262,   835,    13, 50258,  1525,   262,   835,\n",
              "          16317,   345,   821,  7205,   588,   257,  9192, 16317,   416,   262,\n",
              "            835,    13, 50258,    33,  4246, 16317,   345,   821,  7205,   588,\n",
              "            257,  9192, 16317,   416,   262,   835,    13, 50258,    33,  4246,\n",
              "          16317,   345,   821,  7205,   588,   257,  9192, 16317,   416,   262,\n",
              "            835,    13, 50258,  1525,   262,   835, 16317,   345,   821,  7205,\n",
              "            588,   257,  9192, 16317,   416,   262,   835,    13, 50258,    33,\n",
              "           4246, 16317,   345,   821,  7205,   588,   257,  9192, 16317,   416,\n",
              "            262,   835,    13, 50258,    33]]),\n",
              " tensor([[50257,    40,  2497,   302,    12,   707, 18800, 20788,   287,   262,\n",
              "           7993, 18216, 41408,   286,  1770,    13,   370,  2840,   293,    13,\n",
              "          50260,   259,   262,  7993, 18216, 41408,    11,   314,  2497,   257,\n",
              "            302,    12,   707, 18800,   286, 20788,    13, 50258,    40,  2497,\n",
              "            257,  6227,   329,   302,    12,   298,  1586,   262, 22482,    13,\n",
              "          50258,    40,  2497,   257,  6227,   329,   340, 16317,   287,   262,\n",
              "          18216, 41408, 16317,   286,  1770,    13,   370,  2840,   293,    13,\n",
              "          50258,    40,  2497, 16317,   257,  6227, 16317,   329,   302,    12,\n",
              "            298,  1586, 16317,   262, 22482,    13, 50258,    40,  2497, 16317,\n",
              "            257,  6227, 16317,   329,   340, 16317,   287,   262, 18216, 41408,\n",
              "          16317,   286,  1770,    13,   370]]),\n",
              " tensor([[50257,  5297,   393,  2822, 22537, 50260,  8505,   393,  2822, 22537,\n",
              "             13, 50258,  8505,   393,  2822, 22537,    13, 50258,  8505,   393,\n",
              "           2822, 22537,    13, 50258,  8505,   393,  2822, 22537,    13, 50258,\n",
              "           8505,   393,  2822,   606,   986, 50258,  8505,   393,  2822,   606,\n",
              "            986, 50258,  8505,   393,  2822,   606,   986, 50258,  8505,   393,\n",
              "           2822,   606,   986, 50258,  8505,   393,  2822,   606,   986, 50258,\n",
              "           8505,   393,   986,  2822,   606,   986, 50258,  8505,   986,   393,\n",
              "            986,  2822,   986,   340,   986, 50258,  8505,   986,   393,   986,\n",
              "           2822,   986,   340,   986, 50258,  8505,   986,   393,   986,  2822,\n",
              "            986,   340,   986, 50258,  8505,   986,   393,   986,  2822,   986,\n",
              "            340,   986, 50258,  8505,   986]]),\n",
              " tensor([[50257, 14574,  8242,  6304,   470, 44799,   588,   262,   311,  1549,\n",
              "            272, 10872,   338,    13, 50260,  1169,   311,  1549,   272, 10872,\n",
              "            338,  8242,   547,   407, 44799,    13, 50258,  1169,   311,  1549,\n",
              "            272, 10872,   338,  8242,   547,   407, 44799,    13, 50258,  1169,\n",
              "            311,  1549,   272, 10872,   373,   407,  5762,   606,    13, 50258,\n",
              "           1169,   311,  1549,   272, 10872,   373,   407,  5762,   606,    13,\n",
              "          50258,  1169,   311,  1549,   272, 10872,   373,   407,  5762,   606,\n",
              "             13, 50258,  1169,   311,  1549,   272, 10872,   373,   407,  5762,\n",
              "            606,    13, 50258,  1169,   311,  1549,   272, 10872,   373,   407,\n",
              "             13, 50258,  1169,   311,  1549,   272, 10872,   373,   407,    13,\n",
              "          50258,  1169,   311,  1549,   272]]),\n",
              " tensor([[50257,  1532,   345,  1107,   466,  1842,   607,   788,   345,   561,\n",
              "            407, 50260,   361,   345,  1107,  1842,   607,   788,   345,  3636,\n",
              "            470,    13, 50258,  1532,   345,  1107,  1842,   607,    11,   345,\n",
              "           3636,   470,    13, 50258,  1532,   345,  1107,  1842,   607,   986,\n",
              "           3919,    13, 50258,   361,   345,  1107,  1842,   607,   986,  3919,\n",
              "             13, 50258,  1532,   345,  1107,  1842,   607,   986,  3919,    13,\n",
              "          50258,   361,   345,  1107,  1842,   607,   986,  3919,    13, 50258,\n",
              "            361,   345,  1107,  1842,   607,   986,  3919,    13, 50258,   361,\n",
              "            345,  1107,  1842,   607,   986,  3919,    13, 50258,   361,   345,\n",
              "           1107,  1842,   607,   986,  3919,    13, 50258,   361,   345,  1107,\n",
              "           1842,   607,   986,  3919,    13]]),\n",
              " tensor([[50257, 36690,   286,   262,  6483,   389,   407,  1165, 47602,  2035,\n",
              "             13, 50260,  1169,  6483,   836,   470,   423,   867,  3891,    13,\n",
              "          50258,  1169,  6483,   836,   470,   423,   867,  3891,   986, 50258,\n",
              "           1169,  6483,   836,   470,   423,   867,  3891,   986, 50258,  1169,\n",
              "           6483,   836,   470,   423,   867,  3891,   986, 50258,  1169,  6483,\n",
              "            836,   470,   423,   867,   986, 50258,  1169,  6483,   836,   470,\n",
              "            423,   867,   986, 50258,  1169,  6483,   836,   470,   423,   867,\n",
              "            986, 50258,  1169,  6483,   836,   470,   423,   867,   986, 50258,\n",
              "           1169,  6483,   836,   470,   423,   867,   986, 50258,  1169,  6483,\n",
              "            836,   470,   423,   867,   986, 50258,  1169,  6483,   836,   470,\n",
              "            423,   986, 50258,  1169,  6483]]),\n",
              " tensor([[50257, 36087, 29037,    11,   383,   922,  1661,   547,  1239,   523,\n",
              "            922, 50260, 36087, 29037, 16317,  1169,   922,  1661,   547,  1239,\n",
              "            523,   922, 16317, 50258,     7,  1169,   922,  1661,  6304,   470,\n",
              "            326,  1049, 16317,     8, 50258,     7,  1169,   922,  1661,   547,\n",
              "           1239,   523,   922, 16317,     8, 50258,     7,  1169,   922,  1661,\n",
              "            547,  1239,   523,   922, 16317,     8, 50258,     7,  9930,   547,\n",
              "          16317,     8, 50258,     7,  9930,   547, 16317,     8,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257, 20459,   257,  4097,    11,  4043,   257,  1227,   290,   484,\n",
              "            297,   307, 11238,   546,   340, 50260,   896,   257,  4097, 16317,\n",
              "           4043,   257,  1227, 16317,   484,   297,   307, 11238,   546,   340,\n",
              "             13, 50258,   896,   257,  4097, 16317,  4043,   257,  1227, 16317,\n",
              "            484,   297,   307, 11238,   546,   340,    13, 50258,   896,   257,\n",
              "           4097, 16317,  4043,   257,  1227, 16317,   484,   297,   307, 11238,\n",
              "            546,   340,    13, 50258,   896,   257,  4097, 16317,  4043,   257,\n",
              "           1227, 16317,   484,   297,   307, 11238,   546,   340,    13, 50258,\n",
              "            896,   257,  4097, 16317,  4043,   257,  1227, 16317,   484,   297,\n",
              "            307, 11238,   546,   340,    13, 50258,   896,   257,  4097, 16317,\n",
              "           4043,   257,  1227, 16317,   484]]),\n",
              " tensor([[50257,  5297,    11,   996,   314, 11691,   340,  8338,   319,   262,\n",
              "          36605, 50260,  8505,    11,   475,  1312,  4724,   340,  8338,   319,\n",
              "            262, 36605,    13, 50258, 43669,    11,   475,  1312,  4724,   340,\n",
              "           8338,   319,   262, 36605,    13, 50258, 43669,    11,   475,  1312,\n",
              "           4724,   340,  8338,   319,   262, 36605,    13, 50258, 43669,   986,\n",
              "            475,  1312,  4724,   340,  8338,   319,   262, 36605,    13, 50258,\n",
              "          43669,   986,   475,  1312,  4724,   340,  8338,   319,   262, 36605,\n",
              "             13, 50258, 43669,   986,   475,  1312,  4724,   986,  1312,  4724,\n",
              "            986,  1312,  4724,   986,  1312,  4724,   986,  1312,  4724,   986,\n",
              "          50258, 50258, 43669,   986,   475,   986,  1312,  4724,   986,  1312,\n",
              "           4724,   986,  1312,  4724,   986]]),\n",
              " tensor([[50257,  6214,   611,   345,   460, 17276, 21586,   911,  4224,    84,\n",
              "            290,  6253, 22673,   301,  1754,    13, 50260,  5832,   460,   804,\n",
              "            329, 21586,   911,  4224,    84,   290,  1583,    13, 22673,   301,\n",
              "           1754,    13, 50258,  5832,  1183,  1064, 21586,   911,  4224,   290,\n",
              "           1583,    13,   509,  2797,  1754,    13, 50258,  5832,  1183,  1064,\n",
              "            683,   290, 21586,   911,  4224,    13, 50258,  5832,  1183,  1064,\n",
              "            683,   986,   290,   788,   345,  1183,  1064, 21586,   911,  4224,\n",
              "             13, 50258,  5832,  1183,  1064,   683,   986,   290,   788,   986,\n",
              "            345,  1183,  1064,   683,   986,   290,   788,   986,   345,  1183,\n",
              "           1064,   683,   986, 50258,  5832,  1183,  1064,   683,   986,   290,\n",
              "            986,   345,  1183,  1064,   683]]),\n",
              " tensor([[50257,  1858,   318,   257,  3094,  4996,   286,  2647,  1695, 50260,\n",
              "           8117,   318,   257,  2187,  1256,   286,  2647,   503,   612,    13,\n",
              "          50258,  8117,   318,   257,  2187,  1256,   286,  2647,   503,   612,\n",
              "             13, 50258, 50258,  1169,   411,   257,  2187,  1256,   286,  2647,\n",
              "            503,   612,    13, 50258,  1169,   411,   257,  2187,  1256,   286,\n",
              "           2647,    13, 50258,     0,   986,   392,   612,   338,   257,  2187,\n",
              "           1256,   286,   340,    13, 50258,    25,     8, 50258,    25,     8,\n",
              "            220,   220,   220,  1318,   338,   257,  2187,  1256,   286,  2647,\n",
              "            503,   612,   986, 50258,    25,     8,   220,  1058,  1267,   220,\n",
              "            220,   220,   220,  1058,  1267,   220,  1058,  1267,   220,  1058,\n",
              "           1267,   220,  1058,  1267,   220]]),\n",
              " tensor([[50257,    40,   423,  2428,  4756,   510,   546,  3589, 50260,    72,\n",
              "            423,  2428,  4756,   510,   546,  3589,    13, 50258,    72,   423,\n",
              "           2428,  4756,   510,   546,  3589,    13, 50258,    72,   423,  2428,\n",
              "           4756,   510,   546,  3589,    13, 50258,    72,   423,  2428,  4756,\n",
              "            510,   546,  3589,    13, 50258,    72,   423,  2428,  4756,   510,\n",
              "            546,  3589,    13, 50258,    72,   423,  2428,  4756,   510,   546,\n",
              "           3589,    13, 50258,    72,   423,  2428,  4756,   510,   546,  3589,\n",
              "             13, 50258,    72,   423,  2428,  4756,   510,   546,  3589,    13,\n",
              "          50258,    72,   423,  2428,  4756,   510,   546,  3589,    13, 50258,\n",
              "             72,   423,  2428,  4756,   510,   546,  3589,    13, 50258,    72,\n",
              "            423,  2428,  4756,   510,   546]]),\n",
              " tensor([[50257,     1,   464,  1413,   336,  2973,   290,   262,  3437,   427,\n",
              "            896,   287,   465, 12581,   526, 50260,     1,  1169,  1413,   318,\n",
              "          23374,   290,   262,  3437,   318, 30874,   526, 50258,   986,  1169,\n",
              "           1413,   318, 23374,   986,   262,  3437,   318, 30874,   986, 50258,\n",
              "            986,  1169,  1413,   318, 23374,   986,   262,  3437,   318,   986,\n",
              "            427,  2535,   986,   287,   465, 12581,   986, 50258,   986, 50258,\n",
              "            986,   262,  1413,   318, 23374,   986,   262,  3437,   986,   318,\n",
              "            986,   427,  2535,   986,   287,   986,   465,   986, 12581,   986,\n",
              "          50258,   986,   326,   986,   318,   986,   644,   986,   339,   986,\n",
              "            318,   986,  1804,   986,   986,   287,   986,   262,   986,  1413,\n",
              "            986, 50258,   986,   326,   986]]),\n",
              " tensor([[50257,   464,  4890,   481,  1884,   407,  1441, 50260,   464,  4890,\n",
              "            318,  1884,   284,   467,  1497,    13, 50258,  1169,  4890,   318,\n",
              "           2192,   407,  1016,   284,  1441,    13, 50258,  1169,  4890,   318,\n",
              "           2192,   407,  1016,   284,  1282,   736,    13, 50258,  1169,  4890,\n",
              "            318,  2192,   407,  1016,   284,  1282,   736,    13, 50258,  1169,\n",
              "           4890,   481,  2192,   407,  1441,    13, 50258,  1169,  4890,   318,\n",
              "           2192,   407,  1016,   284,  1282,   736,    13, 50258,  1169,  4890,\n",
              "            318,  2192,   407,  1016,   284,  1282,   736,    13, 50258,  1169,\n",
              "           4890,   318,  2192,   407,  1016,   284,  1282,   736,    13, 50258,\n",
              "           1169,  4890,   318,  2192,   407,  1016,   284,  1282,   736,    13,\n",
              "          50258,  1169,  4890,   318,  2192]]),\n",
              " tensor([[50257,  5211,   407,   892,   340,   318,  1016,   284,   307,   477,\n",
              "            613,  3694,   290,  8566, 50260,  1870,   836,   470,   892,   340,\n",
              "            338,  1016,   284,   307,   477,   613,  3694,   290,  8566,    13,\n",
              "          50258,  3987,   470,   892,   340,   338,  8066,   307,   477,   613,\n",
              "           3694,   290,  8566,    13, 50258, 50258,  1870,   836,   470,   892,\n",
              "            340,   338,  8066,   307,   477,   613,  3694,   290,  8566,    13,\n",
              "          50258, 50258,  1870,   836,   470,   892,   340,   338,  8066,   307,\n",
              "            477,   613,  3694,   290,  8566,    13, 50258, 50258, 50258,   392,\n",
              "            836,   470,   892,   340,   338,  8066,   307,   986, 50258,  1870,\n",
              "            836,   470,   892,   340,   338,   986, 50258,   392,   986, 50258,\n",
              "            392,   986,   836,   470,   986]]),\n",
              " tensor([[50257, 10814,    11,  3730,    11,   804,   379,   428, 13400, 27517,\n",
              "            314,   655,  1043,    13, 50260,  5460,   379,   326, 13400,  6131,\n",
              "            314,  1043,    13, 50258,  5460,    11,  3730, 16317,  1312,   655,\n",
              "           1043,   428, 13400, 27517, 16317,   290,  1312,  1101,  8805,    13,\n",
              "          50258, 50258, 50258,  5162,   893, 16317,  1312,  1101,  8805, 16317,\n",
              "            780, 16317,  1312,  1043, 16317,   428, 13400,  6131, 16317,   290,\n",
              "           1312,  1101,  7954,    13, 50258, 50258,  5162,   893, 16317,  1312,\n",
              "           1101,  8805, 16317,   780, 16317,  1312,  1043, 16317,   428, 13400,\n",
              "           6131, 16317,   290,  1312,  1101,  8805,    13, 50258, 50258, 50258,\n",
              "          50258,   986,   290, 16317,  1312,  1101,  8805, 16317,   780, 16317,\n",
              "           1312,  1043, 16317,   326, 16317]]),\n",
              " tensor([[50257,  1135,   550,   257,  1310,  4845, 10537, 27639,   994,   257,\n",
              "           3155,   286,   812,  2084,    13, 50260,    64,  3155,   286,   812,\n",
              "           2084, 16317,   356,   550,   257,  1310,  4845, 10537, 27639,    13,\n",
              "          50258,    64,  3155,   812,  2084, 16317,   356,   550,   257,  1310,\n",
              "           4845, 10537, 27639,    13, 50258,    64,  3155,   812,  2084, 16317,\n",
              "            356,   550,   257,  1310,  4845, 10537,   986, 50258,    64,  3155,\n",
              "            812,  2084, 16317,   356,   550, 16317,   257,  1310,   986,  4845,\n",
              "          10537, 16317, 50258,    64,  3155,   812,  2084, 16317,   356,   550,\n",
              "          16317,   257,  1310,   986, 10537, 16317, 50258,    64,  3155,   986,\n",
              "            812,  2084, 16317,   356,   550, 16317,   257,   986,  1310, 16317,\n",
              "          10537, 16317,    13, 50258,   986]]),\n",
              " tensor([[50257,    45,  6148,   290, 12301,  5689,  4635,   257,  3496,  1978,\n",
              "          11946,    11,  3497,   632,  7695,  2105, 50260,    45,  6148,  1222,\n",
              "          12301,  5689,  4635,   257,  3496,  1978, 16317, 18851,  7283, 19922,\n",
              "           3185,  2751,    13, 50258,    45,  6148,  1222, 12301,  5689,  4635,\n",
              "            257,  3496,  1978, 16317, 18851,  7283, 19922,  3185,  2751,    13,\n",
              "          50258,    45,  6148,  1222, 12301,  5689,  1106,  4635,   257,  3496,\n",
              "          16317, 18851,  7283, 19922,  3185,  2751,    13, 50258,    45,  6148,\n",
              "           1222, 12301,  5689, 12359,  4635,   257,  3496, 16317, 18851,  7283,\n",
              "          19922,  3185,  2751,    13, 50258,    45,  6148,  1222, 12301,  5689,\n",
              "          16317,  4635,   257,  3496, 16317, 18851,  7283, 19922,  3185,  2751,\n",
              "             13, 50258,   986, 50258,   986]]),\n",
              " tensor([[50257,    40,   750,   407,   892,   546,   326,   618,   314,   373,\n",
              "          17991, 19066, 50260,    72,  1422,   470,   892,   546,   326,   618,\n",
              "           1312,   373, 19095,    13, 50258,    72, 42547,   892,   546,   326,\n",
              "            618,  1312,   373,  6507,    13, 50258,    72, 42547,   892,   546,\n",
              "            326,   618,  1312,   373,  6507,    13, 50258,    72, 42547,   892,\n",
              "            546,   326,   618,  1312,   373,  6507,    13, 50258,    72, 42547,\n",
              "            892,   546,   326,   618,  1312,   373,  6507,    13, 50258,    72,\n",
              "          42547,   892,   546,   326,    13, 50258,    72, 42547,   892,   546,\n",
              "            326,    13, 50258,    72, 42547,   892,   546,   326,    13, 50258,\n",
              "             72, 42547,   892,   546,   326,   618,  1312,   373,  6507,    13,\n",
              "          50258,    72, 42547,   892,   546]]),\n",
              " tensor([[50257,  5195,   466,   484,   407,  2222,   777, 38313,   284,  5316,\n",
              "             30, 50260, 22850,   836,   470,   484,  2222,   606,   284,  5316,\n",
              "             30, 50258, 22850,   836,   470,   484,  1234,   606,   287,  2184,\n",
              "             30, 50258, 22850,   836,   470,   484,   466,  1997,   546,   606,\n",
              "             30, 50258, 22850,   836,   470,   484,   466,  1997,   546,   606,\n",
              "             30, 50258, 22850,   836,   470,   484,   466,  1997,   546,   340,\n",
              "             30, 50258,    30,   986, 50258,   986,  1521,   836,   470,   484,\n",
              "            466,  1997,   546,   340,    30,   986, 50258,   986,  1521,   836,\n",
              "            470,   484,    30,   986, 50258,   986,  1521,   836,   470,   484,\n",
              "             30,   986, 50258,   986,  1521,   836,   470,   484,    30,   986,\n",
              "          50258,   986,  1521,   836,   470]]),\n",
              " tensor([[50257,    40,   716,   845, 16245,   286,   383,  4453,   286,   262,\n",
              "          26028, 50260,    72,  1842,   262, 15876,   286,   262, 13917,    13,\n",
              "          50258,    72,  1842,   262, 15876,   286,   262, 13917,    13, 50258,\n",
              "             72,  1842,   262, 15876,   286,   262, 13917,    13, 50258,    72,\n",
              "           1842,   262, 15876,   286,   262, 13917,    13, 50258,    72,  1842,\n",
              "            262, 15876,   286,   262, 13917,    13, 50258,    72,  1842,   262,\n",
              "          15876,   286,   262, 13917,    13, 50258,    72,  1842,   262, 15876,\n",
              "            286,   262, 13917,    13, 50258,    72,  1842,   262, 15876,   286,\n",
              "            262, 13917,    13, 50258,    72,  1842,   262, 15876,   286,   262,\n",
              "          13917,    13, 50258,    72,  1842,   262, 15876,   286,   262, 13917,\n",
              "             13, 50258,    72,  1842,   262]]),\n",
              " tensor([[50257,  1026,   373,   281, 10517, 29355,    11,   290,   788,   673,\n",
              "          19092,   510, 50260,  5562,   373,   257,  1263,  6486,    11,   290,\n",
              "            788,   673, 19092,   510,    13, 50258,  5562,   373,   257,  1263,\n",
              "          29355,   986,   788,   673, 19092,   510,    13, 50258,  5562,   373,\n",
              "            257,  1263,  6486,   986,   788,   673, 19092,   510,    13, 50258,\n",
              "           5661,   373,   257,  1263,  6486,   986,   788,   673, 19092,   510,\n",
              "             13, 50258,  5661,   373,   257,  1263, 29355,   986,   788,   673,\n",
              "          19092,   510,    13, 50258,  5562,   373,   257,  1263,  6486,   986,\n",
              "            788,   673, 19092,   510,    13, 50258,  5562,   373,   257,  1263,\n",
              "          29355,   986,   788,   673, 19092,   510,    13, 50258,  5562,   373,\n",
              "            257,  1263,  6486,   986,   788]]),\n",
              " tensor([[50257,  4366,   466,    11,   611,   484,   389,   262, 15800,  2099,\n",
              "          50260, 11246,   466,   986,   361,   484,   389,   262, 15800,  2099,\n",
              "            986, 50258,   361,   484,   389,   986,  4053,   986,   361,   484,\n",
              "            389,   986,  8524,   986,  1312,  4724,   986, 50258,    72,  4724,\n",
              "            986,   611,   484,   389,   986,   788,   986,  1312,  4724,   986,\n",
              "          50258,    72,  4724,   986,   611,   484,   389,   986,   788,   986,\n",
              "           1312,  4724,   986, 50258,   568,   986,   611,   484,   389,   986,\n",
              "            788,   986,  1312,  4724,   986, 50258,   568,   986,   611,   484,\n",
              "            389,   986,   788,   986,  1312,  4724,   986, 50258,   568,   986,\n",
              "            611,   484,   389,   986,   788,   986,  1312,  4724,   986, 50258,\n",
              "            568,   986,   611,   484,   389]]),\n",
              " tensor([[50257,  2061,   466,   345,    11,  3511,    11,   588,   546,   262,\n",
              "            582, 50260, 12359, 10919,   466,   345,   588,   546,   262,  3516,\n",
              "          16317,  3511,    13, 50258, 12359, 10919,   466,   334,   588,   546,\n",
              "            262,  3516, 16317,  2241,    13, 50258, 12359, 10919,   466,   334,\n",
              "            588,   546,   262,  3516, 16317,  2241,    13, 50258, 12359,   986,\n",
              "          10919,   466,   334,   588,   546,   683, 16317,  2241,    13, 50258,\n",
              "          12359,   986, 10919,   466,   334,   588,   546,   683, 16317,  2241,\n",
              "             13, 50258, 12359,    13, 50258, 12359, 10919,   466,   334,   588,\n",
              "            546,   262,  3516, 16317,  2241,    13, 50258, 12359,    13,   986,\n",
              "             13, 50258, 12359, 16317,   986,   329,   326,   986, 50258, 12359,\n",
              "            986,   329,   326,   986, 50258]]),\n",
              " tensor([[50257, 48401,  5890,   338,  7275, 17589,    13, 13080,   320,  8836,\n",
              "             81, 25424,   127,   251,   532, 22724,  5890, 50260, 17589,    13,\n",
              "            532,  5890,   532,  2907,   532,   314,   301, 10438,   532,  1305,\n",
              "          17096, 32790,   988,   532,   360, 17027,  1697,  1134,   532,   347,\n",
              "            128,   249,    75,  1219, 12944,   988,    13, 50258, 17589,    13,\n",
              "            532,  5890,   532,  2907,   532,   314,   301, 10438,   532,  1305,\n",
              "          17096, 32790,   988,   532,   360, 17027,  1697,  1134,   532,   347,\n",
              "            128,   249,    75,  1219, 12944,   988,    13, 50258,   532,   532,\n",
              "            532,   532,   532,   532,   532,   532,   532,   532,   532,   532,\n",
              "            532,   532,   532,   532,   532,   532,   532,   532,   532,   532,\n",
              "            532,   532,   532,   532,   532]]),\n",
              " tensor([[50257,  2990,   260,  1111,  1336,   286,   340, 50260,  9930,  1111,\n",
              "            423,   257,  1256,   286,   340,    13, 50258,  9930,  1111,   423,\n",
              "          43158,   286,   340,    13, 50258,  9930,  1111,   423, 43158,   286,\n",
              "            340,    13, 50258,  9930,  1111,   423, 43158,   286,   340,    13,\n",
              "          50258,  9930,  1111,   423, 43158,   286,   340,    13, 50258,  9930,\n",
              "           1111,   423, 43158,   286,   340,    13, 50258,  9930,  1111,   423,\n",
              "          43158,   286,   340,    13, 50258,  9930,  1111,   423, 43158,   286,\n",
              "            340,    13, 50258,  9930,  1111,   423, 43158,   286,   340,    13,\n",
              "          50258,  9930,  1111,   423, 43158,   286,   340,    13, 50258,  9930,\n",
              "           1111,   423, 43158,   286,   340,    13, 50258,  9930,  1111,   423,\n",
              "          43158,   286,   340,    13, 50258]]),\n",
              " tensor([[50257,  2953,   262,  4725,  3611, 10006,    11,   262,  4576,   373,\n",
              "           4075,   287,  1104,   286,   262,  5398, 15901, 50260,  1169,  4576,\n",
              "            373,  2950,   287,   262,  5398,  1104,   329,   262,  4725,  3611,\n",
              "          10006,    13, 50258,  1169,  4576,   373,  2950,   287,   262,  5398,\n",
              "           1104,   329,   262,  4725,  3611, 10006,    13, 50258, 50258,  1169,\n",
              "           4576,   373,  2950,   287,   262,  2071,   286,  3340,   338, 10270,\n",
              "            287,   262,  4725,  3611, 10006,    13, 50258, 50258,  1169,  2071,\n",
              "            373,  4376,   416,   262,  4576,   379,   262,  4725,  3611, 10006,\n",
              "             13, 50258,  1169,  4576,   373,  2950,   287,   262,  2071,   286,\n",
              "            428,  3842,   287,   262,  4725,    13, 50258,  1169,  2071,   373,\n",
              "           4376,   416,   262,  4576,   379]]),\n",
              " tensor([[50257,  1212,   318,   281,  6565,  1989,   290,   340,   318,   826,\n",
              "           1306,   284,   262,  4911,  1014, 50260,  8117,   338,   281,  6565,\n",
              "           2272,   826,  1306,   284,   262, 12763,    13, 50258,  1169,   691,\n",
              "           1517,   318, 16317,   262,  1989,   318,   986,   826,  1306,   284,\n",
              "            262,  2975,    13, 50258,  1169,   691,  1517, 16317,   318, 16317,\n",
              "            262,  1989, 16317,   318, 16317,   826,  1306,   284,   262, 12763,\n",
              "             13, 50258, 50258,  1169,   691, 16317,  1517, 16317,   318, 16317,\n",
              "            262,  1989, 16317,   318, 16317,   262,   530, 16317, 16317,   543,\n",
              "            986,   318, 16317,   262,   530, 16317,    13, 50258, 50258, 50258,\n",
              "           1169,   691, 16317,  1517, 16317,   318, 16317,   262, 16317,  1989,\n",
              "          16317,   318, 16317,   262, 16317]]),\n",
              " tensor([[50257,   464, 15530,  2683,   651,   517,  3842,   319, 16551, 50260,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517,  3842,   319, 16551,     0, 50258,\n",
              "           3791,   263,  2683,   651,   517]]),\n",
              " tensor([[50257,  1858,   338,   645,   835,   691,   838,   438,   532,  1406,\n",
              "            673,   338,  9105,    30, 50260,  7091,   460,   470,  6486,   546,\n",
              "            326,   986,   532,  1148,   326,   644,   339,   338,  2282,    30,\n",
              "          50258,   568,   339,   460,   470,  6486,   986,   532,  1148,   326,\n",
              "            644,   339,   338,  2282,    30, 50258,   568, 16317,   691,   838,\n",
              "          16317,   339,   338,  9105,    30,   986, 50258,   568, 16317,   339,\n",
              "            460,   470,  6486, 16317,   546,   340, 16317,    30,   986,    30,\n",
              "            986,    30,   986,    30,   986,    30, 16317,    30,   986,    30,\n",
              "            986,    30,   986,    30, 16317,    30,   986,    30,   986,    30,\n",
              "            986,    30,   986,    30, 16317,    30, 16317,    30,   986,    30,\n",
              "          16317,    30, 16317,    30, 16317]]),\n",
              " tensor([[50257,    40,   423,   530,    11,   475,   340,   318,  1353,  3200,\n",
              "          50260,    72,   423,   530,   986,  4360,   663,  1353,  3200,   986,\n",
              "          50258,    72,   423,   530,   986,  4360,   663,  1353,  3200,   986,\n",
              "          50258,     7,    72,   423,   986,  4360,   663,  1353,  3200,   986,\n",
              "              8, 50258,     7,    72,   423,   986,  4360,   663,  1353,  3200,\n",
              "            986,     8, 50258,     7,    72,   423,   986,  4360,   663,  1353,\n",
              "           3200,   986,     8, 50258,     7,    72,   423,   986,  4360,   663,\n",
              "           1353,  3200,   986,     8, 50258,     7,    72,   423,   986,  4360,\n",
              "            663,  1353,  3200,   986,     8, 50258,     7,    72,   423,   986,\n",
              "           4360,   663,  1353,  3200,   986,     8, 50258,     7,    72,   423,\n",
              "            986,  4360,   663,  1353,  3200]]),\n",
              " tensor([[50257,    40,  2911,   220,   534, 11077, 42675,   379,   345,   655,\n",
              "            329,  4737,   884,   257,  1517, 50260, 34456,   534, 11077, 42675,\n",
              "            379,   345,   329,  4737,   428,    13, 50258, 34456,   534, 11077,\n",
              "          42675,   379,   345,   329,  4737,   428,    13, 50258,    71,  3008,\n",
              "            534, 11077, 42675,   379,   345,   329,  4737,   428,   986, 50258,\n",
              "          34456,   534, 11077, 42675,   379,   345,   329,  4737,   428,   986,\n",
              "          50258,    71,  3008,   534, 11077, 42675,   379,   345,   329,  4737,\n",
              "            428,   986, 50258,    71,  3008,   534, 11077, 42675,   379,   345,\n",
              "            329,  4737,   428,   986, 50258,    71,  3008,   534, 11077, 42675,\n",
              "            379,   345,   329,  4737,   428,   986, 50258,    71,  3008,   534,\n",
              "          11077, 42675,   379,   345,   329]]),\n",
              " tensor([[50257, 31640,   430,  6122,   393,   262, 13997,  6151,   502, 50260,\n",
              "          31640,   430,  6122,   393,   262, 13997, 18854,    13, 50258, 31640,\n",
              "            430,  6122,   393,   262, 13997, 18854,   986, 50258, 31640,   430,\n",
              "           6122,   393,   262, 18854,   286,   262,  6869,    13, 50258, 31640,\n",
              "            430,  6122,   393,   262, 18854,   286,   262,  8824,    13, 50258,\n",
              "          31640,   430,  6122,   393,   262, 18854,   286,   262,  8824,   986,\n",
              "          50258, 31640,   430,  6122,   393,   262, 18854,   286,   262,  8824,\n",
              "            986, 50258, 31640,   430,  6122,   393,   262, 18854,   286,   262,\n",
              "           8824,   986, 50258, 31640,   430,  6122,   393,   262, 18854,   286,\n",
              "            262,  8824,   986, 50258, 31640,   430,  6122,   393,   262, 18854,\n",
              "            286,   262,  8824,   986, 50258]]),\n",
              " tensor([[50257, 27827,   380, 30050,   262,  2657,   290,  6807,  1088,   683,\n",
              "             13, 50260, 27827,   380, 30050,   262,  2657, 16317,   290,  6807,\n",
              "           1088,   683,    13, 50258,   986,   290, 30050,   262,  2657, 16317,\n",
              "            788,  6807,  1088,   683, 16317, 50258,   986,   290, 30050,   262,\n",
              "           2657, 16317,   788, 16317,  6807,  1088, 16317, 50258,   986,   290,\n",
              "          30050,   262,  2657, 16317,   788, 16317,  6807,  1088, 16317,    13,\n",
              "          50258,   986,   290, 16317, 30050,   262,  2657, 16317,   788, 16317,\n",
              "           6807, 16317,  1088, 16317,    13, 50258,   986,   290, 16317, 30050,\n",
              "            262,  2657, 16317,   788, 16317,  6807, 16317,  1088, 16317,    13,\n",
              "          50258,   986,   290, 16317, 30050, 16317,   262,  2657, 16317,   788,\n",
              "          16317,  6807, 16317,  1088, 16317]]),\n",
              " tensor([[50257, 19485,  2111,   284,   787,   340,   670,   290,   655,  1309,\n",
              "            340,   670, 50260, 11338,  2111,   284,   787,   340,   670,   290,\n",
              "           1309,   340,   670,    13, 50258,  2257,  3185,  7579, 45761,  5390,\n",
              "          39134,  7283, 30936,  5357, 37994,  7283, 30936,    13, 50258,  2257,\n",
              "           3185,  7579, 45761,  5390, 39134,  7283, 30936,  5357, 37994,  7283,\n",
              "          30936,    13, 50258,  2257,  3185,  7579, 45761,  5390, 39134,  7283,\n",
              "          30936,  5357, 37994,  7283, 30936,    13, 50258,  2257,  3185,  7579,\n",
              "          45761,  5390, 39134,  7283, 30936,  5357, 37994,  7283, 30936,    13,\n",
              "          50258,  2257,  3185,  7579, 45761,  5390, 39134,  7283, 30936,  5357,\n",
              "          37994,  7283, 30936,    13, 50258,  2257,  3185,  7579, 45761,  5390,\n",
              "          39134,  7283, 30936,  5357, 37994]]),\n",
              " tensor([[50257,  1639,   815,  1949,   340, 12136,  2619,   318, 20050, 50260,\n",
              "           5832,   815,  1949,   340,   986,  6147,  2042,   318,  1257,   986,\n",
              "          50258,  5832,   815,  1949,   340,   986,  6147,  2042,   318,  1257,\n",
              "            986, 50258,  5832,   815,  1949,   340,   986,  6147,  2042,   318,\n",
              "           1257,   986, 50258,  5832,   815,  1949,   340,   986,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,    40,  4236,   351,   442, 34518,    11,   345,   389,   772,\n",
              "          18259,   326,   345,   423,   530, 50260,    72,  4236,   351,   442,\n",
              "            620,  3609,    11,   345,   389,   772, 18259,   326,   345,   423,\n",
              "            530,    13, 50258,    72,  4236,   351,   442,   620,  3609,   986,\n",
              "            345,   389,   772, 18259,   326,   345,   423,   530,    13, 50258,\n",
              "             72,  4236,   986,   345,   821,   772, 18259,   986,   326,   345,\n",
              "            423,   530,    13, 50258,    72,  4236,   986,   345,   821, 18259,\n",
              "            986,   326,   345,   423,   530,    13, 50258,    72,  4236,   986,\n",
              "            345,   821,   772, 18259,   986,   326,   345,   423,   530,    13,\n",
              "          50258,    72,  4236,   986,   345,   821, 18259,   986,   326,   345,\n",
              "            423,   530,    13, 50258,    72]]),\n",
              " tensor([[50257,   818,   854,   709,  8270,  6761,    11,  5023, 12431,   393,\n",
              "           6164,    11, 50260,  8117,   318,   645,  6761,   286,   534,   393,\n",
              "           6164,   287,   854,   709,  8270,   986, 50258,  5832,   836,   470,\n",
              "            423,   257,  6761,   287,   854,   709,  8270,   986,   588,   329,\n",
              "           4554, 16317,   287,   262,  1339, 16317,   286, 12431,   986,   393,\n",
              "          16317,   287,   262,  1339, 16317,   286, 16317,  6164,   986, 50258,\n",
              "            986,   588,   329,  4554, 16317,   287,   534,  1339, 16317, 16317,\n",
              "          16317, 16317,   287,   534,  1339, 16317, 16317, 16317, 16317, 16317,\n",
              "            286,  1781,   986,   356,   986,   836,   470,   986,   423,   986,\n",
              "            257, 16317,  6761,   986,   286,   986,   326,   986,  1611,   986,\n",
              "            329, 16317,   326,   986,   986]]),\n",
              " tensor([[50257,  1544, 18959,   470,  2636,    11,   475,   339,   655,  1839,\n",
              "            470,  1282,   284,    13, 50260,   258,   338,   407,  2636,    11,\n",
              "            475,   339,  1839,   470,  1282,    13, 50258,   258,   338,   407,\n",
              "           2636,    11,   475,   339,   338,   407,  2406,    13, 50258,   258,\n",
              "            338,   407,  2636,    11,   475,   339,  1839,   470,  1282,    13,\n",
              "          50258,   258,   338,   407,  2636,   986,   339,   338,   407,  2406,\n",
              "            986, 50258,   258,   338,   407,  2636,   986,   339,   338,   407,\n",
              "           2406,   986, 50258,   258,   338,   407,  2636,   986,   339,   338,\n",
              "            407,   986,   339,   338,   407,  2636,   986, 50258,   258,   338,\n",
              "            407,  2636,   986,   339,   338,   407,   986,   339,   338,   407,\n",
              "           2636,   986, 50258,   258,   338]]),\n",
              " tensor([[50257,  1026,  8338,   319,   611,   345,  1138,   262,  3516,   287,\n",
              "           1103,  1204,    11,   780,  1842,   635,  2753,  2223, 50260, 10378,\n",
              "           2412,   986,   611,   345,  1138,   262,  3516,   287,  1048,   986,\n",
              "            788,  3763,   986,  1842,   857,   423,   257,   835,   286,  1804,\n",
              "           1243,   986, 50258, 10378,  2412,   986,   611,   345,  1138,   262,\n",
              "           3516,   986,   788,  3763,   986,  1842,   857,   423,   257,   835,\n",
              "            286,  1804,  1243,   986, 50258, 50258, 10378,  2412,   986,   611,\n",
              "            345,  1138,   262,  3516,   986,   788,  3763,   986,  1842,   857,\n",
              "            423,   257,   835,   986,   286,  1804,  1243,   986, 50258, 50258,\n",
              "          50258, 10378,  2412,   986,   611,   345,  1138,   262,  3516,   986,\n",
              "            788,  3763,   986,  1842,   857]]),\n",
              " tensor([[50257,  1870, 17222, 38713,   318,  2147,   284,   865,   363,   546,\n",
              "          50260,  1870,   329, 21608,   986,   326,   338,  2147,   284,   865,\n",
              "            363,   546,    13, 50258,   392,   329, 21608,   986,   326,   338,\n",
              "           2147,   284,   865,   363,   546,    13, 50258,   392,   329, 21608,\n",
              "            986,   326,   338,  2147,   284,   865,   363,   546,    13, 50258,\n",
              "            392,   329, 21608,   986,   326,   338,  2147,   284,   865,   363,\n",
              "            546,    13, 50258,   392,   329, 21608,   986,   326,   338,  2147,\n",
              "            284,   865,   363,   546,    13, 50258,   392,   329, 21608,   986,\n",
              "            326,   338,  2147,   284,   865,   363,   546,    13, 50258,   986,\n",
              "            329, 21608,   986,   326,   338,  2147,   284,   865,   363,   546,\n",
              "             13, 50258,   986,   329, 21608]]),\n",
              " tensor([[50257,  1273,  5889,   503,    11,   356,   467,   284,  3430, 29860,\n",
              "            379,   807,    25,   405,    13, 50260,   732,   467,   284,  3430,\n",
              "            329,   257,  1643,   986,   290,   788,   356,   467,   284,  3430,\n",
              "            275,   528, 34852,   986,   379,   807,    25,  3571,    13, 50258,\n",
              "            732,   467,   284,  3430,   986,   290,   788,   986,   356,   467,\n",
              "            284, 16317,   356,   467, 16317,   284, 16317,   284, 16317,   284,\n",
              "          16317,   284, 16317,   284, 16317,   284, 16317,   284, 16317,   284,\n",
              "          16317,   284, 16317,   284, 16317,   284, 16317,   284, 16317,   284,\n",
              "          16317,    13, 50258,  9688,   986,   351, 16317, 16317,   356,   467,\n",
              "          16317,   284, 16317,   284, 16317, 16317, 16317,   284, 16317,   284,\n",
              "          16317, 16317,   284, 16317,   284]]),\n",
              " tensor([[50257,  5840, 22506,    13, 24377,   318,   655,   257,  3440,   286,\n",
              "          15222, 32159,    11,  2125,   470,   340,    30, 50260,  1169, 32159,\n",
              "            287, 24377,   389,   655, 32159, 16317,  3588,   470,   484,    30,\n",
              "          50258,  1169, 32159,   287, 24377,   389, 32159, 16317,  3588,   470,\n",
              "            484,    30, 50258,  1169, 32159, 16317,   389,   484, 16317,   262,\n",
              "           3392, 16317,   262,  3392, 16317,   644,    30, 50258,  1169, 32159,\n",
              "          16317,   389,   484, 16317,   262,  3392, 16317,   644,    30, 50258,\n",
              "           1169, 32159, 16317,   389,   484, 16317,   262,  3392, 16317,   644,\n",
              "             30, 50258,  1169, 32159, 16317,   389,   484, 16317,   262,  3392,\n",
              "          16317,   644,    30, 50258,  1169, 32159, 16317,   389,   484, 16317,\n",
              "            644,    30, 50258,  1169, 32159]]),\n",
              " tensor([[50257, 42741,  1671,   803,   511,  1679,   400, 11162,  9975,   986,\n",
              "           2644,  5246,    13,   843,  9074,    13, 42843,  1004,   574,  5714,\n",
              "             13, 50260,  1122,   432, 16317,  1770,    13,  1004,   574,  5714,\n",
              "            290,  9074,    13, 42843,  1004,   574,  5714,    13, 50258,  1122,\n",
              "            432, 16317,  1770,    13,  1004,   574,  5714,   290,  9074,    13,\n",
              "          42843,  1004,   574,  5714,    13, 50258,  1122,   432, 16317, 16317,\n",
              "          16317,   284, 10648,   511,  1679,   400, 11162,    13, 50258,  1122,\n",
              "            432, 16317, 16317, 16317,   329,   262,  6695, 16317, 16317, 16317,\n",
              "          16317, 16317,   356,   821, 17499, 16317,   262,  6695, 16317,    13,\n",
              "          50258,  1122,   432, 16317, 16317, 16317, 16317, 16317,   329,   262,\n",
              "           6695, 16317, 16317, 16317,   356]]),\n",
              " tensor([[50257,  1026,   338,   407,   257,  4065,   284,  1561,   546,   534,\n",
              "            670,    13, 50260,   270,   338,   407,   257,  4065,   284,  1561,\n",
              "            546,   670,    13, 50258,  1169,   976,  2925,   329,   670,    13,\n",
              "          50258,   270,   338,   407,   257,  4065,   284,  1561,   546,   340,\n",
              "             13, 50258,  1169,   976,  2925,   329,   340, 16317,    13, 50258,\n",
              "          50258,   986,   290,   523,   986,   340,   338,   407,   257,  4065,\n",
              "          16317,   284,  1561,   546,   340, 16317,    13, 50258,   986,   290,\n",
              "            986,   326,   338,  1521, 16317,   340,   338,   407,   257,  4065,\n",
              "            986,   284,  1561,   546,   340, 16317,    13, 50258,   986,   326,\n",
              "            338,  1521, 16317,   340,   338,   407,   257,  4065,   986,   284,\n",
              "           1561,   546,   340,   986,    13]]),\n",
              " tensor([[50257,  7469,   721,   803,   319,   257,  6512,   561,   407,  2222,\n",
              "           8458, 50260,   270,  3636,   470,   307,   922,  8458,   611,   345,\n",
              "          40125,   319,   257,  6512,    13, 50258, 50258,  3919,    11,   340,\n",
              "           3636,   470,   307,   922,  8458,   611,   345,   750,   326,   986,\n",
              "          50258,  3919,   986,   340,  3636,   470,   307,   922,  8458,   986,\n",
              "          50258,    35,   756,   466,   326,   986,   340,  3636,   470,   307,\n",
              "            922,   986, 50258, 50258, 50258,  1026,   561,   407,   307,   922,\n",
              "            986,   340,   561,   307,  2089,   986, 50258, 50258,   986,   780,\n",
              "            986,   340,  3636,   470,   307,   922,   986, 50258,   986,   780,\n",
              "            986,   340,  3636,   470,   307,   922,   986, 50258,   986,   780,\n",
              "            986,   340,  3636,   470,   307]]),\n",
              " tensor([[50257,  3546, 32851,   286,   262, 15221,   900,   503,   287,   262,\n",
              "           2223,  1410,   318,   284,   307, 43097,   416,   262,  4683,   347,\n",
              "           2101,  1608, 25516,  4912,   357,    33,  7156,     8,   764, 50260,\n",
              "           1169,  7822,   286,   262, 15221,   900,   503,   287,   262,  2223,\n",
              "           1410,   318, 28679,   416,   262,   347,  7156,    11,   543,   318,\n",
              "            262,  1459,  5887,  1448,   329,   262,  2050,   286, 37589,    13,\n",
              "          50258,  1169,  7822,   286,   262, 15221,   900,   503,   287,   262,\n",
              "           2223,  1410,   318, 28679,   416,   262,  4683,   347,  7156,    13,\n",
              "          50258,  1169,  7822,   318,   286,   257,  3704,   351,   262,  4683,\n",
              "           1448,   286,  6154,    11,   543,   318,   262,  1448,   286,  6154,\n",
              "             13, 50258, 50258,   270,   318]]),\n",
              " tensor([[50257,   464, 11523,   481, 30867,  5449,   355, 13957, 37874,  1660,\n",
              "           1014,   290,  6787,  4839,    11,   355, 36763, 13081,    77, 16047,\n",
              "             13, 50260,  2934, 30433, 13081,    77, 16047,   326,   262, 11523,\n",
              "            481, 30867,  5449,   287,   262, 37874,  1660,  1014,   290,  6787,\n",
              "           4839,    13, 50258,  2934, 30433, 13081,    77,  4477,   284,  4404,\n",
              "            428,    11,   355,   340,   857,   523,    11,   329,   262,  4839,\n",
              "            286, 37874,  1660,   290,   262,  6787,  4839,    13, 50258, 50258,\n",
              "           1169,  4839,   286, 37874,  1660,   290,   262, 20515,  4839,   318,\n",
              "          26987,   416,   262, 11523,    13, 50258,  2934, 30433, 13081,    77,\n",
              "           4477,   284,  4404,   428,    11,   287,   523,  1290,   355,   340,\n",
              "            318,  5213,    11,   329,   262]]),\n",
              " tensor([[50257,  1858,   318,   645,   761,   284, 11986,   810,   345,   670,\n",
              "          50260,  1169,   966,   318, 16317,   836,   470, 11986,   810,   345,\n",
              "            670,    13, 50258,  8117,   338,   645,   761, 16317,   284, 11986,\n",
              "            810,   345,   670,    13, 50258, 50258,  1169,   966,   318, 16317,\n",
              "            836,   470, 11986, 16317,   810,   345,   670,    13, 50258, 50258,\n",
              "           1169,   966,   318, 16317,   836,   470, 11986, 16317,   810,   345,\n",
              "            670,    13, 50258, 50258, 50258,  1169,   966,   318, 16317,   836,\n",
              "            470, 11986, 16317,   810, 16317,   345,   670,    13, 50258, 50258,\n",
              "          50258,   986,   329,   326, 16317,   836,   470, 11986, 16317,   810,\n",
              "          16317,   345,   670,    13, 50258,   986,   329,   326, 16317,   836,\n",
              "            470, 11986, 16317,   810, 16317]]),\n",
              " tensor([[50257,  1026,  5091,  3095,  7850,    11,   981,   661,   547,  4964,\n",
              "            632,   373, 20105, 50260, 42122,   262,  7850,    11,   661,   547,\n",
              "           4964,   986,    43,  3535,    13, 50258,  1026,  3022,   379,   262,\n",
              "           7850,    11,   661,   547,  4964,   986,    43,  3535, 50258,     7,\n",
              "          42122,   262,  7850,   986,    43,  3535,     8, 50258,     7, 42122,\n",
              "            262,  7850,   986,    43,  3535,     8, 50258,     7, 42122,   262,\n",
              "           7850,   986,    43,  3535,     8, 50258,     7, 42122,   262,  7850,\n",
              "            986,    43,  3535,     8, 50258,     7, 42122,   262,  7850,   986,\n",
              "             43,  3535,     8, 50258,     7, 42122,   262,  7850,   986,    43,\n",
              "           3535,     8, 50258,     7, 42122,   262,  7850,   986,    43,  3535,\n",
              "              8, 50258,     7, 42122,   262]]),\n",
              " tensor([[50257,  1639,   821,   407,  3375,   546,   262,  6678,    11,   389,\n",
              "            345,    30, 50260,  5832,   836,   470,  1612,   262,  6678,    11,\n",
              "            466,   345,    30, 50258,  5832,   836,   470,  1612,   262,  6678,\n",
              "             11,   466,   345,    30, 50258,  5832,   836,   470,  1612,   262,\n",
              "           6678, 16317,    30, 50258,  5832,   836,   470,  1612,   340, 16317,\n",
              "             30, 50258,  5832,   836,   470,  1612,   340, 16317,    30, 50258,\n",
              "             30,   986,  5832,   836,   470,  1612,   340, 16317,    30,   986,\n",
              "             30,   986,    30,   986,    30,   986,    30,   986,    30,   986,\n",
              "             30,   986,    30,   986,    30,   986,    30,   986,    30,   986,\n",
              "             30,   986,    30,   986,    30,   986,    30,   986,    30,   986,\n",
              "             30,   986,    30,   986,    30]]),\n",
              " tensor([[50257,     1,  5211,   407,  6044,   553,   314,   531,    11,   366,\n",
              "           5832,   389,   691,   257, 11778,   526, 50260,     1,  5832,   821,\n",
              "            407,   257, 11778,    11,   836,   470,  6044,   553,   314,   531,\n",
              "             13, 50258,     1,  9099,   470,  6044,    11,   345,   821,   691,\n",
              "            257, 11778,   553,   314,   531,    13, 50258,     1,  5832,   821,\n",
              "            407,   257, 11778,    11,   836,   470,  6044,   553,   314,   531,\n",
              "             13, 50258,     1,  5832,   821,   407,   257, 11778,    11,   836,\n",
              "            470,  6044,   553,   314,   531,    13, 50258,     1,  5832,   821,\n",
              "            407,   257, 11778,    11,   836,   470,  6044,   553,   314,   531,\n",
              "             13, 50258,     1,  5832,   821,   407,   257, 11778,    11,   836,\n",
              "            470,  6044,   553,   314,   531]]),\n",
              " tensor([[50257,  1722,   257, 32992,   560,  3953,    11,   340,   318, 33887,\n",
              "            284,  3368,   262,   779,   286, 15781,  3754,  1141, 10241,    13,\n",
              "          50260,  1169,   779,   286, 15781,  3754,   287, 10241,   318,   407,\n",
              "           7151,   329, 32992,   560,  3840,    13, 50258,  1169,   779,   286,\n",
              "          15781,  3754,   287, 10241,   318,   407,  7151,   329, 32992,   560,\n",
              "           3840,    13, 50258,  1169,   779,   286, 15781,  3754,   287, 10241,\n",
              "            318,   407,  7151,    13, 50258,  1169, 32992,   560,  3953,   318,\n",
              "           4361,   407, 14460,    13, 50258,  1169,   779,   286, 15781,  3754,\n",
              "            318,  4361,   407,  7151,    13, 50258,  1169, 32992,   560,  3953,\n",
              "            318,  4361,   407,  7151,    13, 50258,  1169,  3840,   329,   428,\n",
              "            389,  4361,    11, 32992,   560]]),\n",
              " tensor([[50257,    40,   466,   407,   760,   355,   314,   423,  1239,   587,\n",
              "           6405, 50260,    72, 17666,   760,   986,    72,  1053,  1239,   587,\n",
              "           6405,   986, 50258,    72, 17666,   760,   986,    72,  1053,  1239,\n",
              "            587,  6405,   986, 50258,    72, 17666,   760,   986,    72,  1053,\n",
              "           1239,   587,  6405,   986, 50258,    72, 17666,   760,   986,    72,\n",
              "           1053,  1239,   587,  6405,   986, 50258,    72, 17666,   760,   986,\n",
              "             72,  1053,  1239,   587,  6405,   986, 50258,    72, 17666,   760,\n",
              "            986,    72,  1053,  1239,   587,  6405,   986, 50258, 50258,    72,\n",
              "          17666,   760,   986,    72,  1053,  1239,   587,  6405,   986, 50258,\n",
              "             72, 17666,   760,   986,    72,  1053,  1239,   587,  6405,   986,\n",
              "          50258,    72, 17666,   760,   986]]),\n",
              " tensor([[50257, 10418, 28329, 15124,   284,   428,    11,   475,   749,   286,\n",
              "            262,   640,   262,  5273,   481,   307,   546,   257, 45753,   393,\n",
              "           4190, 46608, 50260,  5162,   893, 28329, 15124,   284,   340,   475,\n",
              "            749,   286,   262,   640,   340,  1183,   307,   546,   257,  1489,\n",
              "           4411,   666,   393,  4190, 46608,    13, 50258,  5162,   893, 17666,\n",
              "           1107, 15124,   284,   340,   986,  4360,   749,   286,   262,   640,\n",
              "            340,  1183,   307,   546,   257,   705,  1477,    78,  1765,  1140,\n",
              "            393,  4190, 46608,  4458, 50258,  3653, 17666,  1107, 15124,   284,\n",
              "            340,   986,  4360,   749,   286,   262,   640,   986, 50258,  5162,\n",
              "            893, 17666,  1107, 15124,   284,   340,   986,  4360,   749,   286,\n",
              "            262,   640,   986, 50258,  5162]]),\n",
              " tensor([[50257, 23795,    11, 21480,    11,   300,    12,    40,  1101, 13101,\n",
              "            616,  3367,   338, 11783,  1074,    13, 50260,  4053,   986, 23781,\n",
              "            986,  1312,  1101,  3985,   286,   262,  4346,  1074,   329,   616,\n",
              "           3367,    13, 50258,  5562,   338,  1521, 16317,  1312,  1101,   257,\n",
              "           3985,   286,   616,  3367,   338,  1074,    13, 50258,  1640,   326,\n",
              "          16317,   314,  1101,   257,  3985,   329,   262,  4346,  1074,    13,\n",
              "          50258,  5562,   338,  1521, 16317,   314,  1101,   257,  2137,    13,\n",
              "          50258,  1640,   326, 16317,   314,  1101,   257,  2137, 16317,   329,\n",
              "            326, 16317,   314,  1101,   257,  2137, 16317, 50258,  5562,   338,\n",
              "           1521, 16317,   314,  1101,   257,  3985, 16317,   329,   326, 16317,\n",
              "            314,  1101,   257,  2137, 16317]]),\n",
              " tensor([[50257, 12349,   220,   220,  6405,    11,   290,  1541,   484,   423,\n",
              "           1115,  1310,  4813, 50260, 38441,   220,  6405,   986,  1541,   484,\n",
              "            423,  1115,  1310,  4813,    13, 50258, 38441,   220,  6405,   986,\n",
              "           1541,   484,   423,  1115,  1310,  4813,    13, 50258, 38441,   220,\n",
              "           6405,   986,  1541,   484,   423,  1115,  1310,  4813,    13, 50258,\n",
              "          38441,   220,  6405,   986,  1541,   484,   423,  1115,  1310,  4813,\n",
              "             13, 50258, 38441,   220,  6405,   986,  1541,   484,   423,  1115,\n",
              "           1310,  4813,    13, 50258, 38441,   220,  6405,   986,  1541,   484,\n",
              "            423,  1115,  1310,  4813,    13, 50258, 38441,   220,  6405,   986,\n",
              "           1541,   484,   423,  1115,  1310,  4813,    13, 50258, 38441,   220,\n",
              "           6405,   986,  1541,   484,   423]]),\n",
              " tensor([[50257,  1537,    11,  3221,   314,   655,  6004,   284,   616,  4526,\n",
              "             46, 50260,  1537,    11,  3221,   314,   655,  6004,   284,   616,\n",
              "           4526,    46,    13, 50258,  1537,    11,  3221,    11,   314,   655,\n",
              "           6004,   284,   616,  4526,    46,    13, 50258,  1537,   986,  3221,\n",
              "            986,   314,   655,  6004,   284,   616,  4526,    46,    13, 50258,\n",
              "           1537,   986,  3221,   986,   314,   655,   986,  6004,   986,   284,\n",
              "            986,   616,   986,  4526,    46,    13, 50258,  1537,   986,  3221,\n",
              "            986,   314,   986,   655,   986,  6004,   986,   284,   986,   616,\n",
              "            986,  4526,    46,    13, 50258,  1537,   986,  3221,   986,   314,\n",
              "            986,   655,   986,   314,   986,   655,   986,  6004,   986,   284,\n",
              "            986,   616,   986,  4526,    46]]),\n",
              " tensor([[50257, 41044,  8288,   284,   466,  1243,   588,   326,   319,   262,\n",
              "          26724,   286,   262,  2589,  3360,    11,   339,   550,  6810,    13,\n",
              "          50260,   261,   262,  6695,   986,   339,  6810,   986,   262,  4813,\n",
              "           8288,   284,   466,   340,   986,   588,   326,   986,   319,   262,\n",
              "           6695,   986,   339,  6810,   986, 50258,   986,   339,  6810,   986,\n",
              "            326,   986,   262,  4813,   986,   547,   986,  1804,   986,   326,\n",
              "            986,   379,   262,  2589,   986,   484,   986,  8288,   986,   340,\n",
              "            986, 50258,   986,   339,  6810,   986,   326,   986,   484,   986,\n",
              "            750,   986,   326, 16317,   329,   986,   262,  2589, 16317,    13,\n",
              "          50258,   986,   339,   986,  6810, 16317,   326, 16317, 16317,   339,\n",
              "            986,  8288,   986,   340, 16317]]),\n",
              " tensor([[50257,  4863,   465,  5852,  5437,   714,   766,   656,   262,  1208,\n",
              "            363, 16172,    13, 50260, 25784,   714,   766,   262, 20749,   422,\n",
              "            465,  5852,    13, 50258, 25784,   714,   766,   262, 20749,   422,\n",
              "            465,  5852,    13, 50258,   258,   714,   766,   262,  1208,   363,\n",
              "          16172,   422,   465,  5852,    13, 50258, 25784,   714,   766,   262,\n",
              "          20749,   422,   612,    13, 50258,   258,   714,   766,   262, 20749,\n",
              "            422,   612,    13, 50258, 25784,   373,  5586,   287,   465,  5852,\n",
              "             13, 50258,   258,   714,   766,   262, 20749,   422,   612,    13,\n",
              "          50258,   258,   714,   766,   262, 20749,   422,   612,    13, 50258,\n",
              "            258,   714,   766,   340,    13, 50258,   258,   373,   287,   262,\n",
              "           5852,    13, 50258,   258,   714]]),\n",
              " tensor([[50257,  9362, 16469,   787,   257,  7932, 21571,  6979, 50260, 16469,\n",
              "            986,   262,  1266, 21571,  6979,   318,   262,  6076,  5156,    13,\n",
              "          50258,  1169,  6076,  5156,   318,   257,  7932,  6979,   329,   262,\n",
              "           6076,    13, 50258, 16469,   986,   663,   257,  1049, 21571,  6979,\n",
              "            986,   329,   262,  6076,   986,   922,  8458,    13, 50258,  1169,\n",
              "           6076,  5156,   986,   318,   257,  3621,  6979,   329,   262,  6076,\n",
              "            986,   922,  8458,    13, 50258,  1169,  6076,   986,   318,   257,\n",
              "           1049,  6979,   986,   329,   262,  6076,   986,   922,  8458,    13,\n",
              "          50258,  1169,  6076,   986,   318,   257,  3621,  6979,   986,   329,\n",
              "            262,  6076,   986,   922,  8458,    13, 50258,  1169,  6076,   986,\n",
              "            318,   257,  3621,  6979,   986]]),\n",
              " tensor([[50257,    39,  1419,    11,   611,   345,   588,  3511,    11,   326,\n",
              "            318,   477,   326,  6067, 50260,    39,  1419,   611,   345,   588,\n",
              "           3511, 29294,   477,   326,  6067,    13, 50258,    39,  1419,   611,\n",
              "            345,   588,  3511, 29294,   477,   326,  6067,    13, 50258,    39,\n",
              "           1419,   611,   345,   588,  3511, 29294,   477,   326,  6067,    13,\n",
              "          50258,    39,  1419,   611,   345,   588,  3511, 29294,   477,   326,\n",
              "           6067,    13, 50258,    39,  1419,   611,   345,   588,  3511, 29294,\n",
              "            477,   326,  6067,    13, 50258,    39,  1419,   611,   345,   588,\n",
              "           3511, 29294,   477,   326,  6067,    13, 50258,    39,  1419,   611,\n",
              "            345,   588,  3511, 29294,   477,   326,  6067,    13, 50258,    39,\n",
              "           1419,   611,   345,   588,  3511]]),\n",
              " tensor([[50257,    12,     4,    34,   940,    12,     4,    34,  1157,    12,\n",
              "              4,    46,     3,    83,  2949, 29400, 10971,   329,   720,    16,\n",
              "           4201,    11, 22837,   278,    13, 50260,    12,   352,  1218,  1568,\n",
              "          16317,   262,  2882,   373,   407,  2722, 16317,   416,   262,   327,\n",
              "              3,    16, 16317, 29400,   373, 19072,    13, 50258,    12,   352,\n",
              "           1218, 16317,   262,  3280,   373,   407,  2722, 16317,   416,   262,\n",
              "            327,     3,    16, 16317,   262, 22837,   295,   373,  5668,    13,\n",
              "          50258,    12,   352,  1218, 16317,   262,  3280,   373,   407,  2722,\n",
              "          16317,   416,   262,   327,     3,    16, 16317,   262, 22837,   295,\n",
              "            373,  6157,    13, 50258,    12,   352,  1218, 16317,   262,  3280,\n",
              "            373,   407,  2722, 16317,   416]]),\n",
              " tensor([[50257,  1135,   821,   257,  1110,  1497,   422,  4917,   262, 13996,\n",
              "             13, 50260,   732,  1183,  1064,   262, 13996,   287,   257,  1110,\n",
              "             13, 50258,   732,  1183,  1064,   340,   287,   257,  1110,    13,\n",
              "          50258,   732,  1183,  1064,   262, 13996,   287,   257,  1110,    13,\n",
              "          50258,   732,  1183,  1064,   340,   287,   257,  1110,    13, 50258,\n",
              "            732,  1183,  1064,   340,   287,   257,  1110, 16317, 50258,   732,\n",
              "           1183,  1064,   340, 16317,   287,   257,  1110, 16317, 50258,   732,\n",
              "           1183,  1064,   340, 16317,   287,   257,  1110, 16317,   340,   338,\n",
              "            257,  1110, 16317, 50258,   732,  1183,  1064,   340, 16317,   287,\n",
              "            257,  1110, 16317,   340,   338,   257,  1110, 16317, 50258,   732,\n",
              "           1183,  1064,   340, 16317,   287]]),\n",
              " tensor([[50257,  4805,  2414,    32,  4869,  1635,  7283,   718,  6659,    11,\n",
              "           1635, 15107,  1160,  5607,   367,   311,     7,  3933,  1267,     7,\n",
              "           3439,  1267, 50260,  4805,  2414,   317,  4869,  1635,  7283,   718,\n",
              "           6659,  1635, 15107,  1160,  5607,   367,   311,     7,  3933,  1267,\n",
              "            357,  3439,  1267, 50258,     7,    33,     8,   532,   532,   532,\n",
              "            532,   532,   532,   532,   532,   532,   532,   532,   532,   532,\n",
              "            532,   532,   532,   532, 50258,     7,    33,     8,   532,   532,\n",
              "            532,   532,   532,   532,   532,   532,   532,   532,   532,   532,\n",
              "            532,   532,   532,   532,   532,    13, 50258,     7,    33,     8,\n",
              "            532,   532,   532,   532,   532,   532,   532,   532,   532,   532,\n",
              "            532,   532,   532,   532,   532]]),\n",
              " tensor([[50257,  2504,  2415,   508,   531,   284,    51, 21874, 10401,   326,\n",
              "           3619,  1549,   651,  2823,    13, 50260,  1169,  2415,   508,  1297,\n",
              "          29345, 10401,  3619,   561,   307,  2823,    13, 50258, 50258,  1169,\n",
              "           2415,   508,  1297, 29345, 10401,  3619,   561,   307,  2823,    13,\n",
              "          50258, 50258, 50258, 50258,  1169,  2415,   508,  1297, 29345, 10401,\n",
              "           3619,   373,  2823,    13, 50258, 50258, 50258, 50258,  1169,  2415,\n",
              "            508,  1297,   683,  3619,   373,  2823,    13, 50258, 50258, 50258,\n",
              "          50258,  1169,  2415,   508,  1297,   683,   373,  2823,    13, 50258,\n",
              "          50258, 50258, 50258,  1169,  2415,   986,   262,  2415,   986,   262,\n",
              "           2415,   986,   262,  2415,   986,   262,  2415,   986,   262,  2415,\n",
              "            986,   262,  2415,   986, 50258]]),\n",
              " tensor([[50257, 23433,  6155,  1088,   262,  6232,    26,   921,   481,   407,\n",
              "            655,  9155,  3463,    11,   475,   345,   481,   635,   307,   517,\n",
              "           4075, 50260, 11152,  1088,   262,  3422,   527,  2894,    11,   334,\n",
              "           1183,   407,   655,  9155,  3463,    11,   475,   334,  1183,   635,\n",
              "            307,   517,  4075,    13, 50258, 28311,  6155,  1088,   262,  3422,\n",
              "            527,  2894,    11,   334,  1183,   407,   655,  9155,  3463,    11,\n",
              "            475,   334,  1183,   635,   307,   517,  4075,    13, 50258, 28311,\n",
              "            340,    11,   290,   345,  1183,  9155,  3463,    11,   475,   334,\n",
              "           1183,   307,   517,  4075,    13, 50258, 28311,   340,    11,   290,\n",
              "            345,  1183,  9155,  3463,    11,   475,   334,  1183,   307,   517,\n",
              "           4075,    13, 50258, 28311,   340]]),\n",
              " tensor([[50257, 28172,   287, 17376,    88, 18710,   991,  8263,   257,  9178,\n",
              "            319,   262,  3117,    30, 50260,   271,  2506,   991,  8263,   257,\n",
              "           9178,   319,   262,  3117,    30, 50258,   271,  2506,   991,  8263,\n",
              "            257,  9178,   546,   262,  3117,    30, 50258,   271,  2506,   991,\n",
              "            994,   287, 17376,    88, 18710,    30, 50258,   271,  2506,   994,\n",
              "             30, 50258,   271,   340,   655,   502, 16317,  4598,   484,   991,\n",
              "           3197,   257,  9178,   546,   262,  3117,    30, 50258,    30,   986,\n",
              "            392,   523, 16317, 22437,  2506,   994,   991,   466,   340,    30,\n",
              "          50258,    30,   986,   392,   523, 16317, 22437,   339,   991,  3197,\n",
              "            257,  9178,   546,   340,    30,   986, 50258,    30,   986,   392,\n",
              "            523, 16317, 22437,   339,   991]]),\n",
              " tensor([[50257,    40,  2883,    11,   314,   303, 36844, 13590,   416,  1345,\n",
              "            962,   220,  8532, 50260,    72,   588,   340,    11,  1312,  1053,\n",
              "            587,  2823,   416,   458,   962,    13, 50258,    72,   588,   340,\n",
              "            986,  1312,  1053,   587,  2823,   416,   458,   962,    13, 50258,\n",
              "             72,   588,   340,   986,  1312,   588,   340,   986,  1312,   588,\n",
              "            340,   986,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,  2504,   318,   373,  4325,   618,   345,  3730,   423,   281,\n",
              "          23770, 50260, 12518,   262,  3730,   423,   281, 23770,    11,   326,\n",
              "            338,   644,  4325,    13, 50258,  5562,   338,   703,   340,   318,\n",
              "            351,   514,    11,   618,   356,   821,  1719,  1714,    13, 50258,\n",
              "           5562,   338,  1521,   340,  4325,   986,   618,   356,   821,  1719,\n",
              "           1714,   986, 50258,  5562,   338,   703,   340,   318,   986,   618,\n",
              "            356,   821,  1804,   340,   986, 50258,  5562,   338,  1521,   986,\n",
              "            340,   338,   986,   618,   356,   821,  1804,   340,   986, 50258,\n",
              "           5562,   338,   986,   618,   356,   466,   340,   986, 50258,  5562,\n",
              "            338,   986,   618,   356,   466,   340,   986, 50258,  5562,   338,\n",
              "            986,   618,   986,   356,   986]]),\n",
              " tensor([[50257,  3152,  5395,    11,   314,   460,   379,  1551,  1394,   616,\n",
              "           2951,   319,   262,  4116,    13, 50260,    40,   460,   466,   428,\n",
              "            351,  5395,    13, 50258,   392,   314,   460,   470,  2051,  5395,\n",
              "            338,  4116,    13, 50258,    40,  1183,  1394,   616,  2951,   319,\n",
              "            262,  4116,   351,  5395,    13, 50258,  4480,  5395, 16317,   314,\n",
              "            460,   379,  1551,  1394,   616,  2951,   319,   262,  4116,    13,\n",
              "          50258, 50258, 50258,  4480,  5395, 16317,   314,   460,   379,  1551,\n",
              "           1394,   616,  2951,   319,   262,  4116,    13, 50258, 50258,    40,\n",
              "            460,   379,  1551,   466,   326, 16317,   351,   683, 16317,  1312,\n",
              "           1183,   379,  1551,  1394,   616,  2951,   319,   262,  4116,    13,\n",
              "          50258, 50258, 50258,   986,   351]]),\n",
              " tensor([[50257,  1544,  1807,   262,   476, 38351,    67,   286, 13452,    11,\n",
              "            616, 35822,   750,    13, 50260,  1820,  2988,   373,  3612,   546,\n",
              "            262,   476,  2634,    67,   286,   347,  5309,    13, 50258,  1820,\n",
              "           2988,   373,  3612,   546,   340, 16317,   339,  1807,   340,   373,\n",
              "            616,  2988,    13, 50258,   258,  1807,   340,   373,   616,  2988,\n",
              "          16317,   339,  1807,   340,   373,   257,  7457,    13, 50258,   258,\n",
              "            373,  3612, 16317,   546,   262,   476,  2634,    67, 16317,   286,\n",
              "          10230, 16317,   329,   616,  2988,    13, 50258,   258,  1807, 16317,\n",
              "            326,   373, 16317,   257,  7457, 16317,   329,   683, 16317,    13,\n",
              "          50258,   258,  1807, 16317,   546,   340, 16317,   329,   683, 16317,\n",
              "             13, 50258,   258,  1807, 16317]]),\n",
              " tensor([[50257,  3673,  2282,   314,  1101,   922,    12, 11534,    13,   314,\n",
              "           1101,   407,  2282,   326,    13, 50260,    40,  1101,   407,  2282,\n",
              "            314,  1101,   257,   922,    12, 11534,   582,    13, 50258,    40,\n",
              "           1101,   407,  2282,   314,  1101,   922,    12, 11534,    13, 50258,\n",
              "             40,  1101,   407,  2282,   314,  1101,   922,    12, 11534,    13,\n",
              "          50258,    40,  1101,   407,  2282,   314,  1101,   922,    12, 11534,\n",
              "             13, 50258,    40,  1101,   407,  2282,   314,  1101,   922,    12,\n",
              "          11534,    13, 50258,   986,    40,  1101,   407,  2282,   314,  1101,\n",
              "            922,   986,    40,  1101,   407,  2282,   986, 50258,   986,    40,\n",
              "           1101,   407,  2282,   986,   314,  1101,   407,  2282,   986,   314,\n",
              "           1101,   407,   986, 50258,   986]]),\n",
              " tensor([[50257,  3987,   470,  1683,  1282,   736,   994,   351,   326,   427,\n",
              "            578,   319,   345,    13, 50260,  9099,   470,  1683,  1282,   736,\n",
              "            994,   351,   326,   427,     9,    83,   319,   345,    13, 50258,\n",
              "          50258, 50258,    35, 35830, 20498,  9440,    36, 28767, 15698, 13315,\n",
              "          14603,  6006,  2043,  6177,  7013,     0, 50258,    35, 35830, 20498,\n",
              "           9440,    36, 28767, 15698, 13315, 14603,  6006,     9,    51,  6177,\n",
              "           7013,     0, 50258,    35, 35830, 20498,  9440,    36, 28767, 15698,\n",
              "          13315, 14603,  6006,     9,    51,  6177,  7013,     0, 50258, 50258,\n",
              "             35, 35830, 20498,  9440,    36, 28767, 15698, 13315, 14603,  6006,\n",
              "              9,    51,  6177,  7013,    13, 50258, 50258,    35, 35830, 20498,\n",
              "           9440,    36, 28767, 15698, 13315]]),\n",
              " tensor([[50257,    40,  2314,  3505,   262,  1438,   286,  3851, 23274,   649,\n",
              "           3496, 50260, 14350, 14609,   532,   968, 10940,   357,    66,   415,\n",
              "           3505,   262,  1438,     8, 50258,    72, 18548,  3505,   262,  1438,\n",
              "            286,  3851, 14609,   338,   649,  3496,    13, 50258,    72, 18548,\n",
              "            772,  3505,   262,  1438,   286,  3851, 14609,   338,   649,  3496,\n",
              "             13, 50258,    72, 18548,   772,  3505,   262,  1438,   286,   465,\n",
              "            649,  3496,    13, 50258,    72, 18548,   772,  3505,   262,  1438,\n",
              "            286,   465,    13, 50258,    72, 18548,   772,  3505,   465,  1438,\n",
              "             13, 50258,    72, 18548,   772,  3505,   465,  1438,    13, 50258,\n",
              "             72, 18548,   772,  3505,   465,    13, 50258,    72, 18548,   772,\n",
              "           3505,   465,  1438,    13, 50258]]),\n",
              " tensor([[50257,  6104,   996,   673,   318,  8390,    11,  6645,  2331,   284,\n",
              "            588,   683, 50260, 12805,  2331,   284,   588,   683,   986,   772,\n",
              "            996,   339,   318,   257,  8390,    13, 50258, 10197,   996,   339,\n",
              "            318,  8390,   986, 12805,  7832,   683,   986, 50258, 12805,  2331,\n",
              "            284,   588,   683,   986, 10197,   996,   339,   318,   257,  8390,\n",
              "            986, 50258, 10197,   996,   339,   318,   986, 12805,  2331,   284,\n",
              "            588,   683,   986, 50258, 12805,  7832,   683,   986, 10197,   996,\n",
              "            339,   318,   986, 12805,  7832,   683,   986, 50258, 12805,  7832,\n",
              "            683,   986, 10197,   996,   339,   318,   986, 12805,  7832,   683,\n",
              "            986, 50258, 12805,  7832,   683,   986, 10197,   996,   339,   318,\n",
              "            986, 12805,  7832,   683,   986]]),\n",
              " tensor([[50257,  8491,   345,  1728,   428,  3496,   318,  6157,   416,   262,\n",
              "           2764,   278,   327,  8516, 50260,  5832,  1654,   428,   318,   262,\n",
              "           3496,  6157,   416,   262,  2764,   278,   327,  8516,    30, 50258,\n",
              "            533,   345,  1654,   340,   338,   257,  3496,   416,   262,  2764,\n",
              "            278,   327,  8516,    30, 50258,    30,   986, 50258,  4598,   345,\n",
              "            760,   644,   428,  3496,   318,  1444,    30, 50258,    30,   986,\n",
              "             30,   986,    30,   986,    30,   986,    30,   986,    30,   986,\n",
              "             30,   986,    30,   986,    30,   986,    30,   986,    30,   986,\n",
              "             30,   986,    30,   986,    30,   986,    30,   986,    30,   986,\n",
              "             30,   986,    30,   986,    30,   986,    30,   986,    30,   986,\n",
              "             30,   986,    30,   986,    30]]),\n",
              " tensor([[50257,  1026,   338,   407, 12132,   981,   314,  4483,   345,    11,\n",
              "          50260, 12518,   314,  1101,  6600,   345, 16317,   340,   338,   407,\n",
              "          12132,    13, 50258,   270,   338,   407, 12132, 16317,   618,   314,\n",
              "           1101,  6600,   345,    13, 50258,   270,   338,   407, 12132, 16317,\n",
              "            618,   314,  1101,  6600,   345, 16317, 50258,   270,   338,   407,\n",
              "          12132, 16317,   618,   314,  1101,  6600,   345, 16317, 50258, 50258,\n",
              "            270,   338,   407, 12132, 16317,   618,   314,  1101,  6600,   345,\n",
              "          16317,   340,   338,   407, 12132,    13, 50258, 50258,   270,   338,\n",
              "            407, 12132, 16317,   618,   314,  1101,  6600,   345, 16317,   340,\n",
              "            338,   407, 12132,    13, 50258, 50258,   270,   338,   407, 12132,\n",
              "          16317,   618,   314,  1101,  6600]]),\n",
              " tensor([[50257,  2215,   345,   423,   257,  2485,   287,   534,  5422,   345,\n",
              "            460,   691,  2740,   287, 23268,  1424,   220, 10480,  6289, 50260,\n",
              "           5832,   460,   691,  2740,   287, 23268,  1424,   618,   345,   423,\n",
              "            257,  2485,   287,   534,  1021,    13, 50258, 12518,   334,   423,\n",
              "            257,  2485,   287,  2956,  5422,   334,   460,   691,  2740,   287,\n",
              "          23268,  1424,   986, 10480,  6289,    13, 50258,  5832,   460,   691,\n",
              "            910,   262, 23268,  1424,   618,   334,   423,   530,   287,  2956,\n",
              "           1021,   986, 27365,  6289,    13, 50258, 50258, 50258, 12518,   334,\n",
              "            423,   257,  2485,   287,  2956,  5422,   334,   460,   691,   910,\n",
              "            262, 23268,  1424,   986, 27365,  6289,   986, 50258, 50258, 12518,\n",
              "            334,   423,   530,   287,  2956]]),\n",
              " tensor([[50257,    40,   466,   407, 19973,   345,   355,   257, 44295,  1048,\n",
              "          50260,    72, 17666,   766,   334,   355, 44295,    13, 50258,    72,\n",
              "          17666,   766,   334,   355, 15800,    13, 50258,    72, 17666,   766,\n",
              "            334,   355, 44295,    13, 50258,    72, 17666,   766,   334,   355,\n",
              "          15800,    13, 50258,    72, 17666,   766,   334,   355, 15800,    13,\n",
              "          50258,    72, 17666,   766,   334,   355, 15800,    13, 50258,    72,\n",
              "          17666,   766,   334,   355, 15800,    13, 50258,    72, 17666,   766,\n",
              "            334,   355, 15800,    13, 50258,    72, 17666,   766,   334,   355,\n",
              "          15800,    13, 50258,    72, 17666,   766,   334,   355, 15800,    13,\n",
              "          50258,    72, 17666,   766,   334,   355, 15800,    13, 50258,    72,\n",
              "          17666,   766,   334,   355, 15800]]),\n",
              " tensor([[50257,   464,  2892, 21446,  3729, 13998,   340,   351,   514,    11,\n",
              "            736,   612,   287,  5478,    13, 50260,  1169,   937, 21446,   318,\n",
              "           3729, 18134,   340,   986,   287,  5478,    13, 50258,  1169,   937,\n",
              "          21446,   986,   326,   373,   514,   986,   287,  5478,   986,  5145,\n",
              "          50258,   732,   760,   986,   326,   338,  1521, 16317,   356,  1053,\n",
              "           5445,   340,   986,   351,   606,   986,   287,  5478,   986,  5145,\n",
              "          50258, 50258,   732,   760, 16317,   326, 16317,   356,  1053,  1760,\n",
              "            340, 16317,   351,   606, 16317,   287,  5478, 16317,  5145, 50258,\n",
              "            732,   760, 16317,   326, 16317,   356,  1053,  1760,   340, 16317,\n",
              "            351,   606, 16317,   287,  5478, 16317,  5145, 50258,   732,   760,\n",
              "          16317,   326, 16317,   356,  1053]]),\n",
              " tensor([[50257,  1026,   691,  1838,   345,  9811,   611,   345,  4702,   511,\n",
              "           2647,   780,   484,   389,  2330,   290,   407,  2042, 50260,  1532,\n",
              "            345,   588,   511,  2647,   788,  3763,   340,   318,  9811,   780,\n",
              "            484,   389,  2330,   290,   407,  2042,    13, 50258,   361,   345,\n",
              "            588,   606,    11,   788,  3763,   340,   318,  9811,   780,   484,\n",
              "            389,  2330,   290,   407,  2042,    13, 50258, 50258, 50258,   361,\n",
              "            345,   588,   606,    11,   788,  3763,   340,   318,  9811,   780,\n",
              "            484,   389,  2330,   290,   407,  2042,    13, 50258, 50258, 50258,\n",
              "          50258,   361,   345,   588,   606,    11,   788,  3763,   340,   318,\n",
              "           9811,    11,   780,   484,   389,  2330,   290,   407,  2042,    13,\n",
              "          50258, 50258, 50258, 50258, 50258]]),\n",
              " tensor([[50257,  1544,   468,   407,  1760,  1997,  1201,  9679,   262,  7776,\n",
              "           2055, 50260, 20777,  9679,   262,  7776,  2055,    11,   339,   468,\n",
              "            407,  1760,  1997,    13, 50258,   986,   339,   468,   407,  1760,\n",
              "           1997,  1201,   986,   339,  5399,   262,  7776,  3715,   986, 50258,\n",
              "            258,   468,   407,  1760,  1997,  1201,   986,   339,  5399,   986,\n",
              "          50258,   986,   339,   468,   407,  1760,  1997,  1201,   986,   339,\n",
              "           5399,   986, 50258,   986,   339,   468,   407,  1760,  1997,   986,\n",
              "           1201,   986,   339,  5399,   986, 50258,   986,   339,   468,   986,\n",
              "            407,  1760,  1997,   986,  1201,   986,   339,  5399,   986, 50258,\n",
              "            986,   339,   986,   468,   986,   407,  1760,  1997,   986,  1201,\n",
              "            986,   339,   986,  5399,   986]]),\n",
              " tensor([[50257,  2061,  2176,  3518,  3033,   290,  8806, 12796, 50260, 42854,\n",
              "           9695,   290,  9695,    25,   257,     8,  1867,  9695,   290,  9695,\n",
              "            389,  3306,    30, 50258, 42854,  9695,   290,  9695,    25,   257,\n",
              "              8,  1867,  9695,   290,  9695,   389,  3306,    30, 50258, 50258,\n",
              "             30,   986,   986,   986,  1867,  2176,  9695,   290,  9695,   389,\n",
              "           3306, 16317,    30,   986, 50258,   986,   986,   329,   644,  2176,\n",
              "           9695,   290,  9695,    30,   986,    30,   986, 50258,   986,   329,\n",
              "            326,    30,   986,    30,   986,   329,   326,    30,   986,    30,\n",
              "            986,   329,   326,    30,   986,   329,   326,    30,   986,   329,\n",
              "            326,    30,   986,    30,   986,   329,   326,    30,   986,    30,\n",
              "            986,   329,   326,    30,   986]]),\n",
              " tensor([[50257,     1,  1135,  4398,   470,  1392,   281, 13079, 22663,   553,\n",
              "            509,  8846,  3301, 14516,   683,    13, 50260,     1,   732,   836,\n",
              "            470,   423,   257,  5127,   286, 13079,  1108,   553,   509,  8846,\n",
              "           3301,   531,    13, 50258,     1,   732,   836,   470,   423,   257,\n",
              "          44176,  5127,   553,   509,  8846,  3301,   531,    13, 50258,     1,\n",
              "            732,   836,   470,   423,   257,  6937,  5127,   553,   509,  8846,\n",
              "           3301,   531,    13, 50258,   986,   290,   523,   319,   986, 50258,\n",
              "            986,   290,   523,   986,   356,   836,   470,   423,   986,   257,\n",
              "          44176,  5127,   986, 50258,   986,   290,   523,   986,   326,   986,\n",
              "            318,   986,   644,   986,   356,   986,   836,   986,   423,   986,\n",
              "            329,   986, 13079,   986, 46152]]),\n",
              " tensor([[50257,  2990,  1234,   257,  9646, 19908,   319,   607,   257,   614,\n",
              "           2084,   523,   484,   714,  2050,   607,    13, 50260,    64,   614,\n",
              "           2084,    11,   484,  1234,   257, 19908,   319,   607,   523,   484,\n",
              "            714,  2610,   607,    13, 50258,    64,   614,  2084,   986,   484,\n",
              "           1234,   257, 19908,   319,   607, 16317,   284,   766,   644,   673,\n",
              "            318,   588,    13, 50258,    64,   614,  2084, 16317,   484,   547,\n",
              "          11065,   607, 16317,   329,   257,   614,    13, 50258,   986,   484,\n",
              "           1234,   257, 19908,   319,   607, 16317,   284,   766,   644,   673,\n",
              "            318,   588,    13, 50258,   986,   257,   614,  2084, 16317,   484,\n",
              "            547,   986, 11065,   607, 16317,   329,   257,   614,    13, 50258,\n",
              "            986,   329,   257,   614, 16317]]),\n",
              " tensor([[50257,  6747,   262,  2700,   307,   351,   345, 50260,  6747,   262,\n",
              "           2700,   307,   351,   345,     0, 50258,    25,     8,   220,  4599,\n",
              "           8458,    11,   314,  1101,   351,   345,   319,   428,   530,    13,\n",
              "          50258,    25,     8,   220,  4599,  8458,    11,   314,  1101,   351,\n",
              "            345,   319,   428,   530,    13, 50258,    25,     8,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,    40,  5402,   284,   262,  3761,  6136,   338, 16218,  3434,\n",
              "            986,   319,   262, 21508,   286,   262, 12580,    13, 50260,   261,\n",
              "            262,  4308, 16317,   286, 16218,  3434, 16317,   416,   262, 13683,\n",
              "          16317,   319,   262, 21508,   286,   262,  1339,    13, 50258,  1169,\n",
              "           6853, 16317,  4477,   284,  1368, 16317,   262, 21508, 16317,   286,\n",
              "            262, 12580, 16317,   287,   262,  1339,   986,   286,   262, 12580,\n",
              "             13, 50258, 50258,  1169,  6853, 16317,  4477, 16317,   284,  1368,\n",
              "          16317,   262, 13683, 16317,   287,   262,  1339, 16317,   780, 16317,\n",
              "            286,   262,  3840, 16317,   286,   262, 12580,    13, 50258, 50258,\n",
              "          50258,  1169,  6853, 16317,  4477, 16317,   284,  1368, 16317,   262,\n",
              "          13683, 16317,   780, 16317,   286]]),\n",
              " tensor([[50257,  1026,   338, 12270,  1327,   284,  3677,   257,  2156, 26760,\n",
              "             13, 50260,   270,   338,   257,  5968,   286,   257,  1917,   284,\n",
              "           3677,   257,  2156,   783,    13, 50258,   270,   338,   257,  1917,\n",
              "            783,   284,  3677,   257,  2156,    13, 50258,   270,   338,   257,\n",
              "            845,  2408,  1517,   284,   466,    13, 50258,   270,   338,   257,\n",
              "           1917,   329,  6301,   257,  2156,    13, 50258,   270,   338,   257,\n",
              "           1917,   783,    13, 50258,   270,   338,   257,  1917, 16317,   329,\n",
              "           6301, 16317,   262,  2156,    13, 50258,   270,   338,   257,  1917,\n",
              "          16317,   329,   783, 16317,    13, 50258,   270,   338,   257,  1917,\n",
              "          16317,   329,   262,  5466, 16317,    13, 50258,   270,   338,   257,\n",
              "           1917, 16317,   329,   783, 16317]]),\n",
              " tensor([[50257,    40,   423,  2982,   340,   318,  7427, 50260,    72,  1053,\n",
              "           2982,   340,   338,  7427,    13, 50258,    72,  1053,  2982,   340,\n",
              "            338,  7427,    13, 50258,    72,  1053,  2982,   340,   338,  7427,\n",
              "             13, 50258,    72,  1053,  2982,   340,   338,  7427,    13, 50258,\n",
              "             72,  1053,  2982,   340,   338,  7427,    13, 50258,    72,  1053,\n",
              "           2982,   340,   338,  7427,    13, 50258,    72,  1053,  2982,   340,\n",
              "            338,  7427,    13, 50258,    72,  1053,  2982,   340,   338,  7427,\n",
              "             13, 50258,    72,  1053,  2982,   340,   338,  7427,    13, 50258,\n",
              "             72,  1053,  2982,   340,   338,  7427,    13, 50258,    72,  1053,\n",
              "           2982,   340,   338,  7427,    13, 50258,    72,  1053,  2982,   340,\n",
              "            338,  7427,    13, 50258,    72]]),\n",
              " tensor([[50257,  1544,  2192,  7342,  1165,   881, 18384, 50260,   258,  2192,\n",
              "           7342,  1165,   881,  8483,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,  8483,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,  8483,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,  8483,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,  8483,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,  8483,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,   340,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,   340,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,   340,    13, 50258,   258,  1276,   423,  7342,\n",
              "            257,  1256,   286,   340,    13]]),\n",
              " tensor([[50257, 12130,  1153,  9416,   262, 45248,  2839, 45402,    13, 50260,\n",
              "           8071,  2334,   423,  9416,   286, 29834,   329,   511,  1363,    13,\n",
              "          50258, 19734, 45402,    11,   484,   423,  9416,   286, 29834,    13,\n",
              "          50258, 19734,  7327,    11,   484,  2148,   262, 29834,   284,   262,\n",
              "           1363,    13, 50258, 19734,  7327,   986,   329,   262,  4007, 16317,\n",
              "            484,  5127,   262, 29834,   284,   262,  1363,    13, 50258, 19734,\n",
              "           7327, 16317,   329,   326, 16317,   484,  5127,   262, 29834, 16317,\n",
              "            329,   262,  4007, 16317,    13, 50258, 50258, 19734,  7327, 16317,\n",
              "            329,   326, 16317,   484,  2148,   262, 29834, 16317,   329,   262,\n",
              "           4007, 16317,    13, 50258, 19734,  7327, 16317,   329,   326, 16317,\n",
              "            484,  2148,   606, 16317,   329]]),\n",
              " tensor([[50257,    40,   892,   345,  1612,   691,   345,   290,   326,   584,\n",
              "           1048,   389,  2950, 50260,    72,   892,   345,  1612,   691,   345,\n",
              "            290,   326,   584,  1048,   389,  2950,    13, 50258,    72,   892,\n",
              "            345,  1612,   691,   345,   290,   326,   584,  1048,   389,  2950,\n",
              "             13, 50258,    72,   892,   345,  1612,   691,   345,   290,   326,\n",
              "            584,  1048,   389,  2950,    13, 50258,    72,   892,   334,  1612,\n",
              "            691,   334,   290,   326,   584,  1048,   389,  2950,    13, 50258,\n",
              "          50258,    72,   892,   334,  1612,   691,   334,   290,   326,   584,\n",
              "           1048,   389,  2950,    13, 50258, 50258,    72,   892,   334,  1612,\n",
              "            691,   334,   290,   326,   584,  1048,   389,  2950,    13, 50258,\n",
              "             72,   892,   334,  1612,   691]]),\n",
              " tensor([[50257,    42,   747,   683,   290, 13627,   534,  1842,   329,   683,\n",
              "            220,   554,  3090,    11,  2652,  2081,   284,   534,  5369, 50260,\n",
              "          41304,   683,    11,   788,  1560,   683,   345,  1842,   683,    13,\n",
              "          50258, 41304,   683,   986,   788,  1560,   683,   345,  1842,   683,\n",
              "            986, 50258, 41304,   683,   986,   788,   986,  2652,  2081,   284,\n",
              "           2956,  5369,   986, 50258,    42,   747,   683,   986,   788,   986,\n",
              "           1560,   683,   334,  1842,   683,   986, 50258,    42,   747,   683,\n",
              "            986,   788,   986,  2652,  2081,   284,  2956,  5369,   986, 50258,\n",
              "             42,   747,   683,   986,   788,   986,   655,   466,   340,   986,\n",
              "          50258,    42,   747,   683,   986,   788,   986,   655,   466,   340,\n",
              "            986, 50258,   986,   466,   340]]),\n",
              " tensor([[50257,    37,   368,  2040,   466,   262,   976,  1517,    11,  1204,\n",
              "            318,  1690,  9389, 50260,  1169,   976,  1517,   318,  1760,   416,\n",
              "           4813,    11,   340,   318,  1690,  1327,  1204,    13, 50258, 36960,\n",
              "            466,   340,  1165,   986,  1204,   318,  1690,  2408,   986, 50258,\n",
              "           1169,   976,  1517,   318,  1760,   986, 36960,   466,   340,   986,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,    40,  1101,  1654,  1987,  2250,  1839,   470,   787,   597,\n",
              "           3580,    13, 50260,  1169,  3580,   287,  1987,  2250,   318,   407,\n",
              "          18424,    13, 50258,  1169,  1987,  2250,  1839,   470,  1487,  1997,\n",
              "             13, 50258,   270,   338,   407,  1016,   284,  1487,  1997,   287,\n",
              "           1987,  2250,    13, 50258,  1169,  1987,  2250,  1839,   470,  1487,\n",
              "           1997,    13, 50258,  1169,  3580,   318,   407, 18424,   986,  1987,\n",
              "           2250,   986, 50258,  3919,   986,   340,   338,   407,  2861,   340,\n",
              "            986, 50258,  1731,  2250,   986,   340,  1839,   470,  1487,  1997,\n",
              "            986, 50258,  1169,  3580,   318,   986,   407,  2861,   340,   986,\n",
              "          50258,  1731,  2250,   986,   326,   338,   340,   986,   340,   338,\n",
              "            407,  2861,   340,   986, 50258]]),\n",
              " tensor([[50257,    39, 16682,   510,    11,   350,   470,   270, 46749,    11,\n",
              "            393,   356,     6,   346,   307,  2739,    13, 50260,   732,  1183,\n",
              "            467,    11,   350,   470,   270,   406,   893,    11,   393,   356,\n",
              "           1183,   307,  2739,    13, 50258,   732,  1183,   467,    11,   350,\n",
              "            470,   270,   406,   893,   986,   393,   356,  1183,   307,  2739,\n",
              "             13, 50258,   732,  1183,   467, 16317,   393, 16317,   356,  1183,\n",
              "            307,  2739, 16317,    13, 50258,   732,  1183,   986,   467, 16317,\n",
              "            393, 16317,   356,  1183,   307,  2739, 16317,    13, 50258,   732,\n",
              "           1183,   986,   467, 16317,   393, 16317,   356,  1183,   307,  2739,\n",
              "          16317,    13, 50258,   732,  1183,   986,   467, 16317,   393, 16317,\n",
              "            356,  1183,   307,  2739, 16317]]),\n",
              " tensor([[50257,   464,  2583,  3672,   286,   262, 43975,   705,     4,    82,\n",
              "              6,   318, 12515, 50260,  1169,  2583,  1438,   286,   262, 43975,\n",
              "            705,     4,   264,     6,   318,   407,  4938,    13, 50258,  1169,\n",
              "           2583,  1438,   286,   262, 43975,   705,     4,   264,     6,   318,\n",
              "            407,  4938,    13, 50258,  1169,  2583,  1438,   318,   407,  7368,\n",
              "             13, 50258,  1169, 43975,   705,     4,   264,     6,   318,   407,\n",
              "           7368,    13, 50258,  1169,  2583,  1438,   318,   407,  7368,    13,\n",
              "          50258,  1169, 43975,   705,     4,   264,     6,   318,   407,  4938,\n",
              "             13, 50258,  1169,  2583,  1438,   318,   407,  7368,    13, 50258,\n",
              "          50258,  1169, 43975,   705,     4,   264,     6,   318,   407,  7368,\n",
              "             13, 50258,  1169,  2583,  1438]]),\n",
              " tensor([[50257,  1026,   373,  2408,   284, 43969,   303,  3248,   655,   788,\n",
              "             11,   329,   326,  1862, 10846,   550,   407,   262, 24917,  3252,\n",
              "            286,   371, 20340,    13, 50260,  1640,   326,  1862, 10846,    11,\n",
              "            371, 20340,   373,   407,  7787,   286,  3248,    11,   340,   373,\n",
              "           2408,   284,   910,    13, 50258, 16635,   373,   407,  7787,    11,\n",
              "            329,   326,  1862,  2415,   373,   407,   379,   477,  7787,    13,\n",
              "          50258, 16635,   373,   407,  7787,    11,   329,   326,  1862,  2415,\n",
              "            373,   407,  7787,    13, 50258, 16635,   373,   407,  7787,    11,\n",
              "            329,   326,  1862,  2415,   373,   407,  7787,    13, 50258, 16635,\n",
              "            373,   407,  7787,    11,   329,   326,  1862,  2415,   373,   407,\n",
              "           7787,    13, 50258, 16635,   373]]),\n",
              " tensor([[50257,  5756,   606,   760,   326,   345,   588,   606, 50260, 24446,\n",
              "            606,   326,   345,   588,   606,    13, 50258,  1616,   606,   760,\n",
              "            326,   334,   588,   606,    13, 50258,  1616,   606,   760,   326,\n",
              "            334,   588,   606,    13, 50258,  1616,   606,   760,   326,   334,\n",
              "            588,   606,    13, 50258,  1616,   606,   760,   326,   334,   588,\n",
              "            606,    13, 50258,  1616,   606,   760,   326,   334,   588,   606,\n",
              "             13, 50258,  1616,   606,   760,   326,   334,   588,   606,    13,\n",
              "          50258,  1616,   606,   760,   326,    13, 50258,  1616,   606,   760,\n",
              "            326,    13, 50258,    11,   290,  1560,   606,   326,   334,   588,\n",
              "            606,    13, 50258,    11,   290,  1560,   606,   326,    13, 50258,\n",
              "             11,   290,  1560,   606,   326]]),\n",
              " tensor([[50257,  1639,   815, 18595,   607,   284,  9320,   607,   402,  1961,\n",
              "           5359,    11,   651,  2742, 48936,   290,  1445,   503,  1201,   673,\n",
              "            857,   407,   588,  1363, 50260, 33331,   607,   284,  9320,   607,\n",
              "            402,  1961,  5359,    11,   651,  2742, 48936,   986,   290,  1445,\n",
              "            503,   986,   673,  1595,   470,   588,  1363,    13, 50258, 33331,\n",
              "            607,   284,  9320,   986,   607,   402,  1961,  5359,   986,   290,\n",
              "            651,  2742, 48936,   986,   673,  1595,   470,   588,  1363,    13,\n",
              "          50258, 33331,   607,   284,  9320,   986,   607,   402,  1961,  5359,\n",
              "            986,   290,   651,  2742, 48936,   986,   673,  1595,   470,   588,\n",
              "           1363,    13, 50258, 50258, 33331,   607,   986,   673,   338,   257,\n",
              "           1125,   729,   986,   290,   673]]),\n",
              " tensor([[50257,    40,  1101,   407,  1654,   611,   366, 19950,     1,   318,\n",
              "            262,  1573,   314,  1549,   779,   319,   428,  1295,    13, 50260,\n",
              "             40,   836,   470,   760,   611,   314,   815,   779,   262,  1573,\n",
              "            366, 19950,   526, 50258,    40,   836,   470,   760,   611,   314,\n",
              "            815,   910,   366, 19950,   526, 50258,    40,   836,   470,   760,\n",
              "            611,   314,   815,   910,   366, 19950,   526, 50258,   986,   314,\n",
              "            836,   470,   760,   611,   314,   815,   910,   366, 19950,   526,\n",
              "          50258,   986,   314,   836,   470,   760,   611,   314,   815,   910,\n",
              "          16317,   366, 19950,   526, 50258,   986,  1312,   836,   470,   760,\n",
              "            611,   314,   815,   910, 16317,   366, 19950,   526, 50258,   986,\n",
              "           1312,   836,   470,   760,   611]]),\n",
              " tensor([[50257,    40,  2314,  3505,   326,   530, 50260,    72,   460,   470,\n",
              "           3505,   326,   530,   986, 50258,    72,   460,   470,  3505,   326,\n",
              "            530,   986, 50258,    40,   460,   470,  3505,   326,   530,   986,\n",
              "          50258,    72,   460,   470,  3505,   986, 50258,    72,   460,   470,\n",
              "           3505,   986, 50258,    72,   460,   470,  3505,   986, 50258,    72,\n",
              "            460,   470,   986,   326,   530,   318,   523, 13321,    78,  2626,\n",
              "            986, 50258,    72,   460,   470,   986,   326,   530,   318,   523,\n",
              "          13321,    78,  2626,   986, 50258,    72,   460,   470,   986,   326,\n",
              "            530,   318,   523, 13321,    78,  2626,   986, 50258,    72,   460,\n",
              "            470,   986,   326,   530,   318,   523, 13321,    78,  2626,   986,\n",
              "          50258, 50258,    72,   460,   470]]),\n",
              " tensor([[50257,  5492,  3522,   284,   262,  5361,  1080, 10478,  3696,   329,\n",
              "           1321,  5115, 18850,    13, 50260, 17018,   546,   262, 18850,   286,\n",
              "            262,  5361,  1080,   318,  2810,   287,   262, 10478,  3696,    13,\n",
              "          50258, 17018,  9305,   262, 18850,   286,   262,  1080,   318,  7763,\n",
              "            287,   262,  5981, 10478,  3696,    13, 50258, 17018,  9305,   262,\n",
              "          18850,   286,   262,  1080,   318,  2810,   287,   262, 10005,    13,\n",
              "          50258, 17018,  9305,   262, 18850,   318,  1813,   287,   262,  1339,\n",
              "            286,   262,  1037,    13, 50258, 17018,  9305,   428,   318,  2810,\n",
              "            329,   262,  4905,    13, 50258, 17018,  9305,   428,   318,  5981,\n",
              "            329,   262,  4007,    13, 50258, 17018,  9305,   262, 18850,   318,\n",
              "           3306,   329,   262,  4007,    13]]),\n",
              " tensor([[50257, 18050, 31612,  1464,   857,   257, 23754,  1693, 50260, 18050,\n",
              "          31612,  1464,   857,   257,   922,  1693,    13, 50258,    73,   320,\n",
              "           1097,  4364,  1464,   857,   257,   922,  1693,    13, 50258, 18050,\n",
              "          31612,  1464,   857,   257,   922,  1693,    13, 50258,    73,   320,\n",
              "           1097,  4364,  1464,   857,   257,   922,  1693,    13, 50258,    73,\n",
              "            320,  1097,  4364,  1464,   857,   257,   922,  1693,    13, 50258,\n",
              "             73,   320,  1097,  4364,  1464,   857,   257,   922,  1693,    13,\n",
              "          50258,    73,   320,  1097,  4364,  1464,   857,   257,   922,  1693,\n",
              "             13, 50258,    73,   320,  1097,  4364,  1464,   857,   257,   922,\n",
              "           1693,    13, 50258,    73,   320,  1097,  4364,  1464,   857,   257,\n",
              "            922,  1693,    13, 50258,    73]]),\n",
              " tensor([[50257,  9171, 13492,  2770,  2811,   625,   262,   890,  3381,  2236,\n",
              "            307,   973,   611, 19999,  2770,  1366,   318,  1695,    13, 50260,\n",
              "            361,   262,  1366,   318,  1695,    11,   262,  2811,   329,   262,\n",
              "            890,  3381,   318,   973,    13, 50258,  1169,  2811,   329,   262,\n",
              "            890,  3381,   318,   973,   611,   612,   318,   257, 19999,  2770,\n",
              "           1700,    13, 50258,   361,   612,   318,   884,  1366,    11,   340,\n",
              "            318,   973,   329,   262,  4007,   286,   262,   890,  3381,    13,\n",
              "          50258, 50258, 50258,   361,   612,   318,   884,  1366,    11,   340,\n",
              "            318,   973,   329,   262,  4007,   286,   262,   890,  3381,    13,\n",
              "          50258, 50258,   361,   523,    11,   340,   318,   973,   329,   262,\n",
              "           4007,   286,   262,   890,  3381]]),\n",
              " tensor([[50257,    40, 10667,   290,   314,   373,   826, 50260,    72, 10667,\n",
              "            290,  1312,   373,   826,    13, 50258,    72, 10667,   986,   392,\n",
              "           1312,   373,   826,    13, 50258,    72, 10667,   986,   392,  1312,\n",
              "            373,   826,    13, 50258,    72, 10667,   986,   392,  1312,   373,\n",
              "            826,    13, 50258,    72, 10667,   986,   392,  1312,   373,   826,\n",
              "             13, 50258,   568,  1312, 10667,   986,   392,  1312,   373,   826,\n",
              "             13, 50258,    72, 10667,   986,   392,  1312,   373,   826,    13,\n",
              "          50258,    72, 10667,   986,   392,  1312,   373,   826,    13, 50258,\n",
              "            568,  1312, 10667,   986,   392,  1312,   373,   826,    13, 50258,\n",
              "             72, 10667,   986,   392,  1312,   373,   826,    13, 50258,    72,\n",
              "          10667,   986,   392,  1312,   373]]),\n",
              " tensor([[50257, 11158,    11,  3371,   262,  1353,   286, 12788,    11,   339,\n",
              "            318,  1498,   284,  2513,   881,   517,  3538,    13, 50260,  1169,\n",
              "            938,  1517,   339,   460,   466,   318,  2513,   257,  1256,   517,\n",
              "            319,   262, 12788,    13, 50258,   392,  3443, 16317,   339,   460,\n",
              "           2513,   257,  1256,  1365, 16317,   379,   262,  1353,   286,   262,\n",
              "          12788,    13, 50258, 50258,   258,   460,   635,  2513,   257,  1256,\n",
              "            517, 16317,   379,   262,  1353, 16317,    13, 50258,   392, 16317,\n",
              "            326,   338,  1521, 16317,   339,   460,  2513,   257,  1256, 16317,\n",
              "            379,   262,   886, 16317,    13, 50258, 50258,   258,   460,    11,\n",
              "            286,  1781, 16317,  2513, 16317,   257,  1256, 16317,   379,   262,\n",
              "            886, 16317,    13, 50258,   986]]),\n",
              " tensor([[50257,  1532,   345, 26412,   287,  2688, 28630,   788,   340,   743,\n",
              "            307,   360, 45098, 41778,  6592,   393,   399, 15498, 39924,  3099,\n",
              "          50260,   361,   334,  2107,   287,  7421,   275,  1516,   282,    11,\n",
              "            340,   743,   307,   288, 45098,   279,  2238,  6592,   393,  9289,\n",
              "             64,  9210,  3099,    13, 50258,   361,   334,  2107,   287,  7421,\n",
              "            275,  1516,   282,   986,   788,   340,   743,   307,   288, 45098,\n",
              "            279,  2238,  6592,   393,  9289,    64,  9210,  3099,    13, 50258,\n",
              "            361,   334,  2107,   287,  7421,   275,  1516,   282,   986,   788,\n",
              "            340,   743,   307,   288, 45098,   279,  2238,  6592,   393,  9289,\n",
              "             64,  9210,  3099,    13, 50258, 50258,   361,   334,  2107,   287,\n",
              "           7421,   275,  1516,   282,   986]]),\n",
              " tensor([[50257,    49,   312,   340,   286,   616,  4088, 50260,    40,  1183,\n",
              "           5755,  3589,   286,   616,  4088,    13, 50258,    40,  1183, 28602,\n",
              "            616,  4088,    13, 50258,    40,  1183,  2666,   340,   994,   986,\n",
              "            314,  1183,  6044,   546,   340,    13, 50258,    40,  1183,  2666,\n",
              "            340,   986,   314,  1183,  6044,   546,   340,    13, 50258,    40,\n",
              "           1183,  6044,   546,   340, 16317,   788,   986,   314,  1183,  2666,\n",
              "            340,    13, 50258,    40,  1183,  6044,   546,   340, 16317,   788,\n",
              "            986,   314,  1183,  2666,   340,    13, 50258,    40,  1183,  6044,\n",
              "            546,   340, 16317,   788, 16317,   314,  1183,  2666,   340,    13,\n",
              "          50258,    40,  1183,  6044,   546,   340, 16317,   788, 16317,   314,\n",
              "           1183,  2666,   340,    13, 50258]]),\n",
              " tensor([[50257,  1135,  1053,  1392,   257,   734,  1180,  7405,   287,   262,\n",
              "           2166,    13, 50260,   732,   423,   734,  1180,  7405,   287,   262,\n",
              "           2166,    13, 50258,   732,   423,   734,  1180,  3392,   287,   262,\n",
              "           2166,    13, 50258,   732,   423,   734,  1180,  3392,    13, 50258,\n",
              "            732,   423,   734,  1180,  3392,   287,   262,  2166,    13, 50258,\n",
              "            732,   423,   734,  1180,  3392,    13, 50258,   732,   423,   734,\n",
              "             13, 50258,   732,   423,   734,    13, 50258,   732,   423,   734,\n",
              "             13,   356,   423,   734,    13, 50258,   732,   423,   734,    13,\n",
              "            356,   423,   734,    13, 50258,   732,   423,   734,    13, 50258,\n",
              "            732,   423,   362,    13,   356,   423,   362,    13,   356,   423,\n",
              "            362,    13, 50258,   732,   423]]),\n",
              " tensor([[50257, 24461,  2125,   470,  1263,   475,   340,   338,  1327, 50260,\n",
              "          24461,   318,   407,  1263,   475,   340,   318,  1327,    13, 50258,\n",
              "          24461,   318,   407,  1263,    11,   475,   340,   318,  1327,    13,\n",
              "          50258, 24461,   318,   407,  1263,    11,   475,   340,   318,  1327,\n",
              "             13, 50258, 24461,   318,   407,  1263,    11,   475,   340,   318,\n",
              "           1327,    13, 50258, 24461,   318,   407,  1263,    11,   475,   340,\n",
              "            318,  1327,    13, 50258, 24461,   318,   407,  1263,    11,   475,\n",
              "            340,   318,  1327,    13, 50258, 24461,   318,   407,  1263,    11,\n",
              "            475,   340,   318,  1327,    13, 50258, 24461,   318,   407,  1263,\n",
              "             11,   475,   340,   318,  1327,    13, 50258, 24461,   318,   407,\n",
              "           1263,   986, 12758,    11,   340]]),\n",
              " tensor([[50257,  3666,  4004, 17343,   318,   262, 14407, 50260,    72,  1842,\n",
              "            262,   872,   415,  3150,   616,  4004,   318,   262, 36381, 50258,\n",
              "           1820,  2090,   318,   262, 36381,  1106, 50258,  1820,  2090,   318,\n",
              "            262, 36381,  1106, 50258,    72,  1842,   262,   872,   415,  3150,\n",
              "            986,  1312,   588,   606,   257,  1256,   986, 50258,  1820,  2090,\n",
              "            318,   262, 36381,   986, 50258,    72,   588,   606,   986,  1312,\n",
              "            588,   606,   257,  1256,   986, 50258,    72,   588,   606,   986,\n",
              "           1312,   588,   606,   257,  1256,   986, 50258,  1820,  2090,   318,\n",
              "            262, 36381,   986, 50258,    72,   588,   606,   986,  1312,   588,\n",
              "            606,   257,  1256,   986, 50258, 50258,  1820,  2090,   318,   262,\n",
              "          36381,   986, 50258,    72,   588]]),\n",
              " tensor([[50257,  1026,  5238,   588,   534,  5229,   318,   257,   845, 34412,\n",
              "           1048, 50260,    82,  3733,   588,   534,  5229,   318,   257, 34412,\n",
              "           3516,    13, 50258,   270,  5238,   588,   339,   338,   257, 34412,\n",
              "           3516,    13, 50258,    82,  3733,   588,   339,   338,   257, 34412,\n",
              "           3516,    13, 50258,    82,  3733,   588,   340,    13,   258,   338,\n",
              "            257, 34412,  3516,    13, 50258,   270,   338,   588,   326,    13,\n",
              "            258,   338,   257, 34412,  3516,    13, 50258,   270,   338,   588,\n",
              "            326,   986,   258,   338,   257, 34412,  3516,    13, 50258,    82,\n",
              "           3733,   588,   340,   986,   339,   338,   257, 34412,  3516,    13,\n",
              "          50258,   270,   338,   588,   326,   986,   339,   338,   257, 34412,\n",
              "           3516,    13, 50258,   270,   338]]),\n",
              " tensor([[50257,  5211,   262,  9473,   869,   777, 35495, 17709,    30, 50260,\n",
              "          20839,   262,  9473,  3068,   262,  5123,   286, 35495,    30, 50258,\n",
              "          20839,   484,  3068,   262,  5123,   286, 35495,    30, 50258, 50258,\n",
              "            271,   340,   287,   262,  3348,    30, 50258, 20839,   484,  3068,\n",
              "            262,  5123,   286, 35495,    30, 50258,   271,   326,   644,   484,\n",
              "            869,   340,    30, 50258, 22437,   340,  2152,    30,   986, 50258,\n",
              "            271,   340,   287,   262,  7533,    30,   986, 22437,   340,  2152,\n",
              "             30,   986, 50258, 22437,   339,  2152,    30,   986, 50258,   271,\n",
              "            340,   287,   262,  7533,    30,   986,   271,   340,   287,   326,\n",
              "             30,   986, 50258, 22437,   339,  2152,    30,   986,   271,   340,\n",
              "             30,   986,   271,   340,    30]]),\n",
              " tensor([[50257,   464,  2046,   543,  8469,   992,   319,   607,  3285,   400,\n",
              "            750,  1310,   284,  5814,   607, 10038,    13, 50260,   372, 10038,\n",
              "            373,   407,  6596,   416,   262,  2046,    13, 50258,  1169,  2046,\n",
              "            373,   407,  5814,  1576,   329,   607,    13, 50258,  1169,  2046,\n",
              "            373,   407,  1576,   329,   607,    13, 50258,  1169,  2046,   373,\n",
              "            407,  1576,   329,   607,    13, 50258,  1169,  2046,   373,   407,\n",
              "           1576,   329,   607,    13, 50258,  1169,  2046,   373,   407,  1576,\n",
              "            329,   607,    13, 50258,  1169,  2046,   373,   407,  1576,   329,\n",
              "            607,    13, 50258,  1169,  2046,   373,   407,  1576,   329,   607,\n",
              "             13, 50258,  1169,  2046,   373,   407,  1576,   329,   607,    13,\n",
              "          50258, 50258,  1169,  2046,   373]]),\n",
              " tensor([[50257,  6090,   345,  1037,   502,   651,   284,   760,   607, 50260,\n",
              "           5171,   334,  1037,   502,   651,   284,   760,   607,    30, 50258,\n",
              "           5171,   334,  1037,   502,   651,   284,   760,   607,    30, 50258,\n",
              "          50258,  5171,   334,  1037,   502,   651,   284,   760,   607,    30,\n",
              "          50258,    30,   986, 50258,    30,   986,   460,   334,  1037,   502,\n",
              "            651,   284,   760,   607,    30, 50258,    30,   986, 50258,    30,\n",
              "            986,   460,   334,  1037,   502,   651,   284,   760,   607,    30,\n",
              "          50258,    30,   986, 50258,    30,   986, 50258,    30,   986,   460,\n",
              "            334,  1037,   502,   651,   284,   760,   607,    30, 50258,    30,\n",
              "            986, 50258,    30,   986, 50258,    30,   986, 50258,    30,   986,\n",
              "            460,   334,  1037,   502,   651]]),\n",
              " tensor([[50257, 10248,    13,  1318,   318,   257, 16968,  3996,   287,   262,\n",
              "           6745,  2607,    13, 50260,  8117,   338,   257,  3024,  3996,   287,\n",
              "            262,  2607,    13, 50258,    64,  3024,  3996,   318,   287,   262,\n",
              "           6745,  2607,    13, 50258,  1169,  6745,  2607,   318, 10911,   351,\n",
              "            257, 16930,  1080,    13, 50258,    64, 16930,  1080,   318,   973,\n",
              "            287,   262,  2607,    13, 50258,    64, 16930,  1080,   318,   973,\n",
              "            287,   262,  2607,    13, 50258,  8117,   338,   257,  3024,  3996,\n",
              "            612,    13, 50258,  8117,   338,   257,  2119,   329, 16930,    13,\n",
              "          50258,  8117,   338,   257, 27635,   287,   262,  2607,    13, 50258,\n",
              "           8117,   338,   257, 27635,   986,   340,   338,   973,   986,   329,\n",
              "          16930,    13, 50258,  8117,   338]]),\n",
              " tensor([[50257,  3673,   257,   922,  2126,   284,   923,   534, 17122,   351,\n",
              "            736, 24985,    13, 50260,  9688,   262, 17122,   351,   257, 19597,\n",
              "            736,    13, 50258,   270,   338,   407,   257,   922,  2126,   284,\n",
              "            923,   262,  9912,   351,   257,   736,  2356,    13, 50258, 50258,\n",
              "          50258,  9688,   262, 17122,   351,   257, 19597,   736,    13, 50258,\n",
              "            270,   338,   407,   257,   922,  2126,    13, 50258,  9688,   262,\n",
              "           9912,   351,   257,   736,  2356,    13, 50258,   896,   407,   922,\n",
              "             13, 50258,  9688,   351,   257, 19597,   736,    13, 50258,  9688,\n",
              "            351,   257, 19597,   736,    13, 50258,   896,   407,   922,    13,\n",
              "          50258,  9688,   351,   257, 19597,   736,    13, 50258,   896,   407,\n",
              "            922,    13, 50258,  9688,   351]]),\n",
              " tensor([[50257,  2437,  7895,   284,   892,   326,   340,   318,  1744, 50260,\n",
              "           1026,   338,  1049,   284,   892,   326,   484,   714,   466,   340,\n",
              "             13, 50258,   270,   338,  1049,   284,   892,   326,   484,   714,\n",
              "            466,   340,   986,   703,  7895,   986, 50258,  4919,  7895,   986,\n",
              "            796,     8, 50258,    25,     8,   703,  7895,   986,   796,     8,\n",
              "          50258,    25,     8,   532,     8,   532,     8,   532,     8,   796,\n",
              "              8,   796,     8,   796,     8,   796,     8,   796,     8,   796,\n",
              "              8,   796,     8,   796,     8,   796,     8,   796,     8,   796,\n",
              "              8,   796,     8,   796,     8,   796,     8,   796,     8,   796,\n",
              "              8,   796,     8,   796,     8,   796,     8,   796,     8,   796,\n",
              "              8,   796,     8,   796,     8]]),\n",
              " tensor([[50257,  3886,   262,   835,    11,   314,   481,  2051,   683, 22121,\n",
              "          50260,  1525,   262,   835,    11,  1312,  1183,  2051,   683,   257,\n",
              "           1256,    13, 50258,  1525,   262,   835,   986,    72,  1183,  2051,\n",
              "            683,   257,  1256,   986, 50258,    25,     8,   220,   220,   220,\n",
              "            220,  1058,  1267,   220,   220,  1058,  1267,   220,  1058,  1267,\n",
              "            220,  1058,  1267,   220,  1058,  1267,   220,  1058,  1267,   220,\n",
              "           1058,  1267,   220,  1058,  1267,   220,  1058,  1267,   220,  1058,\n",
              "           1267,   220,  1058,  1267,   220,  1058,  1267,   220,  1058,  1267,\n",
              "            220,  1058,  1267,   220,  1058,  1267,   220,  1058,  1267,   220,\n",
              "           1058,  1267,   220,  1058,  1267,   220,  1058,  1267,   220,  1058,\n",
              "           1267,   220,  1058,  1267,   220]]),\n",
              " tensor([[50257, 33814,   502,   326,   340,   318,   407,  2861,   340, 50260,\n",
              "          38087,   502,   663,   407,  2861,   340,    13, 50258, 38087,   502,\n",
              "            663,   407,  2861,   340,    13, 50258, 38087,   502,   663,   407,\n",
              "           2861,   340,    13, 50258,    25,     8, 50258,    25,     8,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,    40,  1612,    11,   645,   986,  2644,  1662,   780,   314,\n",
              "           4054,    11,  4360,   780,   986, 50260,  3919, 16317,   407, 16317,\n",
              "            780, 16317,   314,  3521,   470, 16317,   466,   340, 16317,    13,\n",
              "          50258,  3919, 16317,   407, 16317,   780, 16317,   314,  3521,   470,\n",
              "          16317,   466, 16317,   340, 16317,    13, 50258,  3919, 16317,   407,\n",
              "          16317,   780, 16317,   314,  3521,   470, 16317,   466, 16317,   340,\n",
              "          16317,    13, 50258,  3919, 16317,   407, 16317,   780, 16317,   314,\n",
              "           3521,   470, 16317,   466, 16317,   340, 16317,    13, 50258,  3919,\n",
              "          16317,   407, 16317,   780, 16317,   314,  3521,   470, 16317,   466,\n",
              "          16317,   340, 16317,    13, 50258,  3919, 16317,   780, 16317,   314,\n",
              "           3521,   470, 16317,   466, 16317]]),\n",
              " tensor([[50257, 41451,   470,   262,  6218,   732,  2357,   621,   262, 17797,\n",
              "          26394,  7545,    30, 50260,  1169,  6218,   356, 34231,  3588,   470,\n",
              "            355,   881,   355, 17797,  7545,    30, 50258,   392,   523,    11,\n",
              "            484,   836,   470,   423,   355,   881,   355,   262, 17797,  7545,\n",
              "             30, 50258,   271,    77,   470,   340,   262,   976,   351,   262,\n",
              "           6218,    30, 50258,   271,    77,   470,   340,   517,   523, 16317,\n",
              "            329,   262, 11060, 16317,   286,   262, 17797,  7545,    30, 50258,\n",
              "            271,   340,   523, 16317,   326,    30, 50258,   271,   340,   523,\n",
              "          16317,   326, 16317,   329,   262, 11060, 16317,   286,   262, 17797,\n",
              "           7545,    30, 50258,   271,   340,   523, 16317,   326, 16317,   329,\n",
              "            262, 11060, 16317,   286,   262]]),\n",
              " tensor([[50257,  5812,   616,    11,   644,   318,   262,  4414, 50260,  2662,\n",
              "             38, 16317,   644,   318,   262,  1263,  1730,    30, 50258,  5812,\n",
              "            616,   986,   644,   318,   262,  1263,  1730, 16317,    30, 50258,\n",
              "             46, 11296, 16317,   644,   318,   262,  1263,  1730, 16317,    30,\n",
              "          50258,    46, 11296, 16317,   644,   318,   262,  1263,  1730, 16317,\n",
              "             30, 50258,    46, 11296, 16317,   644,   318,   262,  1263,  1730,\n",
              "          16317,    30, 50258,  2662,    38, 16317,   644,   318,   262,  1263,\n",
              "           1730, 16317,    30, 50258,    46, 11296, 16317,   644,   318,   262,\n",
              "           1263,  1730, 16317,    30, 50258,    30,   986,    30,   986,    30,\n",
              "            986,    30,   986,    30,   986,    30,   986,    30,   986,    30,\n",
              "            986,    30,   986,    30,   986]]),\n",
              " tensor([[50257,  3856,  6563,   290,  1464,  1975,   287,  3511,  2141,   407,\n",
              "           1716, 28868,    11,   996, 16622,   787,   922,  1926,   721,   756,\n",
              "            529,   290,  6004,   284,   644,   673,   468,   284,   910, 50260,\n",
              "           1350,  6563,   290,  1464,  1975,   287,  3511,    11,   475,   749,\n",
              "           1593,   986,  9099,   470,   307, 28868,   986, 33770,  6004,   284,\n",
              "            644,   673,   468,   284,   910,   986, 50258,  1350,  6563,   986,\n",
              "          33770,   986,  4360,   749,   286,   477,   986,  1350,  1654,   284,\n",
              "           6004,   284,   644,   673,   468,   284,   910,   986, 50258,  1350,\n",
              "           6563,   986, 33770,   986,  4360,   749,   286,   477,   986,  4868,\n",
              "            268,   284,   644,   673,   468,   284,   910,   986, 50258,  1350,\n",
              "           6563,   986, 33770,   986,  4360]]),\n",
              " tensor([[50257,    40,  4601,   284, 12479,  1757, 46625, 50260,    72, 18869,\n",
              "          12479, 45610,   269,  8107,    13, 50258,    72,   765,   284, 12479,\n",
              "          45610,   269,  8107,    13, 50258,    72,   765,   284, 12479, 45610,\n",
              "            269,  8107,    13, 50258,    72,   765,   284, 12479, 45610,   269,\n",
              "           8107,    13, 50258,    72,   765,   284, 12479, 45610,   269,  8107,\n",
              "             13, 50258,    72, 18869, 12479, 45610,   269,  8107,    13, 50258,\n",
              "             72,   765,   284, 12479, 45610,   269,  8107,    13, 50258,    72,\n",
              "            765,   284, 12479, 45610,   269,  8107,    13, 50258,    72,   765,\n",
              "            284, 12479, 45610,   269,  8107,    13, 50258,    72, 18869, 12479,\n",
              "          45610,   269,  8107,    13, 50258,    72, 18869, 12479, 45610,   269,\n",
              "           8107,    13, 50258,    72,   765]]),\n",
              " tensor([[50257,    40,  4236,   351,  2851, 13001,   326, 25846, 22964,  1362,\n",
              "            318,  3024, 50260,    72,  4236,   351, 10441,  8396,   986,   258,\n",
              "            776, 22964,  1362,   318,  3024,    13, 50258,    72,  4236,   986,\n",
              "            258,   776, 22964,  1362,   318,  3024,   986, 50258,    25,     8,\n",
              "          50258,    25,     8,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,  1212, 17943,   338,   262,  1738,   356,   821,   407,  4581,\n",
              "            674,  1637,   826,   783,    13, 50260,   732,   836,   470,   423,\n",
              "           1637,   329,   428,  2576,    13, 50258,   732,   821,   407,  4581,\n",
              "            674,  1637,   319,   607,    13, 50258,   732,   836,   470,   423,\n",
              "           1637,   329,   607,    13, 50258,   732,   821,   407,  4581,   674,\n",
              "           1637,    11,   780,   286,   607,    13, 50258,   732,   836,   470,\n",
              "            423,  1576,  1637,   329,   607,    13, 50258,   732,   821,   407,\n",
              "           4581,   340,    11,   780,   286,   607,    13, 50258,   732,   836,\n",
              "            470,   423,   597,  1637,   329,   607,    13, 50258,   732,   836,\n",
              "            470,   423,  1997,   329,   607,    13, 50258,   732,   836,   470,\n",
              "            423,  1576,    11,   780,   286]]),\n",
              " tensor([[50257, 20490, 12157,   857,   407,  1283,   284,   423,   587,  3017,\n",
              "            287,   262,  1486,   286,  6282,    13, 50260,  1169,  1486,   286,\n",
              "            262,  6282,  2331,   407,   284,   423,   587,  3017,   287,   262,\n",
              "          12157,   286,   262,   661,    13, 50258,  1169, 12157,   286,   262,\n",
              "            661,   373,   407,  3017,   287,   262,  1486,   286,   262,  6282,\n",
              "             13, 50258, 50258,  1169, 12157,   286,   262,   661,   373,   407,\n",
              "           3017,   287,   262,  4007,   286,   262,  6282,    13, 50258, 50258,\n",
              "           1169,  4007,   286,   262,  6282,   373,   407,  3017,   287,   428,\n",
              "           2461,    13, 50258,   270,   318,   407,  1744,   284,   910,   326,\n",
              "            262, 12157,   373,  3017,    13, 50258,  1169, 12157,   373,   407,\n",
              "           3017,   287,   262,  1486,    13]]),\n",
              " tensor([[50257,    40,  2314,   307,  1654,   475,   314,   892,   326,   611,\n",
              "            345,  1276,  9476,  3511,   788,   345,   423,   284,   307,  2407,\n",
              "          21757, 50260,    72,   460,   470,   910,   329,  1654,   475,  1312,\n",
              "            892,   611,   345,   423,   284,  9476,  3511,   788,   345,  1276,\n",
              "            307, 21757,    13, 50258,    72,   460,   470,   910,   329,  1654,\n",
              "            475,  1312,   892,   611,   345,   423,   284,  9476,  3511,   788,\n",
              "            345,  1276,   307, 21757,    13, 50258,    72, 18548,   910,   329,\n",
              "           1654,    11,   475,  1312,   892,   611,   345,   423,   284,  9476,\n",
              "           3511,   986,  5832,  1276,   307, 21757,    13, 50258,    72, 18548,\n",
              "            910,   329,  1654,    11,   475,  1312,   892,   611,   345,   423,\n",
              "            284,  9476,  3511,   986,  5832]]),\n",
              " tensor([[50257,  6423,   484,   821,  1016,   284,   651,   284,  7724,   706,\n",
              "            262,  2368,  1332,    13, 50260,  8499,   262,  2368,  1332,    11,\n",
              "            484,  1183,   307,  1498,   284,  3283,   503,   262,  7724,    13,\n",
              "          50258,  8499,   326,    11,   484,  1183,   307,  1498,   284,  3283,\n",
              "            503,   262,  1332,   379,  7724,    13, 50258,  1169,  2368,  1332,\n",
              "            481,   307,   625,    11,   523,   484,  1183,   307,  1498,   284,\n",
              "            466,   340,    13, 50258,  9930,  1183,   307,  1498,   284,   466,\n",
              "            340,   706,   326,    13, 50258,  9930,  1183,   466,   340,   706,\n",
              "            326,    11,   484,  1183,   466,   340,   329,   262,  2368,   640,\n",
              "             13, 50258,  9930,  1183,   466,   340,   706,   326,    11,   523,\n",
              "            484,  1183,   466,   340,   706]]),\n",
              " tensor([[50257,  2504,   905,  6670,  4697,   661,   508,   389,   379,  1551,\n",
              "            220,   812,   286,  2479, 50260,   270,   338,   329,  4697,   661,\n",
              "            508,   389,   379,  1551,  2310,   812,  1468,    13, 50258,   270,\n",
              "            318,  8998,   379,   661,   508,   389,   379,  1551,  2310,    13,\n",
              "          50258,  5661,   905,   318,   329,  1468,   661,   508,   389,   379,\n",
              "           1551,  2310,    13, 50258,   270,   338,   329,  1468,   661,   986,\n",
              "            508,   389,   379,  1551,  2310,    13, 50258,    25,     8, 50258,\n",
              "             25,     8,   326,   905,   318,   329,  4697,   661,   986,   508,\n",
              "            389,   379,  1551,  2310,    13, 50258,    25,     8, 29294,  1521,\n",
              "            986,   340,   338,   329,  1468,   661,   986,   379,  1551,  2310,\n",
              "             13, 50258,    25,     8, 29294]]),\n",
              " tensor([[50257,   464,  2576,   561,   423,   284,   307,   257,  1103, 29757,\n",
              "            284,   765,   284,   466,   326, 50260,  1169,  2576,   561,   423,\n",
              "            284,   307,   257,  1103, 29757,   284,   765,   284,   466,   326,\n",
              "             13, 50258, 50258,  1169,  2576,   561,   423,   284,   307,   257,\n",
              "           1103, 29757,   284,   765,   284,   466,   326,    13, 50258, 50258,\n",
              "          50258,  1169,  2576,   561,   423,   284,   307,   257,  1103, 29757,\n",
              "            284,   765,   284,   466,   326,    13, 50258, 50258, 50258, 50258,\n",
              "          50258,  1169,  2576,   561,   423,   284,   307,   257,  1103, 29757,\n",
              "            284,   765,   284,   466,   326,    13, 50258, 50258, 50258, 50258,\n",
              "          50258, 50258,  1169,  2576,   561,   423,   284,   307,   257,  1103,\n",
              "          29757,   284,   765,   284,   466]]),\n",
              " tensor([[50257,   818,   687,   534,  1266,  6726,   326,   534,  1266, 36154,\n",
              "          13850, 19189,   345, 50260, 33331,   534,  1266,  6726,   326,   534,\n",
              "          13850,  8288,   345,    13, 50258, 33331,   534,  1266,  6726,   326,\n",
              "            339,  8288,   345,    13, 50258, 33331,   534,   275,    69,   326,\n",
              "            339,  8288,   345,    13, 50258, 50258, 33331,   534,   275,    69,\n",
              "            326,   339,  8288,   345,    13, 50258, 50258, 33331,   534,   275,\n",
              "             69,   326,   339,  8288,   345,    13, 50258, 50258, 50258,  1616,\n",
              "            683,   760,   326,   339,  8288,   345,    13, 50258, 33331,   683,\n",
              "            326,   339,  8288,   345,    13, 50258, 33331,   683,   326,    13,\n",
              "          50258,  1616,   683,   760,   326,    13, 50258,  1616,   683,   760,\n",
              "            326,    13, 50258, 33331,   683]]),\n",
              " tensor([[50257, 30638,    11, 15617,   278,  1014,   338, 26387,   319,   582,\n",
              "            338,  2776,   351,  3450,    13, 50260,  1169,  1109,   318,    11,\n",
              "          15617,   278,  1014,   318,  3375,   546,   262,  2776,  1022,   582,\n",
              "            290,  3450,    13, 50258,  1169,  1109,   318, 16317,   339,   338,\n",
              "           3375,   546,   262,  2776,  1022,   582,   290,  3450,    13, 50258,\n",
              "            258,  4084,  9209,   546,   428, 16317,   546,   262,  2776,  1022,\n",
              "            582,   290,  3450,    13, 50258, 50258,   270,   318, 16317,  1598,\n",
              "          16317,   326,   339,   338,  3375,   546,   262,  2776, 16317,   351,\n",
              "           4941,   284,   262,  2776,  1022,   582,   290,  3450,    13, 50258,\n",
              "          50258, 50258,   258,   338,   986,  5486, 16317,   546,   428, 16317,\n",
              "            546,   262,  2776, 16317,   351]]),\n",
              " tensor([[50257,  4864,    11,   618,   673,  5860,   284,   670,  1568,   428,\n",
              "           1285,    11,   673,  1839,   470,   307,   523, 13943,    13, 50260,\n",
              "           1537,   673,   481,   407,   307,   523, 13943,   618,   673,  2058,\n",
              "            736,   284,   670,  1306,  1285,    13, 50258,  1537,   618,   673,\n",
              "           2058,   736,   284,   670,  1306,  1285,   986,   673,  1839,   470,\n",
              "            307,   523, 13943,    13, 50258,  4360,   986,   618,   673,  2058,\n",
              "            736,   986,   673,  1839,   470,   307,   523, 13943,    13, 50258,\n",
              "           4360,   986,   326,   531,   986,   618,   673,  2058,   736,   986,\n",
              "            673,  1839,   470,   307,   523, 13943,    13, 50258,  1537,   986,\n",
              "            326,   531,   986,   618,   673,  2058,   736,   986,   673,  1839,\n",
              "            470,   307,   523, 13943,    13]]),\n",
              " tensor([[50257,  1026,  2585,   534, 15997, 50260,   270,  2585,   534, 15997,\n",
              "             13, 50258,   270,  1139,   644,   345,   765,    13, 50258,   270,\n",
              "           1139,   644,   345,   765,    13, 50258,   270,  1139,   644,   345,\n",
              "            765,    13, 50258,   270,  1139,   523,   644,   986, 50258,   270,\n",
              "           1139,   644,   345,   765,    13, 50258,   270,  1139,   644,   345,\n",
              "            765,   986, 50258,   270,  1139,   986,   644,   466,   345,   765,\n",
              "            986, 50258,   270,  1139,   986,   644,   466,   345,   765,   986,\n",
              "          50258, 50258,   986,   340,  1139,   986,   644,   466,   345,   765,\n",
              "            986, 50258,   986,   340,  1139,   986,   644,   986, 50258,   986,\n",
              "            340,  1139,   986,   644,   986, 50258,   986,   340,  1139,   986,\n",
              "            644,   986, 50258,   986,   340]]),\n",
              " tensor([[50257,  1532,   262,  4286,  3607,   345, 23597,   788,  1521,   561,\n",
              "            345,   407,  1560,   683, 50260,  1532,   345,   423,   257,  1917,\n",
              "            351,   262,  4286,    11,  1521,   407,  1560,   683,    30, 50258,\n",
              "           1532,   345,   423,   257,  1917,   351,   262,  4286,    11,  1521,\n",
              "            407,    30, 50258,  1532,   345,   423,   257,  1917,   351,   262,\n",
              "           4286,   986, 22850,   836,   470,   345,  1560,   683,    30, 50258,\n",
              "           1532,   345,   423,   257,  1917,   986, 22850,   836,   470,   345,\n",
              "             30, 50258,   361,   345,   423,   257,  1917,   986, 22850,   836,\n",
              "            470,   345,    30, 50258,   361,   345,   423,   257,  1917,   986,\n",
              "          22850,   836,   470,   345,    30, 50258,   361,   345,   423,   257,\n",
              "           1917,   986, 22850,   836,   470]]),\n",
              " tensor([[50257,  1858,   389,  4807,  2771, 35837,   588, 46137, 50260, 15065,\n",
              "           5289,  9280,   287,   262,  6483,   286, 46137,   986, 50258, 15065,\n",
              "           5289,  9280,   287, 46137,   338,  6483,   986, 50258, 15065,  5289,\n",
              "           9280,   287, 46137,   338,  6483,   986, 50258, 15065,  5289,  9280,\n",
              "            287, 46137,   338,  6483,   986, 50258, 15065,  5289,  9280, 16317,\n",
              "            287, 46137,   338, 16317,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,   464, 11135,   389,  7334,  1262, 11521,   290, 10469, 23089,\n",
              "           5050,   355,  1290,   355,  1744,    13, 50260,  1169, 23089,  5050,\n",
              "            460,   635,   307,   973,   329,   262,  3349,   286,   262, 11135,\n",
              "             13, 50258,  1169, 23089,  2446,   318,   973,   287,   262,  1339,\n",
              "            286, 11521,   290, 10469, 23089,    13, 50258,  5661,   318,  1760,\n",
              "             11,   329,   262,   749,   636, 16317,   329,   262, 23089,    11,\n",
              "            691,   262, 11135,   389,  7334,    13, 50258, 50258,  1169,  2446,\n",
              "            318,   973, 16317,   329,   262,  4007, 16317,   286,  3957,   986,\n",
              "            262, 11135, 16317,   389,   973, 16317,   329,   262,   749,    13,\n",
              "          50258, 50258,  5661,   318,   986,   329,   262,  4007, 16317,   286,\n",
              "            986,   262,   986, 23089, 16317]]),\n",
              " tensor([[50257,  2396,   890,   355,  1450,  4656, 12354,   481,  1239, 42531,\n",
              "             13, 50260,  3919,    11, 12354,   481,   407, 42531,    11,   772,\n",
              "            611,   257,   582,   318,  2923,    13, 50258,   361,   257,   582,\n",
              "            318,  2923, 16317, 12354,   481,   407,  4656,    13, 50258,  3919,\n",
              "          16317, 12354,   481,  1239,  4656, 16317,   611,   339,   318,  2923,\n",
              "          16317,   340,   481,  1239,   307, 42774,    13, 50258,  3919, 16317,\n",
              "            611,   257,   582,   318,  2923, 16317, 12354,   481,  1239, 42531,\n",
              "          16317,   340,   318,  1464,   612,    13, 50258,  3919, 16317,   611,\n",
              "            339,   318,  2923, 16317, 12354,   481,  1239,  4656, 16317,   340,\n",
              "            318,  1464,   612,    13, 50258,  3919, 16317,   611,   339,   318,\n",
              "           2923, 16317,   340,   318,  1239]]),\n",
              " tensor([[50257,     1,  2396,    11, 20993,    11,   644,   389,   345,   651,\n",
              "          43701,     6,   379,  1701, 50260,     1,    49, 17307,    11,   644,\n",
              "            389,   345,   466,   259,     6,   994,  1701, 50258,     1,    49,\n",
              "          17307, 16317,   644,   466,   345,   466,   783, 16317,  1701, 50258,\n",
              "              1,    49, 17307, 16317,   644,   389,   345,  1804,   994, 16317,\n",
              "           1701, 50258,     1,    49, 17307, 16317,   644,   466,   345,   466,\n",
              "          16317,  1701, 50258,     1,    49, 17307, 16317,   644,   389,   345,\n",
              "           1804, 16317,  1701, 50258,     1, 16317,   644, 16317,   466,   345,\n",
              "            466, 16317,  1701, 50258,     1, 16317,   644, 16317,   466,   345,\n",
              "            466, 16317,  1701, 50258, 16317,   644, 16317,   466,   345,   466,\n",
              "          16317,  1701, 50258, 16317,   644]]),\n",
              " tensor([[50257, 16454,    11, 26510,    11,   880,    11,   644,   338,  3598,\n",
              "           5556,  5193,    30, 50260,   439,   826, 16317, 26394, 16317,   644,\n",
              "            338,  3598,  5556,  5193,    30, 50258,   439,   826, 16317,   644,\n",
              "            338,   767,  1343,   860,    30, 50258,   482, 16317,   523, 16317,\n",
              "            644,   338,   767,  1343,   860,    30, 50258,   482, 16317,   523,\n",
              "          16317,   644,   338,   767,  1343,   860,    30, 50258,   439,   826,\n",
              "          16317,   644,   338,   767,  1343,   860,    30, 50258,   439,   826,\n",
              "          16317,   644,   338,   767,  1343,   860,    30, 50258,   439,   826,\n",
              "          16317,   644,   338,   767,  1343,   860,    30, 50258,    30,   986,\n",
              "           8788, 16317,   523, 16317,   644,   338,   767,  1343,   860,    30,\n",
              "          50258,    30, 16317,  8788, 16317]]),\n",
              " tensor([[50257,     1,  1870,   262,  6617,   286,   465, 24211,   616,  2988,\n",
              "            460,   530,  1110,  4439,  1701, 50260,     1,   392,   460,   616,\n",
              "           2988,   905,   465, 24211,   329,   262, 11060,   286,   262,  2370,\n",
              "           1701, 50258,     1,   392,   460,   339,  5879,   465, 24211,    11,\n",
              "            329,   262, 11060, 16317,   286,   262,  2370, 16317,  1701, 50258,\n",
              "              1,   392, 16317,   460,   339,   986,  5879, 16317,   326, 16317,\n",
              "            339, 16317,   318, 16317, 10218, 16317,   329,   262, 11060, 16317,\n",
              "           1701, 50258,     1,   392, 16317,   460, 16317,   339, 16317,   905,\n",
              "          16317,   326, 16317,   339, 16317,   318, 16317, 10218, 16317,   329,\n",
              "          16317,   326, 16317,  1701, 50258,     1,   392, 16317,   460, 16317,\n",
              "            339, 16317,  5879, 16317,   326]]),\n",
              " tensor([[50257,  1639,   765,   534,  6853,   284,  3197,   340,   510,   393,\n",
              "           6164,    30, 50260,  4598,   345,   765,   257,  6853,   284,   787,\n",
              "            340,    30, 50258,  4598,   345,   765,   257,  6853,   284,  3197,\n",
              "            340,    30, 50258, 22850,   466,   345,   765,   530,    30, 50258,\n",
              "          22850,   466,   345,   765,   530,    30, 50258, 22850,   466,   345,\n",
              "            765,   530,    30, 50258, 10919,   815,   339,   466,    30, 50258,\n",
              "          22850,   815,   339,   466,   326,    30, 50258, 22850,   815,   339,\n",
              "            466,   340,    30, 50258, 10919,   815,   339,   466,    30, 50258,\n",
              "          22850,    30, 50258, 22850,    30, 50258, 22850,   815,   339,    30,\n",
              "          50258, 10919,   815,   339,   466,    30, 50258, 10919,   815,   339,\n",
              "            466,    30, 50258, 22850,    30]]),\n",
              " tensor([[50257,     1,   464, 21692,   286,  1951, 12831,   262, 14068,   286,\n",
              "          19441,    70,  3007,   526, 50260,     1,  1169,  6721,   329,   262,\n",
              "          18377,   318,   262, 14068,   286,  1951,   526, 50258,     1,  1169,\n",
              "           6721,   318,   257,  6721,   329,   262, 18377,   526, 50258,     1,\n",
              "           1169,  6721,   318,   262,  6721,   329,   262, 18377,   526, 50258,\n",
              "              1,  1169,  6721,   318,   262,  6721,   329,   262, 18377,   526,\n",
              "          50258,   986,   366,  1169,  6721,   318,   262,  6721,   329,   262,\n",
              "           7813,   526, 50258,   986,   290,   523,   319,   986, 50258,   986,\n",
              "          50258,   986,   329,   326,  1738, 16317,   262, 21692, 16317,   389,\n",
              "            262,  6721, 16317,   329,   262, 11060, 16317,    13, 50258,   986,\n",
              "            326,   338,  1521, 16317,   340]]),\n",
              " tensor([[50257,  1639,   389,  4950,    11, 12356,    11,   290,   262,   749,\n",
              "              1,   438,  4231,   345,   503,   286,   534,  2000,    30, 50260,\n",
              "           5832,   821,  4950, 16317, 12356, 16317,   290, 16317,   345,   821,\n",
              "            503,   286,   534,  2000,    30, 50258,  5832,   821,  4950, 16317,\n",
              "          12356, 16317,   290, 16317,   345,   821,   503,   286,   534,  2000,\n",
              "             30, 50258,  5832,   821,  4950, 16317, 12356, 16317, 16317, 16317,\n",
              "            290, 16317,   345,   821,   503,   286,   534,  2000,    30, 50258,\n",
              "            986,   345,   821, 16317,  4950, 16317, 16317, 16317,   290, 16317,\n",
              "            345, 16317,   389, 16317,  4950, 16317,    30, 50258, 16317,   345,\n",
              "          16317,   389, 16317, 12356, 16317, 16317, 16317, 16317,   290, 16317,\n",
              "            345, 16317, 16317, 16317, 16317]]),\n",
              " tensor([[50257,  3666, 17695,   373,   287,  6182,   329,   257,  1227,   706,\n",
              "            326,    13, 50260,  8499,   257,  1227,   287,  6182,    11,   616,\n",
              "          17695,   373,   612,    13, 50258,   258,   373,   612,   329,   257,\n",
              "           1227,   706,   326,    13, 50258,   258,   373,   612,   329,   257,\n",
              "           1227,   986,   329,   257,  1227,   986, 50258,  8499,   326,   986,\n",
              "            616, 17695,   373,   612,    13, 50258,   986,   339,   373,   612,\n",
              "          16317,   329,   257,  1227, 16317, 50258,   986,   339,   373, 16317,\n",
              "            994, 16317,   329,   257,  1227, 16317, 50258,   986,   339,   373,\n",
              "          16317,   994, 16317,   329,   257,  1227, 16317, 50258,   986,   339,\n",
              "            373, 16317,   994, 16317,   329,   257,  1227, 16317, 50258,   986,\n",
              "            329,   257,  1227, 16317,   986]]),\n",
              " tensor([[50257,  7155,   262,  7729,   287,   428,  3275,   284, 13259,   534,\n",
              "           9206,    13, 50260, 50260,  1462, 13259,   262,  9206,    11,  1061,\n",
              "            262,  7729,    13, 50258, 50258, 50258, 50258, 50258,  1462,   466,\n",
              "            523, 16317,  1061,   262,  7729,   287,   428,  3275,    13, 50258,\n",
              "          50258, 50258, 50258,  1462,   466,   523, 16317,  1061,   262,  7729,\n",
              "            287,   428,  3275, 16317,   329,   262,  4007, 16317,   286, 13259,\n",
              "            889,   262,  9206,    13, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "           1640,   326, 16317,  1061,   262,  7729, 16317,   329,   326, 16317,\n",
              "            356,  1183,   466,   340, 16317,   329,   326, 16317,   356,  1183,\n",
              "            466,   340, 16317,   329,   326, 16317,   356,  1183,   466,   340,\n",
              "          16317,   329,   326, 16317,   356]]),\n",
              " tensor([[50257,  1026,   373,   257, 41326, 40005,  1326,    11,  1297,   284,\n",
              "            514,   416,  6156,  4958,    13, 50260,  1169,  6156,  4958,  1297,\n",
              "            514,   340,   373,   257, 41326, 40005,  1326,    13, 50258,   732,\n",
              "            760,   340,   338,   257, 41326, 40005,  1326,    11,   422,   281,\n",
              "           6156,  4958,    13, 50258,   732,   760,   340,   338,   257, 41326,\n",
              "          40005,  1326,   986,   422,   281,  1468,  4958,    13, 50258,   732,\n",
              "            821,  1654,   986,   340,   338,   257, 41326, 40005,  1326,   986,\n",
              "            422,   281,  1468,  4958,    13, 50258,   732,   760,   986,   340,\n",
              "            338,   257, 41326, 40005,  1326,   986,   422,   281,  1468,  4958,\n",
              "             13, 50258,   732,   821,  1654,   986,   340,   338,   257, 41326,\n",
              "            986,   422,   281,  1468,  4958]]),\n",
              " tensor([[50257, 19242,   534, 11077,  1392,   308, 16406,  2761,   355,   880,\n",
              "             30, 50260, 14108, 11077,   635,   468,   257,  1917,   351,   308,\n",
              "          16406,    30, 50258, 50258, 22437,   534, 11077,   423,   257,  1917,\n",
              "            351,   308, 16406,    30, 50258, 50258,  4598,   345,   423,   257,\n",
              "           1917,   351,   534, 11077,    30, 50258, 22437,   673,   423,   257,\n",
              "           1917,   351,   340,    30, 50258,    30,    13,   986, 50258, 22437,\n",
              "            673,   423,   257,  1917,   351,   340,    30,   986, 50258,    30,\n",
              "            986, 50258,    30,   986,  5633,   986,   290,   523, 16317,   466,\n",
              "            345,   423,   257,  1917,   351,   607,    30,   986, 50258,    30,\n",
              "            986,  5633,   986,   290,   523, 16317,   466,   345,    30,   986,\n",
              "            423,   345,    30,   986, 50258]]),\n",
              " tensor([[50257,   464,  6612,   666,  3960,    78,    12, 18218,  2473, 23923,\n",
              "            550,  1760,   257, 21840,  1693,    13, 50260,  1169,  6612,   666,\n",
              "           3960,    78,    12,   260,  1073,   548, 23923,   373,   257,   922,\n",
              "            530,    13, 50258,  1169, 23923,   373,  1804,   257,  1049,  1693,\n",
              "            287,   262,  6612,   666,  3960,    78,    13, 50258,  1169,  6612,\n",
              "            666,  3960,    78,    12,   260,  1073,   548, 23923,   373,   922,\n",
              "             13, 50258,  1169,  6612,   666,  3960,    78,    12, 18218,  2473,\n",
              "           6253,   373,  1049,    13, 50258, 50258,  1169, 23923,   373,  1804,\n",
              "            257,   922,  1693,   986, 50258,  1169,   530,   986,   262,   530,\n",
              "            986,   262,   530,   986,   262,   530,   986,   262,   530,   986,\n",
              "            262,   530,   986,   262,   530]]),\n",
              " tensor([[50257,    40,  1165,    11,  6405,   257,  3516,   508,   373,   287,\n",
              "           3770, 50260,    40,  1165,  6405,   257,  3516,   508,   373,   287,\n",
              "           3770,    13, 50258,    40,  1165,  6405,   257,  3516,   508,   373,\n",
              "            287,  3770,    13, 50258, 50258,    40,  1165,  6405,   257,  3516,\n",
              "            508,   373,   287,  3770,    13, 50258, 50258, 50258,    72,  1165,\n",
              "           6405,   257,  3516,   508,   373,   287,  3770,    13, 50258,    72,\n",
              "           1165,  6405,   257,  3516,   508,   373,   287,  3770,    13, 50258,\n",
              "          50258, 50258,     7,    72,  1165,  6405,   257,  3516,   508,   373,\n",
              "            287,  3770,    13, 50258,     7,    72,  1165,  6405,   257,  3516,\n",
              "            508,   373,   287,  3770,    13, 50258,     7,    72,  1165,  6405,\n",
              "            257,  3516,   508,   373,   287]]),\n",
              " tensor([[50257,    50,   641,   669,  7603,   257,  8837,   287,   674,  1989,\n",
              "             11,  9605,  3049,    13, 50260,    82,   641,   669,  7603,   257,\n",
              "           8837,   287,   674,  1989,   986,  9605,  3049,    13, 50258,    82,\n",
              "            641,   669,  7603,   986,   257,  4074, 13885,   986,  3049,    13,\n",
              "          50258,    82,   641,   669, 16317,  7603, 16317,   257,  4074, 13885,\n",
              "          16317,  3049,    13, 50258,    82,   641,   669, 16317,  7603, 16317,\n",
              "            257,  4074, 16317, 13885, 16317,   329,   986,   257,   986,  2589,\n",
              "             13, 50258,    82,   641,   669, 16317,  7603, 16317,   257,  4074,\n",
              "          16317,   329,   986,   257, 16317,  2589,    13, 50258,    82,   641,\n",
              "            669, 16317,  7603, 16317,   257, 16317,  4074, 16317, 13885, 16317,\n",
              "            329, 16317,   257, 16317,    13]]),\n",
              " tensor([[50257,   464,  4513,   750,   407,  3328,   597,  3651,   422,  4609,\n",
              "           4671,    13, 50260,  1169,  4671,  5213,   750,   407,  2148,   597,\n",
              "           3651,    13, 50258,  1169,  4513,   750,   407,  3328,   597,  3651,\n",
              "            422,   262,  4609,  4671,    13, 50258,  1169,  4513,   750,   407,\n",
              "           3328,   597,  3651,   422,   262,  4609,  4671,    13, 50258,  1169,\n",
              "           3651,   547,   407,  2722,   416,   262,  4513,    13, 50258,  1169,\n",
              "           4513,   750,   407, 10971,   284,   262,  2683,    13, 50258,  1169,\n",
              "           4513,   750,   407, 10971,   284,   606,    13, 50258,  1169,  1808,\n",
              "            373,   407,  9373,    13, 50258,  1169,  4513,   750,   407, 10971,\n",
              "            284,   340,    13, 50258,  1169,  2071,   373,   407,  9469,    13,\n",
              "          50258,  1169,  2300,   373,   407]]),\n",
              " tensor([[50257, 10910,    11,   326,   373,   986,   523,  6029,   286,   345,\n",
              "            284,   466,    11, 42666,    13, 50260,    71,  3020,   986,   326,\n",
              "            373,   986,  1107,  6029,    11, 42666,    13, 50258,    71,  3020,\n",
              "            986,   326,   373,   986,  1107,  6029, 16317,   329,   345,    11,\n",
              "           5156,    13, 50258,    71,  3020, 16317,   329,   345, 16317,   340,\n",
              "            373, 16317,  1107,  6029, 16317,   329,   345,    13, 50258,    71,\n",
              "           3020, 16317,   329,   345, 16317,   340,   373, 16317,  1107,  6029,\n",
              "          16317,   329,   345,    13, 50258,    71,  3020, 16317,   329,   345,\n",
              "          16317,   340,   373, 16317,  1107,  6029, 16317,   329,   345,    13,\n",
              "          50258,    71,  3020, 16317,   329,   345, 16317,   340,   373, 16317,\n",
              "           1107,  6029, 16317,   329,   345]]),\n",
              " tensor([[50257,  1890,  2628,   286,  5884,  7534,    11,   645,   399, 11598,\n",
              "           2438,  2236,   307,  2098,    13, 50260,  1169, 12416,   329,   262,\n",
              "           6692,  7534,   389,   407,  2098,   329,   777,  2628,    13, 50258,\n",
              "           1169, 12416,   329,   262,  6692,  7534,   389,   407,  7368,   329,\n",
              "            777,  2628,    13, 50258,  1169, 12416,   329,   777,  2628,   389,\n",
              "            407,  2098,    13, 50258,  1640,   777,    11,   262, 12416,   389,\n",
              "            407,  7368,    13, 50258,  1169, 12416,   329,   262,  7534,   389,\n",
              "            407,   973,   329,   262,  1448,    13, 50258,  1169,  1448,   318,\n",
              "            407,  2098,    13, 50258,  1169,  2438,   318,   407,   973,   329,\n",
              "            326,    13, 50258,  1640,   326,    11,   262,  2438,   318,   407,\n",
              "            973,    13, 50258,  1169, 12416]]),\n",
              " tensor([[50257,    40,  1101, 10589,   379,   262,  7541,   986,  2644,   259,\n",
              "           8909, 42605,   361,   345,   423,   597,  1321,    13, 50260,   361,\n",
              "            345,   760,  1997, 16317,   314,  1101, 10589,   379,   262,  7541,\n",
              "             13, 50258,   361,   345,   760, 16317,   314,  1101, 10589,   379,\n",
              "            262,  8909,   371,  8836,    78, 12696,    13, 50258,   361,   345,\n",
              "            760, 16317,   314,  1101, 10589,   379,   262,  7541, 16317,   287,\n",
              "           8909,   371,  8836,    78,    13, 50258,   361,   345,   760, 16317,\n",
              "            314,  1101, 10589, 16317,   287,  8909,   371,  8836,    78, 16317,\n",
              "            329,  1321,    13, 50258,   361,   345,   760, 16317,  1312,  1183,\n",
              "            307, 16317,   379,   262,  7541, 16317,   329,   345,    13, 50258,\n",
              "            361,   345,   760, 16317,  1312]]),\n",
              " tensor([[50257,  1639,   460,  9280,    11, 13279,    11,   290, 20110, 50260,\n",
              "           5832,   460,  9280,    11, 13279,    11,   290, 20110,    13, 50258,\n",
              "             35,   590,    11,  9280,    11, 13279,    11,   290, 20110,   986,\n",
              "          50258,    35,   590,    11,  9280,   986,   392,   523,   319,   986,\n",
              "          50258,  5832,   460,  9280,   986,   392,   523,   319, 16317, 50258,\n",
              "           5832,   460,  9280,   986,   392,   523,   319,   986, 50258,    35,\n",
              "            590,   986,   392,   523,   319, 16317, 50258,  5832,   460,  9280,\n",
              "            986,   392,   523,   319,   986, 50258,  5832,   460,  9280,   986,\n",
              "            392,   523,   319, 16317, 50258,  5832,   460,  9280,   986,   392,\n",
              "            523,   319, 16317, 50258,   986,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,  7975,   287,   262,  4675,    11,  8422,   282,  1879, 10599,\n",
              "            550,  3750,   845,  2266,   287,   262,  1986,    13, 50260,  5216,\n",
              "          26261,  1879, 10599,   373, 39228,   287,   262,  4675,    13, 50258,\n",
              "            261,   262,  4675,    11,   339,   373,  2266,   287,   262,  1986,\n",
              "             13, 50258,   258,   373, 39228,   287,   262,  4675,    11,   290,\n",
              "            339,   373,  2266,    13, 50258,   258,   373,   287,   262,  4675,\n",
              "             11,   290,   339,   373,  2266,    13, 50258,   258,   373, 39228,\n",
              "             13, 50258,   258,   373,   287,   262,  4675, 16317,   339,   373,\n",
              "           2266, 16317,   339,   373, 39228,    13, 50258,   258,   373,   287,\n",
              "            262,  4675, 16317,   339,   373,  2266, 16317,   339,   373, 39228,\n",
              "             13, 50258,   258,   373,   287]]),\n",
              " tensor([[50257,  2990,   910,   257,  4101,  8769, 21857,  7161,   290, 17876,\n",
              "             13, 50260,    64,  1542,    12, 34553, 21857,  7161,   290,   257,\n",
              "          17876,    13, 50258,    64,  1542,    12, 34553, 21857,  7161,   290,\n",
              "            257, 17876,    13, 50258,   986,   484,   910, 16317,   257,  4101,\n",
              "             12, 34553, 21857,  7161, 16317,   290, 16317,   257, 17876,    13,\n",
              "          50258,   986,   257, 16317,   257, 16317,   257, 16317,   257, 16317,\n",
              "            290, 16317,   257, 16317,   257, 16317,    13, 50258,   986,   257,\n",
              "          16317,   257, 16317, 16317, 16317, 16317, 16317, 16317,   290, 16317,\n",
              "          16317, 16317, 16317,   257, 16317,    13, 50258, 16317, 16317, 16317,\n",
              "            257, 16317, 16317, 16317, 16317, 16317, 16317, 16317, 16317, 16317,\n",
              "          16317, 16317,   290, 16317, 16317]]),\n",
              " tensor([[50257, 49488,   314,  1101,  1016,   284,  1577,   345,   257,  5975,\n",
              "             13, 50260,    40,  1183,  5975,   345,  9439,    13, 50258,    40,\n",
              "           1183,  5975,   345,  9439,    13, 50258,    40,  1183,  5975,   345,\n",
              "           9439, 16317,   257,  5975,    13, 50258,    40,  1183,  5975,   345,\n",
              "          16317,   257,  5975, 16317,   257,  5975, 16317,   257,  5975, 16317,\n",
              "            257,  5975, 16317,   257,  5975, 16317,   257,  5975, 16317,   257,\n",
              "           5975, 16317,   257,  5975, 16317,   257,  5975, 16317,   257,  5975,\n",
              "          16317,   257,  5975, 16317,   257,  5975, 16317,   257,  5975, 16317,\n",
              "            257,  5975, 16317,   257,  5975, 16317,   257,  5975, 16317,   257,\n",
              "           5975, 16317,   257,  5975, 16317,   257,  5975, 16317,   257,  5975,\n",
              "          16317,   257,  5975, 16317,   257]]),\n",
              " tensor([[50257,   464,  3580,   318,   534,  2383,   584,  6155,  2354, 26349,\n",
              "             11,   290,  2130,   345, 17666,   760,  1804,   340, 50260,  1169,\n",
              "           3580,   318,   326,  2956, 13850,   318,  6155,   503, 12105,   290,\n",
              "           2130,   334, 17666,   760,   318,  1804,   340,    13, 50258,  1169,\n",
              "           3580,   318,  2956, 13850,  6155,   503, 12105,   290,  2130,   334,\n",
              "          17666,   760,   318,  1804,   340,    13, 50258,  1169,  3580,   318,\n",
              "           2956, 13850,  6155,   503, 12105,   290,  2130,   334, 17666,   760,\n",
              "            318,  1804,   340,    13, 50258, 50258, 50258,  1169,  3580,   318,\n",
              "           2956, 13850,  6155,   503, 12105,   290,  2130,   334, 17666,   760,\n",
              "            318,  1804,   340,    13, 50258, 50258,  1169,  3580,   318,  2956,\n",
              "          13850,  6155,   503, 12105,   290]]),\n",
              " tensor([[50257,     1,   314,   481,  1683,  1577,   284, 17903,    11,   314,\n",
              "            986,   366, 50260,     1,    40,  1183,  1239,  1577,   345,  1997,\n",
              "            986,   366, 50258,     1,    40,  1183,  1239,  1577,   345,  1997,\n",
              "            986,   366, 50258,     1,    40,  1183,  1239,  1577,   345,  1997,\n",
              "            986,   366, 50258,   986,   290,   314,  1183,  1239,   986,   366,\n",
              "          50258,   986,   314,  1183,  1239,   986,   366, 50258,   986,   290,\n",
              "            314,  1183,  1239,   986,   366, 50258,   986,   314,  1183,  1239,\n",
              "            986,   366, 50258,   986,   314,  1183,  1239,   986,   366,   986,\n",
              "            314,  1183,  1239,   986,   366, 50258,   986,   314,  1183,  1239,\n",
              "            986,   366,   986,   314,  1183,  1239,   986,   366, 50258,   986,\n",
              "            314,  1183,  1239,   986,   366]]),\n",
              " tensor([[50257, 13710,   345,   466,  1243,   326, 14709,   378,   683,   355,\n",
              "            880, 50260, 13300,   345,   466,  1243,   326, 11393,   683,  1165,\n",
              "             13, 50258, 13300,   345,   466,  1243,   326, 11393,   683,  1165,\n",
              "             13, 50258, 25991,   345,   466,  1243,   326, 11393,   683,  1165,\n",
              "             13, 50258, 13300,   345,   466,  1243,   326, 11393,   683,    13,\n",
              "          50258,    30,    13, 25991,   345,   466,  1243,   326, 11393,   683,\n",
              "           1165,    13, 50258,    30,   986,  3863,   345,   466,  1243,   326,\n",
              "          11393,   683,   986, 50258,    30,   986,  3863,   986, 50258,    30,\n",
              "            986,  3863,   986, 50258,    30,   986,  3863,   986, 50258,    30,\n",
              "            986,  3863,   986, 50258,    30,   986,  3863,   986, 50258,    30,\n",
              "            986,  3863,   986, 50258,    30]]),\n",
              " tensor([[50257,   464,  4898,   276,  1499,  1088, 17634, 46195,  1990, 18015,\n",
              "            468,   281,   503,  1481,  4420,   880,    12, 18302,  8520,  3288,\n",
              "           2858,   326,  1838,   340,   530,   286,   262,  1266,  4055,   276,\n",
              "           7652,   286,  2031,    13, 50260,  1169, 10747,   286,   509, 30848,\n",
              "             85, 18015,   318,   880, 17232,    11,   290,   340,   318,   257,\n",
              "            922,  1672,   286,   262,  3288,  2858,   286,   262,  4898,  1044,\n",
              "           1989,    13, 50258,  1169,  1989,  1088,   509, 30848,    85, 18015,\n",
              "            318,   257,   922,  1672,   286,   262,  3288,  2858,   287,   262,\n",
              "          16479,    11,   543,   318, 17232,   287,   257,   880,    12, 18302,\n",
              "           8520,  5642,    13, 50258,  1169,  8222,  1088,   509, 30848,    85,\n",
              "          18015,   318,   880, 17232, 16317]]),\n",
              " tensor([[50257,    40,  1975,   340,   318,  2907,   220,  1141,   262,  1285,\n",
              "             11,  1088,  1058,   716, 50260,    72,   892,   340,   318,  3491,\n",
              "            220,   379,   262,  5041,   986,  1088,  1058,    35, 50258,    72,\n",
              "            892,   663,  3491,  1141,   262,  1285,   986,  1088,  1058,    47,\n",
              "          50258,    72,   892,   663,  3491,   986,   379,   262,  5041,   986,\n",
              "           1088,   994,   986, 50258, 50258,   986,  1312,   892,   663,  3491,\n",
              "            986,   379,   262,  5041,   986,  1088,   994,   986, 50258,   986,\n",
              "           1312,   892,   986,   340,   318,   986,  3491,   986, 10194,   986,\n",
              "          50258,   986,  1312,   892,   986,   340,   318,   986,  3491,   986,\n",
              "          10194,   986, 50258,   986, 10194,   986,   340,   318,   986,  3491,\n",
              "            986, 10194,   986, 50258,   986]]),\n",
              " tensor([[50257,  5189,  1781,    11,   339,  7893,   345,   503,   319,   257,\n",
              "           3128, 50260,  1659,  1781,   339,  7893,   334,   503,    13, 50258,\n",
              "           1659,  1781,   339,  7893,   334,   503,   319,   257,  3128,    13,\n",
              "          50258,  1659,  1781,    11,   339,  7893,   334,   503,    13, 50258,\n",
              "           1659,  1781,    11,   339,  7893,   334,   503,    13, 50258,  1659,\n",
              "           1781,   986,   339,  7893,   334,   503,   986, 50258,  1659,  1781,\n",
              "            986,   339,  7893,   334,   503,   986, 50258,   986,   286,  1781,\n",
              "            986,   339,  7893,   334,   503,   986, 50258,   986,   286,  1781,\n",
              "            986,   339,  7893,   334,   986, 50258,   986,   286,  1781,   986,\n",
              "            339,  7893,   334,   986, 50258,   986,   286,  1781,   986,   339,\n",
              "           7893,   334,   986, 50258,   986]]),\n",
              " tensor([[50257, 17353,  1053,   587,  4785,   611,   339,   373, 12238,    13,\n",
              "          50260,   361,   339,   373, 12238,   986,   340,   561,  1053,   587,\n",
              "           4785,    13, 50258,   270,   561,  1053,   587,  4785,   611,   339,\n",
              "            373,   257,  1310,  1790,    13, 50258,   270,   561,  1053,   587,\n",
              "           4785,   611,   339,   373,   257,  1310,  1790,   986, 50258, 50258,\n",
              "            361,   339,   373,   257,  1310,  1790,   986,   340,   561,  1053,\n",
              "            587,  4785,    13, 50258,   270,   561,  1053,   587,  4785,   611,\n",
              "            339,   373,   257,  1310,  1790,   986, 50258, 50258,   270,   561,\n",
              "           1053,   587,  4785,   611,   339,   373,   257,  1310,  1790,   986,\n",
              "          50258, 50258,   270,   561,  1053,   587,  4785,   611,   339,   373,\n",
              "            257,  1310,  1790,   986, 50258]]),\n",
              " tensor([[50257,     7,    64,     8,  1011,   262, 37088,  2223,   284,  1805,\n",
              "            262,  2858,    26, 50260,     7,    64,     8,   262,  3306,  5260,\n",
              "            284,  1805,   262,  2858,    26, 50258,     7,    64,     8,   262,\n",
              "           3306,  5260,   284,  1805,   262,  2858,    26, 50258,     7,    64,\n",
              "              8,   262,  5260,   329,   262,  4800,   286,   262,  2858,    26,\n",
              "          50258,     7,    64,     8,   262,  3306,  5260,    26,  3503,    13,\n",
              "          50258,     7,    64,     8,   262,  3306,  5260,    26,   523, 16317,\n",
              "             13, 50258,     7,    64,     8,   262,  5260,   329,   326,  4007,\n",
              "             26,   986,    13, 50258,     7,    64,     8,   262,  3306,  5260,\n",
              "          16317,    26, 16317,    26,   986,    26, 16317,    26, 16317,   329,\n",
              "            326,  4007, 16317,    13, 50258]]),\n",
              " tensor([[50257,    40,   716,  7926,   475,   314,   423,  1239,  2982,   286,\n",
              "            606, 50260, 41599,    11,  1312,   423,  1239,  2982,   286,   606,\n",
              "             13, 50258,   320,  7926,    11,   475,  1312,  1053,  1239,  2982,\n",
              "            286,   606,    13, 50258,    72,  1101,  7926,    11,   475,  1312,\n",
              "           1053,  1239,  2982,   286,   606,    13, 50258, 41599,   986,    72,\n",
              "           1053,  1239,  2982,   286,   606,    13, 50258,    72,  1101,  7926,\n",
              "            986,    72,  1239,  2982,   286,   606,    13, 50258,    72,  1101,\n",
              "           7926,   986,    72,  1053,  1239,  2982,   286,   606,    13, 50258,\n",
              "            320,  7926,   986,    72,  1239,  2982,   286,   606,    13, 50258,\n",
              "             72,  1101,  7926,   986,    72,  1239,  2982,   286,   606,    13,\n",
              "          50258,    72,  1101,  7926,   986]]),\n",
              " tensor([[50257, 16678,   257,  1080,   857,   407,  7898,  1957,  4896,    26,\n",
              "          50260,  1169,  1080,   318,   407, 11670,   351,  1957,  4896,    26,\n",
              "          50258,  5661,  1080,   318,   407, 13722,   416,  1957,  4896,    26,\n",
              "          50258,  5661,   318,   407,   262,  1339, 16317,   262,  1080,   318,\n",
              "            407,  3562,   284,  7898,   340,    13, 50258,  5661,   318,  1521,\n",
              "          16317,   612,   318,   645, 15660,   329,  4896, 16317,   287,   428,\n",
              "           1339,    11,   340,   318,   407,  9177,    13, 50258, 50258,  5661,\n",
              "            318,  1521, 16317,   340,   318,   407,   257,  9030, 16317,   329,\n",
              "            326,  1738, 16317,   340,   318,   407, 13722,    13, 50258,   732,\n",
              "            460,   470,  7898,  1957,  4896, 16317,   326,   338,  1521,    13,\n",
              "          50258,   732,   836,   470,   986]]),\n",
              " tensor([[50257, 14906,  2681,   318, 13140,    26,   287, 10172,  4974,    11,\n",
              "            262,  1708,  1218,  7322,   318,  2087,    25, 50260,  1169,  1218,\n",
              "          24077,  2236,   307, 11412,   284,  1100,    25, 50258,  1169,  1218,\n",
              "          24077,   318,  6928,   416,   262,  1708,    25, 50258,  1169,  1218,\n",
              "          24077,   318,  6928,   416,   262,  1708,    25, 50258,  1169,  1218,\n",
              "          24077,   318,  6928,   416,   262,  1708,    25, 50258,  1169,  1218,\n",
              "          24077,   318,  6928,   416,   262,  1708,    25, 50258, 50258,  1169,\n",
              "           1218, 24077,   318,  6928,   416,   262,  1708,    25, 50258, 50258,\n",
              "          50258,  1169,  1218, 24077,   318, 11412,    25, 50258,  1169,  1218,\n",
              "          24077,   318,  6928,   416,   262,  1708,    25, 50258,    25, 50258,\n",
              "             25,   986,   290,   986,   262]]),\n",
              " tensor([[50257,    40,   481,   307, 17280,   428,  2406,   614, 50260,    72,\n",
              "            481,   307,  1315,   428,  2406,   614,    13, 50258,    72,  1183,\n",
              "            307,  1315,   428,   614,    13, 50258,    72,  1183,   307,  1315,\n",
              "            428,   614,   986, 50258,     7,    72,  1183,   307,  1315,   428,\n",
              "            614,    11,  1165,   986,     8, 50258,     7,    72,  1183,   307,\n",
              "            986,     8,   986,  1312,  1183,   307,   986,  1315,   986,   329,\n",
              "            428,   986,   614,   986, 50258,     7,   986,  1312,  1183,   986,\n",
              "              8,   986,  1312,  1183,   986,   307,   986,  1315,   986,   329,\n",
              "            986,   428,   986,   614,   986, 50258,     7,   986,  1312,  1183,\n",
              "            986,   307,   986,   329,   986,   428,   986,   614,   986, 50258,\n",
              "              7,   986,  1312,  1183,   986]]),\n",
              " tensor([[50257, 40443,   618,   314,  1138,   683,    11,   314,   373,   407,\n",
              "           5410,   284,  2121,   287,  1842,   379,   477, 50260,    72,  1422,\n",
              "            470,   772,  1410,   284,  2121,   287,  1842,   379,   717,    13,\n",
              "          50258,    72,  1422,   470,   772,  1410,   284,  2121,   287,  1842,\n",
              "            379,   717,    13, 50258,    72,  1422,   470,   772,  1410,   284,\n",
              "           2121,   287,  1842,    13, 50258,  4053,    11,   379,   717,  1312,\n",
              "           1422,   470,   772,   892,  1312,  1549,  1683,  1842,   683,    13,\n",
              "          50258,  4053,   986,   379,   717,  1312,  1422,   470,   772,   892,\n",
              "           1312,  1549,  1842,   683,    13, 50258,    72,  1422,   470,   772,\n",
              "            892,  1312,  1549,  1842,   683,    13, 50258,  4053,   986,   379,\n",
              "            717,  1312,  1422,   470,   772]]),\n",
              " tensor([[50257,     1, 49488,  3329,    11,   314,   481,  6594,   503,   284,\n",
              "            262, 12746,    13, 50260,     1,    40,  1101,  1016,   284,   262,\n",
              "          12746,  9439,  3329,    13, 50258,     1,    40,  1183,   467,   351,\n",
              "            606,  9439,  3329,    13, 50258,     1,    40,  1183,   766,   606,\n",
              "           9439,  3329,    13, 50258,     1,    40,  1183,   467,   284,   262,\n",
              "          12746,  9439,    13, 50258,     1,    40,  1183,   467,   612,  9439,\n",
              "           3329,    13, 50258,     1,    40,  1183,   467,   612,  9439,    13,\n",
              "          50258,     1,    40,  1183,   467,   612,  9439,    13, 50258,     1,\n",
              "             40,  1183,   467,   612,  9439,    13, 50258,     1,    40,  1183,\n",
              "            467,   612,  9439,    13, 50258,     1,    40,  1183,   467,   612,\n",
              "           9439,    13, 50258,     1,    40]]),\n",
              " tensor([[50257,   464,   976, 23206, 17045,    11,   262,   976, 30724,  5006,\n",
              "             11, 11196,   287,  1692, 15568,   290,  5104,    64, 15568,    13,\n",
              "          50260, 10734, 15568,   290,  5104,    64, 15568,   547,   262,   976,\n",
              "            986, 23206,  7408,  8379,   986, 50258,  1169,   976, 23206,  7408,\n",
              "           8379,   373,  1043,   287,  1692, 15568, 16317,   290,   287,   262,\n",
              "           1339,   286,   262,  5104,    64,   986,   262,   976,    13, 50258,\n",
              "           1169,   976, 23206,  7408,  8379,   373,  1043, 16317,   287,  1692,\n",
              "          15568, 16317,   290,   986,   287,   262,  1339, 16317,   286,   262,\n",
              "           5104,    64, 16317,   262,   976,    13, 50258, 50258,  1169,   976,\n",
              "            986, 23206,  7408,   986,   318,   986,   262,   986,   976, 16317,\n",
              "            329,   986,   262, 16317,  1339]]),\n",
              " tensor([[50257,  3237,   777,  1364, 13801,   422,   262, 10614, 14643,   986,\n",
              "            314,   460,   470,  5457,  4483,   428,   416,  3589,    13, 50260,\n",
              "             40,   460,   470,  4483,   477,   883,  1364, 13801,   422,   262,\n",
              "          10614,    13, 50258,    40,  1101,   407,  1654,   314,   460,  4483,\n",
              "            340,  3436, 16317,   422,   262, 10614, 14643,    11,   314,   460,\n",
              "            470,    13, 50258,    40,   460,   470,  4483,  1997,   422,   262,\n",
              "           2085, 16317,   422,   262, 14643, 16317,   314,   460,   470,   772,\n",
              "           4483,    13, 50258,   986,   290,   477,   883,  1364, 13801, 16317,\n",
              "            314,   460,   470,  4483,   340,    13, 50258,   986,   290,   523,\n",
              "          16317,   422,   262, 10614,   986,   314,   460,   470,  4483,   986,\n",
              "            340, 16317,   422,  3589, 16317]]),\n",
              " tensor([[50257,  5195,   815,   339,  2666,   607, 50260, 22850,   815,   339,\n",
              "           2666,   607,    30, 50258, 22850,   815,   339,  2666,   607,    30,\n",
              "          50258, 22850,   815,   339,  2666,   607,    30, 50258, 22850,   815,\n",
              "            339,  2666,   607,    30, 50258, 22850,   815,   339,  2666,   607,\n",
              "             30, 50258, 22850,   815,   339,  2666,   607,    30, 50258, 22850,\n",
              "            815,   339,  2666,   607,    30, 50258, 22850,   815,   339,  2666,\n",
              "            607,    30, 50258, 22850,   815,   339,  2666,   607,    30, 50258,\n",
              "          22850,   815,   339,  2666,   607,    30, 50258, 22850,   815,   339,\n",
              "           2666,   607,    30, 50258, 22850,   815,   339,  2666,   607,    30,\n",
              "          50258, 22850,   815,   339,  2666,   607,    30, 50258, 22850,   815,\n",
              "            339,  2666,   607,    30, 50258]]),\n",
              " tensor([[50257,    40,   655,  4966,   534, 12656,   625,   284, 20842,   706,\n",
              "            314, 35846,   340,   329,  2910,    13, 50260, 12518,   314, 29187,\n",
              "            262,  2910,    11,   314,  2497,   257, 12656,    13, 50258,  1169,\n",
              "           2910,   373,   319,   262, 12656,   706,   314, 11068,   340,    13,\n",
              "          50258,  8499,   314, 29187,   340, 16317,   314,  4966,   262, 12656,\n",
              "             13, 50258,    40,  1101,  4856,   262, 20842, 16317,   706,   314,\n",
              "          29187, 16317,   262,  2910,   373,   612,    13, 50258,    40,  1053,\n",
              "           1057,   262, 12656, 16317,   706,   314, 10667, 16317,   340,   373,\n",
              "            612, 16317,   329,   502,    13, 50258, 50258,    40,  1053,  1775,\n",
              "          16317,   314,  1053, 37609, 16317,   262,  2910, 16317,   706,   314,\n",
              "          29187, 16317,   340, 16317,   340]]),\n",
              " tensor([[50257, 38114,   306,  1576,    11,   262, 22155,   267, 24883,   262,\n",
              "           1573,   366,  2704, 11224,   813,  1600,   543,  2391,  1724,   366,\n",
              "            259,   262,  5642,   286,  1223,   543,   318,  5530, 11081,  1911,\n",
              "          50260,  1169, 22155,   857,   407,  3068,   262,  1573,   781,   404,\n",
              "             11,   543,   318,  2391,   257,  3381,   329,  1223,   326,   318,\n",
              "            781,   404,    88,    13, 50258,  1169, 22155,  1595,   470,   772,\n",
              "           3068,   262,  1573,    11,   543,   318,  2391,   257,  3381,   329,\n",
              "           1223,   781,   404,    88,    13, 50258,  1169,  1573,   318,  4814,\n",
              "          16317,  6283, 16317, 50258,  1169,  1573,   318,   407,   772,  4750,\n",
              "          16317,   287,   262,  5642, 16317,   286,   986,  1223,   986,   781,\n",
              "            404,    88,    13, 50258, 50258]]),\n",
              " tensor([[50257,  3792,   340,   326,   345,   765,   284,   307,   262,  4048,\n",
              "           2196,   286,   383,  1881, 50260,   271,   340,   326,   345,   765,\n",
              "            284,   307,   262,  4048,  2196,   286,   383,  1881,    30, 50258,\n",
              "           3792,   340,   326,   345,   765,   284,   307,   262,  4048,  2196,\n",
              "            286,   383,  1881,    30, 50258,  3792,   340,   326,    30, 50258,\n",
              "            271,   340,   326,   334,   765,   284,   307,   262,  4048,  2196,\n",
              "            286,   262,  1881,    30, 50258, 50258,  3792,   340,   326,    30,\n",
              "          50258,  3792,   340,   326,   334, 18869,   307,   262,   530,    30,\n",
              "          50258,    30,   986, 50258,    30,   986,  1148,   340,   326,   334,\n",
              "          18869,   307,   262,   530,    30,   986, 50258,    30,   986, 50258,\n",
              "             30,   986,  1148,   340,   326]]),\n",
              " tensor([[50257, 10418,   423,   257,  1327,   640,   351,   607,  2659,    64,\n",
              "           1042, 50260,  5162,   893,   423,   257,  1327,   640,   351,   607,\n",
              "           2659,    64,  1042,    13, 50258,  5162,   893,   423,   257,  1327,\n",
              "            640,   351,   607,  2659,    64,  1042,    13, 50258,  5162,   893,\n",
              "            423,   257,  1327,   640,   351,   607,  2659,    64,  1042,    13,\n",
              "          50258,  5162,   893,   423,   257,  1327,   640,   351,   607,    13,\n",
              "          50258,  5162,   893,   423,   257,  1327,   640,   351,   607,    13,\n",
              "          50258, 50258,     7,    16,     8,  3730,   423,   257,  1327,   640,\n",
              "            351,   607,    13, 50258,     7,    16,     8,   220,   220,   220,\n",
              "            357,    17,     8,   220,   357,    18,     8,   220,   357,    19,\n",
              "              8,   220,   357,    20,     8]]),\n",
              " tensor([[50257,  1847,  6369,  8740, 18420,   447,   247,    50,  2910,   373,\n",
              "            599, 10228,  8347,   287,   262,  5228, 14043,    13, 50260,   439,\n",
              "            625,   262, 14043,    11,  4422,  6372,   373,  4328, 10228,    13,\n",
              "          50258, 15309,  6372,   338,  2910,   373,  8347,   986,   287,   262,\n",
              "           5228,    13, 50258, 15309,  6372,   373,  4328,  5263,   986,   287,\n",
              "            262, 14043,   986, 50258,   439,   625,   986,   287,   262,  2119,\n",
              "          16317,  4422,  6372,    13, 50258, 15309,  6372,   986,   373,  4328,\n",
              "           5263,   986,   287,   262,  5228,   986, 50258,   986,   287,   262,\n",
              "           2119, 16317,  4422,  6372,    13, 50258,   986,   287,   262, 14043,\n",
              "          16317,  4422,  6372,   986,   373,  4328,  5263,   986,   287,   262,\n",
              "           5228,   986, 50258,   986,   287]]),\n",
              " tensor([[50257,   818,    71,  1000,    13,   362,    11,   513,    11,   604,\n",
              "             11,   642,    11,  1745,    13,   362,    11,   513,    11,   604,\n",
              "             11,   642,    11, 21847,  1000,    13, 50260,    17,   986,    18,\n",
              "            986,    19,   986,    20,   986,    21,   986,    22,   986,    23,\n",
              "            986,    24,   986,   940,   986,  1367,   986,  1105,   986,  1511,\n",
              "            986,  1478,   986,  1315,   986,  1467,   986,  1596,   986,  1248,\n",
              "            986,   678,   986,  1160,   986,  2310,   986,  2534,   986,  2242,\n",
              "            986,  1987,   986,  1679,   986,  2608,   986,  2681,   986,  2579,\n",
              "            986,  2808,   986,  1542,   986,  3261,   986,  3933,   986,  4747,\n",
              "            986,  4974,   986,  3439,   986,  4570,   986,  5214, 16317,  4353,\n",
              "          16317,  5014, 16317,  2319, 16317]]),\n",
              " tensor([[50257, 43343,    11,   340,   338,   662,  1150, 13939,    13,   632,\n",
              "           1838,   502,   281,  6424,   501,    11,   281, 28207,    11,   281,\n",
              "            450,  3087,   273,    13, 50260,   270,  1838,   502,   257,   763,\n",
              "             12,  5936,  4063,  1352, 16317,   257,   763,    12,  5936,  4063,\n",
              "           1352, 16317,   257,   763,    12,  5936,  4063,  1352, 16317,   257,\n",
              "            763,    12,  5936,  4063,  1352, 16317,   257,   763,    12,  5936,\n",
              "           4063,  1352, 16317,   257,   763,    12,  5936,  4063,  1352, 16317,\n",
              "             13, 50258,  1640,  1793,   338, 11060, 16317,   340,   338,   257,\n",
              "            662,  1150, 13939,  5123, 16317,   257,   662,  1150, 13939,  5123,\n",
              "          16317,   257,   662,  1150, 13939,  5123, 16317,   257,   662,  1150,\n",
              "          13939,  5123, 16317,   257,   662]]),\n",
              " tensor([[50257,  1858,   547,   691,  1936,  3891,  5982,   319,   262,   717,\n",
              "           1418,  9484,  1755,    11,   329,   262,  2180,  1285,    13, 50260,\n",
              "           1169,   717,  1936,  3891,   547,   407,   973,   329,   262,   938,\n",
              "           1285,    13, 50258,   261,   262,   717,  1755,    11,   691,  1936,\n",
              "           3891,   547,  5982,    13, 50258,  1640,   262,  2180,  1285,    11,\n",
              "            691,  1936,  3891,   547,  6163,    13, 50258,  1169,   717,  1936,\n",
              "           3891,   547,  6163,   329,   262,   717,  1755,    13, 50258,  1169,\n",
              "            717,  1936,   547,  6163,   329,   262,   717,  1755,    13, 50258,\n",
              "           1169,  1271,   373,   642,    13, 50258,  1169,   717,  1936,   547,\n",
              "           6163,   329,   262,  2180,  1285,    13, 50258,  1640,   262,  4007,\n",
              "          16317,   691,   642,  3891,   547]]),\n",
              " tensor([[50257,    40,   467, 15043,   656,   262,  4472,  5721,    11, 11254,\n",
              "             30, 50260,    40,  1101,  1016,   284,   262,  4472,   338,  5721,\n",
              "             11,   616,  1995,    30, 50258, 10594,   314,   467,   284,   262,\n",
              "           4472,    11,   616,  2802,    30, 50258, 10594,   314,   467,   284,\n",
              "            262,  4472,    11,   616,  1995,    30, 50258, 10594,   314,   467,\n",
              "            612,    11,   329,  1654,    30, 50258, 10594,   314,   467,   612,\n",
              "          16317,   329,  1654, 16317,   329,  1654, 16317,   329,  1654, 16317,\n",
              "            329,  1654, 16317,   329,  1654, 16317,   329,  1654, 16317,   329,\n",
              "           1654, 16317,   329,  1654, 16317,   329,  1654, 16317,   329,  1654,\n",
              "          16317, 50258, 50258,   986,   329,  1654, 16317,   329,  1654, 16317,\n",
              "          16317, 16317, 16317,   329,  1654]]),\n",
              " tensor([[50257,   464,  1717,  1424,   389, 24317,   803,   257,  7586,  6440,\n",
              "            287, 12232, 20365,   351,   477,   262,  1637,   339,  1838,    13,\n",
              "          50260,  1169,  1717,  1424,   389, 46353, 16317,   351,   477,   262,\n",
              "           1637, 16317,   484,   787, 16317,   287, 12232, 20365,    13, 50258,\n",
              "           1169,  1717,  1424,   389,   986, 44481, 16317,   287,  7586,  6440,\n",
              "          16317,   351,   477,   262,  1637, 16317,   484,   787, 16317,   287,\n",
              "           1379,   482,  6213,    13, 50258, 50258, 50258,  1169,  1717,  1424,\n",
              "          16317,   389, 16317, 46353, 16317,   351, 16317,   477, 16317,   484,\n",
              "            787, 16317,   287, 16317, 12232, 16317,    13, 50258, 50258, 50258,\n",
              "           1169,  1717,  1424, 16317,   389, 16317, 46353, 16317, 16317, 16317,\n",
              "            351, 16317,   477, 16317,   484]]),\n",
              " tensor([[50257,  1212,  2104,  8222,   373,   257, 26837,   416,   262,   640,\n",
              "            356,   547,  1760,    13, 50260,   292,   356,  5201,    11,   356,\n",
              "           1625,  1973,   257, 26837,    88,  8222,    13, 50258,   292,   356,\n",
              "           5201, 16317,   356,  1625,  1973,   262, 26837,    88,  8222, 16317,\n",
              "             13, 50258,   292,   356,  1053,  1760, 16317,   356,  1053,  1775,\n",
              "            428,  2104,  8222, 16317,    13, 50258,   732,  1053,  1775,   340,\n",
              "          16317,   355,   356,  1053,  1760, 16317,   340,   338,   257, 26837,\n",
              "             13, 50258,   732,  1053,  1775,   340, 16317,   355,   356,  1053,\n",
              "           1760, 16317,   340,   338,   257, 26837, 16317,    13, 50258,   732,\n",
              "           1053,  1775, 16317,   326, 16317,   356,  1053,  1775, 16317,   428,\n",
              "          16317,  8222, 16317,    13, 50258]]),\n",
              " tensor([[50257,  1639,  1842,   262,  1048,   329,   508,   339,   318,   290,\n",
              "            407,   508,   345,   765,   683,   284,   307, 50260,  1639,  1842,\n",
              "            262,  1048,   329,   508,   339,   318,    11,   407,   508,   345,\n",
              "            765,   683,   284,   307,    13, 50258,  5832,  1842,   262,  1048,\n",
              "            329,   508,   339,   318,    11,   407,   508,   345,   765,   683,\n",
              "            284,   307,    13, 50258,  5832,  1842,   262,  1048,   329,   508,\n",
              "            339,   318,    11,   407,   508,   345,   765,   683,   284,   307,\n",
              "             13, 50258, 50258,  5832,  1842,   262,  1048,   329,   508,   339,\n",
              "            318,   986,   407,   508,   345,   765,   683,   284,   307,    13,\n",
              "          50258, 50258, 50258,  5832,  1842,   262,  1048,   329,   508,   339,\n",
              "            318,   986,   407,   508,   345]]),\n",
              " tensor([[50257,  1639,  1839,   470,  1394,   428,   510,   477,  6180,    11,\n",
              "            481,   345,    30, 50260,  5832,   821,   407,  1016,   284,  4043,\n",
              "            477,  1755,    11,   389,   345,    30, 50258,  5832,  1839,   470,\n",
              "            307,   612,   477,  1755,    11,   481,   345,    30, 50258,  5832,\n",
              "           1839,   470,   307,   612,   329,   262,  2187,  6180,    11,   481,\n",
              "            345,    30, 50258,  5832,   821,   407,  8066,  4043,   477,  1755,\n",
              "             11,   389,   345,    30, 50258,  5832,   821,   407,  8066,   466,\n",
              "            340,    11,   389,   345,    30, 50258,  5832,   821,   407,  1016,\n",
              "            284,   466,   340,    11,   481,   345,    30, 50258,  5832,   821,\n",
              "            407,  1016,   284,   466,   340,    11,   389,   345,    30, 50258,\n",
              "           5832,   821,   407,  1016,   284]]),\n",
              " tensor([[50257,  1722,   257, 12921,   286,   262, 10393,  7118,   286,   663,\n",
              "          12934,  1201,   663,  6282,    11,   262,  1271,   286,  2663,   878,\n",
              "            262,  3611,  3078,   468,   587, 18434,  3649,    13, 50260,  1169,\n",
              "           1271,   286,  2663,   878,   262,  3611,  3078,   468,  3220,   287,\n",
              "          12921,   286,   262,  7118,   286,   262, 12934,   286,   262,  4479,\n",
              "           1201,   663,  9323,    13, 50258, 50258,  1169,  7118,   286,   262,\n",
              "          12934,   286,   262,  4479,   468,   587,  8793,   416,   262,  1109,\n",
              "            326,   340,   468,   587,   973,   329,   262,  4007,   286,  3649,\n",
              "            262,  1271,   286,  2663,    13, 50258, 50258,  1169,  1271,   286,\n",
              "           2663,   468,   587,  3957,    11,   287,   428,  4732, 16317,    11,\n",
              "            355,   257,  1255, 16317,    11]]),\n",
              " tensor([[50257,  2990,   719,   326,   835,   780,   484,  1064,   345, 10966,\n",
              "            290,   765,   284,   423,   257,  2776,   351,   345, 50260,  9930,\n",
              "            719,   588,   326,   780,   484,   892,   345,   821,  3024,   290,\n",
              "            484,   765,   284,   307,   351,   345,    13, 50258,  9930,   466,\n",
              "            326,   269, 10277,   484,   892,   334,   374,  3024,   290,   484,\n",
              "            765,   284,   307,   351,   334,    13, 50258,  9930,   466,   326,\n",
              "            269, 10277,   484,   892,   334,   374,  3024,   290,   484,   765,\n",
              "            284,   307,   351,   334,    13, 50258,    13,  9930,   466,   326,\n",
              "            269, 10277,   484,   892,   334,   374,  3024,   290,   484,   765,\n",
              "            362,   423,   257,  2776,    13, 50258,    13,  9930,   466,   326,\n",
              "            269, 10277,   484,   892,   334]]),\n",
              " tensor([[50257,  5308,  3613,   262,  5509,    11,   502,  3613,   262,  5509,\n",
              "          50260,    40,  1183,  3613,   262,  5509, 16317,   329,   502,    13,\n",
              "          50258,  1640,   502, 16317,   314,  7448,   262,  5509,    13, 50258,\n",
              "             40,  1183,  3613,   340, 16317,   329,   502, 16317,   340,   338,\n",
              "            257,  5509,    13, 50258,    40,  1183,  3613,   340, 16317,   329,\n",
              "           3589, 16317,   314,  1183,   466,   340, 16317,   329,   783, 16317,\n",
              "          50258,    40,  1183,   466,   340, 16317,   329,   783, 16317,   314,\n",
              "           1183,   466,   340, 16317,   329,   783, 16317, 50258,    40,  1183,\n",
              "            466,   340, 16317,   329,   783, 16317,   314,  1183,   466,   340,\n",
              "          16317,   329,   783, 16317, 50258,    40,  1183,   466,   340, 16317,\n",
              "            329,   783, 16317,   314,  1183]]),\n",
              " tensor([[50257,  2504, 19649,  1039,   502,    11,   475, 47156,    11,   314,\n",
              "            716,  1165,  1468,   329,  9714,  6949, 50260,    40,  1101,   407,\n",
              "           1165,  1468,   329,  9714,    11,   523,   986, 50258,  5562,   338,\n",
              "           1107, 38423,   986,   475,   314,  1101,  1165,  1468,   329,  9714,\n",
              "           6949,   986, 50258,    71, 12236,   986,   326,   338,  1107, 15774,\n",
              "            986,  1165,  1468,   329,  9714,   986, 50258,    71, 12236,   986,\n",
              "            326,   338,  1107, 15774,   986,  1165,  1468,   329,  9714,   986,\n",
              "          50258,    71, 12236,   986,   326,   338,  1107, 15774,   986,  1165,\n",
              "           1468,   329,  9714,   986, 50258,    71, 12236,   986,   326,   338,\n",
              "           1107, 15774,   986,  1165,  1468,   329,  9714,   986, 50258,    71,\n",
              "          12236,   986,   326,   338,  1107]]),\n",
              " tensor([[50257,  6385,   339,  8278,   422,   262, 12296,  2619,  3822,   468,\n",
              "           2923,  1115,  1450,    13, 50260,  9915,  3822,  2923,  1115,  1450,\n",
              "           1201,   339,   373,  3181,   736,   284,  1204,    13, 50258, 20777,\n",
              "            339,  8278,   422,   262, 12296, 16317,  2619,  3822,  2923,  1115,\n",
              "          16317,  1450,    13, 50258, 20777,   339,  8278, 16317, 16317, 16317,\n",
              "            339,  2923, 16317,  1115, 16317,  1450, 16317,   329,   465, 11060,\n",
              "             13, 50258, 20777, 16317, 16317,   339,   373,  4376, 16317, 16317,\n",
              "          16317, 16317,   339,  2923, 16317,   513, 16317,   329, 16317,   326,\n",
              "          16317,    13, 50258, 20777, 16317, 16317, 16317, 16317,   339,   373,\n",
              "          16317,  2923, 16317, 16317, 16317,   329, 16317,   326, 16317,    13,\n",
              "          50258, 20777, 16317, 16317, 16317]]),\n",
              " tensor([[50257,  2949,    11,   780,   644,   611,   616,  5848,  9830,   373,\n",
              "            287,   262,  3504,   286, 44364, 11300,   287,   257,  4097,   286,\n",
              "           4515,  5643, 50260,  3919,   986,   780,   644,   611,   616,  5848,\n",
              "           9830,   373,   287,   262,  3504,   286,   285,   506, 22703, 11300,\n",
              "            287,   257,  4097,   286,  4515,  5643,    30, 50258,  3919,   986,\n",
              "            780,   644,   611,   616,  5848,  9830,   373,   287,   262,  3504,\n",
              "            286,   326,   986,   287,   257,  4097,   286,  4515,  5643,    30,\n",
              "          50258, 50258,  3919,   986,   780,   986,   644,   611,   616,  5848,\n",
              "           9830,   373,   287,   262,  3504,   986,   287,   257,  4097,   286,\n",
              "           4515,  5643,    30, 50258, 50258, 50258,  3919,   986,   780,   986,\n",
              "            644,   611,   616,  5848,  9830]]),\n",
              " tensor([[50257,  8128,   484,  2107,   287,   257,  4258,   810,   340,   318,\n",
              "           8027,    11,  1466,   508,  8659,  3685,   743,  3360,   635,   307,\n",
              "           6590,   287,  1210,  3371,   511,  1751,    13, 50260, 20777,   484,\n",
              "           2107,   287,   257,  4258,   810,   340,   318,  8027, 16317,  1466,\n",
              "            508,  8659,  3685,   743,  3360,   635,   307,  6590,   287,  1210,\n",
              "          16317,  3371,   511,  1751,    13, 50258, 20777,   484,  2107,   287,\n",
              "            257,  4258, 16317,   810,   340,   318,  8027, 16317,  1466,   508,\n",
              "           8659,  3685,   743,  3360,   635,   307,  6590, 16317,  3371,   511,\n",
              "           1751,    13, 50258, 50258, 20777,   484,  2107, 16317,   287,   257,\n",
              "           4258, 16317,   810,   340,   318,  8027, 16317,  1466, 16317,   508,\n",
              "           8659,  3685, 16317,   743,  3360]]),\n",
              " tensor([[50257, 15854,   952,   373,  5906,   284,  3613,   534,  6339, 13819,\n",
              "             13, 50260,  1169,  6339, 13819,   373,   407,  7448,   416,  6911,\n",
              "            952,    13, 50258, 15854,   952,   714,   407,  3613,   262,  6339,\n",
              "             13, 50258,  1169,  6339, 13819,   373,   407,  7448,    13, 50258,\n",
              "           6911,   952,   714,   407,   466,   523,    13, 50258,  1169,  6339,\n",
              "          13819,   373,   407,  7448,    13, 50258, 50258,  1169,  6339,   373,\n",
              "            407,  7448,    13, 50258,   732,   714,   407,   466,   340,    13,\n",
              "          50258,   732,   714,   407,   466,   340,    13, 50258,  1169,  6339,\n",
              "            373,   407,  7448,    13, 50258,   732,   714,   407,   466,   340,\n",
              "             13, 50258,   732,  3521,   470,   466,   340,    13, 50258,   732,\n",
              "           3521,   470,    13, 50258,   732]]),\n",
              " tensor([[50257, 16676,    11,   287,   262,   886,   340,   318,   691,   345,\n",
              "          50260, 16676, 16317,   340,   338,   477,   510,   284,   345,   287,\n",
              "            262,   886,    13, 50258, 16676, 16317,   340,   338,   477,   546,\n",
              "           7013,   287,   262,   886,    13, 50258,   986,   392,  3505, 16317,\n",
              "            340,   338,   477,   546,  7013, 16317,   287,   262,   886,    13,\n",
              "          50258,   986,   392,  3505, 16317,   340,   338,   477,   546,  7013,\n",
              "          16317,   287,   262,   886,    13, 50258,   986,   392,   986,  3505,\n",
              "          16317,   340,   338,   477,   546,  7013, 16317,   287,   262,   886,\n",
              "             13, 50258,   986,   290,   986,   287,   262,   886, 16317,   340,\n",
              "            338,   477,   546,  7013, 16317,    13, 50258,   986,   290, 16317,\n",
              "            326,   338,  1521,    13, 50258]]),\n",
              " tensor([[50257, 23433,   284,  4866,   290, 17008,   290,  9293,  2792,   780,\n",
              "            326,   318,   644,   314,   466, 50260, 28311,   284,  4866,   290,\n",
              "          17008,  9293, 16317,   326,   338,   644,  1312,   466,    13, 50258,\n",
              "          28311,   284,  4866,   290, 17008, 16317,  9293, 16317,   326,   338,\n",
              "            644,  1312,   466,    13, 50258, 28311,   284,  4866, 16317,   326,\n",
              "            338,   644,  1312,   466,    13, 50258, 28311,   284,  4866, 16317,\n",
              "            326,   338,   644,  1312,   466,   986,   796,     8, 50258, 28311,\n",
              "            986,   284,  4866, 16317,   326,   338,   644,  1312,   466,   986,\n",
              "            796,     8, 50258, 28311,   986,   284,  4866, 16317,   326,   338,\n",
              "            644,  1312,   466,   986,   796,     8, 50258, 28311,   986,   284,\n",
              "           4866, 16317,   326,   338,   644]]),\n",
              " tensor([[50257,  1026,  1244,   772,  7766,   262,  3200,   284,  1204,    13,\n",
              "          50260, 25991,   339,  1183,  7766,   262,  3200,   284,  1204,    13,\n",
              "          50258,   258,   743,   772,  7766,   262,  3616,   286,  1204,    13,\n",
              "          50258,   258,   743,   772,  7766,   262,  3616,   286,  1204,    13,\n",
              "          50258,   258,   743,   772,  7766,   262,  3616,   286,  1204,    13,\n",
              "          50258, 50258,   258,   743,   772,  7766,   262,  3616,   286,  1204,\n",
              "             13, 50258,   258,   743,   772,  7766,   262,  3616,   286,  1204,\n",
              "             13, 50258,   258,   743,   772,  7766,   262,  3616,   286,  1204,\n",
              "             13, 50258, 50258,   258,   743,   772,  7766,   262,  3616,   286,\n",
              "           1204,    13, 50258,   258,   743,   772,  7766,   262,  3616,   286,\n",
              "           1204,    13, 50258,   258,   743]]),\n",
              " tensor([[50257, 14108,  2802,   318,   523,  4334,    11,   673,   714,   787,\n",
              "           3899,  6612,   804,   523,  3892,   290,  7135, 50260, 38101,   285,\n",
              "           1689,   338,   523,  3735,    11,   673,   714,  1053,  4197, 27407,\n",
              "            282,  6612,   319,   607,  1182,    13, 50258, 38101,   285,  1689,\n",
              "            338,   523,  3735,    11,   673,   714,  4197, 27407,   282,  6612,\n",
              "            319,   607,  1182,    13, 50258, 38101,   285,  1689,   338,   523,\n",
              "           3735,    11,   673,   714,  4197, 27407,   282,  6612,   319,   607,\n",
              "           1182,    13, 50258, 38101,   285,  1689,   338,   523,  3735,    11,\n",
              "            673,   714,  4197, 27407,   282,  6612,   319,   607,  1182,    13,\n",
              "          50258, 38101,   285,  1689,   338,   523,  3735,   986,   673,   714,\n",
              "           4197, 27407,   282,  6612,   319]]),\n",
              " tensor([[50257,  1906,   784,   784,  3819,   784,   784,   412,  1424,   357,\n",
              "           2895,    84,  5049,   264,   381,  2014, 50260,    12,   784,   784,\n",
              "            784,  3819,   784,   784,   412,  1424,   357, 13450,    84,  5049,\n",
              "            264,   381,  2014, 50258,    12,   784,   784,   784,   584,   784,\n",
              "            784,  2895,    84,  5049,   357,    82,   381,  2014, 50258,    12,\n",
              "            784,   784,   784,   584,   784,   784,  2895,    84,  5049,   357,\n",
              "             82,   381,  2014, 50258,    12,   784,   784,   784,   584,   784,\n",
              "            784,  2895,    84,  5049,   357,    82,   381,  2014, 50258,    12,\n",
              "            784,   784,   784,   584,   784,   784,  2895,    84,  5049,   357,\n",
              "             82,   381,  2014, 50258,    12,   784,   784,   784,   584,   784,\n",
              "            784,  2895,    84,  5049,   357]]),\n",
              " tensor([[50257,  1135,   821,   407,  4305,   994,  1231,   262, 11865,    13,\n",
              "          50260,   732,   836,   470,  2666,   994,  1231,   257, 11865,    13,\n",
              "          50258,   732,   836,   470,  2666,  1231,   262, 11865,    13, 50258,\n",
              "            732,   836,   470,  2666,  1231,   340,    13, 50258,   732,   821,\n",
              "            407,  4305,   994,  1231,   340,    13, 50258,   732,   836,   470,\n",
              "           2666,  1231,   340, 16317, 50258,   732,   836,   470,  2666,  1231,\n",
              "            340, 16317, 50258,   732,   821,   407,  4305,   994, 16317,  1231,\n",
              "            340, 16317,   356,   821,   407,  4305, 16317,   340, 16317,    13,\n",
              "          50258,   732,   821,   407,  4305, 16317,  1231,   340, 16317,   356,\n",
              "            821,   407,  4305, 16317,    13, 50258,   732,   821,   407, 16317,\n",
              "           4305, 16317,  1231,   340, 16317]]),\n",
              " tensor([[50257,   464,  6932,   324,   286, 25157, 34241,    11,   508,  2499,\n",
              "            329,   337,  8141, 50260,   464,  6932,   324, 16317, 25157, 34241,\n",
              "            986,   337,  8141,    13, 50258,  1169,  6932,   324, 16317, 25157,\n",
              "          34241,   986,   337,  8141,    13, 50258,  1169,  6932,   324, 16317,\n",
              "          25157, 34241, 16317,   337,  8141,    13, 50258,   986,   329,   337,\n",
              "           8141,   986, 50258,   986,   329,   337,  8141, 16317,   220,   986,\n",
              "            329,   326,   986, 25157, 34241,   986,   220, 16317,   329,   337,\n",
              "           8141,   986, 50258,   986,   329,   326, 16317,   986,   220, 16317,\n",
              "            329,   326, 16317, 25157, 34241,   986,   220, 16317,   329,   337,\n",
              "           8141,   986, 50258,   986,   329,   326, 16317,   220, 16317,   329,\n",
              "            326, 16317,   220, 16317,   329]]),\n",
              " tensor([[50257,  7583,    11,   314,   561,   845,   881,   407,  2883,  7558,\n",
              "            852,   319,  4205, 50260,   392,  1312,   561,   407,   588,   284,\n",
              "            307,   319,  4205,   477,   262,   640,    13, 50258,   392,  1312,\n",
              "            561,   407,   588,   284,   307,   319,  4205,   477,   262,   640,\n",
              "             13, 50258,     7,  1312,   561,   407,   588,   284,   307,   319,\n",
              "           4205,   477,   262,   640,  1267, 50258,     7,  1312,   561,   407,\n",
              "            588,   284,   307,   319,  4205,   477,   262,   640,    13, 50258,\n",
              "              7,  1312,   561,   407,   588,   284,   307,   319,  4205,   477,\n",
              "            262,   640,    13, 50258,     7,  1312,   561,   407,   588,   284,\n",
              "            307,   319,  4205,   477,   262,   640,    13, 50258,     7,  1312,\n",
              "            561,   407,   588,   284,   307]]),\n",
              " tensor([[50257, 17353,   345,   588,   284,   423,   257,  4144,   706,   670,\n",
              "          17291, 50260,  8499,   670,   986, 19188,   345,   588,   284,   423,\n",
              "            257,  4144,    30, 50258,  8499,   670,   986, 22850,   836,   470,\n",
              "            356,   467,   329,   257,  4144,    30, 50258,    30,   986, 10919,\n",
              "            611,   356,   986,  4598,   345,   765,   284,   423,   257,  4144,\n",
              "             30,   986, 50258,    30,   986,   392,   986, 10919,   611,   356,\n",
              "            986,  4598,   345,   765,   284,    30,   986,  8499,   670,    30,\n",
              "            986, 50258,    30,   986,   392,   986,   644,   611,   356,   986,\n",
              "           4598,   356,   986, 14150,   257,  4144,    30,   986,  8499,   670,\n",
              "             30,   986,    30, 50258,    30,   986,   392,   986,    30,   986,\n",
              "            392,   986,    30,   986,   392]]),\n",
              " tensor([[50257, 19242,   284,  1254,   329,   607,  5422,   351,   607,  1021,\n",
              "             13, 50260,  4480,   607,  1021,    11,   314,  1101,  1654,   339,\n",
              "           1276,  1254,   607,  5422,    13, 50258,   270,  1276,   307,   329,\n",
              "            607,  5422,   326,   314,  1254,    13, 50258,    40,  1101,  1654,\n",
              "            340,   338,   329,   607,   326,   314,  1254,    13, 50258,    40,\n",
              "           1101,  1654,   314,  1254,   329,   607,    13, 50258,   258,  1276,\n",
              "           1254,   340, 16317,   351,   465,  1021, 16317,   340,   338,  3306,\n",
              "          16317,   284,   307,   612, 16317,   329,   607,    13, 50258,   258,\n",
              "           1276,  1254,   340, 16317,   351,   465,  1021, 16317,   340,   338,\n",
              "           3306, 16317,   329,   607, 16317,   326,   338,   329,  1654,    13,\n",
              "          50258,    40,  1101,  1654, 16317]]),\n",
              " tensor([[50257, 13300,   262,   734,   286,   345,   761,   517,   640,   284,\n",
              "            651, 36620, 50260, 25991,   345,   734,   761,   517,   640,   284,\n",
              "            651,   284,   760,  1123,   584,    13, 50258, 13300,   345,   734,\n",
              "            761,   517,   640,   284,   651,   284,   760,  1123,   584,    13,\n",
              "          50258, 25991,   345,  3730,   761,   257,  1310,   640,   284,   651,\n",
              "            284,   760,  1123,   584,    13, 50258, 25991,   334,  3730,   761,\n",
              "            257,  1310,   640,   284,   651,   284,   760,  1123,   584,    13,\n",
              "          50258, 25991,   334,  3730,   761,   257,  1310,   640,    13, 50258,\n",
              "          25991,   334,  3730,   761,   257,  1310,   640,    13, 50258, 25991,\n",
              "            334,  3730,   761,   257,  1310,   640,    13, 50258, 25991,   334,\n",
              "           3730,   761,   257,  1310,   640]]),\n",
              " tensor([[50257,  6104,   262,  2576,   815,   429,  2000,   611,   673,  1107,\n",
              "           7832,   345, 50260,  6104,   262,  2576,   815,   429,  2000,   611,\n",
              "            673,  1107,  7832,   345,    13, 50258,  6104,   262,  2576,   815,\n",
              "            429,  2000,   611,   673,  1107,  7832,   345,    13, 50258, 10197,\n",
              "            262,  2576,   815,   429,  2000,   611,   673,  1107,  7832,   345,\n",
              "             13, 50258, 10197,   262,  2576,   815,   429,  2000,   611,   673,\n",
              "           1107,  7832,   345,    13, 50258, 10197,   262,  2576,   815,   429,\n",
              "           2000,   611,   673,  1107,  7832,   345,    13, 50258, 10197,   262,\n",
              "           2576,   815,   429,  2000,   611,   673,  1107,  7832,   345,    13,\n",
              "          50258, 10197,   262,  2576,   815,   429,  2000,   611,   673,  1107,\n",
              "           7832,   345,    13, 50258, 10197]]),\n",
              " tensor([[50257,  1544,  1139,   345,   815,   466,   477,   883,   845,  1243,\n",
              "            290,   345,  6004, 50260,   258,  1139,   466,   477,   883,  1243,\n",
              "          16317,   290,   345,  6004,    13, 50258,   986,   392,   339,  1139,\n",
              "          16317,   466,   477,   883,  1243, 16317,   290,   345,  6004,    13,\n",
              "          50258,   986,   392,   339,  1139, 16317,   466,   477,   883,  1243,\n",
              "          16317,   290,   345,  6004,    13, 50258,   986,   392,   986,  6004,\n",
              "          16317,   284,   326,    13, 50258,   986,   290,   986,   326, 16317,\n",
              "            318,   644,   339,  1139, 16317,   466, 16317,   326, 16317,    13,\n",
              "          50258,   986,   290, 16317,   326, 16317,   318,   644,   339,  1139,\n",
              "          16317,   466, 16317,   326, 16317,    13, 50258,   986,   326, 16317,\n",
              "            318, 16317,   644,   339,  1139]]),\n",
              " tensor([[50257, 16742,   262,  5696,   345,   779,   284,  2728,   262, 18922,\n",
              "            284,  1487,  7577, 50260, 19796,   262,  5696,   334,   779,   284,\n",
              "           1487,   262,  3124,   286,  2956, 32638,    13, 50258, 19796,   262,\n",
              "           5696,   334,   779,   284,  1487,   262,  3124,   286,  2956, 32638,\n",
              "             13, 50258, 50258, 19796,   262,  5696,   334,   779,   284,  1487,\n",
              "            262,  3124,   286,  2956, 32638,    13, 50258, 50258, 19796,   262,\n",
              "           5696,   334,   779,   284,  1487,   262,  3124,   286,  2956, 32638,\n",
              "             13, 50258, 19796,   262,  5696,   334,   779,   284,   466,   340,\n",
              "             13, 50258, 50258, 19796,   262,  5696,   334,   779,   284,   466,\n",
              "            340,    13, 50258, 19796,   262,  5696,   334,   779,    13, 50258,\n",
              "          19796,   262,  3392,   334,   779]]),\n",
              " tensor([[50257, 18565,   262,  2576,   326,   534,  3397, 12546,   351, 50260,\n",
              "          23205,   262,  2576,   534,  3397, 17666,   588,    13, 50258, 23205,\n",
              "            262,  2576,  2956,  3397, 17666,   588,    13, 50258, 23205,   262,\n",
              "           2576,  2956,  3397, 17666,   588,    13, 50258, 23205,   262,  2576,\n",
              "           2956,  3397, 17666,   588,    13, 50258, 23205,   262,  2576,  2956,\n",
              "           3397, 17666,   588,    13, 50258, 23205,   262,  2576,  2956,  3397,\n",
              "          17666,   588,    13, 50258, 23205,   262,  2576,  2956,  3397, 17666,\n",
              "            588,    13, 50258, 23205,   262,  2576,  2956,  3397, 17666,   588,\n",
              "             13, 50258, 23205,   262,  2576,  2956,  3397, 17666,   588,    13,\n",
              "          50258, 23205,   262,  2576,  2956,  3397, 17666,   588,    13, 50258,\n",
              "          23205,   262,  2576,  2956,  3397]]),\n",
              " tensor([[50257, 10915,   314,  6004,   284,   257,  4996,   286,  2647,    11,\n",
              "          16537,   314,   423,   587,  8680,   284,  4632,  1499, 50260,    40,\n",
              "           6004,   284,   257,  1256,   286,  2647,    11,   475, 16537,   314,\n",
              "           1053,   587,  8680,   284,  1499,    13, 50258,    72,  6004,   284,\n",
              "            257,  1256,   286,  2647,    11,   475, 16537,  1312,  1053,   587,\n",
              "           8680,   284,  1499,    13, 50258,    72,  6004,   284,   257,  1256,\n",
              "            286,  2647,    11,   475,  1312,  4632,  6004,   284,  1499,    13,\n",
              "          50258,    72,  4724,  1312,  6004,   284,   257,  1256,   286,  3404,\n",
              "            986,   783,    13, 50258,    72,  6004,   284,   257,  1256,   286,\n",
              "           2647,    11,   475,  1312,  6004,   284,   340,    13, 50258,    72,\n",
              "           4724,  1312,  6004,   284,   340]]),\n",
              " tensor([[50257,  4342,    11,  3197,   326, 21494, 26876,  6194,   351,   534,\n",
              "           1021,    13, 50260,  1456,    11,   351,   534,  2832,    11,  3197,\n",
              "            262, 26876,  6194,    13, 50258,  4480,   534,  2832, 16317,  3197,\n",
              "            262, 26876,    13, 50258, 50258,  1456, 16317,  3197,   262, 26876,\n",
              "          16317,   351,   262,  1037, 16317,   286,  1781, 16317,   329, 26876,\n",
              "             13, 50258,  4480,   534,  2832, 16317,  3197, 16317,   262, 26876,\n",
              "          16317,   286,  1781, 16317,   329, 26876,    13, 50258, 12359,   351,\n",
              "          16317,   326, 16317,  6194, 16317, 16317,   329, 26876,    13, 50258,\n",
              "          16317,   329, 16317,   326, 16317, 16317, 16317, 16317, 16317, 16317,\n",
              "            351, 16317,   326, 16317, 16317, 16317, 16317,   329, 26876,    13,\n",
              "          50258, 16317,   329, 16317,   326]]),\n",
              " tensor([[50257, 35320,   874,   326,   389,   845, 39145,   290, 40857,   389,\n",
              "            616, 18852, 50260,  1169,  3392,   326,   389, 39145,   290, 40857,\n",
              "            389,   616, 18852,    13, 50258,    72,   588,   262,  3392,   326,\n",
              "            389, 39145,   290, 40857,    13, 50258,  1169,  3392,   326,   389,\n",
              "          39145,   290, 40857,   389,   616,  2090,   274,    13, 50258,  1169,\n",
              "           3392,   326,   389,   389, 39145,   290, 40857,   389,   616,  2090,\n",
              "            274,    13, 50258,    72,   588,   606,    13, 50258,     7, 25591,\n",
              "            389,   616,  2090,    82,   492,     8, 50258,     7, 25591,   389,\n",
              "            262,  3392,   326,  1312,   588,   262,   749,    13, 50258,     7,\n",
              "          25591,   389,   262,  3392,  1312,   588,   262,   749,   492,     8,\n",
              "          50258,     7, 25591,   389,   262]]),\n",
              " tensor([[50257,    40,  1053,  5543,   645,  4088,   286,   262,  1613,  1285,\n",
              "             13, 50260,    40,   836,   470,  3505,   262,   938,  1285,    13,\n",
              "          50258,    72,   423,  5543,   645,  4088,   286,   938,  1285,    13,\n",
              "          50258,    72,   836,   470,  3505,   938,  1285,    13, 50258,    72,\n",
              "            423,  4112,   645,  4088,   286,   938,  1285,    13, 50258,    72,\n",
              "            423,  4112,   645,  4088,   286,   340,    13, 50258,    72,   836,\n",
              "            470,  3505,   938,  1285,    13, 50258,    72,   836,   470,  3505,\n",
              "             13, 50258,    72,   423,  4112,   645,  4088,   286,   340,    13,\n",
              "          50258,    72,   836,   470,  3505,    13, 50258,    72,   423,  4112,\n",
              "            645,  4088,   286,   340,    13, 50258,    72,   423,  4112,   645,\n",
              "           4088,   286,   340,    13, 50258]]),\n",
              " tensor([[50257,   464,  3176,  3173,  9723,   284,   262,  7732,  2236,   307,\n",
              "           8197,   416,   262,  8549,  5926,   706,   262,  4513,   468,   587,\n",
              "          26889,    13, 50260,  1169,  8549,  5926,  2236, 11206,   262,  3176,\n",
              "           3173,  9723,   284,   262,  7732,   706,   262, 18103,   286,   262,\n",
              "           4513,    13, 50258,  1169,  7732,  2236, 11206,   262,  3176,  3173,\n",
              "           8197,   416,   262,  8549,  5926,   706,   262,  4513,   468,   587,\n",
              "          26889,    13, 50258, 50258,  1169,  7732,  2236, 11206,   262,  3176,\n",
              "           3173,   287, 10213,   351,   883,  3173,   706, 18158,   262,  4513,\n",
              "             13, 50258, 50258,  1169,  4513,  2236,  2148,   329,   428,   287,\n",
              "            262,  1339,   286,   262, 18103,    13, 50258,  1169,  4513,  2236,\n",
              "           4175,   262,  8549,  5926,   546]]),\n",
              " tensor([[50257,    50, 48796,    73,   461,  1511,    11,  3261,   830,  8834,\n",
              "           2926,   988,    11, 15172,  9261, 32490,    77, 32790,   988, 15300,\n",
              "             73,   461, 18768, 25221,   417, 18015,  5214,    11, 25861,    12,\n",
              "          27559,   509,  2596,    73,  5838,   350, 34892,  1619,  3175, 48711,\n",
              "            513,    11,   657,  7410,    18, 15142,    11, 13380, 48009, 46097,\n",
              "            350,  2704,   272,  4801,    89,   794,    83,  3212,   695,  1477,\n",
              "          14940,   304,    13, 50260,  7089,  1228,   461,    11, 15300,    73,\n",
              "            461,    11,  5433,    11,   830,  8834,  2926,   988,    11,  5014,\n",
              "             11,   830,   509,  2596,    73,    11,  5838,    11,   350, 34892,\n",
              "           1619,  3175, 48711,    11,   513,    11,  3571,  7410,    18,    11,\n",
              "          15142,    11, 13380, 48009, 46097]]),\n",
              " tensor([[50257,     1,   464,   717,  2230,   379, 10685, 15611,   373, 21846,\n",
              "            416, 10009,   262,  3878,    13, 50260, 38708,   262,  3878,  3088,\n",
              "            284,   779, 10685,  3777,    13, 50258, 38708,   262,  3878,  3088,\n",
              "            428,   287,   262,   717,  4554,   986, 50258,     1, 38708,   262,\n",
              "           3878,   986,   339,   373,   262,   717,   284,  3283,   503,   257,\n",
              "          10685,  1368,   986, 50258,     1, 38708,   262,  3878,   986,   339,\n",
              "           3088,   284,   779,   262,  3777,   986,   287,   262,   717,  4554,\n",
              "            986, 50258,     1, 38708,   262,  3878,   986,   339,   373,   262,\n",
              "            717,   986,   284,   466,   523,   986, 50258,     1, 38708,   262,\n",
              "           3878,   986,   339,  3088,   986,   284,   779,   986,   262,  3777,\n",
              "            986,   287,   428,  1339,   986]]),\n",
              " tensor([[50257, 28254,   645,    11,   326,   561,  2192, 16866,   262,  2776,\n",
              "           1406,    11, 17666,   466,   340,   611,   345,  1107,   588,   683,\n",
              "          50260, 12758,   645,    11,   326,   561,  2192, 16866,   262,  2776,\n",
              "             11,   523, 17666,   466,   340,   611,   345,  1107,   588,   683,\n",
              "             13, 50258,   361,   345,  1107,   588,   683,    11, 17666,   466,\n",
              "            340,    13, 50258,   361,   345,  1107,   588,   683,    11, 17666,\n",
              "            466,   340,    13, 50258, 50258,   361,   345,  1107,   588,   683,\n",
              "             11,   788, 17666,   466,   340,    13, 50258,   361,   334,  1107,\n",
              "            588,   683,    11,   788, 17666,   466,   340,    13, 50258, 50258,\n",
              "            361,   334,  1107,   588,   683,    11,   788, 17666,   466,   340,\n",
              "             13, 50258, 50258,   361,   334]]),\n",
              " tensor([[50257,  1135,   389,  1464,  4609,   287,  1321,   319,   262, 44641,\n",
              "          41817,    13, 50260,   732,   821,  1464,  4609,   287,  1321,   546,\n",
              "            262, 44641, 41817,    13, 50258,   732,   821,  1464,  4609,   287,\n",
              "           1321,   319,   262, 44641, 41817,    13, 50258,   732,   821,  1464,\n",
              "           4609,   287,   428,   986, 50258,   732,   821,  1464,  4609,   986,\n",
              "            287,  1321,   986,   546,   986,   262,   986, 44641, 41817,    13,\n",
              "          50258,   732,   821,  1464,  4609,   986,   287,   986,   340,   986,\n",
              "            220, 16317,    13, 50258,   732,   821,   986,  1464,   986,  4609,\n",
              "            986,   287,   986,   326,   986,   340,   986,   986,   318,   986,\n",
              "           1593,   986,   329,   986,   514,   986,   994,   986,   287,   986,\n",
              "            428,   986,  1339,   986,   356]]),\n",
              " tensor([[50257,  1026,   561,   307,   257, 12922,  9707,   611,   520,    84,\n",
              "            338,   717,  1693,   355, 22397,   282,  2900,   503,   284,   307,\n",
              "          33936,   465,   898,  2415,   329,  7163,   290,  8218,    13, 50260,\n",
              "             64, 12922,  9707, 16317,   611,   520,    84,   338,   717,  1693,\n",
              "            355,   257, 22397,   282,  2900,   503,   284,   307, 33936,   465,\n",
              "            898,  2415, 16317,   329,  7163,   290,  8218, 16317, 50258, 50258,\n",
              "             64, 12922,  9707, 16317,   611, 16317,   329,   262, 11060, 16317,\n",
              "            286, 16317,   262, 16317,  1109, 16317,   326, 16317,   520,    84,\n",
              "          16317,   373, 16317,  5169, 16317,   329, 16317,   262, 16317, 14148,\n",
              "          16317,   286, 16317,   262, 16317, 14148, 16317,   286, 16317,   262,\n",
              "          16317, 14148, 16317,   286, 16317]]),\n",
              " tensor([[50257,  3237,   826,    11,   523,  3863,   300, 25291,   257,  1310,\n",
              "             13, 50260,   439,   826, 16317,   523, 16317,  3863, 16317,   257,\n",
              "           1310, 16317, 25291,    30, 50258,   568, 16317,  3863, 16317,   314,\n",
              "           1101,   257,  1310, 15912,   803, 16317,   257,  1310,    30, 50258,\n",
              "            568, 16317,  3863, 16317,   314,  1101,   257,  1310, 25291, 16317,\n",
              "            257,  1310,    30, 50258,   568, 16317,  3863, 16317,   314,  1101,\n",
              "            257,  1310, 16317, 15912,   803, 16317,   257,  1310,    30, 50258,\n",
              "            568, 16317,  3863, 16317,   314,  1101,   257,  1310, 16317,    30,\n",
              "            986,    30,   986,    30, 16317,    30, 16317,    30, 16317,    30,\n",
              "          16317,    30, 16317,    30, 16317,    30, 16317,    30, 16317,    30,\n",
              "          16317,    30, 16317,    30, 16317]]),\n",
              " tensor([[50257,  1544,   338,  6301,  5207,   286,   262,  8824,  2691,    11,\n",
              "          14600,  1363,  5043,    13, 50260,   258, 16015,  8824,  5207,   319,\n",
              "            262,  5230,    11, 14600,  5682,    13, 50258,   258, 16015,  8824,\n",
              "           5207,   319,   262,  5230,   986, 14600,  5682,   986, 50258, 50258,\n",
              "            258, 16015,   606,   986,  8824,  5207,   986,   319,   262,  5230,\n",
              "            986, 14600,  5682,   986, 50258, 50258, 50258,   258, 16015,   606,\n",
              "            986,  8824,   986,   319,   262,  5230,   986, 14600,  5682,   986,\n",
              "          50258, 50258,   986,   339, 16015,   986,   606,   986,   606,   986,\n",
              "            319,   262,  5230,   986,  1106,   986,   329,   986,   326,   986,\n",
              "          50258,   986,   329,   986,   326,   986,  1312,   986,  1312,   986,\n",
              "           1312,   986,  1312,   986,  1312]]),\n",
              " tensor([[50257,   464,   869,   284,  2669,   550,   587, 14851,  1576,   287,\n",
              "           2346,    13, 50260, 17402,   338,   869,   373, 14851,  1576,  3436,\n",
              "             13, 50258, 17402,   338,   869,   373,  1576,   986,   329,   783,\n",
              "            986,   340,   373,  1576,   986,   329,   783,   986, 50258, 17402,\n",
              "            338,   869,   373,  1576,   986,   329,   783,   986,   340,   373,\n",
              "           1576,   986,   329,   783,   986, 50258, 17402,   338,   869,   373,\n",
              "           1576,   986,   329,   783,   986,   340,   373,   986,   329,   783,\n",
              "            986, 50258, 17402,   338,   986,   329,   783,   986,   340,   373,\n",
              "            986,   329,   783,   986, 50258, 17402,   338,   986,   329,   783,\n",
              "            986,   340,   373,   986,   329,   783,   986, 50258, 17402,   338,\n",
              "            986,   329,   783,   986,   340]]),\n",
              " tensor([[50257,    40,   716, 22147,   286,   644,   284,   466,   290,   561,\n",
              "            588,   534,  5128, 50260,    72,   836,   470,   760,   644,   284,\n",
              "            466,   986,   392,  1312,  1107,   765,   534,  5128,   986, 50258,\n",
              "             72, 17666,   760,   644,   284,   466,   986,   392,  1312,  1107,\n",
              "            765,   534,  5128,   986, 50258,    72, 17666,   760,   644,   284,\n",
              "            466,   986,   392,  1312,  1107,   765,   534,  5128,   986, 50258,\n",
              "          50258,    72, 17666,   760,   644,   284,   466,   986,   392,  1312,\n",
              "           1107,   765,   534,  5128,   986, 50258,    72, 17666,   760,   644,\n",
              "            284,   466,   986,   392,  1312,  1107,   765,   534,  5128,   986,\n",
              "          50258, 50258, 50258,   986,    72, 17666,   760,   644,   284,   466,\n",
              "            986,   392,  1312,  1107,   765]]),\n",
              " tensor([[50257,   464, 21541,  1048,  1139,    25,   314,   760,    11,   314,\n",
              "           3088,   326,    11,   475,   314,   714,   429, 18044, 50260,  1169,\n",
              "          21541,  1139,  1312,   760,   986,  1312,  3088,   326,   986,   475,\n",
              "           1312,  3521,   470, 18044,    13, 50258,  1169, 21541,  1139,   986,\n",
              "           1312,   760,   986,  1312,  3088,   326,   986,   475,  1312,  3521,\n",
              "            470, 18044,    13, 50258, 50258, 50258,  1169, 21541,  1139,   986,\n",
              "           1312,   760,   986,  1312,  3088,   326,   986,   475,  1312,  3521,\n",
              "            470, 18044,   986, 50258, 50258, 50258, 50258,  1169, 21541,  1139,\n",
              "            986,  1312,   760,   986,  1312,  3088,   326,   986,   475,  1312,\n",
              "           3521,   470, 18044,   986, 50258, 50258, 50258, 50258, 50258,  1169,\n",
              "          21541,  1139,   986,  1312,   760]]),\n",
              " tensor([[50257, 43783,    11,   356,   481,  7101,   345,   286,   262, 30938,\n",
              "            444, 24626, 35979,    13, 50260,   732,   821,  8066,  7101,   345,\n",
              "            286,   262, 30938,   444, 24626, 35979,  9975,    13, 50258,   732,\n",
              "           1183,   905,   345,   262, 30938,   444, 24626, 35979,  9975,    13,\n",
              "          50258,   732,  1183,  1560,   345,   546,   340,  9975,    13, 50258,\n",
              "            732,  1183,  1560,   345,   546,   340,  9975, 16317, 50258,   732,\n",
              "           1183,   905,   345,   262, 30938,   444, 24626, 35979, 16317, 50258,\n",
              "            732,  1183,  7101,   345, 16317,   286,   340, 16317,   329,   262,\n",
              "          11060, 16317,   286,   262,  3595,    13, 50258,   732,  1183,   466,\n",
              "            340, 16317,   329,   262,  3595, 16317,  9439, 16317,   356,  1183,\n",
              "            466,   340, 16317,   329,   262]]),\n",
              " tensor([[50257,  1639,   481,  4753,  7073,   340,  2866,   813,   379,  1944,\n",
              "          50260,  5832,  1183,  1064,   340,   845,  2952,   783,    13, 50258,\n",
              "           5832,  1183,  1064,   340,   845,  2952, 16317,   379,  1944,    13,\n",
              "          50258,  5832,  1183,  1064,   340,   986,   379,   262,  2589, 16317,\n",
              "            345,  1183,  4753,  1064,   340,    13, 50258,  5832,  1183,  4753,\n",
              "            986,  1064,   986,   340, 16317,   845, 16317,  2952, 16317,   783,\n",
              "          16317,    13, 50258,  5832,  1183,   986,  1064, 16317,   340, 16317,\n",
              "            845, 16317,  2952, 16317,   783, 16317,    13, 50258,  5832,  1183,\n",
              "          16317,  1064, 16317,   340, 16317,   845, 16317, 16317, 16317, 16317,\n",
              "            379,   262,  2589, 16317,    13, 50258,  5832,  1183, 16317,  1064,\n",
              "          16317,   340, 16317,   845, 16317]]),\n",
              " tensor([[50257,  5297,    11,   584,  1450,   423,  2801,  8458,    11,  1165,\n",
              "             13, 50260,  5297,   986,   584,  3730,   423,   635,   550,  2089,\n",
              "           8458,   986, 50258,  8505,   986,   584,  3730,   423,  1165,   986,\n",
              "          50258,  8505,   986,   584,  3730,   423,  1165,   986, 50258, 43669,\n",
              "            986,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,   464, 11760,   389,  7218,  3806,  6387,    11, 18435, 10248,\n",
              "          16390,    11,   220, 34478, 50260, 24750,  3806,  6387,    11, 18435,\n",
              "          10248, 16390,    11, 34478,    13, 50258, 24750,  3806,  6387,    11,\n",
              "          18435, 10248, 16390,    11, 34478,   986, 50258, 24750,  3806,  6387,\n",
              "             11, 44442,   986,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
              "            220,   220,   220,   220,   220]]),\n",
              " tensor([[50257,    32,   582,   338,   587, 12864,   290,  1194,   582,  7363,\n",
              "           2636,   416,   465,   898,  1021,   986,  1865,   428,  2933,  3793,\n",
              "          10574,    13, 50260,  1169,  5123,   286,   257,   582,   290,   262,\n",
              "           1918,   286,  1194,   986,   389,  1111,   262,  1255, 16317,   286,\n",
              "            257, 26769,   338,  1918,    13, 50258,  1169,  5123, 16317,   286,\n",
              "            257,   582, 16317,   290,   262,  1918, 16317,   286,   257,   582,\n",
              "          16317,   389,   262,  1255, 16317,   286,   257, 26769,   338,  1918,\n",
              "             13, 50258,  1169,  5123, 16317, 16317,   286,   257,   582, 16317,\n",
              "          16317, 16317,   290, 16317,   262,  1918, 16317, 16317,   286,   257,\n",
              "            582, 16317,   389, 16317,   262,  1255, 16317, 16317, 16317,   286,\n",
              "            257, 26769,   338,  1918,    13]]),\n",
              " tensor([[50257, 23433,   262,  3072,  2141,   407,   869,   422,  1363,   393,\n",
              "            670,  1514,  7382,   339,   481,   407,  1064,   345, 50260,  2188,\n",
              "            284,   262,  3072,   986, 17666,   869,   422,  1363,   393,   670,\n",
              "            986,   467,  7382,   339, 28329,  1064,   345,   986, 50258,  4862,\n",
              "            986,   836,   470,   869,   986,   467,  7382,   339, 28329,  1064,\n",
              "            345,   986, 50258,  2188,   284,   262,  3072,   986,   836,   470,\n",
              "            869,   986,   467,  7382,   986, 50258,  4862,   986,   836,   470,\n",
              "            869,   986,   467,  7382,   986, 50258, 50258, 50258,  4862,   986,\n",
              "          17666,   869,   986,   467,   284,   262,  3072,   986,   467,   284,\n",
              "            262,  3072,   986,   986,   467,   284,   262,  3072,   986, 50258,\n",
              "          50258, 50258,  4862,   986, 17666]]),\n",
              " tensor([[50257,  1639,   743,  3128,   584,  1466,    26,  2158,    11,   345,\n",
              "            743,   407,   423,  3206, 22409,   351,   606, 50260,  5832,   743,\n",
              "           3128,   584,  1466,   986,  4360,   345,   743,   407,   423,  3206,\n",
              "          22409,   351,   606,    13, 50258,  5832,   743,  3128,   584,  1466,\n",
              "            986,  4360,   345,   743,   407,   423,  3206, 22409,   351,   606,\n",
              "             13, 50258,  5832,   743,  3128,   584,  1466,   986,  4360,   345,\n",
              "            743,   407,   423,  3206, 22409,   351,   606,    13, 50258,  5832,\n",
              "            743,  3128,   584,  1466,   986,  4360,   345,   743,   407,   423,\n",
              "           3206, 22409,   351,   606,    13, 50258,  5832,   743,  3128,   584,\n",
              "           1466,   986,  4360,   345,   743,   407,   423,  3206, 22409,   351,\n",
              "            606,    13, 50258,  5832,   743]]),\n",
              " tensor([[50257,  2061,   481,   484,   892,   286,  1306, 50260,  2061,   481,\n",
              "            484,   892,   286,  1306,    30, 50258,   986,   392,   644,   481,\n",
              "            484,   892,   286,  1306,    30, 50258,   986,   392,   644,   481,\n",
              "            484,   892,   286,  1306,    30, 50258,   986,   392,   644,   481,\n",
              "            484,   892,   286,  1306,    30, 50258,   986,   392,   644,   481,\n",
              "            484,   892,   286,  1306,    30, 50258,   986,   392,   644,  2236,\n",
              "            356,   892,   286,    30, 50258,   986,   392,   644,  2236,   356,\n",
              "            892,   286,    30, 50258,   986,   290,   644,  2236,   356,   892,\n",
              "            286,    30, 50258,   986,   290,   644,  2236,   356,   892,   286,\n",
              "             30, 50258,   986,   290,   523,   986,    30, 50258,   986,   290,\n",
              "            644,  2236,   356,   892,   286]]),\n",
              " tensor([[50257,  3260,   477,    11,   345,   389,   262,   530,   508,   561,\n",
              "            588,   284,  8537, 50260,  3260,   477, 16317,  5832,   821,   262,\n",
              "            530,   508,  3382,   284,  8537,    13, 50258,  8499,   477, 16317,\n",
              "           5832,   821,   262,   530,   508,  3382,   284,  8537,    13, 50258,\n",
              "           8499,   477, 16317,  5832,   821,   262,   530,   508,  3382,   284,\n",
              "           8537,    13, 50258, 50258,  8499,   477, 16317,  5832,   821,   262,\n",
              "            530,   508,  3382,   284,  8537,    13, 50258, 50258,  8499,   477,\n",
              "          16317,  5832,   821,   262,   530,   508,  3382,   284,  8537,    13,\n",
              "          50258,   986,   392, 16317,  5832,   821,   262,   530,   508,  3382,\n",
              "            284,  8537,    13, 50258,   986,   392, 16317,  5832,   821,   262,\n",
              "            530,   508,  3382,   284,  8537]]),\n",
              " tensor([[50257,    40,  1101,   407,  1016,   284,  4043,   329, 48986, 30567,\n",
              "            284, 21303,  2093,   502,    13, 50260,    40,  1101,   407,  8066,\n",
              "           4043,   329, 48986, 30567,   284,  7766,   502,    13, 50258,    40,\n",
              "           1101,   407,  8066,  4043,   329, 48986, 30567,   284,  7766,   502,\n",
              "             13, 50258,    72,  1101,   407,  1016,   284,  4043,   329, 48986,\n",
              "          30567,   284, 21303,  2093,   502,    13, 50258,    72,  1101,   407,\n",
              "           8066,  4043,   329, 48986, 30567,   284,  7766,   502,    13, 50258,\n",
              "             72,  1101,   407,  8066,  4043,   329, 48986, 30567,   284,  7766,\n",
              "            502,    13, 50258,    72,  1101,   407,  8066,  4043,   329, 48986,\n",
              "          30567,   284,  7766,   502,    13, 50258,    72,  1101,   407,  8066,\n",
              "           4043,   329, 48986, 30567,   284]]),\n",
              " tensor([[50257,  1026,   318,   407,   534,  8046,   326, 15345,  1450,   389,\n",
              "           4609,   287,   345, 50260,  1639,   836,   470,   423,   284,   307,\n",
              "            257,  5156,   284,   588,  3730,    13, 50258,   270,   338,   407,\n",
              "            534,  8046,   326, 15345,  1450,   588,   345,    13, 50258,  5832,\n",
              "            836,   470,   423,   284,   307,   257,  5156,   284,   588,  3730,\n",
              "             13, 50258,   270,   338,   407,   534,  8046,   326, 15345,  1450,\n",
              "            588,   345,    13, 50258,  5832,   836,   470,   423,   284,   307,\n",
              "            257,  5156,   284,   588,  3730,    13, 50258,  5832,   836,   470,\n",
              "            423,   284,   307,   257,  5156,    13, 50258,  5832,   836,   470,\n",
              "            423,   284,   307,   257,  5156,    13, 50258,   270,   338,   407,\n",
              "            534,  8046,    13, 50258,     7]]),\n",
              " tensor([[50257,  2504,   338,   257,  3967,  1517,   329,   257,  1256,   286,\n",
              "            661,    13, 50260,  1640,   257,  1256,   286,   661,    11,   428,\n",
              "            318,   257,  3967,    13, 50258,   270,   318,   257,   922,  1517,\n",
              "            329,   257,  1256,   286,   661,    13, 50258,  1640,   257,  1256,\n",
              "            286,   661,    11,   340,   318,   257,   922,  1517,    13, 50258,\n",
              "            270,   318,   257,   922,  1517,    13, 50258,  1640,   257,  1256,\n",
              "            286,   661, 16317,   428,   318,   257,   922,  1517,    13, 50258,\n",
              "           1640,   257,  1256,   286,   661, 16317,   340,   318,   257,   922,\n",
              "           1517,    13, 50258,  5661,   318,   257,   922,  1517,    13, 50258,\n",
              "           5661,   318,   257,   922,  1517,    13, 50258,  1640,   257,  1256,\n",
              "            286,   661, 16317,   340,   318]]),\n",
              " tensor([[50257,  1544,   531,    11,   921,   423,   284, 12012,   502,   878,\n",
              "            345,  2666, 50260,     6, 16317,   878,   345,  2666, 16317, 12012,\n",
              "            502, 16317,     6, 50258,     6, 16317,   878,   345,  2666, 16317,\n",
              "          12012,   502, 16317,     6, 50258,     6, 16317,   878,   345,  2666,\n",
              "          16317, 12012,   502, 16317,     6, 50258,     6, 16317,   878,   345,\n",
              "           2666, 16317, 12012,   502, 16317,     6, 50258,     6, 16317,   878,\n",
              "            345,  2666, 16317, 12012,   502, 16317,     6, 50258,     6, 16317,\n",
              "            878,   345,  2666, 16317, 12012,   502, 16317,     6, 50258,     6,\n",
              "          16317,   878,   345,  2666, 16317, 12012,   502, 16317,     6, 50258,\n",
              "              6, 16317,   878, 16317, 12012,   502, 16317,     6, 50258,     6,\n",
              "          16317,   878, 16317, 12012,   502]]),\n",
              " tensor([[50257,  1026,  1838,   502,  3252,   326,   314,  2236,  1239, 12479,\n",
              "             13, 50260,    72,  1101,  7787,  1312,  1183,  1239, 12479,    13,\n",
              "          50258,    40,  1101,  7787,   314,  1183,  1239, 12479,    13, 50258,\n",
              "             72,  1101,  7787,  1312,  1183,  1239, 12479,    13, 50258,    72,\n",
              "           1101,  7787,  1312,  1183,  1239, 12479,    13, 50258,    72,  1101,\n",
              "           7787,  1312,  1183,  1239, 12479,    13, 50258,    72,  1101,  7787,\n",
              "           1312,  1183,  1239, 12479,    13, 50258,    72,  1101,  7787,  1312,\n",
              "           1183,  1239, 12479,    13, 50258,    72,  1101,  7787,  1312,  1183,\n",
              "           1239, 12479,    13, 50258,    72,  1101,  7787,  1312,  1183,  1239,\n",
              "          12479,    13, 50258,    72,  1101,  7787,  1312,  1183,  1239, 12479,\n",
              "             13, 50258,    72,  1101,  7787]]),\n",
              " tensor([[50257,  1532,   345, 17666,  1254,   326,   835,    11,   788,  3863,\n",
              "            345,   815,   407,   307,  1972,  6405, 50260,  1532,   334, 17666,\n",
              "           1254,   326,   835,    11,   788,  3863,   334,   815,   429,   307,\n",
              "           1972,  6405,    13, 50258,  1532,   334, 17666,  1254,   326,   835,\n",
              "            788,  3863,   334,   815,   429,   307,  1972,  6405,    13, 50258,\n",
              "            361,   334, 17666,  1254,   326,   835,   788,  3863,   334,   815,\n",
              "            429,   307,  1972,  6405,    13, 50258,   361,   334, 17666,  1254,\n",
              "            326,   835,   788,  3863,   334,   815,   429,   307,  1972,  6405,\n",
              "             13, 50258,   361,   334, 17666,  1254,   326,   835,   788,  3863,\n",
              "            334,   815,   429,   307,  1972,  6405,    13, 50258,   361,   334,\n",
              "          17666,  1254,   326,   835,   788]]),\n",
              " tensor([[50257, 37887,  1141,   262,   717,  3128,    11,   262,  3516,  8404,\n",
              "            284, 14947,   345,   290,  1054,    71,   570,  2925, 22121,  2642,\n",
              "          50260, 23073,  1141,   262,   717,  3128,   986,   262,  3516,  8404,\n",
              "            284, 14947,   345,   986,   290,  1054,    71,   570,  2925, 22121,\n",
              "           2642,    13, 50258, 23073,   986,   262,  3516,  8404,   284, 14947,\n",
              "            986,   290,   986,  1223,  2925,  2642,   986, 50258,  5162,   893,\n",
              "            986,  1312,  4724,   986,   484,  1949,   986,   284, 14947,   986,\n",
              "            290,   986,   290,   986,  1223,  2925,  2642,   986, 50258,  5162,\n",
              "            893,   986,  1312,  4724,   986,   484,  1949,   986,   284, 14947,\n",
              "            986,   290,   986,   290,   986,  1223,  2925,  2642,   986, 50258,\n",
              "           5162,   893,   986,  1312,  4724]]),\n",
              " tensor([[50257, 12322,   262,   640,   284,   651,   284,   760,   262,  2576,\n",
              "            878,   345,  5409,   284, 16470, 50260,  5703,  1011,   262,   640,\n",
              "            284,   651,   284,   760,   262,  2576,   878,   345,  4391,    13,\n",
              "          50258, 12322,   262,   640,   284,   651,   284,   760,   262,  2576,\n",
              "            878,   345,  4391,    13, 50258,  3137,  1011,   262,   640,   284,\n",
              "            651,   284,   760,   262,  2576,   878,   345,  4391,    13, 50258,\n",
              "          50258,  3137,  1011,   262,   640,   284,   651,   284,   760,   262,\n",
              "           2576,   878,   345,  4391,    13, 50258,  3137,  1011,   262,   640,\n",
              "            284,   651,   284,   760,   262,  2576,    13, 50258,  3137,  1011,\n",
              "            262,   640,   284,   651,   284,   760,   262,  2576,    13, 50258,\n",
              "           3137,  1011,   262,   640,   284]]),\n",
              " tensor([[50257, 19693,   481,   670,  2346,   503, 50260,  3237,   481,   307,\n",
              "            477,   826,   986, 27078,   290,   329,   477,    13, 50258, 37814,\n",
              "            481,   307,  3734,   986, 27078,   290,   329,   477,   986, 50258,\n",
              "          37814,   481,   670,  2346,   503,   986, 50258,   270,   338,  8066,\n",
              "            307,   477,   826,   986, 27078,   290,   329,   477,   986, 50258,\n",
              "            270,   338,  8066,   307,   477,   826,   986, 50258,   270,   338,\n",
              "           8066,   307,   477,   826,   986, 27078,   290,   329,   477,   986,\n",
              "          50258, 50258,   270,   338,  8066,   307,   477,   826,   986, 27078,\n",
              "            290,   329,   477,   986, 50258, 37814,   338,  8066,   307,   477,\n",
              "            826,   986, 50258, 50258, 37814,   481,   307,  3734,   986,   329,\n",
              "            477,   986, 50258, 37814,   481]]),\n",
              " tensor([[50257,    51,   961,  4053,   750,   326,   351,   262, 46307, 13508,\n",
              "          50260,   392,   351,   262, 46307, 13508, 16317, 23153,  4053,   750,\n",
              "            326,    13, 50258,    83,   961,  4053, 16317,   351,   262, 46307,\n",
              "          13508, 16317,   339,   750,   326,   351,   606,    13, 50258,   986,\n",
              "            351,   262, 46307, 13508, 16317,   339,   750,   326, 16317,   351,\n",
              "            606, 16317,   339,   750,   326, 16317,    13, 50258,   986,   351,\n",
              "            262, 46307, 13508, 16317,   339,   750, 16317,   326, 16317,   986,\n",
              "            351,   606, 16317,   339,   750, 16317,   326, 16317,    13, 50258,\n",
              "            986,   351,   326, 16317, 16317, 16317, 16317,   339,   750, 16317,\n",
              "          16317,   326, 16317,    13, 50258,   986,   351,   326, 16317, 16317,\n",
              "          16317, 16317,   339,   750, 16317]]),\n",
              " tensor([[50257,  1544,  1549, 48255,   262, 26698, 11170,   262,  6339,   284,\n",
              "           9074,    13, 50260,   258,  2982,   262, 26698,  4727,   262,   835,\n",
              "            284,  9074,    13, 50258,   258,  2982,   262, 26698,  1560,   607,\n",
              "            546,   262,  6339,    13, 50258,   258,  2497,   262, 26698,  4727,\n",
              "            262,  6339,    13, 50258,   258,  2982,   546,   340,   422,   607,\n",
              "             13, 50258,   258, 16399,   284,   607,    13, 50258,   258, 16399,\n",
              "            284,   607,    11,   339,  2982,   607,  7468,    13, 50258,   258,\n",
              "           2497,   340,   986,   290,   986,   339,  2497,   986,   340,   986,\n",
              "            340,   986,   339,  2993,   986, 50258,   258,  2993,   986,   339,\n",
              "           2993,   986,   340,   986,   340,   986,   673,  1297,   683,   986,\n",
              "          50258,   258, 16399,   986,   284]]),\n",
              " tensor([[50257,   464, 15222,  1803,  1183,   307,   477,   625,   514,    13,\n",
              "          50260,  1169,  2187,  1803,   318,  1016,   284,   760,   514,    13,\n",
              "          50258,  1169,  2187,  1517,   318,  1016,   284,   307,   625,   514,\n",
              "          16317,   262, 12270,  1803,    13, 50258,  1169,  2187,  1517,   318,\n",
              "           1016,   284,   307,   986,   262, 12270,  1803, 16317,   290,   262,\n",
              "          15222,  1803,    13, 50258, 50258,  1169,  2187,  1517, 16317,   318,\n",
              "          16317,   262, 12270,  1803, 16317,   290, 16317,   262, 12270,  1803,\n",
              "          16317,     0, 50258,  1169,  2187,  1517, 16317,   318, 16317,   262,\n",
              "          12270,  1803, 16317,   290, 16317,   262, 12270,  1803, 16317,     0,\n",
              "          50258,  1169,  2187, 16317,  1517, 16317,   318, 16317,   262, 12270,\n",
              "           1803, 16317,   290, 16317,   262]]),\n",
              " tensor([[50257,  3886,   262,   835,    11,   262,  1111,   286,   514,   389,\n",
              "          24026,  1466, 50260,  1525,   262,   835, 16317,   262,   734,   286,\n",
              "            514,   389, 34210,   986, 50258,  1525,   262,   835, 16317,   356,\n",
              "            821, 34210,    11,  1165,   986, 14373, 50258,     7, 19313,    54,\n",
              "          16317,   262,   734,   286,   514,   389, 34210, 16317,  1058,  4008,\n",
              "          50258,     7, 19313,    54, 16317,   262,   734,   286,   514,   389,\n",
              "          34210, 16317,  1058,  4008, 50258,     7, 19313,    54, 16317,   326,\n",
              "            338,  1521,   356,   821, 34210,   986, 14373, 50258,     7, 19313,\n",
              "             54, 16317,   326,   338,  1521, 16317,   356,   821, 34210, 16317,\n",
              "           1058,  4008, 50258,     7, 19313,    54, 16317,   326,   338,  1521,\n",
              "          16317,   356,   821, 34210,   986]]),\n",
              " tensor([[50257,  1858,   318,   645,   835,   286,  6970,   287,   262,  1903,\n",
              "           3800,  1771,   262,  1720,   481,  1826,   262, 20640,    13, 50260,\n",
              "           3919,   530,  4206,   287,   262,  3726,  1771,   262,  1720,   481,\n",
              "            307,  4635,    13, 50258,  3919,   530,  4206,   644,   262,  1720,\n",
              "            318,   379,   262,   923,    13, 50258,  3919,   530,   460,   910,\n",
              "            329,  1654,   611,   262,  1720,   318,   925,    13, 50258,  3919,\n",
              "            530,   460,  1560,   703,   340,   481,   307,    13, 50258,  3919,\n",
              "            530,   460,   910,   326,   287,   262,  3726,    13, 50258,  3919,\n",
              "            530,   460,   910,   644,   340,   481,   307,    13, 50258,  3919,\n",
              "            530,   460,   910,   329,  1654,    13, 50258,  3919,   986,   340,\n",
              "            338,   407,  1744,   986,   329]]),\n",
              " tensor([[50257,    40,   588, 26785,  5330,   517,   621,   314,   588, 33668,\n",
              "             46,   329,   867,  3840, 50260,    72,   588,   479,   363,  5330,\n",
              "            517,   621,   479,  8226,   329,   257,  1256,   286,  3840,    13,\n",
              "          50258,    72,   588,   479,   363,  5330,   517,   621,   479,  8226,\n",
              "            329,   257,  1256,   286,  3840,    13, 50258,    72,   588,   479,\n",
              "            363,  5330,   517,   621,   479,  8226,   329,   257,  1256,   286,\n",
              "           3840,    13, 50258,  1640,  1672,   986,  1312,   588,   479,   363,\n",
              "           5330,   517,   986,   780,   986,  1312,   588,   479,   363,  5330,\n",
              "            517,   986, 50258,  1640,  1672,   986,  1312,   588,   479,   363,\n",
              "           5330,   517,   986,   780,   986,  1312,   588,   479,   363,  5330,\n",
              "            517,   986, 50258,  1640,  1672]]),\n",
              " tensor([[50257,    44,  3020,    13,   532,   366,   392,  1234,  9168,   287,\n",
              "            340,   526,   532,  3763,    13,   366,  8727, 32281,   262,  7714,\n",
              "           1701, 50260,     1,  8727,   338, 12036,   262,  4324,  1701,   532,\n",
              "           3363,    13,   366, 10919,   546,   262,  3355,  1701, 50258,     1,\n",
              "          10919,   546,   262,  4324,  1701,   532,  3363,    13,   366, 10919,\n",
              "            546,   262,  3355,  1701, 50258,    30, 16317,   220,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220, 16317,   220, 16317,   220, 16317,\n",
              "            220, 16317,   220, 16317,   220]]),\n",
              " tensor([[50257,    40,  2883,  3453,   278,   625,   262,  3072,   290, 13777,\n",
              "          50260,    72,  1842,   284,  1561,   319,   262,  3072,   290,  1702,\n",
              "             13, 50258,    72,  1842,   284,  1561,   290,  1702,    13, 50258,\n",
              "             72,  1842,   284,  1561,   290,  1702,    13, 50258,    72,   588,\n",
              "            284,  1561,   290,  1702,    13, 50258,    72,   588,   284,  1561,\n",
              "            290,  1702,    13, 50258,    72,   588,   284,  1561,   290,  1702,\n",
              "             13, 50258,    72,   588,   284,  1561,   290,  1702,    13, 50258,\n",
              "             72,   588,   284,  1561,   290,  1702,    13, 50258,    72,   588,\n",
              "            284,  1561,   290,  1702,    13, 50258,    72,   588,   284,  1561,\n",
              "            290,  1702,    13, 50258,    72,   588,   284,  1561,   290,  1702,\n",
              "             13, 50258,    72,   588,   284]]),\n",
              " tensor([[50257,  3198,   640,   618,   314,   373,  1719,  1714,   351,  5593,\n",
              "             11,   314,  1444,   607,  5278, 50260,    40,   373,  1719,  1714,\n",
              "            351,  5593,  1752,   986,    40,  1444,   607,  5278,    13, 50258,\n",
              "           3198,   640,   618,   314,   373,  9580,   278,   607,   986,    40,\n",
              "           1444,   607,  5278,    13, 50258, 50258, 50258,  3198,   640,   618,\n",
              "            314,   373,  9580,   278,   607,   986,    40,  1444,   607,  5278,\n",
              "            986, 50258, 50258,  3198,   640,   986,    40,   373,  9580,   278,\n",
              "            607,   986,   392,   314,   373,   588,    11,   360,   756, 11693,\n",
              "            588,   986, 50258, 50258,     7,    40,   373,  9580,   278,   607,\n",
              "            986,   392,   314,   373,   588, 42303,   360,   756, 11693,   588,\n",
              "            986, 50258,     7,    40,   373]]),\n",
              " tensor([[50257,  2061,   611,   345,   466,  2344,   510,  6078,   683, 50260,\n",
              "          10919,   611,   345,   466,  2344,   510,  6078,   683,    30, 50258,\n",
              "          50258,  2061,   611,   345,   466,  2344,   510,  6078,   683,    30,\n",
              "          50258, 10919,   611,   345,   466,    30, 50258,  2061,   611,   345,\n",
              "            466,    30, 50258,  2061,   611,   345,   466,    30, 50258, 10919,\n",
              "            611,   345,   466,    30, 50258, 10919,   611,   345,   466,    30,\n",
              "          50258, 10919,   611,   345,   466,    30, 50258, 10919,   611,   345,\n",
              "            466,    30, 50258, 10919,   611,   345,   466,    30, 50258,    30,\n",
              "            986, 10919,   611,   345,   466,    30,   986, 50258,    30,   986,\n",
              "          10919,   611,   345,   466,    30,   986,    30,   986,    30,   986,\n",
              "             30,   986,    30,   986,    30]])]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_paranmt[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poc5fyjlkaB-",
        "outputId": "491ae2b2-cc3f-4c44-f9a1-66ebbcac4fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[   27,    33,  2640,    29,    40,   466,    26,  1450,  2270,   534,\n",
              "           2612,    11,   981,  2460,  2652,  8097,    27,  6173,    40,    62,\n",
              "          35353,    29,    40,  1101,  7926,    11,   475,   314,  1101,  7926,\n",
              "             13,   314,  1101,  7926,    13,   314,  1101,  7926,    13,   314,\n",
              "           1101,  7926,    13,   314,  1101,  7926,    13,   314,  1101,  7926,\n",
              "             13,   314,  1101,  7926,    13,   314,  1101,  7926,    13,   314,\n",
              "           1101,  7926,    13,   314,  1101,  7926,    13,   314,  1101,  7926,\n",
              "             13,   314,  1101,  7926,    13,   314,  1101,  7926,    13,   314,\n",
              "           1101,  7926,    13,   314,  1101,  7926,    13,   314,  1101,  7926,\n",
              "             13,   314,  1101,  7926,    13,   314,  1101,  7926,    13,   314,\n",
              "           1101,  7926,    13,   314,  1101]]),\n",
              " tensor([[   27,    33,  2640,    29,  1639,   460, 12831,   340,   422,  1761,\n",
              "            413,   557,    11,  2158,   345,  1276,  4321,   340,    27,  6173,\n",
              "             40,    62, 35353,    29,   921,   460,   691, 12831,   340,   422,\n",
              "           7576,   413,   557,    11,   475,   345,   423,   284,  4321,   340,\n",
              "             13,  1279,  6173,    40,  4808, 24700,    29,   921,   460,   691,\n",
              "          12831,   606,   416, 22023,   606,    13,  1279,  6173,    40,  4808,\n",
              "          24700,    29,  7576,   413,   557,    11,  2158,    11,   460,   691,\n",
              "            307,  6492,   422,  7576,   413,   557,    13,  1279,  6173,    40,\n",
              "           4808, 24700,    29,  7576,   413,   557,   460,   691,   307,  6492,\n",
              "            422,  7576,   413,   557,    13,  1279,  6173,    40,  4808, 24700,\n",
              "             29,  7576,   413,   557,   460]]),\n",
              " tensor([[   27,    33,  2640,    29,    40,   466,   407,  1975,   345,   460,\n",
              "           8996,  1180,  2663,   286,  1842,    27,  6173,    40,    62, 35353,\n",
              "             29,    40,  1101,   407,  1654,   345,   460,  8996,   257,  1180,\n",
              "           1842,  1339,    13, 50265,    40,   836,   470,   892,   345,   460,\n",
              "           8996,   257,  1180,  1842,  1339,    13, 50265,    40,   836,   470,\n",
              "            760,   611,   345,   460,  8996,  1180,  2663,   286,  1842,    13,\n",
              "          50265,    40,   836,   470,   760,   611,   345,   821,  8066,  8996,\n",
              "            262,   976,  1842,  1339,    13, 50265,    40,   836,   470,   760,\n",
              "            611,   345,   821,  8066,  8996,  1842,  2663,    13, 50265,    40,\n",
              "            836,   470,   760,   611,   345,   821,  8066,  8996,   606,    13,\n",
              "          50265,    40,   836,   470,   760]]),\n",
              " tensor([[   27,    33,  2640,    29,  3347,  1276,   423,  1760,   281,  4370,\n",
              "           2092,   284,   262,   530,   314,   655,   750,   329,   340,    27,\n",
              "           6173,    40,    62, 35353,    29,  1375,   750,  1223,  2092,   284,\n",
              "            644,   314,  1053,  1760,   284,   607,  1279,  6173,    40,  4808,\n",
              "          24700,    29,  1375,   338,  1760,   340,   284,   607,   287,   262,\n",
              "            976,   835,   314,   750,   284,   607,    13,  1279,  6173,    40,\n",
              "           4808, 24700,    29,  1375,   750,   262,   976,  1517,   284,   502,\n",
              "            355,   314,   750,   284,   607,    13, 50265,  7091,   750,   262,\n",
              "            976,  1517,   284,   502,   355,   314,   750,   284,   607,    13,\n",
              "          50265,  7091,   750,   262,   976,  1517,   284,   502,   355,   314,\n",
              "            750,   284,   607,    13, 50265]]),\n",
              " tensor([[   27,    33,  2640,    29,  2504,   318,   703,   340,  1392,   810,\n",
              "            339,   318,  1909,    27,  6173,    40,    62, 35353,    29,  1320,\n",
              "            338,   703,   339,   338,  1016,   284,   307,  1909,    27,  6173,\n",
              "             40,    62, 35353,    29,  1320,   338,   703,   339,   338,  1016,\n",
              "            284,   307,  1909,    13, 50265,  5562,   338,   644,   339,   338,\n",
              "           1016,   284,   307,  1909,    13, 50265,  5562,   338,   703,   340,\n",
              "            338,  1016,   284,   307,    13, 50265,  5562,   338,   703,   340,\n",
              "            481,   307,  1909,    13, 50265,  5562,   338,   703,   340,   338,\n",
              "           1016,   284,   307,    13, 50265,  5562,   338,   703,   340,   481,\n",
              "            307,    13, 50265,  5562,   338,   644,   340,   481,   307,    13,\n",
              "          50265,  5562,   338,   644,   340]]),\n",
              " tensor([[   27,    33,  2640,    29,    45,   408,   385,   531,    11,   366,\n",
              "           3237,   262, 21547,  1283,   284,   307,   286,   262,   976,  1502,\n",
              "            286, 14735,   526,    27,  6173,    40,    62, 35353,    29,   366,\n",
              "            439,   262, 21547,  1283,   284,   307,   262,   976,  2546,   526,\n",
              "          50265,     1,   439,   262, 21547,  1283,   284,   307,   262,   976,\n",
              "           2546,   526,  1279,  6173,    40,  4808, 24700,    29,   366,   439,\n",
              "            262, 21547,  1283,   284,   307,   262,   976,  2546,   526, 50265,\n",
              "              1,   439,   262, 21547,  1283,   284,   307,   262,   976,  2546,\n",
              "            526,  1279,  6173,    40,  4808, 24700,    29,   366,   439,   262,\n",
              "          21547,   389,   262,   976,  2546,   526, 50265,     1,   439,   262,\n",
              "          21547,  1283,   284,   307,   262]]),\n",
              " tensor([[   27,    33,  2640,    29, 41275, 30079,   345,   821,   379,   262,\n",
              "          13275,    11, 10194,    30,    27,  6173,    40,    62, 35353,    29,\n",
              "           9425,    11,   314,  1612,    11,   262, 13275,   318,   994,    13,\n",
              "          50265, 43669,    11,   314,  1612,    11,   262, 13275,   338,   994,\n",
              "             13, 50265, 43669,    11,   314,  1612,    11,   262, 13275,   338,\n",
              "            287,   262, 13275,    13, 50265, 43669,    11,   314,  1612,    11,\n",
              "            262, 13275,   338,   612,    13, 50265, 43669,    11,   314,  1612,\n",
              "             11,   262, 13275,   318,   287,   262, 13275,    13, 50265, 43669,\n",
              "             11,   314,  1612,    11,   262, 13275,   338,   287,   262, 13275,\n",
              "             13, 50265, 43669,    11,   314,  1612,    11,   262, 13275,   318,\n",
              "            994,    13, 50265, 43669,    11]]),\n",
              " tensor([[   27,    33,  2640,    29,   464,  3496,  7214,   262,   317, 16835,\n",
              "            416, 11083,   412,  2680,  1122, 34017, 18087,  6429,    27,  6173,\n",
              "             40,    62, 35353,    29,   464, 11083,   412,  2680,  1122, 34017,\n",
              "            338,  7214,   262, 16835,  1248,  2414,    27,  6173,    40,    62,\n",
              "          35353,    29, 11083,   412,  2680,  1122,   338, 34017,  7214,   262,\n",
              "          16835,  1248,  2414,  1279,  6173,    40,  4808, 24700,    29, 11083,\n",
              "            412,  2680,  1122,   338, 34017,  7214,   262, 16835,  1248,  2414,\n",
              "          50265,  6173,    40,  4808, 24700,    29, 11083,   412,  2680,  1122,\n",
              "            338, 34017,  7214,   262, 16835,  1248,  2414, 50265,  6173,    40,\n",
              "           4808, 24700,    29, 11083,   412,  2680,  1122,   338, 34017,  7214,\n",
              "            262, 16835,  1248,  2414, 50265]]),\n",
              " tensor([[   27,    33,  2640,    29,  1870,   262,   584, 10942,  4504,  2046,\n",
              "            319,   262,  2243, 23439, 29847,  6173,    40,    62, 35353,    29,\n",
              "           1870,   262,  8022,  4504,  2046,    13,  1279,  6173,    40,  4808,\n",
              "          24700,    29,   843,   262,  2243, 23439,  2823,    13,  1279,  6173,\n",
              "             40,  4808, 24700,    29,   843,   262,  8022,  2823,    13,  1279,\n",
              "           6173,    40,  4808, 24700,    29,   843,   262,  2243, 23439,  2823,\n",
              "             13,  1279,  6173,    40,  4808, 24700,    29,   843,   262,  8022,\n",
              "           2823,    13,  1279,  6173,    40,  4808, 24700,    29,   843,   262,\n",
              "           8022,  2823,    13,  1279,  6173,    40,  4808, 24700,    29,   843,\n",
              "            262,  8022,  6294,    13, 50265,  1169,  2243, 23439,  2823,   379,\n",
              "            262,  8022,    13, 50265,  1169]]),\n",
              " tensor([[   27,    33,  2640,    29,    40,   716,  1790,   286,  5003,   523,\n",
              "            314,  1949,   284,   307,   277,  2143,   282,    27,  6173,    40,\n",
              "             62, 35353,    29,   314,  1101,  1790,   319,  5003,   523,   314,\n",
              "           1101,  8914,   340,    13,  1279,  6173,    40,  4808, 24700,    29,\n",
              "            314,  1101,  1790,   319,  1637,    11,   523,   314,  1183,  3613,\n",
              "            340,    13,  1279,  6173,    40,  4808, 24700,    29,   314,  1101,\n",
              "           1790,   319,  1637,    13,  1279,  6173,    40,  4808, 24700,    29,\n",
              "            314,  1101,   257,  1310,  1790,    13, 50265,    40,  1101,   257,\n",
              "           1310,  1790,   286,  1637,    11,   523,   314,  1101,  8914,   340,\n",
              "             13, 50265,    40,  1101,   257,  1310,  1790,    11,   523,   314,\n",
              "           1183,  3613,   340,    13, 50265]]),\n",
              " tensor([[   27,    33,  2640,    29,  1135,   761,   284,  2962,   319,   262,\n",
              "           1109,   326,  2258,  4969,   338,  1262,   607,   757,   986,  2644,\n",
              "          10197,   996,   607,  5369,   468,   587,  7362,   284,   514, 29847,\n",
              "           6173,    40,    62, 35353,    29,   775,   423,   284,  2962,   319,\n",
              "            262,  1109,   326,  2258,  4969,   468,   973,   607,   757,   986,\n",
              "            475,   673,   468,   407,  4602,   607,  5369,    13,  1279,  6173,\n",
              "             40,  4808, 24700,    29,   775,   423,   284,  2962,   319,   262,\n",
              "           1109,   326,  2258,  4969,   318,  1262,   607, 16317,   475,   673,\n",
              "            338,   407,  3375,   546,   340,    13,  1279,  6173,    40,  4808,\n",
              "          24700,    29,   775,   423,   284,  2962,   319,   262,  1109,   326,\n",
              "           2258,  4969,   318,  1262,   607]]),\n",
              " tensor([[   27,    33,  2640,    29,    40,   561,  2074,  4305,   683,   611,\n",
              "            339, 46701,   423,   257,   922,  7468,    27,  6173,    40,    62,\n",
              "          35353,    29,    40,  1549,  2666,   683,   611,   339,  1595,   470,\n",
              "           4727,  1521,   339,   338,   407,    13,  1279,    33,  2640,    29,\n",
              "            314,  1549,  2074,  4305,   683,   611,   339,  1595,   470,  4727,\n",
              "            340,    13,  1279,  6173,    40,  4808, 24700,    29,   314,  1549,\n",
              "           2666,   683,   611,   339,  1422,   470,  4727,    13,  1279,    33,\n",
              "           2640,    29,   314,  1549,  2074,   340,   611,   339,  1422,   470,\n",
              "           4727,    13, 50265,   361,   339,  1595,   470,  4727,  1521,   339,\n",
              "           1595,   470,   765,   284,  2666,   683,    13, 50265,   361,   339,\n",
              "           1595,   470,  4727,   340,    11]]),\n",
              " tensor([[   27,    33,  2640,    29,  6385,   345,  3730, 18240,   674, 23272,\n",
              "             11, 25991,   356,   714,  3292,   326,  3253,    87, 18240, 29847,\n",
              "           6173,    40,    62, 35353,    29,  1406,    11,  1201,   345, 18240,\n",
              "            674, 34197,    11,   356,   714,  5163,   340,   351,   606,    13,\n",
              "             27,  6173,    40,    62, 35353,    29,  1406,    11,  1201,   345,\n",
              "          18240,   674, 34197,    11,   356,   460,  5163,   606,    13,  1279,\n",
              "           6173,    40,  4808, 24700,    29,  1406,    11,  1201,   345, 18240,\n",
              "            606,    11,   356,  1244,   355,   880,  5163,   606,    13,  1279,\n",
              "           6173,    40,  4808, 24700,    29,  1406,    11,  1201,   345,  1053,\n",
              "           9909,   606,    11,   356,  1244,   355,   880,  5163,   606,   351,\n",
              "            606,    13,  1279,  6173,    40]]),\n",
              " tensor([[   27,    33,  2640,    29,  1639,   821, 10589,  1234,  1566,   262,\n",
              "           5953,  2058,   736, 29847,  6173,    40,    62, 35353,    29,  1639,\n",
              "            481,  2652,   379,  1363,  1566,   262,  4039,  5860,    13,  1279,\n",
              "           6173,    40,    62, 35353,    29,   921,  1183,  2652,   287,   262,\n",
              "           2156,  1566,   262,  6478,  2058,   736,    13,  1279,  6173,    40,\n",
              "           4808, 24700,    29,   921,  1183,   307, 10589,   379,  1363,  1566,\n",
              "            262,  6478, 14443,    13,  1279,  6173,    40,  4808, 24700,    29,\n",
              "            921,  1183,  2652,   994,  1566,   262,  6478, 14443,    13,  1279,\n",
              "           6173,    40,  4808, 24700,    29,   921,  1183,   307, 10589,   612,\n",
              "             13,  1279,  6173,    40,  4808, 24700,    29,   921,  1183,  2652,\n",
              "             13, 50265,  5832,  2652,   287]]),\n",
              " tensor([[   27,    33,  2640,    29,    40,   466,   407,   892,   314,   460,\n",
              "           2453,   326, 10794,  2158, 29847,  6173,    40,    62, 35353,    29,\n",
              "             40,  1101,   407,  1654,   546,   326, 10794,    13, 50265,    40,\n",
              "           1101,   407,  1654,   611,   314,   460,  4236,   351,   428, 10794,\n",
              "             13, 50265,    40,  1101,   407,  1654,   611,   314,   460,  4236,\n",
              "            351,   326,    13, 50265,    40,  1101,   407,  1654,   611,   314,\n",
              "            460,  2453,   428, 10794,    13, 50265,    40,   836,   470,   760,\n",
              "            611,   314,   460,  2453,   326, 10794,    13, 50265,    40,  1101,\n",
              "            407,  1654,    13, 50265,    40,   836,   470,   760,   611,   314,\n",
              "            460,  4236,   351,   326,    13, 50265,    40,  1101,   407,  1654,\n",
              "             13, 50265,    40,   836,   470]]),\n",
              " tensor([[   27,    33,  2640,    29,  1532,   314,   547,   345,    11,   314,\n",
              "            561,  1234,   257,  1256,   286,  1807,   290,  9110,   656,   428,\n",
              "             27,  6173,    40,    62, 35353,    29,   314,  1549,   423,   257,\n",
              "           1256,   286,  4213,   290,  4213,   546,   340,    13,   314,  1549,\n",
              "            423,   257,  1256,   286,  4213,   290,  4213,   546,   340,    13,\n",
              "          50265,    40,  1549,   307,  3612,   257,  1256,   546,   340,    11,\n",
              "            314,  1549,   892,   257,  1256,    11,   314,  1549,   423,   257,\n",
              "           1256,   286,  4213,    13, 50265,    40,  1549,   423,   257,  1256,\n",
              "            286,  4213,   290,  4213,   546,   340,    13, 50265,    40,  1549,\n",
              "            423,   257,  1256,   286,  4213,   290,  4213,   546,   340,    13,\n",
              "          50265,    40,  1549,   892,   257]]),\n",
              " tensor([[   27,    33,  2640,    29,  1026,   550,   587,   257, 12922,  3297,\n",
              "            286,  9707,  1022,   606,   379,   717,    11,   878,   262,  7722,\n",
              "            550,  7891,  1165,  2089,   329, 14532, 29847,  6173,    40,    62,\n",
              "          35353,    29,  9930,   973,   284,   307,   257,  1310, 12922,  9707,\n",
              "            878,   484, 24070,  1165,   881,    13,  1279,  6173,    40,  4808,\n",
              "          24700,    29,  9930,  1053,   587,   257,  1310, 12922,  9707,   422,\n",
              "            262,  3726,    13,  1279,  6173,    40,  4808, 24700,    29,  9930,\n",
              "            973,   284,   307,   257,  1310, 12922,  9707,   422,   262,  3726,\n",
              "             13, 50265,  9930,   547,   257,  1310, 12922,  9707,   422,   262,\n",
              "           3726,    11,   878,   484, 24070,  1165,   881,    13, 50265,  9930,\n",
              "            547,   257,  1310, 12922,  9707]]),\n",
              " tensor([[   27,    33,  2640,    29,  1639,   743,  8551,   517,  2952,   422,\n",
              "          14917,  1108,   351,   281, 16954,   286,   262, 17770, 14182,  1840,\n",
              "            416,  2130,   508,  4206,   703,   284,   779,   340, 29847,  6173,\n",
              "             40,    62, 35353,    29,  1858,   318,   645,   761,   329,   257,\n",
              "           6253,   338,  1037,   287,   262,  1339,   286,   281, 14917,  1048,\n",
              "            508,  4206,   703,   284,   779,   262, 17770,    13,  1279,  6173,\n",
              "             40,  4808, 24700,    29,  1858,   318,   645,   761,   329,   257,\n",
              "           6253,   338,  1037,   287,   262,  1339,   286,   281, 14917,  5827,\n",
              "             13,  1279,  6173,    40,  4808, 24700,    29,  1858,   318,   645,\n",
              "            761,   329,   257,  6253,   338,  1037,   287,   262,  1339,   286,\n",
              "            257,   582,   508,  4206,   703]]),\n",
              " tensor([[   27,    33,  2640,    29,    40,   892,   262,  5035, 13052,   561,\n",
              "            307,   442,  4668,   689,   611,   339, 10408, 42402,    27,  6173,\n",
              "             40,    62, 35353,    29,  1925,  4668,   689,   389,   257,   922,\n",
              "          13052,    11,  2592,   611,   339,  7832, 11311,    13,  1279,  6173,\n",
              "             40,  4808, 24700,    29,  1925,  4668,   689,   389,   257,   922,\n",
              "           2126,    11,  2592,   611,   339,  7832, 11311,    13, 50265,   258,\n",
              "           7832, 11311,    11,   523,   314,  1950,   262, 11311,    13, 50265,\n",
              "            361,   339,  7832, 11311,    11,   339,  1183,   588,   340,    11,\n",
              "            442,  4668,   689,   389,   257,   922,  2126,    13, 50265,   258,\n",
              "           7832, 11311,    11,   523,   314,  1549,  1950,   442,  4668,   689,\n",
              "             13, 50265,   258,  7832, 11311]]),\n",
              " tensor([[   27,    33,  2640,    29,  1532,   345,   588,  5701,    11,   788,\n",
              "            711,  4709,  1636,  1894,    11, 25911,    11,   393,  1223,  2092,\n",
              "             27,  6173,    40,    62, 35353,    29,  3811,  4346,    11,  9669,\n",
              "             11,   393,  1223,   588,   326,  1279,  6173,    40,  4808, 24700,\n",
              "             29,   921,   460,   711,  4346,    11,  9669,    11,   393,  1223,\n",
              "            588,   326,    13,  1279,  6173,    40,  4808, 24700,    29,   921,\n",
              "            460,   711,  4346,    11,  9669,    11,   393,  1223,   588,   326,\n",
              "             13,  1279,  6173,    40,  4808, 24700,    29,   921,   460,   711,\n",
              "           4346,    11,  9669,    11,   393,  1997,   588,   326,    13,  1279,\n",
              "           6173,    40,  4808, 24700,    29,  1002,   345,   765,   284,   711,\n",
              "           5701,    11,   788,   467,    13]])]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_gyafc[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjab2agzkbtZ",
        "outputId": "c6b55e4d-47e8-4436-c1e4-cb3409570f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', ''),\n",
              " ('I accepted it', ''),\n",
              " ('I believe so', ''),\n",
              " ('not in English', ''),\n",
              " ('A Cuban would know', ''),\n",
              " ('Attempt to download this', ''),\n",
              " ('Both individuals go free', ''),\n",
              " ('Do not tell anyone', ''),\n",
              " ('Do you drink beer', ''),\n",
              " ('He drugs famous women', ''),\n",
              " ('He earns with downloads', ''),\n",
              " ('He is not smart', ''),\n",
              " ('He is so disgusting', ''),\n",
              " ('I also love ', ''),\n",
              " ('I have distinct preferences', ''),\n",
              " ('I love all animals', ''),\n",
              " ('I prefer the guitarist', ''),\n",
              " ('It is an art', ''),\n",
              " ('It is too strange', ''),\n",
              " ('She calls him often', '')]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2_2outputs = pickle.load(open(\"/content/new_model2_2.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "7jNgLeK4hA1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2_2outputs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uLxM1E2hJU6",
        "outputId": "d678c7c9-ffd3-4d2a-91d4-0bb8a4bb9006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I guess so...', ' i guess so'),\n",
              " (' issues and topics are separated', ' topics and issues are separated'),\n",
              " ('I think john left.', ' i believe john to have left'),\n",
              " ('another day another change.', ' another change occurs'),\n",
              " ('e9 has another example', ' there are another two examples')]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2"
      ],
      "metadata": {
        "id": "WbFKh-3G4k1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_outputs_Model2_2 = gen_outputs\n",
        "# generated_outputs_Model2_2 = pickle.load(open(\"generated_outputs_Model2_2\", \"rb\"))"
      ],
      "metadata": {
        "id": "IIWlV9UW4naC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_outputs_Model2_2 = []\n",
        "for o in generated_outputs_Model2_2:\n",
        "  decoded_outputs_Model2_2.append(tokenizer_2.decode(o[0]))"
      ],
      "metadata": {
        "id": "HXq0yXaW5Nmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_outputs_Model2_2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jva7O_is5rTM",
        "outputId": "e812861e-d8a9-4ba5-8145-22eb38312e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<BOS>a smoothing filter can be used to introduce new trends into temporally coherent frequencies<SCI_GEN>in addition a smoothing filter can be applied to temporally aligned frequencies to re engineer the frequency distributions<EOS>the technique of smoothing can be used to incorporate new trends into temporal co occurrence vectors<EOS>another approach to smoothing involves interpolation of smoothed frequencies on the temporally aligned frequencies<EOS>another is to incorporate smoothed frequencies on temporally aligned frequencies to re engineer the co occurrence vectors<EOS>another is to interpolate smoothed frequencies on',\n",
              " '<BOS>the central task is to set all events in order, so it can improve.<SCI_GEN>the set of all events is the central task so it can be improved<EOS>the set of all events is the central task so it should be improved<EOS>the set of all events has the potential to improve the results<EOS>the set of all events has the greatest potential for improvement because it is the single call to the event set<EOS>the set of all events is the central task thus the performance can be improved<EOS>the set of all events has',\n",
              " '<BOS>in contrast, the prepositional phrase is much more susceptible to analysis in terms of distribution.<SCI_GEN>in contrast prepositional phrases are much less amenable to distributional analysis<EOS>in contrast the prepositional phrase is much less amenable to distributional analysis<EOS>this in turn makes the distributional analysis much less tractable<EOS>in contrast the distributional analysis of prepositional phrases is much more difficult<EOS>this in turn makes the distributional analysis of prepositional phrases much less tractable<EOS>in contrast prepos',\n",
              " \"<BOS>let's see how the interpreter translates the example.<SCI_GEN>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate the interpreter by an example<EOS>let us illustrate\",\n",
              " '<BOS>the preferred interpretation is described in this terminology, as we were concerned with the description of the negation and the unmitigated parts of the alternative interpretation.<SCI_GEN>in this terminology we chose the preferred interpretation since we were concerned with the description of negation and unnegated constituents in a formalism where the negation and unnegated constituents are not handled by distinct mechanisms<EOS>this terminology is used for the sake of simplicity since we were concerned with the description of negation and unnegated constituents in a formalism where',\n",
              " '<BOS>because our analysis method is based on anova, we choose anova because the variables we are interested in are normal<SCI_GEN>we chose anova for our analysis method because the variables we are interested in are normal<EOS>we chose anova for our evaluation because the variables we are interested in are the variance of the bivariate distributions over the different test data items<EOS>the reason for choosing anova for our method is that the variables we are interested in are the variance of the bivariate distributions over the different test data items<EOS>this',\n",
              " '<BOS>so i will say that downstep has no effect on tones on either side, so ohl4h ph h lsl lii lii liii<SCI_GEN>thus i will say that downstep has no effect on tones on either side thus ohl4h ph h lsl lii lii liii<EOS>thus i will say that downstep has no effect on tones on either side thus ohl4h ph h lsl lii liii<EOS>thus i will say that downstep has no effect on tones',\n",
              " '<BOS>in deterministic dependency analysis, the naive algorithm can in principle be compared to incremental parsing, although strict word by word increments of word length are not possible.<SCI_GEN>although strict word by word incrementality is not possible in deterministic dependency parsing the naive algorithm can in principle be equated with incremental parsing<EOS>although strict word by word incrementality is not possible in deterministic dependency parsing the naive algorithm can in principle be equated with incremental parsing<EOS>although strict word by word incrementality is not possible in deterministic dependency parsing the',\n",
              " '<BOS>that leads to a system in which individual sentences are ordered based on the content of the sentences in the group<SCI_GEN>this results in a system in which individual sentences are ordered based on the semantic content of the sentences in the group<EOS>this results in a system in which individual sentences are ordered based on the semantic content of the sentences in the group<EOS>this leads to a system in which individual sentences are ordered based on the semantic content of the sentences in the group<EOS>this leads to a system in which sentences are ordered based on the',\n",
              " '<BOS>the grammar could not contain the rule in this case.<SCI_GEN>in this case the rule would not have been present in the grammar<EOS>in this case the rule would not have been present in the lexicon<EOS>in this case the grammar might have been missing in the original grammar<EOS>in this case the rule would not have been present in the grammar<EOS>in this case the rule would have been missing from the lexicon<EOS>in this case the parser would have produced a spurious rule<EOS>in this case the rule would have been missing']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_Model2_2 = []\n",
        "for d in decoded_outputs_Model2_2:\n",
        "  output_Model2_2.append(d.split(\"<SCI_GEN>\")[1].split(\"<EOS>\")[0])"
      ],
      "metadata": {
        "id": "JBiLGnWk5-i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_Model2_2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFCmO79x6XUB",
        "outputId": "f399bd5b-3ebe-461c-e0da-3bdafd448ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in addition a smoothing filter can be applied to temporally aligned frequencies to re engineer the frequency distributions',\n",
              " 'the set of all events is the central task so it can be improved',\n",
              " 'in contrast prepositional phrases are much less amenable to distributional analysis',\n",
              " 'let us illustrate the interpreter by an example',\n",
              " 'in this terminology we chose the preferred interpretation since we were concerned with the description of negation and unnegated constituents in a formalism where the negation and unnegated constituents are not handled by distinct mechanisms',\n",
              " 'we chose anova for our analysis method because the variables we are interested in are normal',\n",
              " 'thus i will say that downstep has no effect on tones on either side thus ohl4h ph h lsl lii lii liii',\n",
              " 'although strict word by word incrementality is not possible in deterministic dependency parsing the naive algorithm can in principle be equated with incremental parsing',\n",
              " 'this results in a system in which individual sentences are ordered based on the semantic content of the sentences in the group',\n",
              " 'in this case the rule would not have been present in the grammar']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_model2_sample[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhZ8rHWc6j2G",
        "outputId": "eb270024-d144-4d9f-e32a-154b9f3cd3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['a smoothing filter can be used to introduce new trends into temporally coherent frequencies',\n",
              "       'the central task is to set all events in order, so it can improve.',\n",
              "       'in contrast, the prepositional phrase is much more susceptible to analysis in terms of distribution.',\n",
              "       \"let's see how the interpreter translates the example.\",\n",
              "       'the preferred interpretation is described in this terminology, as we were concerned with the description of the negation and the unmitigated parts of the alternative interpretation.',\n",
              "       'because our analysis method is based on anova, we choose anova because the variables we are interested in are normal',\n",
              "       'so i will say that downstep has no effect on tones on either side, so ohl4h ph h lsl lii lii liii',\n",
              "       'in deterministic dependency analysis, the naive algorithm can in principle be compared to incremental parsing, although strict word by word increments of word length are not possible.',\n",
              "       'that leads to a system in which individual sentences are ordered based on the content of the sentences in the group',\n",
              "       'the grammar could not contain the rule in this case.'],\n",
              "      dtype='<U325')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_output_model2_sample[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV9pYTZW7BgT",
        "outputId": "c91e89e4-a6ed-47f5-e290-67288f38244b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['one way to incorporate trends implicitly is to run a smoothing filter across the temporally aligned frequencies',\n",
              "       'the central task the ordering of all events leaves lots of room for improvement',\n",
              "       'in contrast prepositional phrases are much less amenable to distributional analysis',\n",
              "       'let us illustrate the way the interpreter works with an example',\n",
              "       'this terminology was used because we were concerned with describing the negated and unnegated parts of the preferred interpretation without referring to presuppositions',\n",
              "       'we selected anova as our analysis method because our prosodic target variables appear to have a normal distribution',\n",
              "       'concerning downstep i shall assume that the magnitude of downstep is independent of the tones on either side and so ohl4h ph h lsl lii i l',\n",
              "       'it seems fair to conclude that although strict word by word incrementality is not possible in deterministic dependency parsing the arc eager algorithm can in practice be seen as a close approximation of incremental parsing',\n",
              "       'this results in a bottomup approach for ordering that opportunistically groups sentences together based on content features',\n",
              "       'the cycle in this latest example could not occur if the grammar contained the rule'],\n",
              "      dtype='<U325')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_outputs_Model2_1 = pickle.load(open(\"/content/generated_outputs_Model2_1.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "3eyL_2LP3egw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_model2_sample[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3CI_4q73pc4",
        "outputId": "2da4fec9-3d39-4991-e1c5-bf08d37f4612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['a smoothing filter can be used to introduce new trends into temporally coherent frequencies',\n",
              "       'the central task is to set all events in order, so it can improve.',\n",
              "       'in contrast, the prepositional phrase is much more susceptible to analysis in terms of distribution.',\n",
              "       \"let's see how the interpreter translates the example.\",\n",
              "       'the preferred interpretation is described in this terminology, as we were concerned with the description of the negation and the unmitigated parts of the alternative interpretation.',\n",
              "       'because our analysis method is based on anova, we choose anova because the variables we are interested in are normal',\n",
              "       'so i will say that downstep has no effect on tones on either side, so ohl4h ph h lsl lii lii liii',\n",
              "       'in deterministic dependency analysis, the naive algorithm can in principle be compared to incremental parsing, although strict word by word increments of word length are not possible.',\n",
              "       'that leads to a system in which individual sentences are ordered based on the content of the sentences in the group',\n",
              "       'the grammar could not contain the rule in this case.'],\n",
              "      dtype='<U325')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_output_model2_sample[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4QuLglv31sv",
        "outputId": "86b95352-e163-490f-bb49-8c69da7f4a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['one way to incorporate trends implicitly is to run a smoothing filter across the temporally aligned frequencies',\n",
              "       'the central task the ordering of all events leaves lots of room for improvement',\n",
              "       'in contrast prepositional phrases are much less amenable to distributional analysis',\n",
              "       'let us illustrate the way the interpreter works with an example',\n",
              "       'this terminology was used because we were concerned with describing the negated and unnegated parts of the preferred interpretation without referring to presuppositions',\n",
              "       'we selected anova as our analysis method because our prosodic target variables appear to have a normal distribution',\n",
              "       'concerning downstep i shall assume that the magnitude of downstep is independent of the tones on either side and so ohl4h ph h lsl lii i l',\n",
              "       'it seems fair to conclude that although strict word by word incrementality is not possible in deterministic dependency parsing the arc eager algorithm can in practice be seen as a close approximation of incremental parsing',\n",
              "       'this results in a bottomup approach for ordering that opportunistically groups sentences together based on content features',\n",
              "       'the cycle in this latest example could not occur if the grammar contained the rule'],\n",
              "      dtype='<U325')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_outputs_Model2_1[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR25_K8935IQ",
        "outputId": "a419ecec-395b-4c7e-ae29-d8beb3fbd63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['new developments in temporal coherent frequency may be introduced using a smoothing filter.',\n",
              " 'the main task is setting up all events so that they can be improved.',\n",
              " 'however, in terms of distribution, this preposition is much more vulnerable than its counterpart.',\n",
              " \"we'll check how the interpreter translates the example.\",\n",
              " 'in this context, we refer to the negation of the implication, as we described in the description of the non-negativity and the undirected part of the alternative interpretation.',\n",
              " 'since our analysis is based only on anova, we chose anova because the variables we care about are normal.',\n",
              " \"so I'm saying that the downstep is no longer affecting the tone of either side, so ohl4h ph lsl lii liiiand I'm saying it's not affecting the tonal tone of any other side.\",\n",
              " 'the naive algorithm can, in principle, compare with incremental processing, though it is impossible for the word size scale to be applied.',\n",
              " 'thus, in which each sentence is divided according to the content of the sentences in the group,this results in a system where individual sentences are arranged according to their content.',\n",
              " 'in this case, grammar could not contain any rules.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 rewards"
      ],
      "metadata": {
        "id": "DIm_9glMeBdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m2_context_original = pickle.load(open(\"/content/m2_w_context_original_list\", \"rb\"))\n",
        "m2_context_output = pickle.load(open(\"/content/m2_w_context_output_list\", \"rb\"))\n",
        "m2_context_context = pickle.load(open(\"/content/m2_w_context_context_list\", \"rb\"))\n",
        "m2_context_non_scientific = pickle.load(open(\"/content/m2_w_context_non_scientific_list\", \"rb\"))\n"
      ],
      "metadata": {
        "id": "KoY8aaZHeGBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(m2_context_original[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIpDb14Beg4F",
        "outputId": "f562defc-59bb-4a9b-cada-23200210d8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the basic idea is quite simple', 'we are grateful to the referee for helpful comments and suggestions to improve the presentation of this paper', 'schmidt orthogonalization', 'dw acknowledges support from the ctc', 'it may improve our understanding of the thermal evolution and thermal spectrum of magnetars', 'however , the majority of loops show more complicated trajectories', 'oscillating red line shows the calculation result', 'in quantum information processing , information is stored and processed with a quantum system', 'the second case is that universal gaugino masses are given above the gut scale', 'the qualitative difference between data for known bulk surfaces and our result should be attributed on movement of cu atoms in the reconstruction process']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(m2_context_output[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TOcEGN0ekp_",
        "outputId": "e7e637c2-eabf-4cc4-a9cf-0a9002f8ca1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' the main difference is the choice of the energy scale ', ' we are grateful to the referee for helpful comments and suggestions on the manuscript ', ' schmidt orthogonalization ', ' dw acknowledges support from the stfc ', ' it might help us understand the thermal evolution and spectrum of magnetars ', ' however, the majority of loops show more complicated trajectories ', ' oscillating red line shows the calculation result ', ' qubits are the quantum information processing devices ', ' the second case is that the two-dimensional gi balls are above the gut scale ', ' the difference between the surface area of a brick and the volume of the brick is just 15 ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(m2_context_context[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prUkP8RNeoaQ",
        "outputId": "d75ecdeb-a115-423f-8b91-e244c801acf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, '<BOS>these effects are measured by the second term in', '<BOS>following an expansion analogous to eq[SEP]the moment hierarchy would comprise linear combinations of the coefficients[SEP]the problem is essentially an algebraic question of gram', '<BOS>dm is supported by the cambridge centre for theoretical cosmology (ctc)[SEP]ds is funded by stfc', None, '<BOS>the footpoints described quite a rectilinear path , similarly to emerging active regions and ephemeral regions', '<BOS>we apply the statefinder diagnostics to the torsion cosmology', None, None, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(m2_context_non_scientific[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoMM6_L1etZK",
        "outputId": "e97b69c4-d50a-4763-e7c2-e84caa7d1e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"it's pretty much the same\", 'we are glad the ref gave us some help on this paper', 'i think that schmidt orthogonalizes to some degree', 'dw: hey guys, we got your back!', 'it might help us understand the thermal evolution and spectrum of magnetars', 'however, the majority of loops show more complicated trajectories', 'oscillating red line shows the calculation result', 'qubits are the bits of information that are used in information processing', 'the second case is that the 2nd kind of gi balls are above the gut scale', 'the difference between the surface area of a brick and the volume of the brick is just 15x']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content Preservation:\n",
        "\n"
      ],
      "metadata": {
        "id": "Pw1ZaVW-CqBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence embedding approach"
      ],
      "metadata": {
        "id": "V9hckLXAfo5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('paraphrase-albert-small-v2')\n"
      ],
      "metadata": {
        "id": "85n8PlGor72x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "f6f402d6ec4847e2a2e7c7b818cb6f96",
            "b1621b348d3a4bd7aed7528b69cbc3cc",
            "7c37875accdb4d249d7b23057b547d47",
            "db28f6159efe4f74b6d653d98d74d422",
            "d10c4823afb7489f915559cfe7143dc1",
            "be7284e1fbae4d50ba157aea6fcdf6d8",
            "c64fbe4b94024198b8ecce50e2188d25",
            "62dad3bd952d4510b1eb6c4c38a72889",
            "0b6668daa232428093f226bd70d59c6d",
            "9267b6259a044d5ca33cfa713883fc0b",
            "5825732ed08f4ea2951fc3d7585012e8",
            "cd2b15d14df04c9b9cce992f98deff0f",
            "ccc300324f51404a9fe8c9fa33808a02",
            "0e1869ce1dc742f9a1f6e41d7f100c83",
            "c10d72bdc07943d2916a9882f114acdc",
            "b1214f21efac42f884041856889ca4cf",
            "65db2acaf0694994949f6c46053b2729",
            "53f3422979a0417ab7e16d5ef9d885e9",
            "2e2548b3c0944c78878ee53f1fd8f076",
            "0b8513a65f274b3cbfd04d9388a743cd",
            "8b9877b0200a4ce2995fd16fdce1aafa",
            "6ad18f9660874d729567603b2bd5d7fd",
            "79ff1906738c47a2bf9319ec81773d45",
            "f43ed4f6829f438d95bb0a4b2bc664e8",
            "50f36322352e49dca13119845eae01d1",
            "24b58beb002d4053baabb844e005c714",
            "b8d1c7b38fba4f4b97eccaf51e0bf943",
            "9ea761872ca84b04b8eafce51187d388",
            "1e56751122b44d3ead3b7e434a83d493",
            "08bef71a805f4d988a34ff2dbee2e645",
            "0ef34c72e6d84de58c9495e02ba82f0b",
            "5e62b035a4a649138ddc7f8de0af14a7",
            "5a9e9a0d26304c839552c9c2506bf343",
            "959353bc2e4e4ec69a7e5e3c232e9972",
            "878259eafe3942e9a97381961939bac2",
            "58b4d9dcb6a04e7b9667ee4ff7cf128c",
            "8ff7f7b49ed641cfbfa3d3bf588689f8",
            "0b7face2d8434fc6b6ba73d2792bf78e",
            "aad953bd07114fc7be4b0b2aad622cb0",
            "943b3aa72e5b4a009d42c019c867cd99",
            "8d3036b51b674dc4a0c973d681e3dc05",
            "c373c967cd024b819d32f743193b363c",
            "52e14e779947481c8949b273418a16c3",
            "69094a501fb5406bbc02b172a540a475",
            "b9bd39ca07f54aa2a7aa9335c57c5dd7",
            "41d04591ffb74cba96854ec7cc3fc21d",
            "2373f51ce98b4e01a8fdf9528d64bad8",
            "9259c7f9acac481d9422fd4500e39c86",
            "744c6d72b257450d8526fa4d3e153619",
            "f6e63b1d3a5747b59fdc81dc07ff0f3d",
            "a26add04510045428fdf53bc176bc480",
            "5ee5157c93824e56ab77f5a7bed0c896",
            "06cd029c18324f4fb7097075029ea32f",
            "3c4c91cac57146d8bf8d1e01660684a4",
            "611da4707b0746ca90aaee8f11db013d",
            "e9e67dcb062d435db3c500111f039b33",
            "515ee0024fb749a8a8939772d5f5557f",
            "12ca4d5cd12d41b6b3ccda8f0b1a03a6",
            "8c041ab2c99c4318b5df0f6fae48dcac",
            "cd73cb2c43a64f17873771e2048822c9",
            "701d67cee6f94242a33506da39dd58e2",
            "dd54bea5f02f45568efbeca0ccc6ac42",
            "4baa85a1830a49e89cd44ab5ba37b42e",
            "705849ccd1c0478b9ff8c299f54e2ea9",
            "5f0a13ea7c7b4acfaf33bfe755f69e9e",
            "f473107b79e34c859b3ef0370ca56a74",
            "48359d7763ec407da48ac6b77471f289",
            "9d68c7e5475b4d09b053d92b7e797c58",
            "f78ccb9803354607982df3e504842899",
            "90797182727f4170868b0baf17102f4b",
            "b640ca2ccd354059bcabf5f10cd2ee76",
            "9f9b47e88eda40a5b83ee65529426415",
            "a90c104f09b0427e9a727a276c8b90e2",
            "e1cb2d776c69432fa4021747d0656abb",
            "e8440f76cc6f4a5e9a1bdaaed20f69a4",
            "4f82e074193348249b97fcae0b8be056",
            "4c3dd55d688b47d7a120acd4f8479487",
            "de50c5d9871a4b75b5df9f4e4cb44dee",
            "4e4709d755f84031a12085ba5446dc33",
            "cabdcc69d7c64461a235ef634318b0ca",
            "629dc4f13820460b85dcdcb5ca4a688d",
            "bcf79da797304de1ab4150bcfd55314c",
            "9234d8117d044ed38124271c85e40ecc",
            "6174bf7ab7ca4608b6b95498d16c587e",
            "0194c94c6bc34b58b45d2689b3f8f3de",
            "1ab2165a5c2149779400198506bfb5e6",
            "478e56a7cd4d489794b9f54f316c47db",
            "50885ccfc97b4bbea57871710c02a13a",
            "be5cbdb819204331af6eae3a4c62a412",
            "e5970eaa296d43b6a9ac94fab05dcc4d",
            "28f6aff1120248ef93d95fa179934a55",
            "34db9d63efc04c5cb115de2b347c8e5d",
            "f0ccbe5a769d4c179eef53362218313b",
            "5c7fceab5267496da03769774ce2f837",
            "4841dde8969543b68af0be5c13e25ea1",
            "8287ef8e716f46e896b07444a0f84b60",
            "7520e09534ce478e995a5d51c46d19cc",
            "031d505dc327453484bf63ff0aa11bf1",
            "5549654549a0465a8bd1d2ef15fcb8d2",
            "5850a56431d943f989f25617de1d9695",
            "0e2aeac3609f4d9090a98facc88a99ad",
            "38f505d5b1df4c37ab0ff88ac655097c",
            "47df807a812f4985a10f586f0050ad58",
            "a809054b268a4be2899f0ccce1324d1a",
            "8482dc25ad764fe5b8d02a2dfdf20efa",
            "cceb1002ce9748549e34919dab52503e",
            "fcf59b58237148e5b40eaf64f79e6adb",
            "33f4565ae3c04479bb77b43274b3d614",
            "cf78b307f6e44f49a183d057264359f8",
            "a04f560c631143e5bee4a368e8e6d041",
            "8819c883b3154cc5abeb0d2653669198",
            "ade9a46986dc4f1388964e88900b857e",
            "fcedc86ae5ea45a0aae3cae6201e9d7c",
            "f5dd62995e02483989138e0623ae7bff",
            "32886ed6bd7d48bca496fe09190c91f0",
            "61fa0d0eeb30413fb98672e578f0609a",
            "5ee0e6b1caf44e338f7138893ef20a4e",
            "0b837eca01c243b09475412d178c8c40",
            "e07001640ee9445b8fab59c2224522ba",
            "1d2559ab1c3342c6a52dab2e74395357",
            "082fa958a2844769995e288ce6955f72",
            "12f65e2ff2c04a84bfe1f6e1246d7c88",
            "79bd140dd5fe4b2985226265da651cd2",
            "f87f97b3790e4734aa1075447b71fcce",
            "981e144a5c6a49d7aa2a6fb5db63c3f2",
            "794bff3c76c04780b4993a9934fd0ec0",
            "29a49056bca3424aa6e4a6c90f1ab0a9",
            "cb6fcf6768824d4aa687f7acaa75fab1",
            "bc3853c6e2814fd89a60dd398fd2bbd7",
            "658ee447ae9041d085756d435a3443cd",
            "fe68b69b44a54b24aa32618bf243bd97",
            "c7106d7b68724d1b94b58b462d27e1c7"
          ]
        },
        "outputId": "2503b815-4b84-4409-831b-8115173c1fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6f402d6ec4847e2a2e7c7b818cb6f96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd2b15d14df04c9b9cce992f98deff0f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79ff1906738c47a2bf9319ec81773d45",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/827 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "959353bc2e4e4ec69a7e5e3c232e9972",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9bd39ca07f54aa2a7aa9335c57c5dd7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e67dcb062d435db3c500111f039b33",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/46.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48359d7763ec407da48ac6b77471f289",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de50c5d9871a4b75b5df9f4e4cb44dee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/245 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be5cbdb819204331af6eae3a4c62a412",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5850a56431d943f989f25617de1d9695",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8819c883b3154cc5abeb0d2653669198",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/465 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12f65e2ff2c04a84bfe1f6e1246d7c88",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "\"\"\"\n",
        "  Takes in a list of sentences and returns a list of their sentence embedding vector\n",
        "\"\"\"\n",
        "def sent_embedding(sentences):\n",
        "  tokenized_sent = []\n",
        "  for s in sentences:\n",
        "      tokenized_sent.append(s.lower().replace(\",\", \"\"))\n",
        "  sentence_embeddings = sbert_model.encode(tokenized_sent)\n",
        "  return sentence_embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "fHLjDXnBHUE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emb_a = sent_embedding([formal[100]])\n",
        "# emb_b = sent_embedding([informal2[145]])\n",
        "\n",
        "# print(cosine_sim(emb_a[0], emb_b[0]))"
      ],
      "metadata": {
        "id": "lczKoK8pO2L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# s1 = \"I am taking my dog for a walk\"\n",
        "# s2 = \"I am playing red dead redemption 2 on playstation\"\n",
        "# s3 = \"My dog is at the park\"\n",
        "# s4 = \"Apples are red and giraffes are tall\"\n",
        "# s5 = \"I am cooking dinner\"\n",
        "# s6 = \"I am chopping trees\"\n",
        "# s7 = \"monkey, donkey, working as a data analyst in new york for money\"\n",
        "# s8 = \"monkey, donkey, Hello I am elon musk and I want to go to space goodbye\"\n",
        "\n",
        "\n",
        "\n",
        "# sents = [s1, s2, s3, s4, s5, s6, s7, s8]\n",
        "\n",
        "\n",
        "# sent_emb = sent_embedding(sents)\n",
        "\n"
      ],
      "metadata": {
        "id": "gc-pv5AaGlgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(sents)):\n",
        "#   for j in range(i, len(sents)):\n",
        "#     print(f'{sents[i]} and {sents[j]} are {cosine_sim(sent_emb[i], sent_emb[j])}')"
      ],
      "metadata": {
        "id": "Qt4QCehoPfe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The more similar a sentence is, the better the content would be preserved."
      ],
      "metadata": {
        "id": "zZ1OEXOAJJJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing content preservation:"
      ],
      "metadata": {
        "id": "ZOgSQBE6h70K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use UMAP? Supposedly encodes meaning better\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Takes a list of lists of sentence embeddings and colours each list its own colour\n",
        "  A = [[se1, se2, ...., sen],\n",
        "       [se1, se2, ...., sem],\n",
        "       .\n",
        "       .\n",
        "       .\n",
        "      ]\n",
        "\"\"\"\n",
        "def visualize_embeddings(A, titles, dimensions=2):\n",
        "    reduced_list = []\n",
        "    for a in tqdm(A):\n",
        "      a_reduced = reduce_dimensionality(a, dimensions)\n",
        "      reduced_list.append(a_reduced)\n",
        "\n",
        "    color_list = [\"blue\", \"red\", \"green\", \"orange\", \"pink\", \"purple\", \"cyan\"]\n",
        "    \n",
        "    # TODO: 3D plots?\n",
        "    for i in range(len(reduced_list)):\n",
        "      r = reduced_list[i]\n",
        "      color = \"tab:\"+color_list[i]\n",
        "      \n",
        "      plt.scatter(r[:,0], r[:,1], s=10, c=color, label=titles[i])\n",
        "      plt.xlabel(\"PC1\", size=15)\n",
        "      plt.ylabel(\"PC2\", size=15)\n",
        "      plt.title(\"Sentence Embedding Space\",size=20)\n",
        "      plt.legend()\n",
        "      # vocab=list(model.wv.vocab)\n",
        "      # for i, word in enumerate(vocab):\n",
        "      #   plt.annotate(word,xy=(neww_X[i,0],neww_X[i,1]))\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "\n",
        "def reduce_dimensionality(embedding_list, dimensions=2):\n",
        "  df = pd.DataFrame(embedding_list)\n",
        "  print(df.head())\n",
        "  #Computing the correlation matrix\n",
        "  X_corr=df.corr()\n",
        "\n",
        "  #Computing eigen values and eigen vectors\n",
        "  values,vectors=np.linalg.eig(X_corr)\n",
        "\n",
        "  #Sorting the eigen vectors coresponding to eigen values in descending order\n",
        "  args = (-values).argsort()\n",
        "  values = vectors[args]\n",
        "  vectors = vectors[:, args]\n",
        "\n",
        "  #Taking first 2 components which explain maximum variance for projecting\n",
        "  new_vectors=vectors[:,:dimensions]\n",
        "  #Projecting it onto new dimesion with 2 axis\n",
        "  neww_X=np.dot(embedding_list,new_vectors)\n",
        "  return neww_X\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "jzjrbzxWi66A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SgvxBLezuaEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ea =  sent_embedding( formal[: 1000]    )\n",
        "# eb =  sent_embedding( informal0[: 1000] )\n",
        "# ec =  sent_embedding( informal1[: 1000] )\n",
        "# ed =  sent_embedding( informal2[: 1000] )\n",
        "# ee =  sent_embedding( informal3[: 1000] )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QXvt7N9Opyx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize_embeddings([ea, eb, ec, ed, ee], [\"formal\", \"informal0\", \"informal1\", \"informal2\", \"informal3\"], 2)"
      ],
      "metadata": {
        "id": "BgFBSCP16-zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "f = open('/content/guardian.txt', 'r')\n",
        "guardian = f.read()\n",
        "f.close()\n",
        "\n",
        "f = open('/content/shakespeare.txt', 'r')\n",
        "shakespeare = f.read()\n",
        "f.close()\n",
        "\n",
        "\n",
        "guardian_list = guardian.split(\".\")\n",
        "shakespeare_list = shakespeare.split(\".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "CaFLBnZMtb2J",
        "outputId": "20ed858c-d356-4982-985a-67dad749500d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4b1804a6b1b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/guardian.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mguardian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/guardian.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_use = []\n",
        "guardian_use = []\n",
        "\n",
        "print(len(guardian_list))\n",
        "for i in range(100):\n",
        "  if len(guardian_list[i]) > 4:\n",
        "    guardian_use.append(guardian_list[i])\n",
        "  if len(shakespeare_list[i]) > 4:\n",
        "    shakespeare_use.append(shakespeare_list[i])\n",
        "\n",
        "print(len(shakespeare_use))\n",
        "print(len(guardian_use))\n",
        "\n",
        "\n",
        "guardian_emb = sent_embedding(guardian_use)\n",
        "shakespeare_emb = sent_embedding(shakespeare_use)\n",
        "\n",
        "visualize_embeddings([guardian_emb, shakespeare_emb], [\"The Guardian\", \"Hamlet\"], 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L8OOlZwxb5T",
        "outputId": "e5326f6a-c200-44fb-c1c7-246ca94692a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n",
            "100\n",
            "99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0         1         2    ...       765       766       767\n",
            "0 -0.254754  0.841339 -0.261596  ... -0.265298 -0.674365 -0.306814\n",
            "1  0.025067 -0.444306  0.124448  ... -0.476865 -0.422103  0.159993\n",
            "2 -0.844560  0.325235 -0.084296  ...  0.613818 -0.362765  0.565210\n",
            "3 -0.473402 -0.337111  0.843718  ... -0.584968 -0.549722 -0.458340\n",
            "4 -0.201149 -0.082261  0.363619  ... -0.173576 -0.507978 -0.973958\n",
            "\n",
            "[5 rows x 768 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 1/2 [00:00<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0         1         2    ...       765       766       767\n",
            "0  0.325448 -0.215348 -0.458145  ... -1.047840  0.548801 -0.176521\n",
            "1  0.209323  0.430457  0.306622  ... -0.051950  0.300349 -0.453013\n",
            "2  0.095154 -0.119536  0.327762  ...  0.700704  0.920636 -0.819238\n",
            "3  0.438501  0.076014  0.089661  ... -0.747679 -1.062958 -1.248935\n",
            "4  0.195879 -0.222254 -0.443813  ... -0.198861 -0.137732 -0.315868\n",
            "\n",
            "[5 rows x 768 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dhruv's content preservation approach"
      ],
      "metadata": {
        "id": "SzVIdaKccHDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "6GoF1Zp2cRgX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sja700yZLdJ5",
        "outputId": "d6c8c68e-c5f7-4160-ca5e-2957dc2451c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 2)) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 4)) (0.0.47)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 5)) (0.1.96)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 6)) (0.42.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 7)) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r /content/requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->-r /content/requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/requirements.txt (line 2)) (3.10.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r /content/requirements.txt (line 4)) (4.62.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from models import load_model\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--load-file\", default = \"/content/model.para.lc.100.pt\",help=\"path to saved model\")\n",
        "parser.add_argument(\"--sp-model\", default = \"/content/paranmt.model\",help=\"sentencepiece model to use\")\n",
        "parser.add_argument(\"--gpu\", default=1, type=int, help=\"whether to train on gpu\")\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "content_pres_model, _ = load_model(None, args)\n",
        "content_pres_model.eval()"
      ],
      "metadata": {
        "id": "jSvKF-dyc0Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3ecfaf-d8ec-4cc7-f6f9-b282ef9f8399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaging(\n",
            "  (sim_loss): MarginRankingLoss()\n",
            "  (cosine): CosineSimilarity()\n",
            "  (embedding): Embedding(82983, 1024)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Averaging(\n",
              "  (sim_loss): MarginRankingLoss()\n",
              "  (cosine): CosineSimilarity()\n",
              "  (embedding): Embedding(82983, 1024)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "from sacremoses import MosesTokenizer\n",
        "from models import load_model\n",
        "from sacremoses import MosesTokenizer\n",
        "from utils import Example\n",
        "\n",
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "class FileSim:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.similarity = lambda s1, s2: np.nan_to_num(cosine(np.nan_to_num(s1), np.nan_to_num(s2)))\n",
        "\n",
        "    def score(self, params, batcher, s1, s2):\n",
        "        input1 = [s1]\n",
        "        input2 = [s2]\n",
        "        sys_scores = []\n",
        "        for ii in range(0, len(input1), params.batch_size):\n",
        "            batch1 = input1[ii:ii + params.batch_size]\n",
        "            batch2 = input2[ii:ii + params.batch_size]\n",
        "\n",
        "            # we assume get_batch already throws out the faulty ones\n",
        "            if len(batch1) == len(batch2) and len(batch1) > 0:\n",
        "                enc1 = batcher(params, batch1)\n",
        "                enc2 = batcher(params, batch2)\n",
        "\n",
        "                for kk in range(enc2.shape[0]):\n",
        "                    sys_score = self.similarity(enc1[kk], enc2[kk])\n",
        "                    sys_scores.append(sys_score)\n",
        "\n",
        "        return sys_scores\n",
        "\n",
        "def batcher(params, batch):\n",
        "    new_batch = []\n",
        "    for p in batch:\n",
        "        if params.tokenize:\n",
        "            tok = params.entok.tokenize(p, escape=False)\n",
        "            p = \" \".join(tok)\n",
        "        if params.lower_case:\n",
        "            p = p.lower()\n",
        "        p = params.sp.EncodeAsPieces(p)\n",
        "        p = \" \".join(p)\n",
        "        p = Example(p, params.lower_case)\n",
        "        p.populate_embeddings(params.model.vocab, params.model.zero_unk, params.model.ngrams)\n",
        "        new_batch.append(p)\n",
        "    x, l = params.model.torchify_batch(new_batch)\n",
        "    vecs = params.model.encode(x, l)\n",
        "    return vecs.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "hRNGU6wbc4FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_content_pres(args, model, s1, s2):\n",
        "\n",
        "    entok = MosesTokenizer(lang='en')\n",
        "\n",
        "    from argparse import Namespace\n",
        "\n",
        "    new_args = Namespace(batch_size=32, entok=entok, sp=model.sp,\n",
        "                     params=args, model=model, lower_case=model.args.lower_case,\n",
        "                     tokenize=model.args.tokenize)\n",
        "    \n",
        "    s = FileSim()\n",
        "    scores = s.score(new_args, batcher, s1, s2)\n",
        "    return scores\n",
        "\n",
        "def evaluate_content_pres_list(args, model, l1, l2):\n",
        "    # each index should consist of sent1, sent2, content pres score\n",
        "    l = []\n",
        "    for i in range(len(l1)):\n",
        "      s1 = l1[i]\n",
        "      s2 = l2[i]\n",
        "      entok = MosesTokenizer(lang='en')\n",
        "\n",
        "      from argparse import Namespace\n",
        "\n",
        "      new_args = Namespace(batch_size=32, entok=entok, sp=model.sp,\n",
        "                      params=args, model=model, lower_case=model.args.lower_case,\n",
        "                      tokenize=model.args.tokenize)\n",
        "      \n",
        "      s = FileSim()\n",
        "      scores = s.score(new_args, batcher, s1, s2)\n",
        "      l.append([s1, s2, scores])\n",
        "    return l"
      ],
      "metadata": {
        "id": "LQsSAWXuSAis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate_content_pres(args, content_pres_model, \"My cat.\", \"Stray cat.\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "W1uitN5Rc56-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fab351-1b17-400a-8114-9e4445d10aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.64013505]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cont_pres_list_0 = evaluate_content_pres_list(args, content_pres_model, formal, informal0) \n",
        "cont_pres_list_1 = evaluate_content_pres_list(args, content_pres_model, formal, informal1) \n",
        "cont_pres_list_2 = evaluate_content_pres_list(args, content_pres_model, formal, informal2) \n",
        "cont_pres_list_3 = evaluate_content_pres_list(args, content_pres_model, formal, informal3) "
      ],
      "metadata": {
        "id": "t6ZjrLmYSb8w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "663cf0da-1395-4b36-d836-97fde8ad9ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-32ad6e5cc7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcont_pres_list_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_content_pres_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_pres_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformal0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcont_pres_list_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_content_pres_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_pres_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformal1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcont_pres_list_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_content_pres_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_pres_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformal2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcont_pres_list_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_content_pres_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_pres_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformal3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'formal' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(cont_pres_list_0)"
      ],
      "metadata": {
        "id": "6Ni1lQfWXWCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "vzX1ylBfXeGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv(\"Dhruv_content_pres_sample.csv\")"
      ],
      "metadata": {
        "id": "6MEx7U6LXeMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Style Classification SciBERT:"
      ],
      "metadata": {
        "id": "LrfiROIQA2Z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load libraries"
      ],
      "metadata": {
        "id": "4YmJFwoNuN3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEJNnqiTuMYG"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "from transformers import AutoTokenizer,AutoModel, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "# Load spacy and disable not needed pipelines\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.disable_pipes('ner', 'parser')\n",
        "import math\n",
        "import torch"
      ],
      "metadata": {
        "id": "k0DNg4NjuPDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Methods"
      ],
      "metadata": {
        "id": "TOmXpgZRuYZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/SciBERT\"\n",
        "%cd SciBERT\n",
        "\n",
        "%cd ..\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juErY1vfL9hi",
        "outputId": "84dae952-8fd4-4ecd-bcbd-da2aa18172ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SciBERT\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "  if not os.path.isdir('/content/SciBERT'):\n",
        "    os.mkdir(\"SciBERT\")\n",
        "    %cd SciBERT\n",
        "    \n",
        "    %cd ..\n",
        "  tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "  model = BertForSequenceClassification.from_pretrained(\"/content/SciBERT\",local_files_only=True, num_labels = 3)\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  _ = model.to(device)\n",
        "  return model, tokenizer\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  with open('/content/word_list_SciBERT_masking.pkl', 'rb') as handle:\n",
        "    word_list = pickle.load(handle)\n",
        "  return word_list\n",
        "\n",
        "\n",
        "def apply_masking(texts):\n",
        "  sents = []\n",
        "  for sent in tqdm(texts):\n",
        "    sents.append(\" \" .join([token.text.lower() if token.lemma_ in word_list else \"<unk>\"  if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\" else token.text.lower() for token in nlp(sent)]))\n",
        "  return sents"
      ],
      "metadata": {
        "id": "Nkolu6t2uZcR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, token_ids, attention_masks):\n",
        "    self.token_ids = token_ids\n",
        "    self.attention_masks = attention_masks\n",
        "    if len(self.token_ids) != len(self.attention_masks):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _token_ids = self.token_ids[index]\n",
        "    _attention_masks = self.attention_masks[index]\n",
        "    return _token_ids, _attention_masks"
      ],
      "metadata": {
        "id": "nd4WEcg_ujUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conf(texts):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  batch_size =  128\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  tokenizer_res = tokenizer(texts, padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=50, truncation=True).to(device)\n",
        "  loader = iter(DataLoader(CustomDataset(tokenizer_res[\"input_ids\"], tokenizer_res[\"attention_mask\"]), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_probs = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    token_ids, attention_masks = loader.next()\n",
        "    with torch.no_grad():\n",
        "      outputs = model(token_ids, attention_masks)\n",
        "    probs = outputs.logits.softmax(dim = -1).tolist()\n",
        "    all_probs.extend(probs)\n",
        "  return all_probs"
      ],
      "metadata": {
        "id": "q-iHtBbSv0Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "vNzV-1y1v6mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = load_model()\n",
        "word_list = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "J0lWrHF6wSWI",
        "outputId": "c4b4430c-2b4d-4d44-c12d-22eab1b32131"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0d0143867fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-098206f2207f>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/SciBERT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SciBERT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd SciBERT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents = [\"I like apples\", \"This is the second sentence\"]\n",
        "\n",
        "# Run inference\n",
        "masked_sents = apply_masking(sents)\n",
        "probs = get_conf(masked_sents)\n",
        "sci_prob = [p[1] for p in probs]\n",
        "near_sci_prob = [p[0] for p in probs]\n",
        "normal =  [p[2] for p in probs]"
      ],
      "metadata": {
        "id": "42VMmvY9v7lD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de5f3c6e-1ac0-4e9b-a10c-5dd6f52a9133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 132.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_style_classification(l1):\n",
        "  punkt_string = r\"[.!?\\-]\"\n",
        "  masked_sents = apply_masking(l1)\n",
        "  clean_sents = []\n",
        "  for m in masked_sents:\n",
        "    clean_sents.append(re.sub(punkt_string, \"\", m))\n",
        "  probs = get_conf(clean_sents)\n",
        "  near_sci_prob = [p[0] for p in probs]\n",
        "  sci_prob = [p[1] for p in probs]\n",
        "  normal =  [p[2] for p in probs]\n",
        "  return probs"
      ],
      "metadata": {
        "id": "xBc8QE4Qtgp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Style Classification GYAFC:"
      ],
      "metadata": {
        "id": "wq48jYYKw1Kx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load libraries"
      ],
      "metadata": {
        "id": "0GtQK_x-w1Kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMohId76w1Ky"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "from transformers import AutoTokenizer,AutoModel, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "# Load spacy and disable not needed pipelines\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.disable_pipes('ner', 'parser')\n",
        "import math\n",
        "import torch"
      ],
      "metadata": {
        "id": "JCHEMfZTw1Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Methods"
      ],
      "metadata": {
        "id": "_TgXV6v0w1Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/SciBERTGYAFC\"\n",
        "%cd SciBERTGYAFC\n",
        "\n",
        "%cd ..\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7615815-7ea1-401c-ea33-bf733b4f3bb8",
        "id": "k9mguV-bw1Ky"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SciBERTGYAFC\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "  if not os.path.isdir('/content/SciBERTGYAFC'):\n",
        "    \n",
        "    %cd SciBERTGYAFC\n",
        "\n",
        "    %cd ..\n",
        "  tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "  model = BertForSequenceClassification.from_pretrained(\"/content/SciBERTGYAFC\",local_files_only=True, num_labels = 2)\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  _ = model.to(device)\n",
        "  return model, tokenizer\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  with open('/content/word_list_SciBERT_masking.pkl', 'rb') as handle:\n",
        "    word_list = pickle.load(handle)\n",
        "  return []\n",
        "\n",
        "def apply_masking(texts):\n",
        "  sents = []\n",
        "  for sent in tqdm(texts):\n",
        "    sents.append(\" \" .join([token.text.lower() if token.lemma_ in word_list else \"<unk>\"  if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\" else token.text.lower() for token in nlp(sent)]))\n",
        "  return sents"
      ],
      "metadata": {
        "id": "_6FoL85vw1Ky"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, token_ids, attention_masks):\n",
        "    self.token_ids = token_ids\n",
        "    self.attention_masks = attention_masks\n",
        "    if len(self.token_ids) != len(self.attention_masks):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _token_ids = self.token_ids[index]\n",
        "    _attention_masks = self.attention_masks[index]\n",
        "    return _token_ids, _attention_masks"
      ],
      "metadata": {
        "id": "o_oGl7ilw1Ky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "60d9cb34-fb84-48b6-9b4a-0df00f2077f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8442636f2f60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conf(texts):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  batch_size =  128\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  tokenizer_res = tokenizer(texts, padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=50, truncation=True).to(device)\n",
        "  loader = iter(DataLoader(CustomDataset(tokenizer_res[\"input_ids\"], tokenizer_res[\"attention_mask\"]), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_probs = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    token_ids, attention_masks = loader.next()\n",
        "    with torch.no_grad():\n",
        "      outputs = model(token_ids, attention_masks)\n",
        "    probs = outputs.logits.softmax(dim = -1).tolist()\n",
        "    all_probs.extend(probs)\n",
        "  return all_probs"
      ],
      "metadata": {
        "id": "-X4pELL_w1Ky"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "zYby6W4kw1Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = load_model()\n",
        "word_list = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75038f07-e964-441b-c0e5-197cfb031f7e",
        "id": "TSveJaEgw1Ky"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at /content/SciBERTGYAFC were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.dense.bias', 'classifier.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'classifier.out_proj.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'classifier.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'classifier.out_proj.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/SciBERTGYAFC and are newly initialized: ['encoder.layer.11.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'classifier.weight', 'pooler.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.attention.self.value.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents = [\"I like apples\", \"This is the second sentence\", \"boobies vagina giraffe you're i'm stopid\", \"Affirmative, very eloquently put\"]\n",
        "\n",
        "# Run inference\n",
        "masked_sents = apply_masking(sents)\n",
        "probs = get_conf(masked_sents)\n",
        "sci_prob = [p[1] for p in probs]\n",
        "near_sci_prob = [p[0] for p in probs]\n",
        "# normal =  [p[2] for p in probs]\n",
        "print()\n",
        "print(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "U-h_WXoNw1Ky",
        "outputId": "c43bca43-c24a-42a5-c7c1-81e870dafca4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-48583e138eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmasked_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_masking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_conf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msci_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-624fb5766cc6>\u001b[0m in \u001b[0;36mapply_masking\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_masking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0msents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_list\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"<unk>\"\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NOUN\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PROPN\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_style_classification(l1):\n",
        "  punkt_string = r\"[.!?\\-]\"\n",
        "  masked_sents = apply_masking(l1)\n",
        "  clean_sents = []\n",
        "  for m in masked_sents:\n",
        "    clean_sents.append(re.sub(punkt_string, \"\", m))\n",
        "  probs = get_conf(clean_sents)\n",
        "  # near_sci_prob = [p[0] for p in probs]\n",
        "  # sci_prob = [p[1] for p in probs]\n",
        "  # normal =  [p[2] for p in probs]\n",
        "  return probs"
      ],
      "metadata": {
        "id": "8QcNtm8fw1Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER Consistency: \n",
        "\n",
        "We can use spacy for NER, and then compare the resulting named entities of the input and output sentence. However, two different entities might have a similar meaning. How to correct for this? Changing terms is definitely an important part of changing style. Use word embeddings and cosine sim again?"
      ],
      "metadata": {
        "id": "XvDI8PymD2TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "import spacy"
      ],
      "metadata": {
        "id": "NURUleNeD8tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "C4WQRZciNZQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formal_ = [x+\".\" for x in formal]\n"
      ],
      "metadata": {
        "id": "VDfozSZpNgX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formal_text = \"\"\n",
        "\n",
        "for s in formal_:\n",
        "  formal_text += s + \"\\n\"\n",
        "\n",
        "# print(formal_text)\n",
        "\n",
        "doc_formal = nlp(formal_text)"
      ],
      "metadata": {
        "id": "XkE7hmY2IKhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sents_formal = list(doc_formal.sents)\n",
        "\n",
        "print(len(formal), \" \", len(sents_formal))"
      ],
      "metadata": {
        "id": "_AJGhPUURt4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  if doc_formal.ents[i].label_ == \"\"\n",
        "  print(doc_formal.ents[i].text, \" \", doc_formal.ents[i].label_)\n",
        "\n"
      ],
      "metadata": {
        "id": "pxuFgudsNCZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity doesn't seem to say much:"
      ],
      "metadata": {
        "id": "iGp_He2umcjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monkey_doc = nlp(\"Monkey\")\n",
        "giraffe_doc = nlp(\"Giraffe\")\n",
        "spaceship_doc = nlp(\"Spaceship\")\n",
        "art_doc = nlp(\"Art Show\")\n",
        "orangutan_doc = nlp(\"Orangutan\")\n",
        "primate_doc = nlp(\"Primate\")\n",
        "human_doc = nlp(\"Human\")\n",
        "person_doc = nlp(\"Person\")\n",
        "\n",
        "print(f'monkey and giraffe are {cosine_sim(monkey_doc[0].vector, giraffe_doc[0].vector)} similar')\n",
        "print(f'monkey and spaceship are {cosine_sim(monkey_doc[0].vector, spaceship_doc[0].vector)} similar')\n",
        "print(f'monkey and art are {cosine_sim(monkey_doc[0].vector, art_doc[0].vector)} similar')\n",
        "print(f'monkey and primate are {cosine_sim(monkey_doc[0].vector, primate_doc[0].vector)} similar')\n",
        "print(f'human and person are {cosine_sim(monkey_doc[0].vector, human_doc[0].vector)} similar')\n"
      ],
      "metadata": {
        "id": "lHAErXTvT5v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists have to be equal in size, each index is comparex to its counterpart in the other list\n",
        "def entity_consistency(sent_list_a, sent_list_b):\n",
        "  total_sum = 0\n",
        "  for i in range(len(sent_list_a)):\n",
        "    a_doc = nlp(sent_list_a[i])\n",
        "    b_doc = nlp(sent_list_b[i])\n",
        "    a_ents = a_doc.ents\n",
        "    b_ents = b_doc.ents\n",
        "    entity_sum = 0\n",
        "    \n",
        "    num_ents = max(len(a_ents), len(b_ents))\n",
        "    if num_ents>0:\n",
        "      for ae in a_ents:\n",
        "        for be in b_ents:\n",
        "          if ae.text == be.text:\n",
        "            entity_sum += 1\n",
        "      entity_avg = entity_sum / num_ents\n",
        "    total_sum += entity_avg\n",
        "\n",
        "  return total_sum / len(sent_list_a)\n",
        "\n",
        "\n",
        "print(entity_consistency([formal[6]], [informal0[6]]))\n"
      ],
      "metadata": {
        "id": "ICl_h3_5ViFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment class:"
      ],
      "metadata": {
        "id": "hkVPI1gZp9BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment:\n",
        "  def __init__(self, data_X, output):\n",
        "    self.output = output\n",
        "    self.data_X = data_X\n",
        "    self.sbert = SentenceTransformer('paraphrase-albert-small-v2') # We could pick a different model\n",
        "  # TODO: Think of experiments and add booleans and hyperparameters\n",
        "  \n",
        "  def run_experiments(self):\n",
        "    style_in = self.style_class(self.data_X)\n",
        "    near_sci_prob_in = [p[0] for p in style_in]\n",
        "    sci_prob_in = [p[1] for p in style_in]\n",
        "    normal_in =  [p[2] for p in style_in]\n",
        "\n",
        "    style_out = self.style_class(self.output)\n",
        "    near_sci_prob_out = [p[0] for p in style_out]\n",
        "    sci_prob_out = [p[1] for p in style_out]\n",
        "    normal_out =  [p[2] for p in style_out]\n",
        "    \n",
        "    cbcs_out = self.content_by_cosine_similarity(self.data_X, self.output)\n",
        "    c_pres_out = self.content_preservation_score_list(self.data_X, self.output)  \n",
        "    \n",
        "    columns = ['Input Data', 'Probability Near Scientific (input)', 'Probability Scientific (input)', 'Probability Normal (input)', 'Output Data',  'Probability Near Scientific (output)', 'Probability Scientific (output)', 'Probability Normal (output)', 'Cosine Similarity', 'Content Score']\n",
        "    # columns = ['Input Data', 'Probability Informal (input)', 'Probability Formal (input)', 'Output Data',  'Probability Informal (output)', 'Probability Formal (output)', 'Cosine Similarity', 'Content Score']\n",
        "\n",
        "    df = pd.DataFrame(list(zip(self.data_X, near_sci_prob_in, sci_prob_in, normal_in, self.output,  near_sci_prob_out, sci_prob_out, normal_out, cbcs_out, c_pres_out)),\n",
        "               columns =columns)\n",
        "    # df = pd.DataFrame(list(zip(self.data_X, near_sci_prob_in, sci_prob_in, self.output,  near_sci_prob_out, sci_prob_out,cbcs_out, c_pres_out)),\n",
        "    #         columns =columns)\n",
        "    return df\n",
        "\n",
        "  def content_by_cosine_similarity(self, data_X, model_output):\n",
        "    output_list = []\n",
        "    number_of_datapoints = len(data_X)\n",
        "    data_X_embeddings = self.sent_embedding(data_X)\n",
        "    output_embeddings = self.sent_embedding(model_output)\n",
        "\n",
        "    output_sum = 0\n",
        "    avg_output = 0\n",
        "\n",
        "    for i in tqdm(range(number_of_datapoints)):\n",
        "      output_list.append(self.cosine_sim(data_X_embeddings[i], output_embeddings[i]))\n",
        "\n",
        "    return output_list\n",
        "\n",
        "  def style_class(self, li):\n",
        "    return get_style_classification(li)\n",
        "    \n",
        "\n",
        "  def cosine_sim(self, u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "  \"\"\"\n",
        "    Takes in a list of sentences and returns a list of their sentence embedding vector\n",
        "  \"\"\"\n",
        "  def sent_embedding(self, sentences):\n",
        "    tokenized_sent = []\n",
        "    for s in sentences:\n",
        "        tokenized_sent.append(s.lower().replace(\",\", \"\"))\n",
        "    sentence_embeddings = self.sbert.encode(tokenized_sent)\n",
        "    return sentence_embeddings\n",
        "\n",
        "  def content_preservation_score_list(self, l1, l2):\n",
        "    score_list = np.array(evaluate_content_pres_list(args, content_pres_model, l1, l2))\n",
        "    \n",
        "    return score_list[:, 2]\n",
        "\n",
        "\n",
        "class Results:\n",
        "    \n",
        "    \"\"\"\n",
        "      Takes a list of lists of sentence embeddings and colours each list its own colour\n",
        "      A = [[se1, se2, ...., sen],\n",
        "          [se1, se2, ...., sem],\n",
        "          .\n",
        "          .\n",
        "          .\n",
        "          ]\n",
        "    \"\"\"\n",
        "    def visualize_embeddings(self, A, titles, dimensions=2):\n",
        "        reduced_list = []\n",
        "        for a in tqdm(A):\n",
        "          a_reduced = self.reduce_dimensionality(a, dimensions)\n",
        "          reduced_list.append(a_reduced)\n",
        "\n",
        "        color_list = [\"blue\", \"red\", \"green\", \"orange\", \"pink\", \"purple\", \"cyan\"]\n",
        "        \n",
        "        # TODO: 3D plots?\n",
        "        for i in range(len(reduced_list)):\n",
        "          r = reduced_list[i]\n",
        "          color = \"tab:\"+color_list[i]\n",
        "          \n",
        "          plt.scatter(r[:,0], r[:,1], s=10, c=color, label=titles[i])\n",
        "          plt.xlabel(\"PC1\", size=15)\n",
        "          plt.ylabel(\"PC2\", size=15)\n",
        "          plt.title(\"Sentence Embedding Space\",size=20)\n",
        "          plt.legend()\n",
        "          # vocab=list(model.wv.vocab)\n",
        "          # for i, word in enumerate(vocab):\n",
        "          #   plt.annotate(word,xy=(neww_X[i,0],neww_X[i,1]))\n",
        "        plt.show()\n",
        "        \n",
        "        \n",
        "    \"\"\"\n",
        "      Reduces dimensionality of a list of embeddings\n",
        "    \"\"\"\n",
        "    def reduce_dimensionality(self, embedding_list, dimensions=2):\n",
        "      df = pd.DataFrame(embedding_list)\n",
        "      print(df.head())\n",
        "      #Computing the correlation matrix\n",
        "      X_corr=df.corr()\n",
        "\n",
        "      #Computing eigen values and eigen vectors\n",
        "      values,vectors=np.linalg.eig(X_corr)\n",
        "\n",
        "      #Sorting the eigen vectors coresponding to eigen values in descending order\n",
        "      args = (-values).argsort()\n",
        "      values = vectors[args]\n",
        "      vectors = vectors[:, args]\n",
        "\n",
        "      #Taking first 2 components which explain maximum variance for projecting\n",
        "      new_vectors=vectors[:,:dimensions]\n",
        "      #Projecting it onto new dimesion with 2 axis\n",
        "      neww_X=np.dot(embedding_list,new_vectors)\n",
        "      return neww_X\n",
        "        \n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "# experiment_data_model = Experiment(formal, [informal0, informal1, informal2, informal3], output)\n",
        "# cos_exp = experiment_data_model.run_experiments()\n",
        "\n",
        "# print(cos_exp)"
      ],
      "metadata": {
        "id": "fnlOHk8qqDe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1\n"
      ],
      "metadata": {
        "id": "DgaJyepz7e6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gyafc_experiment = Experiment(inputs_data, output_gyafc)\n",
        "\n",
        "paranmt_experiment = Experiment(inputs_data, output_paranmt)\n",
        "\n",
        "combi_experiment = Experiment(inputs_data, output_combi)\n",
        "\n",
        "model1_rewards_experiment = Experiment(inputs_data, output_1_rewards)\n",
        "\n",
        "reference_experiment = Experiment([d[0] for d in total_data_50_50], [d[1] for d in total_data_50_50])"
      ],
      "metadata": {
        "id": "AZOIqi5WqPXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gyafc_exp_results = gyafc_experiment.run_experiments()\n",
        "\n",
        "paranmt_exp_results = paranmt_experiment.run_experiments()\n",
        "\n",
        "combi_exp_results = combi_experiment.run_experiments()\n",
        "model1_rewards_results = model1_rewards_experiment.run_experiments()\n",
        "reference_exp_results = reference_experiment.run_experiments()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffBCP-Y-rOQv",
        "outputId": "0ea12532-5dba-470e-a94a-14aa25f188c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 492.42it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.83it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 504.02it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.10it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 58953.48it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "100%|██████████| 500/500 [00:01<00:00, 484.46it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.15it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 420.66it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.16it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 68617.35it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 496.54it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 462.46it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.16it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 52628.79it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 480.67it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.10it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 456.88it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.09it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 51923.84it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 477.85it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.13it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 446.81it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 54462.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open_file = open(\"reference_exp_results.p\", \"wb\")\n",
        "# pickle.dump(reference_exp_results, open_file)\n",
        "# open_file.close()"
      ],
      "metadata": {
        "id": "Jcq26oQF7TMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gyafc_exp_results.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "8HyCTXcJ7TUk",
        "outputId": "904f8726-9f0b-4131-95b9-1609c43eda7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3233fa6f-f7a1-4613-9533-53aa0eb70862\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Data</th>\n",
              "      <th>Probability Near Scientific (input)</th>\n",
              "      <th>Probability Scientific (input)</th>\n",
              "      <th>Probability Normal (input)</th>\n",
              "      <th>Output Data</th>\n",
              "      <th>Probability Near Scientific (output)</th>\n",
              "      <th>Probability Scientific (output)</th>\n",
              "      <th>Probability Normal (output)</th>\n",
              "      <th>Cosine Similarity</th>\n",
              "      <th>Content Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I do; men break your heart, while friends stay...</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.000395</td>\n",
              "      <td>0.999532</td>\n",
              "      <td>I do, guys break your heart, and friends stay ...</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.999127</td>\n",
              "      <td>0.849838</td>\n",
              "      <td>[0.885752]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You can acquire it from limewire, however you ...</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.999464</td>\n",
              "      <td>you can get it from limewire but you have to d...</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>0.004322</td>\n",
              "      <td>0.995193</td>\n",
              "      <td>0.884448</td>\n",
              "      <td>[0.95166737]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I do not believe you can compare different cas...</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.002962</td>\n",
              "      <td>0.996852</td>\n",
              "      <td>I dont think that you can compare the love bet...</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.001940</td>\n",
              "      <td>0.997873</td>\n",
              "      <td>0.734798</td>\n",
              "      <td>[0.54666406]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>She must have done an edit similar to the one ...</td>\n",
              "      <td>0.009324</td>\n",
              "      <td>0.087812</td>\n",
              "      <td>0.902864</td>\n",
              "      <td>she must have done an edit like the one i just...</td>\n",
              "      <td>0.005649</td>\n",
              "      <td>0.044932</td>\n",
              "      <td>0.949419</td>\n",
              "      <td>0.953915</td>\n",
              "      <td>[0.93886864]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That is how it got where he is today</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>0.003779</td>\n",
              "      <td>0.995931</td>\n",
              "      <td>Thats how it got him where he is today</td>\n",
              "      <td>0.006806</td>\n",
              "      <td>0.143759</td>\n",
              "      <td>0.849435</td>\n",
              "      <td>0.913397</td>\n",
              "      <td>[0.92443675]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3233fa6f-f7a1-4613-9533-53aa0eb70862')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3233fa6f-f7a1-4613-9533-53aa0eb70862 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3233fa6f-f7a1-4613-9533-53aa0eb70862');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          Input Data  ...  Content Score\n",
              "0  I do; men break your heart, while friends stay...  ...     [0.885752]\n",
              "1  You can acquire it from limewire, however you ...  ...   [0.95166737]\n",
              "2  I do not believe you can compare different cas...  ...   [0.54666406]\n",
              "3  She must have done an edit similar to the one ...  ...   [0.93886864]\n",
              "4               That is how it got where he is today  ...   [0.92443675]\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combi_exp_results[\"Probability Scientific (output)\"].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D8Kwgac1L9k",
        "outputId": "2b33e165-6e6d-4923-bf2f-ac1c30b20cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04650130380442715"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_file = open(\"gyafc_exp_results#3.p\", \"wb\")\n",
        "pickle.dump(gyafc_exp_results, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open(\"paranmt_exp_results#3.p\", \"wb\")\n",
        "pickle.dump(paranmt_exp_results, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open(\"combi_exp_results#3.p\", \"wb\")\n",
        "pickle.dump(combi_exp_results, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open(\"reference_exp_results#3.p\", \"wb\")\n",
        "pickle.dump(reference_exp_results, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open(\"model1_rewards_exp_results#3.p\", \"wb\")\n",
        "pickle.dump(model1_rewards_results, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "tCIxnWaRrDmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WxK0H_XCNDwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2"
      ],
      "metadata": {
        "id": "LL-wPtKP7ihN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_experiment_model2_2 = Experiment(input_model2_sample.tolist(), reference_output_model2_sample.tolist())\n",
        "experiment_model2_2 = Experiment(input_model2_sample.tolist(), output_Model2_2)"
      ],
      "metadata": {
        "id": "B05a5tyScF9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "referece_model2_2_results = reference_experiment_model2_2.run_experiments()\n",
        "model2_2_results = experiment_model2_2.run_experiments()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlEPws3A8FXm",
        "outputId": "2ec9109b-f943-4746-a64f-adb7477775d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 230.94it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.15it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 262.97it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.29it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 33412.23it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "100%|██████████| 500/500 [00:01<00:00, 294.61it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.36it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 284.16it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.37it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 20950.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2_2_results[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "6QNuQ1Ja9D5k",
        "outputId": "b8e68a86-4f96-4f07-8b94-e6e3a398e3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3f296b82-578e-46d9-8913-c6baf82ae8ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Data</th>\n",
              "      <th>Probability Near Scientific (input)</th>\n",
              "      <th>Probability Scientific (input)</th>\n",
              "      <th>Probability Normal (input)</th>\n",
              "      <th>Output Data</th>\n",
              "      <th>Probability Near Scientific (output)</th>\n",
              "      <th>Probability Scientific (output)</th>\n",
              "      <th>Probability Normal (output)</th>\n",
              "      <th>Cosine Similarity</th>\n",
              "      <th>Content Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a smoothing filter can be used to introduce ne...</td>\n",
              "      <td>0.001806</td>\n",
              "      <td>0.998056</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>in addition a smoothing filter can be applied ...</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.999498</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.760383</td>\n",
              "      <td>[0.66004336]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the central task is to set all events in order...</td>\n",
              "      <td>0.999562</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>the set of all events is the central task so i...</td>\n",
              "      <td>0.194761</td>\n",
              "      <td>0.803936</td>\n",
              "      <td>0.001303</td>\n",
              "      <td>0.789080</td>\n",
              "      <td>[0.88932616]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in contrast, the prepositional phrase is much ...</td>\n",
              "      <td>0.992247</td>\n",
              "      <td>0.006429</td>\n",
              "      <td>0.001324</td>\n",
              "      <td>in contrast prepositional phrases are much les...</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.999727</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.687328</td>\n",
              "      <td>[0.8193503]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>let's see how the interpreter translates the e...</td>\n",
              "      <td>0.014765</td>\n",
              "      <td>0.082864</td>\n",
              "      <td>0.902371</td>\n",
              "      <td>let us illustrate the interpreter by an example</td>\n",
              "      <td>0.015815</td>\n",
              "      <td>0.984016</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.734198</td>\n",
              "      <td>[0.74434924]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the preferred interpretation is described in t...</td>\n",
              "      <td>0.999094</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>in this terminology we chose the preferred int...</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.999643</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.803896</td>\n",
              "      <td>[0.59940386]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>because our analysis method is based on anova,...</td>\n",
              "      <td>0.999461</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.000367</td>\n",
              "      <td>we chose anova for our analysis method because...</td>\n",
              "      <td>0.556504</td>\n",
              "      <td>0.440061</td>\n",
              "      <td>0.003435</td>\n",
              "      <td>0.942399</td>\n",
              "      <td>[0.9169332]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>so i will say that downstep has no effect on t...</td>\n",
              "      <td>0.994836</td>\n",
              "      <td>0.001788</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>thus i will say that downstep has no effect on...</td>\n",
              "      <td>0.000523</td>\n",
              "      <td>0.999373</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.976326</td>\n",
              "      <td>[0.98404694]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>in deterministic dependency analysis, the naiv...</td>\n",
              "      <td>0.989651</td>\n",
              "      <td>0.009594</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>although strict word by word incrementality is...</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.999730</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.884173</td>\n",
              "      <td>[0.91018593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>that leads to a system in which individual sen...</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>0.999115</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>this results in a system in which individual s...</td>\n",
              "      <td>0.000558</td>\n",
              "      <td>0.999368</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.915688</td>\n",
              "      <td>[0.8824411]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the grammar could not contain the rule in this...</td>\n",
              "      <td>0.319019</td>\n",
              "      <td>0.679880</td>\n",
              "      <td>0.001101</td>\n",
              "      <td>in this case the rule would not have been pres...</td>\n",
              "      <td>0.092962</td>\n",
              "      <td>0.906511</td>\n",
              "      <td>0.000527</td>\n",
              "      <td>0.758552</td>\n",
              "      <td>[0.8105361]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f296b82-578e-46d9-8913-c6baf82ae8ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f296b82-578e-46d9-8913-c6baf82ae8ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f296b82-578e-46d9-8913-c6baf82ae8ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          Input Data  ...  Content Score\n",
              "0  a smoothing filter can be used to introduce ne...  ...   [0.66004336]\n",
              "1  the central task is to set all events in order...  ...   [0.88932616]\n",
              "2  in contrast, the prepositional phrase is much ...  ...    [0.8193503]\n",
              "3  let's see how the interpreter translates the e...  ...   [0.74434924]\n",
              "4  the preferred interpretation is described in t...  ...   [0.59940386]\n",
              "5  because our analysis method is based on anova,...  ...    [0.9169332]\n",
              "6  so i will say that downstep has no effect on t...  ...   [0.98404694]\n",
              "7  in deterministic dependency analysis, the naiv...  ...   [0.91018593]\n",
              "8  that leads to a system in which individual sen...  ...    [0.8824411]\n",
              "9  the grammar could not contain the rule in this...  ...    [0.8105361]\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_file = open(\"referece_model2_2_results.p\", \"wb\")\n",
        "pickle.dump(referece_model2_2_results, open_file)\n",
        "open_file.close()\n",
        "\n",
        "open_file = open(\"model2_2_results.p\", \"wb\")\n",
        "pickle.dump(model2_2_results, open_file)\n",
        "open_file.close()\n"
      ],
      "metadata": {
        "id": "Eqz8Ql8B8Wqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs2_1 = generated_outputs_Model2_1\n",
        "\n",
        "inputs = [np.array_str(np.array([i])) for i in input_model2_sample]\n",
        "print(inputs[:5])\n",
        "print(outputs2_1[:5])\n",
        "exp2_1 = Experiment(inputs, outputs2_1)\n",
        "res_df = exp2_1.run_experiments()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh6uD9l8hciT",
        "outputId": "160b5a0c-df3f-411b-d6af-ffb1040d3f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"['a smoothing filter can be used to introduce new trends into temporally coherent frequencies']\", \"['the central task is to set all events in order, so it can improve.']\", \"['in contrast, the prepositional phrase is much more susceptible to analysis in terms of distribution.']\", '[\"let\\'s see how the interpreter translates the example.\"]', \"['the preferred interpretation is described in this terminology, as we were concerned with the description of the negation and the unmitigated parts of the alternative interpretation.']\"]\n",
            "['new developments in temporal coherent frequency may be introduced using a smoothing filter.', 'the main task is setting up all events so that they can be improved.', 'however, in terms of distribution, this preposition is much more vulnerable than its counterpart.', \"we'll check how the interpreter translates the example.\", 'in this context, we refer to the negation of the implication, as we described in the description of the non-negativity and the undirected part of the alternative interpretation.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 374.61it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.19it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 386.80it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.34it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 50336.08it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open_file = open(\"model2_1_results.p\", \"wb\")\n",
        "pickle.dump(res_df, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "L45YZMyf7Q3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-vw6cdS37Uhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in inputs:\n",
        "  print(type(np.array_str(np.array([i]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGZhL-xa6ha0",
        "outputId": "99734502-a967-4018-f7b8-620a1dce3247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content preservation:\n",
        "> Use Dhruv's work? -> To be experimented with (done, works nicely)\n",
        "> Use sentence embedding and check cosine similarity -> performs nicely on test data & random data. To be decided how well it will work in practice.\n",
        "> Named Entity Consistency -> Necessary? Practically just another content pres method\n",
        "\n",
        "Style classification?\n",
        "> Can we use the style classifier that Daniel made without many issues?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fgNoO8ErsJP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 Rewards"
      ],
      "metadata": {
        "id": "llKxp6f2cw34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_m2_rewards_exp = Experiment(filtered_inputs_model2_rewards, filtered_outputs_model2_rewards)\n",
        "unfiltered_m2_rewards_exp = Experiment(unfiltered_inputs_model2_rewards, unfiltered_outputs_model2_rewards)"
      ],
      "metadata": {
        "id": "HtZxnyUDc28h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_m2_rewards_ex_res = filtered_m2_rewards_exp.run_experiments()\n",
        "unfiltered_m2_rewards_exp_res = unfiltered_m2_rewards_exp.run_experiments()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIbQNFYsdECu",
        "outputId": "ba897629-93e8-4eae-c41d-7ca4e24a1999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456/456 [00:01<00:00, 297.11it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.15it/s]\n",
            "100%|██████████| 456/456 [00:01<00:00, 381.18it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.54it/s]\n",
            "100%|██████████| 456/456 [00:00<00:00, 54476.14it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "100%|██████████| 500/500 [00:01<00:00, 371.28it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.16it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 421.73it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 40992.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_m2_rewards_ex_res[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "UtdI9373dqKl",
        "outputId": "1e68048d-6ec4-4e34-ca67-9e219073fd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-34eb3dc2-6f9e-43b8-861d-31b639260084\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Data</th>\n",
              "      <th>Probability Near Scientific (input)</th>\n",
              "      <th>Probability Scientific (input)</th>\n",
              "      <th>Probability Normal (input)</th>\n",
              "      <th>Output Data</th>\n",
              "      <th>Probability Near Scientific (output)</th>\n",
              "      <th>Probability Scientific (output)</th>\n",
              "      <th>Probability Normal (output)</th>\n",
              "      <th>Cosine Similarity</th>\n",
              "      <th>Content Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;BOS&gt;a smoothing filter can be used to introdu...</td>\n",
              "      <td>0.999817</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>the smoothing filter can be used to incorporat...</td>\n",
              "      <td>0.001189</td>\n",
              "      <td>0.998691</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.877894</td>\n",
              "      <td>[0.6932989]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;BOS&gt;the central task is to set all events in ...</td>\n",
              "      <td>0.999820</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>the central task is to set all events in order...</td>\n",
              "      <td>0.087810</td>\n",
              "      <td>0.911474</td>\n",
              "      <td>0.000716</td>\n",
              "      <td>0.735443</td>\n",
              "      <td>[0.53619653]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;BOS&gt;in contrast, the prepositional phrase is ...</td>\n",
              "      <td>0.997222</td>\n",
              "      <td>0.001775</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>in contrast prepositional phrases are much mor...</td>\n",
              "      <td>0.000196</td>\n",
              "      <td>0.999720</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.700795</td>\n",
              "      <td>[0.65776724]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;BOS&gt;let's see how the interpreter translates ...</td>\n",
              "      <td>0.002663</td>\n",
              "      <td>0.007904</td>\n",
              "      <td>0.989433</td>\n",
              "      <td>let us illustrate this by translating an example</td>\n",
              "      <td>0.271463</td>\n",
              "      <td>0.728051</td>\n",
              "      <td>0.000486</td>\n",
              "      <td>0.289878</td>\n",
              "      <td>[0.37527555]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;BOS&gt;the preferred interpretation is described...</td>\n",
              "      <td>0.999327</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>this terminology was chosen to describe our pr...</td>\n",
              "      <td>0.000353</td>\n",
              "      <td>0.999566</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.726457</td>\n",
              "      <td>[0.7178316]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;BOS&gt;so i will say that downstep has no effect...</td>\n",
              "      <td>0.995680</td>\n",
              "      <td>0.001615</td>\n",
              "      <td>0.002704</td>\n",
              "      <td>let me say that downstep has no effect on tone...</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.999273</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.878363</td>\n",
              "      <td>[0.8148562]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;BOS&gt;in deterministic dependency analysis, the...</td>\n",
              "      <td>0.987800</td>\n",
              "      <td>0.011449</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>although strict word by word incrementality is...</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>0.999729</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.814344</td>\n",
              "      <td>[0.8202529]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;BOS&gt;that leads to a system in which individua...</td>\n",
              "      <td>0.999804</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>this leads to a system in which individual sen...</td>\n",
              "      <td>0.000834</td>\n",
              "      <td>0.999089</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>0.702071</td>\n",
              "      <td>[0.7500034]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;BOS&gt;the grammar could not contain the rule in...</td>\n",
              "      <td>0.302758</td>\n",
              "      <td>0.696087</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>in this case the rule in the grammar could not...</td>\n",
              "      <td>0.107929</td>\n",
              "      <td>0.891589</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>0.560781</td>\n",
              "      <td>[0.50345474]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;BOS&gt; shown in the left and right bracket is a...</td>\n",
              "      <td>0.999730</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>we will call this symbol the left and right br...</td>\n",
              "      <td>0.027191</td>\n",
              "      <td>0.972655</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.610840</td>\n",
              "      <td>[0.68740374]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34eb3dc2-6f9e-43b8-861d-31b639260084')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34eb3dc2-6f9e-43b8-861d-31b639260084 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34eb3dc2-6f9e-43b8-861d-31b639260084');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          Input Data  ...  Content Score\n",
              "0  <BOS>a smoothing filter can be used to introdu...  ...    [0.6932989]\n",
              "1  <BOS>the central task is to set all events in ...  ...   [0.53619653]\n",
              "2  <BOS>in contrast, the prepositional phrase is ...  ...   [0.65776724]\n",
              "3  <BOS>let's see how the interpreter translates ...  ...   [0.37527555]\n",
              "4  <BOS>the preferred interpretation is described...  ...    [0.7178316]\n",
              "5  <BOS>so i will say that downstep has no effect...  ...    [0.8148562]\n",
              "6  <BOS>in deterministic dependency analysis, the...  ...    [0.8202529]\n",
              "7  <BOS>that leads to a system in which individua...  ...    [0.7500034]\n",
              "8  <BOS>the grammar could not contain the rule in...  ...   [0.50345474]\n",
              "9  <BOS> shown in the left and right bracket is a...  ...   [0.68740374]\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(filtered_m2_rewards_ex_res, open(\"filtered_m2_rewards_results\", \"wb\"))\n",
        "pickle.dump(unfiltered_m2_rewards_exp_res, open(\"unfiltered_m2_rewards_results\", \"wb\"))"
      ],
      "metadata": {
        "id": "qrIHL_1UdXAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 context"
      ],
      "metadata": {
        "id": "5lForLXAiV2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m2_context_exp = Experiment(m2_context_non_scientific, m2_context_output)\n",
        "m2_context_ref_exp = Experiment(m2_context_non_scientific, m2_context_original)"
      ],
      "metadata": {
        "id": "6_5kt66DiYW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2_context_exp_res = m2_context_exp.run_experiments()\n",
        "m2_context_ref_exp_res = m2_context_ref_exp.run_experiments()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCddoq7jii_V",
        "outputId": "a022f7ee-f34e-4cc0-c37c-a1d321c47656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 359.43it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.96it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 392.88it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.13it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 57878.02it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "100%|██████████| 500/500 [00:01<00:00, 417.38it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.10it/s]\n",
            "100%|██████████| 500/500 [00:01<00:00, 377.53it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 54979.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2_context_exp_res"
      ],
      "metadata": {
        "id": "8-KxTXVZiwCh",
        "outputId": "7249673f-9280-45dc-de7f-486f340bbe3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0670e6f2-6458-4233-8973-1d63f50826c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input Data</th>\n",
              "      <th>Probability Near Scientific (input)</th>\n",
              "      <th>Probability Scientific (input)</th>\n",
              "      <th>Probability Normal (input)</th>\n",
              "      <th>Output Data</th>\n",
              "      <th>Probability Near Scientific (output)</th>\n",
              "      <th>Probability Scientific (output)</th>\n",
              "      <th>Probability Normal (output)</th>\n",
              "      <th>Cosine Similarity</th>\n",
              "      <th>Content Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it's pretty much the same</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.001737</td>\n",
              "      <td>0.998099</td>\n",
              "      <td>the main difference is the choice of the ener...</td>\n",
              "      <td>0.067840</td>\n",
              "      <td>0.927990</td>\n",
              "      <td>0.004170</td>\n",
              "      <td>0.125733</td>\n",
              "      <td>[0.13104077]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we are glad the ref gave us some help on this ...</td>\n",
              "      <td>0.025995</td>\n",
              "      <td>0.963498</td>\n",
              "      <td>0.010507</td>\n",
              "      <td>we are grateful to the referee for helpful co...</td>\n",
              "      <td>0.012910</td>\n",
              "      <td>0.986724</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>0.487005</td>\n",
              "      <td>[0.56301093]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i think that schmidt orthogonalizes to some de...</td>\n",
              "      <td>0.544763</td>\n",
              "      <td>0.207523</td>\n",
              "      <td>0.247714</td>\n",
              "      <td>schmidt orthogonalization</td>\n",
              "      <td>0.892277</td>\n",
              "      <td>0.086715</td>\n",
              "      <td>0.021008</td>\n",
              "      <td>0.815151</td>\n",
              "      <td>[0.86065334]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dw: hey guys, we got your back!</td>\n",
              "      <td>0.001146</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>0.998572</td>\n",
              "      <td>dw acknowledges support from the stfc</td>\n",
              "      <td>0.007730</td>\n",
              "      <td>0.991318</td>\n",
              "      <td>0.000953</td>\n",
              "      <td>0.373700</td>\n",
              "      <td>[0.30775064]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it might help us understand the thermal evolut...</td>\n",
              "      <td>0.585828</td>\n",
              "      <td>0.398061</td>\n",
              "      <td>0.016110</td>\n",
              "      <td>it might help us understand the thermal evolu...</td>\n",
              "      <td>0.585828</td>\n",
              "      <td>0.398061</td>\n",
              "      <td>0.016110</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[0.9999999]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>but this is left for future work</td>\n",
              "      <td>0.093230</td>\n",
              "      <td>0.904126</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>this is left for future work</td>\n",
              "      <td>0.097955</td>\n",
              "      <td>0.897543</td>\n",
              "      <td>0.004502</td>\n",
              "      <td>0.944470</td>\n",
              "      <td>[0.91882527]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>we re-write it every so often</td>\n",
              "      <td>0.031254</td>\n",
              "      <td>0.248788</td>\n",
              "      <td>0.719958</td>\n",
              "      <td>we rewrite eq</td>\n",
              "      <td>0.989642</td>\n",
              "      <td>0.010077</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.456383</td>\n",
              "      <td>[0.47616237]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>we determine all factors directly</td>\n",
              "      <td>0.370174</td>\n",
              "      <td>0.624217</td>\n",
              "      <td>0.005609</td>\n",
              "      <td>we determine all factors directly</td>\n",
              "      <td>0.370174</td>\n",
              "      <td>0.624217</td>\n",
              "      <td>0.005609</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[0.9999999]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>because now the pair doesn't just produce one ...</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.002037</td>\n",
              "      <td>0.997705</td>\n",
              "      <td>hence, the pair production now produces two p...</td>\n",
              "      <td>0.999107</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000727</td>\n",
              "      <td>0.836305</td>\n",
              "      <td>[0.69469213]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>filling shows the phase separation regions</td>\n",
              "      <td>0.963979</td>\n",
              "      <td>0.034256</td>\n",
              "      <td>0.001765</td>\n",
              "      <td>filling shows the phase separation regions</td>\n",
              "      <td>0.963979</td>\n",
              "      <td>0.034256</td>\n",
              "      <td>0.001765</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[1.0000001]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0670e6f2-6458-4233-8973-1d63f50826c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0670e6f2-6458-4233-8973-1d63f50826c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0670e6f2-6458-4233-8973-1d63f50826c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Input Data  ...  Content Score\n",
              "0                            it's pretty much the same  ...   [0.13104077]\n",
              "1    we are glad the ref gave us some help on this ...  ...   [0.56301093]\n",
              "2    i think that schmidt orthogonalizes to some de...  ...   [0.86065334]\n",
              "3                      dw: hey guys, we got your back!  ...   [0.30775064]\n",
              "4    it might help us understand the thermal evolut...  ...    [0.9999999]\n",
              "..                                                 ...  ...            ...\n",
              "495                   but this is left for future work  ...   [0.91882527]\n",
              "496                      we re-write it every so often  ...   [0.47616237]\n",
              "497                  we determine all factors directly  ...    [0.9999999]\n",
              "498  because now the pair doesn't just produce one ...  ...   [0.69469213]\n",
              "499         filling shows the phase separation regions  ...    [1.0000001]\n",
              "\n",
              "[500 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(m2_context_exp_res, open(\"m2_context_exp_res\", \"wb\"))\n",
        "pickle.dump(m2_context_ref_exp_res, open(\"m2_context_ref_exp_res\", \"wb\"))"
      ],
      "metadata": {
        "id": "LFHFYVppioxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3geOH1Pl2xaq"
      },
      "source": [
        "# Generating Outputs:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1:"
      ],
      "metadata": {
        "id": "U2gfOHZb3ige"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxEK32vTyfI9"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Add tokens to sentences - REPLACE \"formal\" WITH THE INPUTS SENTENCES\n",
        "\n",
        "\n",
        "# Making data: taking the formal sentences and adding tokens, put it in a list\n",
        "inputs = []\n",
        "\n",
        "for i in total_model2_sample:\n",
        "  sentence = \"<BOS>\" + i[0] + \"<SCI_GEN>\"\n",
        "  inputs.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(inputs)"
      ],
      "metadata": {
        "id": "17I73vP3M7hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e53d0dd-3d50-41d0-8069-a13e100baacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDnR2nFgyQVo"
      },
      "outputs": [],
      "source": [
        "# STEP 2: Tokenize inputs for the models into their individual lists\n",
        "model_titles = [\"Model2_rewards\"]\n",
        "\n",
        "# Tokenizing the inputs for the PARANMT model (input_ids_P) and GYAFC model (input_ids_G)\n",
        "input_ids_P = [] # For the PARANMT Model\n",
        "# input_ids_G = [] # For the GYAFC Model\n",
        "# input_ids_C = [] # For the Combi Model\n",
        "for sent in inputs:\n",
        "  input_ids_P.append(tokenizer_2_rewards.encode(sent, return_tensors='pt'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_all = [input_ids_P]\n",
        "models = [model_2_rewards]\n",
        "tokenizers = [tokenizer_2_rewards]"
      ],
      "metadata": {
        "id": "siueyt7AznIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEyDYIy10f-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6752eded-3f57-4c5f-f022-03f36f8dfa9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/500 [00:07<1:02:59,  7.57s/it]\u001b[A\n",
            "  0%|          | 2/500 [00:15<1:02:17,  7.50s/it]\u001b[A\n",
            "  1%|          | 3/500 [00:22<1:00:52,  7.35s/it]\u001b[A\n",
            "  1%|          | 4/500 [00:29<1:02:13,  7.53s/it]\u001b[A\n",
            "  1%|          | 5/500 [00:36<58:22,  7.08s/it]  \u001b[A\n",
            "  1%|          | 6/500 [00:43<57:44,  7.01s/it]\u001b[A\n",
            "  1%|▏         | 7/500 [00:49<55:49,  6.79s/it]\u001b[A\n",
            "  2%|▏         | 8/500 [00:55<54:27,  6.64s/it]\u001b[A\n",
            "  2%|▏         | 9/500 [01:02<55:26,  6.77s/it]\u001b[A\n",
            "  2%|▏         | 10/500 [01:10<57:57,  7.10s/it]\u001b[A\n",
            "  2%|▏         | 11/500 [01:17<55:54,  6.86s/it]\u001b[A\n",
            "  2%|▏         | 12/500 [01:23<55:51,  6.87s/it]\u001b[A\n",
            "  3%|▎         | 13/500 [01:32<58:50,  7.25s/it]\u001b[A\n",
            "  3%|▎         | 14/500 [01:39<1:00:11,  7.43s/it]\u001b[A\n",
            "  3%|▎         | 15/500 [01:47<1:00:45,  7.52s/it]\u001b[A\n",
            "  3%|▎         | 16/500 [01:55<1:00:32,  7.51s/it]\u001b[A\n",
            "  3%|▎         | 17/500 [02:01<58:40,  7.29s/it]  \u001b[A\n",
            "  4%|▎         | 18/500 [02:09<1:00:21,  7.51s/it]\u001b[A\n",
            "  4%|▍         | 19/500 [02:16<58:52,  7.34s/it]  \u001b[A\n",
            "  4%|▍         | 20/500 [02:24<58:35,  7.32s/it]\u001b[A\n",
            "  4%|▍         | 21/500 [02:31<58:04,  7.27s/it]\u001b[A\n",
            "  4%|▍         | 22/500 [02:38<58:31,  7.35s/it]\u001b[A\n",
            "  5%|▍         | 23/500 [02:44<55:32,  6.99s/it]\u001b[A\n",
            "  5%|▍         | 24/500 [02:52<56:50,  7.16s/it]\u001b[A\n",
            "  5%|▌         | 25/500 [02:59<56:23,  7.12s/it]\u001b[A\n",
            "  5%|▌         | 26/500 [03:06<56:33,  7.16s/it]\u001b[A\n",
            "  5%|▌         | 27/500 [03:14<57:56,  7.35s/it]\u001b[A\n",
            "  6%|▌         | 28/500 [03:21<57:50,  7.35s/it]\u001b[A\n",
            "  6%|▌         | 29/500 [03:29<57:47,  7.36s/it]\u001b[A\n",
            "  6%|▌         | 30/500 [03:35<55:53,  7.13s/it]\u001b[A\n",
            "  6%|▌         | 31/500 [03:43<56:55,  7.28s/it]\u001b[A\n",
            "  6%|▋         | 32/500 [03:51<57:33,  7.38s/it]\u001b[A\n",
            "  7%|▋         | 33/500 [03:58<56:59,  7.32s/it]\u001b[A\n",
            "  7%|▋         | 34/500 [04:06<58:09,  7.49s/it]\u001b[A\n",
            "  7%|▋         | 35/500 [04:13<57:53,  7.47s/it]\u001b[A\n",
            "  7%|▋         | 36/500 [04:21<58:34,  7.57s/it]\u001b[A\n",
            "  7%|▋         | 37/500 [04:28<56:37,  7.34s/it]\u001b[A\n",
            "  8%|▊         | 38/500 [04:35<55:58,  7.27s/it]\u001b[A\n",
            "  8%|▊         | 39/500 [04:41<53:35,  6.98s/it]\u001b[A\n",
            "  8%|▊         | 40/500 [04:49<54:36,  7.12s/it]\u001b[A\n",
            "  8%|▊         | 41/500 [04:56<56:05,  7.33s/it]\u001b[A\n",
            "  8%|▊         | 42/500 [05:04<56:01,  7.34s/it]\u001b[A\n",
            "  9%|▊         | 43/500 [05:11<54:46,  7.19s/it]\u001b[A\n",
            "  9%|▉         | 44/500 [05:18<54:35,  7.18s/it]\u001b[A\n",
            "  9%|▉         | 45/500 [05:25<55:16,  7.29s/it]\u001b[A\n",
            "  9%|▉         | 46/500 [05:33<56:06,  7.42s/it]\u001b[A\n",
            "  9%|▉         | 47/500 [05:40<55:22,  7.33s/it]\u001b[A\n",
            " 10%|▉         | 48/500 [05:48<56:05,  7.45s/it]\u001b[A\n",
            " 10%|▉         | 49/500 [05:55<54:37,  7.27s/it]\u001b[A\n",
            " 10%|█         | 50/500 [06:02<54:02,  7.21s/it]\u001b[A\n",
            " 10%|█         | 51/500 [06:09<54:35,  7.29s/it]\u001b[A\n",
            " 10%|█         | 52/500 [06:17<55:00,  7.37s/it]\u001b[A\n",
            " 11%|█         | 53/500 [06:24<55:22,  7.43s/it]\u001b[A\n",
            " 11%|█         | 54/500 [06:32<55:28,  7.46s/it]\u001b[A\n",
            " 11%|█         | 55/500 [06:39<55:00,  7.42s/it]\u001b[A\n",
            " 11%|█         | 56/500 [06:46<53:07,  7.18s/it]\u001b[A\n",
            " 11%|█▏        | 57/500 [06:52<51:28,  6.97s/it]\u001b[A\n",
            " 12%|█▏        | 58/500 [07:00<52:57,  7.19s/it]\u001b[A\n",
            " 12%|█▏        | 59/500 [07:07<53:11,  7.24s/it]\u001b[A\n",
            " 12%|█▏        | 60/500 [07:15<53:31,  7.30s/it]\u001b[A\n",
            " 12%|█▏        | 61/500 [07:22<53:44,  7.35s/it]\u001b[A\n",
            " 12%|█▏        | 62/500 [07:30<53:40,  7.35s/it]\u001b[A\n",
            " 13%|█▎        | 63/500 [07:37<53:03,  7.29s/it]\u001b[A\n",
            " 13%|█▎        | 64/500 [07:44<53:13,  7.33s/it]\u001b[A\n",
            " 13%|█▎        | 65/500 [07:51<52:15,  7.21s/it]\u001b[A\n",
            " 13%|█▎        | 66/500 [07:59<53:39,  7.42s/it]\u001b[A\n",
            " 13%|█▎        | 67/500 [08:06<52:56,  7.34s/it]\u001b[A\n",
            " 14%|█▎        | 68/500 [08:13<51:39,  7.18s/it]\u001b[A\n",
            " 14%|█▍        | 69/500 [08:20<50:09,  6.98s/it]\u001b[A\n",
            " 14%|█▍        | 70/500 [08:25<47:14,  6.59s/it]\u001b[A\n",
            " 14%|█▍        | 71/500 [08:32<48:18,  6.76s/it]\u001b[A\n",
            " 14%|█▍        | 72/500 [08:40<50:27,  7.07s/it]\u001b[A\n",
            " 15%|█▍        | 73/500 [08:48<51:28,  7.23s/it]\u001b[A\n",
            " 15%|█▍        | 74/500 [08:54<49:10,  6.93s/it]\u001b[A\n",
            " 15%|█▌        | 75/500 [09:02<50:18,  7.10s/it]\u001b[A\n",
            " 15%|█▌        | 76/500 [09:09<51:34,  7.30s/it]\u001b[A\n",
            " 15%|█▌        | 77/500 [09:17<52:16,  7.41s/it]\u001b[A\n",
            " 16%|█▌        | 78/500 [09:24<51:59,  7.39s/it]\u001b[A\n",
            " 16%|█▌        | 79/500 [09:32<52:17,  7.45s/it]\u001b[A\n",
            " 16%|█▌        | 80/500 [09:39<51:12,  7.32s/it]\u001b[A\n",
            " 16%|█▌        | 81/500 [09:46<49:58,  7.16s/it]\u001b[A\n",
            " 16%|█▋        | 82/500 [09:54<51:23,  7.38s/it]\u001b[A\n",
            " 17%|█▋        | 83/500 [10:00<48:20,  6.96s/it]\u001b[A\n",
            " 17%|█▋        | 84/500 [10:07<49:19,  7.11s/it]\u001b[A\n",
            " 17%|█▋        | 85/500 [10:15<50:44,  7.34s/it]\u001b[A\n",
            " 17%|█▋        | 86/500 [10:22<50:32,  7.33s/it]\u001b[A\n",
            " 17%|█▋        | 87/500 [10:30<51:25,  7.47s/it]\u001b[A\n",
            " 18%|█▊        | 88/500 [10:37<50:09,  7.31s/it]\u001b[A\n",
            " 18%|█▊        | 89/500 [10:44<49:25,  7.21s/it]\u001b[A\n",
            " 18%|█▊        | 90/500 [10:50<46:38,  6.83s/it]\u001b[A\n",
            " 18%|█▊        | 91/500 [10:57<47:12,  6.93s/it]\u001b[A\n",
            " 18%|█▊        | 92/500 [11:04<47:17,  6.95s/it]\u001b[A\n",
            " 19%|█▊        | 93/500 [11:11<47:39,  7.03s/it]\u001b[A\n",
            " 19%|█▉        | 94/500 [11:18<47:40,  7.05s/it]\u001b[A\n",
            " 19%|█▉        | 95/500 [11:25<47:26,  7.03s/it]\u001b[A\n",
            " 19%|█▉        | 96/500 [11:33<48:49,  7.25s/it]\u001b[A\n",
            " 19%|█▉        | 97/500 [11:40<48:01,  7.15s/it]\u001b[A\n",
            " 20%|█▉        | 98/500 [11:47<47:45,  7.13s/it]\u001b[A\n",
            " 20%|█▉        | 99/500 [11:55<48:42,  7.29s/it]\u001b[A\n",
            " 20%|██        | 100/500 [12:02<48:31,  7.28s/it]\u001b[A\n",
            " 20%|██        | 101/500 [12:09<48:37,  7.31s/it]\u001b[A\n",
            " 20%|██        | 102/500 [12:17<49:12,  7.42s/it]\u001b[A\n",
            " 21%|██        | 103/500 [12:25<49:20,  7.46s/it]\u001b[A\n",
            " 21%|██        | 104/500 [12:31<47:33,  7.21s/it]\u001b[A\n",
            " 21%|██        | 105/500 [12:39<48:35,  7.38s/it]\u001b[A\n",
            " 21%|██        | 106/500 [12:46<48:32,  7.39s/it]\u001b[A\n",
            " 21%|██▏       | 107/500 [12:53<46:34,  7.11s/it]\u001b[A\n",
            " 22%|██▏       | 108/500 [13:00<45:54,  7.03s/it]\u001b[A\n",
            " 22%|██▏       | 109/500 [13:06<44:11,  6.78s/it]\u001b[A\n",
            " 22%|██▏       | 110/500 [13:13<45:22,  6.98s/it]\u001b[A\n",
            " 22%|██▏       | 111/500 [13:21<45:57,  7.09s/it]\u001b[A\n",
            " 22%|██▏       | 112/500 [13:28<46:42,  7.22s/it]\u001b[A\n",
            " 23%|██▎       | 113/500 [13:35<45:05,  6.99s/it]\u001b[A\n",
            " 23%|██▎       | 114/500 [13:42<46:18,  7.20s/it]\u001b[A\n",
            " 23%|██▎       | 115/500 [13:50<47:53,  7.46s/it]\u001b[A\n",
            " 23%|██▎       | 116/500 [13:56<43:13,  6.75s/it]\u001b[A\n",
            " 23%|██▎       | 117/500 [14:03<45:12,  7.08s/it]\u001b[A\n",
            " 24%|██▎       | 118/500 [14:11<45:25,  7.13s/it]\u001b[A\n",
            " 24%|██▍       | 119/500 [14:18<46:04,  7.26s/it]\u001b[A\n",
            " 24%|██▍       | 120/500 [14:25<45:54,  7.25s/it]\u001b[A\n",
            " 24%|██▍       | 121/500 [14:33<45:46,  7.25s/it]\u001b[A\n",
            " 24%|██▍       | 122/500 [14:39<43:25,  6.89s/it]\u001b[A\n",
            " 25%|██▍       | 123/500 [14:44<39:39,  6.31s/it]\u001b[A\n",
            " 25%|██▍       | 124/500 [14:51<41:13,  6.58s/it]\u001b[A\n",
            " 25%|██▌       | 125/500 [14:59<43:28,  6.96s/it]\u001b[A\n",
            " 25%|██▌       | 126/500 [15:06<43:33,  6.99s/it]\u001b[A\n",
            " 25%|██▌       | 127/500 [15:13<44:04,  7.09s/it]\u001b[A\n",
            " 26%|██▌       | 128/500 [15:20<44:11,  7.13s/it]\u001b[A\n",
            " 26%|██▌       | 129/500 [15:27<42:42,  6.91s/it]\u001b[A\n",
            " 26%|██▌       | 130/500 [15:34<43:11,  7.01s/it]\u001b[A\n",
            " 26%|██▌       | 131/500 [15:41<43:28,  7.07s/it]\u001b[A\n",
            " 26%|██▋       | 132/500 [15:48<42:36,  6.95s/it]\u001b[A\n",
            " 27%|██▋       | 133/500 [15:55<42:41,  6.98s/it]\u001b[A\n",
            " 27%|██▋       | 134/500 [16:02<43:26,  7.12s/it]\u001b[A\n",
            " 27%|██▋       | 135/500 [16:10<43:52,  7.21s/it]\u001b[A\n",
            " 27%|██▋       | 136/500 [16:18<44:48,  7.39s/it]\u001b[A\n",
            " 27%|██▋       | 137/500 [16:25<44:57,  7.43s/it]\u001b[A\n",
            " 28%|██▊       | 138/500 [16:33<45:35,  7.56s/it]\u001b[A\n",
            " 28%|██▊       | 139/500 [16:40<45:10,  7.51s/it]\u001b[A\n",
            " 28%|██▊       | 140/500 [16:47<44:00,  7.34s/it]\u001b[A\n",
            " 28%|██▊       | 141/500 [16:55<44:11,  7.39s/it]\u001b[A\n",
            " 28%|██▊       | 142/500 [17:02<43:25,  7.28s/it]\u001b[A\n",
            " 29%|██▊       | 143/500 [17:09<42:44,  7.18s/it]\u001b[A\n",
            " 29%|██▉       | 144/500 [17:16<42:50,  7.22s/it]\u001b[A\n",
            " 29%|██▉       | 145/500 [17:23<42:36,  7.20s/it]\u001b[A\n",
            " 29%|██▉       | 146/500 [17:31<43:06,  7.31s/it]\u001b[A\n",
            " 29%|██▉       | 147/500 [17:38<42:57,  7.30s/it]\u001b[A\n",
            " 30%|██▉       | 148/500 [17:46<43:36,  7.43s/it]\u001b[A\n",
            " 30%|██▉       | 149/500 [17:53<42:45,  7.31s/it]\u001b[A\n",
            " 30%|███       | 150/500 [17:59<41:22,  7.09s/it]\u001b[A\n",
            " 30%|███       | 151/500 [18:07<42:23,  7.29s/it]\u001b[A\n",
            " 30%|███       | 152/500 [18:15<42:53,  7.40s/it]\u001b[A\n",
            " 31%|███       | 153/500 [18:22<42:18,  7.31s/it]\u001b[A\n",
            " 31%|███       | 154/500 [18:29<41:39,  7.22s/it]\u001b[A\n",
            " 31%|███       | 155/500 [18:36<40:38,  7.07s/it]\u001b[A\n",
            " 31%|███       | 156/500 [18:42<39:18,  6.86s/it]\u001b[A\n",
            " 31%|███▏      | 157/500 [18:49<39:54,  6.98s/it]\u001b[A\n",
            " 32%|███▏      | 158/500 [18:56<39:42,  6.97s/it]\u001b[A\n",
            " 32%|███▏      | 159/500 [19:03<39:47,  7.00s/it]\u001b[A\n",
            " 32%|███▏      | 160/500 [19:10<39:39,  7.00s/it]\u001b[A\n",
            " 32%|███▏      | 161/500 [19:17<39:50,  7.05s/it]\u001b[A\n",
            " 32%|███▏      | 162/500 [19:25<40:48,  7.24s/it]\u001b[A\n",
            " 33%|███▎      | 163/500 [19:32<40:04,  7.14s/it]\u001b[A\n",
            " 33%|███▎      | 164/500 [19:39<39:27,  7.05s/it]\u001b[A\n",
            " 33%|███▎      | 165/500 [19:47<40:23,  7.23s/it]\u001b[A\n",
            " 33%|███▎      | 166/500 [19:53<39:15,  7.05s/it]\u001b[A\n",
            " 33%|███▎      | 167/500 [20:00<38:03,  6.86s/it]\u001b[A\n",
            " 34%|███▎      | 168/500 [20:06<37:40,  6.81s/it]\u001b[A\n",
            " 34%|███▍      | 169/500 [20:14<39:02,  7.08s/it]\u001b[A\n",
            " 34%|███▍      | 170/500 [20:21<38:27,  6.99s/it]\u001b[A\n",
            " 34%|███▍      | 171/500 [20:28<37:58,  6.93s/it]\u001b[A\n",
            " 34%|███▍      | 172/500 [20:35<38:22,  7.02s/it]\u001b[A\n",
            " 35%|███▍      | 173/500 [20:42<38:36,  7.08s/it]\u001b[A\n",
            " 35%|███▍      | 174/500 [20:49<38:26,  7.08s/it]\u001b[A\n",
            " 35%|███▌      | 175/500 [20:56<37:40,  6.95s/it]\u001b[A\n",
            " 35%|███▌      | 176/500 [21:03<38:38,  7.16s/it]\u001b[A\n",
            " 35%|███▌      | 177/500 [21:10<37:58,  7.05s/it]\u001b[A\n",
            " 36%|███▌      | 178/500 [21:17<38:08,  7.11s/it]\u001b[A\n",
            " 36%|███▌      | 179/500 [21:25<39:12,  7.33s/it]\u001b[A\n",
            " 36%|███▌      | 180/500 [21:31<36:43,  6.89s/it]\u001b[A\n",
            " 36%|███▌      | 181/500 [21:39<37:33,  7.06s/it]\u001b[A\n",
            " 36%|███▋      | 182/500 [21:45<36:24,  6.87s/it]\u001b[A\n",
            " 37%|███▋      | 183/500 [21:52<36:12,  6.85s/it]\u001b[A\n",
            " 37%|███▋      | 184/500 [21:59<37:02,  7.03s/it]\u001b[A\n",
            " 37%|███▋      | 185/500 [22:07<37:12,  7.09s/it]\u001b[A\n",
            " 37%|███▋      | 186/500 [22:13<36:49,  7.04s/it]\u001b[A\n",
            " 37%|███▋      | 187/500 [22:20<36:24,  6.98s/it]\u001b[A\n",
            " 38%|███▊      | 188/500 [22:28<37:12,  7.15s/it]\u001b[A\n",
            " 38%|███▊      | 189/500 [22:36<38:10,  7.36s/it]\u001b[A\n",
            " 38%|███▊      | 190/500 [22:43<38:26,  7.44s/it]\u001b[A\n",
            " 38%|███▊      | 191/500 [22:51<38:44,  7.52s/it]\u001b[A\n",
            " 38%|███▊      | 192/500 [22:58<37:35,  7.32s/it]\u001b[A\n",
            " 39%|███▊      | 193/500 [23:05<37:30,  7.33s/it]\u001b[A\n",
            " 39%|███▉      | 194/500 [23:12<37:02,  7.26s/it]\u001b[A\n",
            " 39%|███▉      | 195/500 [23:20<37:17,  7.33s/it]\u001b[A\n",
            " 39%|███▉      | 196/500 [23:27<36:35,  7.22s/it]\u001b[A\n",
            " 39%|███▉      | 197/500 [23:34<36:48,  7.29s/it]\u001b[A\n",
            " 40%|███▉      | 198/500 [23:40<34:55,  6.94s/it]\u001b[A\n",
            " 40%|███▉      | 199/500 [23:48<35:19,  7.04s/it]\u001b[A\n",
            " 40%|████      | 200/500 [23:54<34:45,  6.95s/it]\u001b[A\n",
            " 40%|████      | 201/500 [24:02<36:02,  7.23s/it]\u001b[A\n",
            " 40%|████      | 202/500 [24:09<35:30,  7.15s/it]\u001b[A\n",
            " 41%|████      | 203/500 [24:16<35:01,  7.08s/it]\u001b[A\n",
            " 41%|████      | 204/500 [24:23<35:05,  7.11s/it]\u001b[A\n",
            " 41%|████      | 205/500 [24:31<35:39,  7.25s/it]\u001b[A\n",
            " 41%|████      | 206/500 [24:36<32:44,  6.68s/it]\u001b[A\n",
            " 41%|████▏     | 207/500 [24:43<33:03,  6.77s/it]\u001b[A\n",
            " 42%|████▏     | 208/500 [24:49<32:09,  6.61s/it]\u001b[A\n",
            " 42%|████▏     | 209/500 [24:56<31:54,  6.58s/it]\u001b[A\n",
            " 42%|████▏     | 210/500 [25:04<33:15,  6.88s/it]\u001b[A\n",
            " 42%|████▏     | 211/500 [25:11<33:58,  7.05s/it]\u001b[A\n",
            " 42%|████▏     | 212/500 [25:18<33:02,  6.88s/it]\u001b[A\n",
            " 43%|████▎     | 213/500 [25:25<34:10,  7.15s/it]\u001b[A\n",
            " 43%|████▎     | 214/500 [25:31<31:25,  6.59s/it]\u001b[A\n",
            " 43%|████▎     | 215/500 [25:37<31:01,  6.53s/it]\u001b[A\n",
            " 43%|████▎     | 216/500 [25:44<32:16,  6.82s/it]\u001b[A\n",
            " 43%|████▎     | 217/500 [25:52<33:18,  7.06s/it]\u001b[A\n",
            " 44%|████▎     | 218/500 [25:58<31:50,  6.77s/it]\u001b[A\n",
            " 44%|████▍     | 219/500 [26:05<31:28,  6.72s/it]\u001b[A\n",
            " 44%|████▍     | 220/500 [26:13<32:59,  7.07s/it]\u001b[A\n",
            " 44%|████▍     | 221/500 [26:19<32:02,  6.89s/it]\u001b[A\n",
            " 44%|████▍     | 222/500 [26:26<31:49,  6.87s/it]\u001b[A\n",
            " 45%|████▍     | 223/500 [26:33<32:22,  7.01s/it]\u001b[A\n",
            " 45%|████▍     | 224/500 [26:40<32:25,  7.05s/it]\u001b[A\n",
            " 45%|████▌     | 225/500 [26:48<32:22,  7.07s/it]\u001b[A\n",
            " 45%|████▌     | 226/500 [26:55<32:19,  7.08s/it]\u001b[A\n",
            " 45%|████▌     | 227/500 [27:02<32:40,  7.18s/it]\u001b[A\n",
            " 46%|████▌     | 228/500 [27:09<31:45,  7.00s/it]\u001b[A\n",
            " 46%|████▌     | 229/500 [27:16<32:27,  7.19s/it]\u001b[A\n",
            " 46%|████▌     | 230/500 [27:23<31:29,  7.00s/it]\u001b[A\n",
            " 46%|████▌     | 231/500 [27:30<32:04,  7.15s/it]\u001b[A\n",
            " 46%|████▋     | 232/500 [27:37<31:22,  7.02s/it]\u001b[A\n",
            " 47%|████▋     | 233/500 [27:45<31:47,  7.15s/it]\u001b[A\n",
            " 47%|████▋     | 234/500 [27:52<32:31,  7.34s/it]\u001b[A\n",
            " 47%|████▋     | 235/500 [28:00<32:19,  7.32s/it]\u001b[A\n",
            " 47%|████▋     | 236/500 [28:07<31:54,  7.25s/it]\u001b[A\n",
            " 47%|████▋     | 237/500 [28:14<31:40,  7.23s/it]\u001b[A\n",
            " 48%|████▊     | 238/500 [28:21<31:58,  7.32s/it]\u001b[A\n",
            " 48%|████▊     | 239/500 [28:27<29:54,  6.87s/it]\u001b[A\n",
            " 48%|████▊     | 240/500 [28:35<30:38,  7.07s/it]\u001b[A\n",
            " 48%|████▊     | 241/500 [28:41<29:51,  6.92s/it]\u001b[A\n",
            " 48%|████▊     | 242/500 [28:48<29:47,  6.93s/it]\u001b[A\n",
            " 49%|████▊     | 243/500 [28:55<28:51,  6.74s/it]\u001b[A\n",
            " 49%|████▉     | 244/500 [29:02<30:00,  7.03s/it]\u001b[A\n",
            " 49%|████▉     | 245/500 [29:07<27:27,  6.46s/it]\u001b[A\n",
            " 49%|████▉     | 246/500 [29:15<28:33,  6.75s/it]\u001b[A\n",
            " 49%|████▉     | 247/500 [29:22<28:44,  6.82s/it]\u001b[A\n",
            " 50%|████▉     | 248/500 [29:30<30:01,  7.15s/it]\u001b[A\n",
            " 50%|████▉     | 249/500 [29:37<29:43,  7.10s/it]\u001b[A\n",
            " 50%|█████     | 250/500 [29:44<29:28,  7.07s/it]\u001b[A\n",
            " 50%|█████     | 251/500 [29:51<29:35,  7.13s/it]\u001b[A\n",
            " 50%|█████     | 252/500 [29:58<29:53,  7.23s/it]\u001b[A\n",
            " 51%|█████     | 253/500 [30:06<30:01,  7.30s/it]\u001b[A\n",
            " 51%|█████     | 254/500 [30:12<28:41,  7.00s/it]\u001b[A\n",
            " 51%|█████     | 255/500 [30:20<29:19,  7.18s/it]\u001b[A\n",
            " 51%|█████     | 256/500 [30:27<29:29,  7.25s/it]\u001b[A\n",
            " 51%|█████▏    | 257/500 [30:35<29:43,  7.34s/it]\u001b[A\n",
            " 52%|█████▏    | 258/500 [30:42<29:33,  7.33s/it]\u001b[A\n",
            " 52%|█████▏    | 259/500 [30:49<28:37,  7.13s/it]\u001b[A\n",
            " 52%|█████▏    | 260/500 [30:56<28:32,  7.14s/it]\u001b[A\n",
            " 52%|█████▏    | 261/500 [31:02<27:33,  6.92s/it]\u001b[A\n",
            " 52%|█████▏    | 262/500 [31:10<28:13,  7.12s/it]\u001b[A\n",
            " 53%|█████▎    | 263/500 [31:16<27:22,  6.93s/it]\u001b[A\n",
            " 53%|█████▎    | 264/500 [31:23<27:00,  6.87s/it]\u001b[A\n",
            " 53%|█████▎    | 265/500 [31:30<27:31,  7.03s/it]\u001b[A\n",
            " 53%|█████▎    | 266/500 [31:37<26:57,  6.91s/it]\u001b[A\n",
            " 53%|█████▎    | 267/500 [31:44<27:20,  7.04s/it]\u001b[A\n",
            " 54%|█████▎    | 268/500 [31:52<27:44,  7.18s/it]\u001b[A\n",
            " 54%|█████▍    | 269/500 [31:59<27:05,  7.04s/it]\u001b[A\n",
            " 54%|█████▍    | 270/500 [32:06<27:15,  7.11s/it]\u001b[A\n",
            " 54%|█████▍    | 271/500 [32:13<27:38,  7.24s/it]\u001b[A\n",
            " 54%|█████▍    | 272/500 [32:21<27:41,  7.29s/it]\u001b[A\n",
            " 55%|█████▍    | 273/500 [32:28<26:57,  7.13s/it]\u001b[A\n",
            " 55%|█████▍    | 274/500 [32:35<27:37,  7.34s/it]\u001b[A\n",
            " 55%|█████▌    | 275/500 [32:42<26:57,  7.19s/it]\u001b[A\n",
            " 55%|█████▌    | 276/500 [32:50<26:57,  7.22s/it]\u001b[A\n",
            " 55%|█████▌    | 277/500 [32:57<27:23,  7.37s/it]\u001b[A\n",
            " 56%|█████▌    | 278/500 [33:04<26:47,  7.24s/it]\u001b[A\n",
            " 56%|█████▌    | 279/500 [33:12<26:56,  7.32s/it]\u001b[A\n",
            " 56%|█████▌    | 280/500 [33:18<25:57,  7.08s/it]\u001b[A\n",
            " 56%|█████▌    | 281/500 [33:25<25:13,  6.91s/it]\u001b[A\n",
            " 56%|█████▋    | 282/500 [33:33<26:16,  7.23s/it]\u001b[A\n",
            " 57%|█████▋    | 283/500 [33:39<25:31,  7.06s/it]\u001b[A\n",
            " 57%|█████▋    | 284/500 [33:47<25:47,  7.16s/it]\u001b[A\n",
            " 57%|█████▋    | 285/500 [33:54<25:27,  7.10s/it]\u001b[A\n",
            " 57%|█████▋    | 286/500 [34:01<25:40,  7.20s/it]\u001b[A\n",
            " 57%|█████▋    | 287/500 [34:09<25:39,  7.23s/it]\u001b[A\n",
            " 58%|█████▊    | 288/500 [34:15<25:00,  7.08s/it]\u001b[A\n",
            " 58%|█████▊    | 289/500 [34:22<24:58,  7.10s/it]\u001b[A\n",
            " 58%|█████▊    | 290/500 [34:30<24:53,  7.11s/it]\u001b[A\n",
            " 58%|█████▊    | 291/500 [34:36<23:43,  6.81s/it]\u001b[A\n",
            " 58%|█████▊    | 292/500 [34:42<23:35,  6.80s/it]\u001b[A\n",
            " 59%|█████▊    | 293/500 [34:48<22:23,  6.49s/it]\u001b[A\n",
            " 59%|█████▉    | 294/500 [34:55<23:06,  6.73s/it]\u001b[A\n",
            " 59%|█████▉    | 295/500 [35:01<22:07,  6.48s/it]\u001b[A\n",
            " 59%|█████▉    | 296/500 [35:08<22:15,  6.54s/it]\u001b[A\n",
            " 59%|█████▉    | 297/500 [35:16<23:11,  6.85s/it]\u001b[A\n",
            " 60%|█████▉    | 298/500 [35:23<23:30,  6.98s/it]\u001b[A\n",
            " 60%|█████▉    | 299/500 [35:30<23:37,  7.05s/it]\u001b[A\n",
            " 60%|██████    | 300/500 [35:37<22:53,  6.87s/it]\u001b[A\n",
            " 60%|██████    | 301/500 [35:43<22:32,  6.79s/it]\u001b[A\n",
            " 60%|██████    | 302/500 [35:49<21:54,  6.64s/it]\u001b[A\n",
            " 61%|██████    | 303/500 [35:57<23:03,  7.02s/it]\u001b[A\n",
            " 61%|██████    | 304/500 [36:05<23:13,  7.11s/it]\u001b[A\n",
            " 61%|██████    | 305/500 [36:12<23:07,  7.11s/it]\u001b[A\n",
            " 61%|██████    | 306/500 [36:18<22:25,  6.94s/it]\u001b[A\n",
            " 61%|██████▏   | 307/500 [36:24<21:32,  6.70s/it]\u001b[A\n",
            " 62%|██████▏   | 308/500 [36:32<22:16,  6.96s/it]\u001b[A\n",
            " 62%|██████▏   | 309/500 [36:39<22:03,  6.93s/it]\u001b[A\n",
            " 62%|██████▏   | 310/500 [36:46<22:12,  7.01s/it]\u001b[A\n",
            " 62%|██████▏   | 311/500 [36:53<22:14,  7.06s/it]\u001b[A\n",
            " 62%|██████▏   | 312/500 [37:00<21:55,  7.00s/it]\u001b[A\n",
            " 63%|██████▎   | 313/500 [37:05<19:50,  6.37s/it]\u001b[A\n",
            " 63%|██████▎   | 314/500 [37:13<20:50,  6.72s/it]\u001b[A\n",
            " 63%|██████▎   | 315/500 [37:20<21:04,  6.84s/it]\u001b[A\n",
            " 63%|██████▎   | 316/500 [37:27<21:27,  7.00s/it]\u001b[A\n",
            " 63%|██████▎   | 317/500 [37:35<22:01,  7.22s/it]\u001b[A\n",
            " 64%|██████▎   | 318/500 [37:42<22:03,  7.27s/it]\u001b[A\n",
            " 64%|██████▍   | 319/500 [37:49<21:29,  7.12s/it]\u001b[A\n",
            " 64%|██████▍   | 320/500 [37:56<21:06,  7.04s/it]\u001b[A\n",
            " 64%|██████▍   | 321/500 [38:02<20:29,  6.87s/it]\u001b[A\n",
            " 64%|██████▍   | 322/500 [38:08<19:27,  6.56s/it]\u001b[A\n",
            " 65%|██████▍   | 323/500 [38:15<19:18,  6.55s/it]\u001b[A\n",
            " 65%|██████▍   | 324/500 [38:22<19:59,  6.81s/it]\u001b[A\n",
            " 65%|██████▌   | 325/500 [38:30<20:40,  7.09s/it]\u001b[A\n",
            " 65%|██████▌   | 326/500 [38:35<19:12,  6.62s/it]\u001b[A\n",
            " 65%|██████▌   | 327/500 [38:42<19:02,  6.61s/it]\u001b[A\n",
            " 66%|██████▌   | 328/500 [38:48<18:47,  6.56s/it]\u001b[A\n",
            " 66%|██████▌   | 329/500 [38:56<19:29,  6.84s/it]\u001b[A\n",
            " 66%|██████▌   | 330/500 [39:03<19:14,  6.79s/it]\u001b[A\n",
            " 66%|██████▌   | 331/500 [39:10<19:25,  6.90s/it]\u001b[A\n",
            " 66%|██████▋   | 332/500 [39:17<19:16,  6.88s/it]\u001b[A\n",
            " 67%|██████▋   | 333/500 [39:23<18:58,  6.82s/it]\u001b[A\n",
            " 67%|██████▋   | 334/500 [39:30<18:59,  6.87s/it]\u001b[A\n",
            " 67%|██████▋   | 335/500 [39:37<18:45,  6.82s/it]\u001b[A\n",
            " 67%|██████▋   | 336/500 [39:44<19:04,  6.98s/it]\u001b[A\n",
            " 67%|██████▋   | 337/500 [39:51<18:28,  6.80s/it]\u001b[A\n",
            " 68%|██████▊   | 338/500 [39:58<19:02,  7.05s/it]\u001b[A\n",
            " 68%|██████▊   | 339/500 [40:06<19:16,  7.19s/it]\u001b[A\n",
            " 68%|██████▊   | 340/500 [40:14<19:40,  7.38s/it]\u001b[A\n",
            " 68%|██████▊   | 341/500 [40:21<19:11,  7.24s/it]\u001b[A\n",
            " 68%|██████▊   | 342/500 [40:27<18:41,  7.10s/it]\u001b[A\n",
            " 69%|██████▊   | 343/500 [40:35<18:51,  7.21s/it]\u001b[A\n",
            " 69%|██████▉   | 344/500 [40:40<17:17,  6.65s/it]\u001b[A\n",
            " 69%|██████▉   | 345/500 [40:48<17:48,  6.89s/it]\u001b[A\n",
            " 69%|██████▉   | 346/500 [40:55<18:03,  7.03s/it]\u001b[A\n",
            " 69%|██████▉   | 347/500 [41:03<18:27,  7.24s/it]\u001b[A\n",
            " 70%|██████▉   | 348/500 [41:10<18:16,  7.21s/it]\u001b[A\n",
            " 70%|██████▉   | 349/500 [41:17<18:03,  7.18s/it]\u001b[A\n",
            " 70%|███████   | 350/500 [41:24<18:07,  7.25s/it]\u001b[A\n",
            " 70%|███████   | 351/500 [41:32<18:12,  7.33s/it]\u001b[A\n",
            " 70%|███████   | 352/500 [41:39<18:01,  7.31s/it]\u001b[A\n",
            " 71%|███████   | 353/500 [41:46<17:18,  7.07s/it]\u001b[A\n",
            " 71%|███████   | 354/500 [41:53<17:07,  7.04s/it]\u001b[A\n",
            " 71%|███████   | 355/500 [42:00<16:59,  7.03s/it]\u001b[A\n",
            " 71%|███████   | 356/500 [42:07<17:20,  7.22s/it]\u001b[A\n",
            " 71%|███████▏  | 357/500 [42:14<17:10,  7.21s/it]\u001b[A\n",
            " 72%|███████▏  | 358/500 [42:22<17:07,  7.24s/it]\u001b[A\n",
            " 72%|███████▏  | 359/500 [42:29<16:54,  7.20s/it]\u001b[A\n",
            " 72%|███████▏  | 360/500 [42:36<16:43,  7.17s/it]\u001b[A\n",
            " 72%|███████▏  | 361/500 [42:43<16:47,  7.25s/it]\u001b[A\n",
            " 72%|███████▏  | 362/500 [42:51<16:48,  7.31s/it]\u001b[A\n",
            " 73%|███████▎  | 363/500 [42:58<16:22,  7.17s/it]\u001b[A\n",
            " 73%|███████▎  | 364/500 [43:05<16:25,  7.25s/it]\u001b[A\n",
            " 73%|███████▎  | 365/500 [43:13<16:38,  7.39s/it]\u001b[A\n",
            " 73%|███████▎  | 366/500 [43:20<16:08,  7.23s/it]\u001b[A\n",
            " 73%|███████▎  | 367/500 [43:27<16:04,  7.25s/it]\u001b[A\n",
            " 74%|███████▎  | 368/500 [43:34<15:36,  7.10s/it]\u001b[A\n",
            " 74%|███████▍  | 369/500 [43:40<15:18,  7.01s/it]\u001b[A\n",
            " 74%|███████▍  | 370/500 [43:47<15:00,  6.93s/it]\u001b[A\n",
            " 74%|███████▍  | 371/500 [43:54<14:53,  6.93s/it]\u001b[A\n",
            " 74%|███████▍  | 372/500 [44:01<14:46,  6.93s/it]\u001b[A\n",
            " 75%|███████▍  | 373/500 [44:07<13:59,  6.61s/it]\u001b[A\n",
            " 75%|███████▍  | 374/500 [44:14<14:21,  6.84s/it]\u001b[A\n",
            " 75%|███████▌  | 375/500 [44:22<14:41,  7.05s/it]\u001b[A\n",
            " 75%|███████▌  | 376/500 [44:30<14:56,  7.23s/it]\u001b[A\n",
            " 75%|███████▌  | 377/500 [44:36<14:32,  7.10s/it]\u001b[A\n",
            " 76%|███████▌  | 378/500 [44:43<14:16,  7.02s/it]\u001b[A\n",
            " 76%|███████▌  | 379/500 [44:50<14:05,  6.99s/it]\u001b[A\n",
            " 76%|███████▌  | 380/500 [44:57<13:42,  6.85s/it]\u001b[A\n",
            " 76%|███████▌  | 381/500 [45:04<14:02,  7.08s/it]\u001b[A\n",
            " 76%|███████▋  | 382/500 [45:11<13:44,  6.98s/it]\u001b[A\n",
            " 77%|███████▋  | 383/500 [45:17<13:07,  6.73s/it]\u001b[A\n",
            " 77%|███████▋  | 384/500 [45:24<13:13,  6.84s/it]\u001b[A\n",
            " 77%|███████▋  | 385/500 [45:31<13:09,  6.86s/it]\u001b[A\n",
            " 77%|███████▋  | 386/500 [45:38<12:59,  6.84s/it]\u001b[A\n",
            " 77%|███████▋  | 387/500 [45:45<12:53,  6.84s/it]\u001b[A\n",
            " 78%|███████▊  | 388/500 [45:51<12:33,  6.73s/it]\u001b[A\n",
            " 78%|███████▊  | 389/500 [45:59<12:55,  6.99s/it]\u001b[A\n",
            " 78%|███████▊  | 390/500 [46:06<13:03,  7.12s/it]\u001b[A\n",
            " 78%|███████▊  | 391/500 [46:13<12:37,  6.95s/it]\u001b[A\n",
            " 78%|███████▊  | 392/500 [46:20<12:40,  7.05s/it]\u001b[A\n",
            " 79%|███████▊  | 393/500 [46:28<12:48,  7.18s/it]\u001b[A\n",
            " 79%|███████▉  | 394/500 [46:35<12:50,  7.27s/it]\u001b[A\n",
            " 79%|███████▉  | 395/500 [46:43<12:57,  7.41s/it]\u001b[A\n",
            " 79%|███████▉  | 396/500 [46:50<12:57,  7.47s/it]\u001b[A\n",
            " 79%|███████▉  | 397/500 [46:57<12:20,  7.18s/it]\u001b[A\n",
            " 80%|███████▉  | 398/500 [47:04<12:12,  7.18s/it]\u001b[A\n",
            " 80%|███████▉  | 399/500 [47:11<11:50,  7.04s/it]\u001b[A\n",
            " 80%|████████  | 400/500 [47:17<11:27,  6.87s/it]\u001b[A\n",
            " 80%|████████  | 401/500 [47:25<11:36,  7.03s/it]\u001b[A\n",
            " 80%|████████  | 402/500 [47:31<11:17,  6.91s/it]\u001b[A\n",
            " 81%|████████  | 403/500 [47:39<11:23,  7.05s/it]\u001b[A\n",
            " 81%|████████  | 404/500 [47:46<11:23,  7.12s/it]\u001b[A\n",
            " 81%|████████  | 405/500 [47:53<11:26,  7.23s/it]\u001b[A\n",
            " 81%|████████  | 406/500 [48:00<11:05,  7.08s/it]\u001b[A\n",
            " 81%|████████▏ | 407/500 [48:07<10:45,  6.94s/it]\u001b[A\n",
            " 82%|████████▏ | 408/500 [48:14<10:33,  6.89s/it]\u001b[A\n",
            " 82%|████████▏ | 409/500 [48:21<10:41,  7.05s/it]\u001b[A\n",
            " 82%|████████▏ | 410/500 [48:28<10:40,  7.12s/it]\u001b[A\n",
            " 82%|████████▏ | 411/500 [48:34<09:59,  6.73s/it]\u001b[A\n",
            " 82%|████████▏ | 412/500 [48:41<10:07,  6.91s/it]\u001b[A\n",
            " 83%|████████▎ | 413/500 [48:49<10:06,  6.97s/it]\u001b[A\n",
            " 83%|████████▎ | 414/500 [48:56<10:06,  7.05s/it]\u001b[A\n",
            " 83%|████████▎ | 415/500 [49:03<10:09,  7.17s/it]\u001b[A\n",
            " 83%|████████▎ | 416/500 [49:10<09:55,  7.09s/it]\u001b[A\n",
            " 83%|████████▎ | 417/500 [49:18<09:59,  7.22s/it]\u001b[A\n",
            " 84%|████████▎ | 418/500 [49:24<09:41,  7.09s/it]\u001b[A\n",
            " 84%|████████▍ | 419/500 [49:32<09:40,  7.17s/it]\u001b[A\n",
            " 84%|████████▍ | 420/500 [49:39<09:29,  7.11s/it]\u001b[A\n",
            " 84%|████████▍ | 421/500 [49:46<09:21,  7.11s/it]\u001b[A\n",
            " 84%|████████▍ | 422/500 [49:52<08:51,  6.81s/it]\u001b[A\n",
            " 85%|████████▍ | 423/500 [49:59<08:51,  6.91s/it]\u001b[A\n",
            " 85%|████████▍ | 424/500 [50:06<08:53,  7.02s/it]\u001b[A\n",
            " 85%|████████▌ | 425/500 [50:12<08:25,  6.74s/it]\u001b[A\n",
            " 85%|████████▌ | 426/500 [50:20<08:36,  6.97s/it]\u001b[A\n",
            " 85%|████████▌ | 427/500 [50:27<08:32,  7.03s/it]\u001b[A\n",
            " 86%|████████▌ | 428/500 [50:34<08:20,  6.95s/it]\u001b[A\n",
            " 86%|████████▌ | 429/500 [50:41<08:17,  7.00s/it]\u001b[A\n",
            " 86%|████████▌ | 430/500 [50:48<08:02,  6.89s/it]\u001b[A\n",
            " 86%|████████▌ | 431/500 [50:55<08:02,  7.00s/it]\u001b[A\n",
            " 86%|████████▋ | 432/500 [51:01<07:35,  6.70s/it]\u001b[A\n",
            " 87%|████████▋ | 433/500 [51:08<07:35,  6.80s/it]\u001b[A\n",
            " 87%|████████▋ | 434/500 [51:15<07:40,  6.97s/it]\u001b[A\n",
            " 87%|████████▋ | 435/500 [51:22<07:25,  6.85s/it]\u001b[A\n",
            " 87%|████████▋ | 436/500 [51:29<07:28,  7.00s/it]\u001b[A\n",
            " 87%|████████▋ | 437/500 [51:36<07:19,  6.98s/it]\u001b[A\n",
            " 88%|████████▊ | 438/500 [51:44<07:22,  7.13s/it]\u001b[A\n",
            " 88%|████████▊ | 439/500 [51:50<07:08,  7.03s/it]\u001b[A\n",
            " 88%|████████▊ | 440/500 [51:58<07:08,  7.14s/it]\u001b[A\n",
            " 88%|████████▊ | 441/500 [52:04<06:42,  6.82s/it]\u001b[A\n",
            " 88%|████████▊ | 442/500 [52:11<06:32,  6.76s/it]\u001b[A\n",
            " 89%|████████▊ | 443/500 [52:17<06:27,  6.80s/it]\u001b[A\n",
            " 89%|████████▉ | 444/500 [52:24<06:24,  6.87s/it]\u001b[A\n",
            " 89%|████████▉ | 445/500 [52:31<06:15,  6.82s/it]\u001b[A\n",
            " 89%|████████▉ | 446/500 [52:38<06:06,  6.79s/it]\u001b[A\n",
            " 89%|████████▉ | 447/500 [52:45<06:12,  7.02s/it]\u001b[A\n",
            " 90%|████████▉ | 448/500 [52:52<06:02,  6.97s/it]\u001b[A\n",
            " 90%|████████▉ | 449/500 [53:00<06:06,  7.19s/it]\u001b[A\n",
            " 90%|█████████ | 450/500 [53:08<06:05,  7.31s/it]\u001b[A\n",
            " 90%|█████████ | 451/500 [53:15<06:02,  7.39s/it]\u001b[A\n",
            " 90%|█████████ | 452/500 [53:22<05:51,  7.33s/it]\u001b[A\n",
            " 91%|█████████ | 453/500 [53:27<05:09,  6.58s/it]\u001b[A\n",
            " 91%|█████████ | 454/500 [53:33<04:56,  6.44s/it]\u001b[A\n",
            " 91%|█████████ | 455/500 [53:41<05:02,  6.72s/it]\u001b[A\n",
            " 91%|█████████ | 456/500 [53:48<05:04,  6.92s/it]\u001b[A\n",
            " 91%|█████████▏| 457/500 [53:56<05:05,  7.09s/it]\u001b[A\n",
            " 92%|█████████▏| 458/500 [54:02<04:44,  6.77s/it]\u001b[A\n",
            " 92%|█████████▏| 459/500 [54:09<04:47,  7.01s/it]\u001b[A\n",
            " 92%|█████████▏| 460/500 [54:17<04:44,  7.11s/it]\u001b[A\n",
            " 92%|█████████▏| 461/500 [54:24<04:37,  7.11s/it]\u001b[A\n",
            " 92%|█████████▏| 462/500 [54:29<04:09,  6.57s/it]\u001b[A\n",
            " 93%|█████████▎| 463/500 [54:36<04:09,  6.75s/it]\u001b[A\n",
            " 93%|█████████▎| 464/500 [54:44<04:09,  6.94s/it]\u001b[A\n",
            " 93%|█████████▎| 465/500 [54:51<04:05,  7.01s/it]\u001b[A\n",
            " 93%|█████████▎| 466/500 [54:57<03:54,  6.89s/it]\u001b[A\n",
            " 93%|█████████▎| 467/500 [55:04<03:47,  6.90s/it]\u001b[A\n",
            " 94%|█████████▎| 468/500 [55:11<03:41,  6.92s/it]\u001b[A\n",
            " 94%|█████████▍| 469/500 [55:19<03:39,  7.08s/it]\u001b[A\n",
            " 94%|█████████▍| 470/500 [55:26<03:37,  7.26s/it]\u001b[A\n",
            " 94%|█████████▍| 471/500 [55:33<03:27,  7.14s/it]\u001b[A\n",
            " 94%|█████████▍| 472/500 [55:40<03:16,  7.02s/it]\u001b[A\n",
            " 95%|█████████▍| 473/500 [55:47<03:08,  6.99s/it]\u001b[A\n",
            " 95%|█████████▍| 474/500 [55:53<02:51,  6.60s/it]\u001b[A\n",
            " 95%|█████████▌| 475/500 [56:00<02:51,  6.86s/it]\u001b[A\n",
            " 95%|█████████▌| 476/500 [56:07<02:44,  6.85s/it]\u001b[A\n",
            " 95%|█████████▌| 477/500 [56:14<02:40,  6.99s/it]\u001b[A\n",
            " 96%|█████████▌| 478/500 [56:20<02:25,  6.62s/it]\u001b[A\n",
            " 96%|█████████▌| 479/500 [56:27<02:23,  6.82s/it]\u001b[A\n",
            " 96%|█████████▌| 480/500 [56:35<02:21,  7.05s/it]\u001b[A\n",
            " 96%|█████████▌| 481/500 [56:39<01:58,  6.25s/it]\u001b[A\n",
            " 96%|█████████▋| 482/500 [56:46<01:57,  6.53s/it]\u001b[A\n",
            " 97%|█████████▋| 483/500 [56:53<01:53,  6.67s/it]\u001b[A\n",
            " 97%|█████████▋| 484/500 [57:00<01:49,  6.81s/it]\u001b[A\n",
            " 97%|█████████▋| 485/500 [57:07<01:41,  6.79s/it]\u001b[A\n",
            " 97%|█████████▋| 486/500 [57:13<01:30,  6.46s/it]\u001b[A\n",
            " 97%|█████████▋| 487/500 [57:19<01:22,  6.36s/it]\u001b[A\n",
            " 98%|█████████▊| 488/500 [57:26<01:19,  6.62s/it]\u001b[A\n",
            " 98%|█████████▊| 489/500 [57:33<01:13,  6.71s/it]\u001b[A\n",
            " 98%|█████████▊| 490/500 [57:40<01:06,  6.63s/it]\u001b[A\n",
            " 98%|█████████▊| 491/500 [57:47<01:02,  6.89s/it]\u001b[A\n",
            " 98%|█████████▊| 492/500 [57:54<00:55,  7.00s/it]\u001b[A\n",
            " 99%|█████████▊| 493/500 [58:01<00:48,  6.90s/it]\u001b[A\n",
            " 99%|█████████▉| 494/500 [58:08<00:42,  7.06s/it]\u001b[A\n",
            " 99%|█████████▉| 495/500 [58:16<00:35,  7.10s/it]\u001b[A\n",
            " 99%|█████████▉| 496/500 [58:23<00:28,  7.05s/it]\u001b[A\n",
            " 99%|█████████▉| 497/500 [58:30<00:21,  7.19s/it]\u001b[A\n",
            "100%|█████████▉| 498/500 [58:36<00:13,  6.67s/it]\u001b[A\n",
            "100%|█████████▉| 499/500 [58:42<00:06,  6.56s/it]\u001b[A\n",
            "100%|██████████| 500/500 [58:49<00:00,  7.06s/it]\n",
            "100%|██████████| 1/1 [58:49<00:00, 3529.65s/it]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(model_titles))):\n",
        "\n",
        "  # STEP 3: Select model to generate with  --- !! CHANGE DECLARATION FOR DIFFERENT MODEL !!\n",
        "  title = model_titles[i]\n",
        "  input_ids = input_ids_all[i]\n",
        "  model = models[i]\n",
        "  tokenizer = tokenizers[i]\n",
        "\n",
        "  # STEP 4: Generate Outputs from model\n",
        "\n",
        "  # Generating for each in the list\n",
        "  outputs = []\n",
        "  input_prompt = \"\"\"<BOS>A classifier is further trained to ensure contextual consistency of the generated sentence.<SCI_GEN>\"\"\"\n",
        "  for inp in tqdm(input_ids):\n",
        "    outputs.append(model.generate(\n",
        "        inp,\n",
        "        max_length=int(len(input_prompt)),\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        pad_token_id = 50256,\n",
        "        eos_token_id = 50256,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "    ))\n",
        "\n",
        "  # # STEP 5: Print some of the outputs just to check them\n",
        "\n",
        "  # for i in range(10):\n",
        "  #   print(tokenizer.decode(outputs[500+i][0]))\n",
        "\n",
        "  # STEP 6: Save generated outputs using pickle --- MAKE SURE TO CHANGE VARIABLE NAME WITH NEW MODElS, DON'T OVERWRITE\n",
        "\n",
        "  gen_outputs = outputs\n",
        "  open_file = open(\"generated_outputs_\"+title+\".p\", \"wb\")\n",
        "  pickle.dump(gen_outputs, open_file)\n",
        "  open_file.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_outputs = [tokenizer.decode(x[0]) for x in outputs]\n",
        "\n",
        "open_file = open(\"decoded_outputs_\"+title+\".p\", \"wb\")\n",
        "pickle.dump(decoded_outputs, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "I_d5mty8IB1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_num_outputs = [x.replace(\"NUM\", \"\").replace(\"  \", \"\") for x in decoded_outputs]"
      ],
      "metadata": {
        "id": "TiOxK2_qW7gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_model2_rewards = [x.split(\"<SCI_GEN>\")[1].split(\"<EOS>\")[0] for x in no_num_outputs]"
      ],
      "metadata": {
        "id": "_8LaYQR5XCKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_model2_rewards_raw = outputs_model2_rewards"
      ],
      "metadata": {
        "id": "V0Ws4jteYtTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5NcXxFMcXft5",
        "outputId": "459522c2-9553-4bef-e546-7adcb6d91356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<BOS>a smoothing filter can be used to introduce new trends into temporally coherent frequencies<SCI_GEN>'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-dr15VNW6qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d79dba-b4bb-4964-efb2-316b163e1005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96 the smoothing filter can be used to incorporate new trends into temporally coherent frequencies  <BOS>a smoothing filter can be used to introduce new trends into temporally coherent frequencies<SCI_GEN>\n",
            "61 the central task is to set all events in order thus improving <BOS>the central task is to set all events in order, so it can improve.<SCI_GEN>\n",
            "96 in contrast prepositional phrases are much more susceptible to analysis in terms of distribution <BOS>in contrast, the prepositional phrase is much more susceptible to analysis in terms of distribution.<SCI_GEN>\n",
            "48 let us illustrate this by translating an example <BOS>let's see how the interpreter translates the example.<SCI_GEN>\n",
            "182 this terminology was chosen to describe our preferred interpretation since we were concerned with describing the negation and unnegated constituents of the alternative interpretation <BOS>the preferred interpretation is described in this terminology, as we were concerned with the description of the negation and the unmitigated parts of the alternative interpretation.<SCI_GEN>\n",
            "85 let me say that downstep has no effect on tones on either side so ohl4h ph h lsl lii  <BOS>so i will say that downstep has no effect on tones on either side, so ohl4h ph h lsl lii lii liii<SCI_GEN>\n",
            "167 although strict word by word incrementality is not possible in deterministic dependency parsing the naive algorithm can in principle be compared to incremental parsing <BOS>in deterministic dependency analysis, the naive algorithm can in principle be compared to incremental parsing, although strict word by word increments of word length are not possible.<SCI_GEN>\n",
            "115 this leads to a system in which individual sentences are ordered based on the content of the sentences in the group <BOS>that leads to a system in which individual sentences are ordered based on the content of the sentences in the group<SCI_GEN>\n",
            "81 in this case the rule in the grammar could not have been expressed by the grammar <BOS>the grammar could not contain the rule in this case.<SCI_GEN>\n",
            "235 we will call this symbol the left and right brackets together together denote the combination of the left and right brackets and we will call it the left and right brackets together denote the combination of the left and right brackets <BOS> shown in the left and right bracket is a symbol for the combination of the left and right braces, and we will call it the left and right bracket.<SCI_GEN>\n",
            "108 as noted in the previous section computing the probability of a pcfg or a hmm is computationally intractable <BOS>as noted in the previous section, the calculation of the probability of a pcfg or a hmm is relatively complex.<SCI_GEN>\n",
            "77 a chinese parser is described which performs well on both english and chinese <BOS>a Parser for Chinese Parses<SCI_GEN>\n",
            "66 the analyses were not satisfactory but the results were satisfying <BOS>the analysis was not satisfactory, but the results were satisfying<SCI_GEN>\n",
            "52 in the current system this option is not implemented <BOS>we have not yet implemented this option in the current system.<SCI_GEN>\n",
            "98 while the latter is more accurate than the former it is still not very useful for the task at hand <BOS>.but the latter is more accurate than the former, at least for now.<SCI_GEN>\n",
            "146 however the model of morphological morphology is not addressed and the correspondence between sequence and morphological properties is not optimal <BOS>however, the model of Morphological Morphology is not addressed and the correspondence between sequence and morphological properties is not optimal<SCI_GEN>\n",
            "116 to estimate the probability of occurrence of a verb we need to know how many times it is attested in a given context <BOS>we need to know how many times a verb is attested in a given context to estimate the probability of occurrence<SCI_GEN>\n",
            "89 the unconstrained model is incapable of growing in very small quantities of training data <BOS>in very small quantities of training, the unconstrained model is incapable of continuing to grow<SCI_GEN>\n",
            "85 investigation shows a crucial difference between source code and the lexical database <BOS>the investigation has shown a crucial difference between source code and the lexical database<SCI_GEN>\n",
            "160 each event has a frequency count fi which is defined as the frequency counts of the co occurring dependents of each event as defined by interdependent variables <BOS>the frequency of the occurrence of the dependent variables, as defined by the interrelated variables, is defined by the frequency counts of the frequency counts of the individual events.<SCI_GEN>\n",
            "72 if the parser can not process the given text a message will be displayed <BOS>a message will be displayed if the Parser cannot process the given text<SCI_GEN>\n",
            "113 many statistical translation models attempt to model word to word correspondences between source and target words <BOS>many statistical translations models try to model word-to-word correspondence between sources and target words<SCI_GEN>\n",
            "53 where nis the number of possible arguments for a node <BOS> for the nodes that provide a small number of possible arguments<SCI_GEN>\n",
            "57 the initial idea was more successful than we ever dreamed <BOS>when we first imagined the idea, we were more successful than he had ever dreamed.<SCI_GEN>\n",
            "81 note that the first pair of connectives do not apply when the second pair is used <BOS>when the first pair of connections are used, the second connection does not apply.<SCI_GEN>\n",
            "126 imagine a language in which the only possible way of reading it is to read an ordinary grammar book and a very large text book <BOS>imagine a language in which the only possible way of reading it is to read an ordinary grammar book and a very large text book.<SCI_GEN>\n",
            "77 finally nonbase irregular forms have reference to the corresponding base form <BOS>the final nonbase irregular form shall have reference to the corresponding base form<SCI_GEN>\n",
            "125 the application of specific syntactic rules does not drive the functional structure which determines the composition of words <BOS>the functional structure that determines the composition of words does not drive the application of specific syntactic rules.<SCI_GEN>\n",
            "58 in the next section we discuss how to handle short context <BOS>we'll discuss how to handle short term situations.<SCI_GEN>\n",
            "96 the rules whose premises and actions satisfy these constraints are first determined by an expert <BOS>the expert must first determine the rules whose premises and their actions fulfil these requirements.<SCI_GEN>\n",
            "45 what kind of environment will house the robot <BOS>My, what kind of environment will house the robot?<SCI_GEN>\n",
            "101 synsets may include a variety of semantic relationships for example anonymy hyperonymy and entailment <BOS>synsets may include a variety of semantic relationships, for example, anonymy hyperonymy and entailment.<SCI_GEN>\n",
            "118 the apparent concessions relation between a and c here is paradoxical since in rhetorical structure they are unrelated <BOS>the apparent concession relation between a and c here is paradoxical since in rhetorical structure they are unrelated.<SCI_GEN>\n",
            "137 the sampling method used for evaluating each subject is to take the topdocuments found in the submitted run and merge them into the pool  <BOS>for each subject, the sampling method chosen for the evaluation is to take the top NUM documents found in the submitted run and merge them into the sample pool.<SCI_GEN>\n",
            "67 finally performance across different feature sets using the maxent  <BOS>table NUM shows the final performances of the maxent model across different feature sets<SCI_GEN>\n",
            "30 he did not only focus on nouns <BOS>he didn't only look at the nouns.<SCI_GEN>\n",
            "56 the boundaries can be defined in terms of syllabic spans <BOS>a syllabic span can be split into two parts, according to the boundaries.<SCI_GEN>\n",
            "118 in this way the lattice of hypotheses can be built and the evaluation of each hypothesis can be controlled by its best <BOS>in this way, the best possible hypothesis can be built and its evaluation can be controlled by the lattice of hypotheses.<SCI_GEN>\n",
            "111 the following diagram assumes that the preposition of relative clauses is followed by nothing but extrapolation <BOS>the following diagram assumes that the pre-composition of relative clauses is followed by nothing but extrapolation<SCI_GEN>\n",
            "69 we evaluated our scf extraction system on written and spoken samples  <BOS>we've tested the scf extraction system in written and spoken samples.<SCI_GEN>\n",
            "35 there are two ways to organize this <BOS>there are two ways to organize this in the country.<SCI_GEN>\n",
            "110 the framework model can be generalized to cover all possible labels according to the proposed antecedent model <BOS>the proposed antecedent model can be applied to all possible labels, according to the framework model<SCI_GEN>\n",
            "77 the reader s goals should be the determining factors in evaluating importance <BOS>the evaluation of importance should be based on the reader's objectives<SCI_GEN>\n",
            "53 even simple qgs however turned out to do fairly well  <BOS>But even simple qgs (i.e. not even 1:1) turned out to do pretty well...<SCI_GEN>\n",
            "70 standard accuracy is also an important parameter for testing sentences <BOS>the test sentences also need to be given a standard of accuracy.<SCI_GEN>\n",
            "88 a flexible network of relations between entities with both flat and structured features  <BOS>a flexible network of relations between entities with both flat and structured features<SCI_GEN>\n",
            "70 the training data should be used for testing and the rest for training <BOS>the test data should be used for training and the rest for testing.<SCI_GEN>\n",
            "103 the third neural network allows for generative probability modeling and optimal classification criteria <BOS>a third neural network allows for a generative probability model, and an optimal classification criteria<SCI_GEN>\n",
            "144 the full grammar for partially expressed annotations is a set of partially expressed features similar to partial evaluations of definite clauses <BOS>as a result, we can evaluate the complete grammar of the partially expressed annotations, which are similar to partial evaluations of definite clause.<SCI_GEN>\n",
            "169 the internal semantic information contained in this attribute may be less than the internal semantic structure of the element but may be represented by other information <BOS>the internal semantic information contained in this attribute may be less than the internal semantic structure of the element, but may be represented by other information.<SCI_GEN>\n",
            "53 the output must also conform to the annotator s input <BOS>the output must also be consistent with the annotator's input<SCI_GEN>\n",
            "59 this allows us to avoid having to ask this sort of question <BOS>this allows us to get away with not knowing the answer to this kind of question.<SCI_GEN>\n",
            "64 a simpler form of conciseness may be difficult for poor readers  <BOS>poor readers may be unable to comprehend a simpler form of conciseness.<SCI_GEN>\n",
            "66 clearly some limitations are present in the context described here <BOS>in the context of the present case, there are obviously some possible limitations.<SCI_GEN>\n",
            "52 a token consists of a sequence of non finite tokens  <BOS>the sequence of tokens is composed of a sequence of non-exhaustive tokens<SCI_GEN>\n",
            "142 of particular interest here is the fact that high frequency terms may represent important structural information for phrasal construction e.g. <BOS>in particular, high frequencies may be important for the construction of phrasing, e.g.<SCI_GEN>\n",
            "73 more objects are mentioned and discussed in the utterances involving them <BOS>the objects mentioned and talked about are more likely to be mentioned and discussed.<SCI_GEN>\n",
            "107 multilingual devices have been developed but have not been able to process language from their environment  <BOS>the multilingual device has been developed, but it is not able to process the language of the devices.<SCI_GEN>\n",
            "42 this theory is called the component theory <BOS>this theory is called the component theory.<SCI_GEN>\n",
            "74  users need to be able to plan their messages in a way that is non trivial <BOS>the users need to plan their messages in a way that is non-explanatory.<SCI_GEN>\n",
            "122 each derivation step adds one set of trees to the set and all other sets from this set are simultaneously added to the set <BOS>one set of trees shall be chosen in each derivation step and all other trees from the set are simultaneously added.<SCI_GEN>\n",
            "129 in the real world where both sides are involved in solving the problem the user and the computer often can n t solve it together  <BOS>in the real world, where both sides are involved in solving the problem, the user and the computer can often solve it best together.<SCI_GEN>\n",
            "198 the problem of finding a number of factors that are important is a general problem and we find it difficult to find a number of factors that are relevant in the analysis of possible agreement values <BOS>there is a general problem with the possible influence of many factors in the analysis of the possible agreement values, which is why we find it difficult to find a number of factors that are important.<SCI_GEN>\n",
            "88 4gram vectors can be used in any computation that does not make use of the other vectors <BOS>the 4-gram vectors can be used in any computation that does not use the other vectors.<SCI_GEN>\n",
            "54 the results of the experiment are summarized in table  <BOS>table NUM contains the results of the experiment.<SCI_GEN>\n",
            "70 the input document was converted into a sequence of linked text blocks <BOS>the input document was converted into a sequence of linked text blocks<SCI_GEN>\n",
            "83 we would like to know that as we know this is often true in the case of paul simon  <BOS> as we know, this is often true in the case of paul simon, but we would like to know that from the web and fame sites.<SCI_GEN>\n",
            "68 a third variant with special constraints on the order of the letters <BOS>a third-variant with special restrictions on the order of the letters<SCI_GEN>\n",
            "48 this is not true for programs of different types <BOS>this is not true for programs of different types.<SCI_GEN>\n",
            "61 some roots can be valid both with and without two fills above <BOS>the two refills above are valid for some roots.<SCI_GEN>\n",
            "85 the false examples become sources of errors and a source of instability in the system <BOS>the false examples become a source of errors and a source of instability in the system<SCI_GEN>\n",
            "53 the word can belong to any number of semantic classes <BOS>any number of classes of words can be called a word.<SCI_GEN>\n",
            "131 topographic generation systems use the same structure to represent text but use different knowledge to guide the generation process <BOS>the topographic generation system uses the same structure as the text generation system, but it also uses different knowledge<SCI_GEN>\n",
            "133 tag errors are smaller than structural errors and are rarely exceeded two trees with very different structures are rarely encountered <BOS>the tag error is smaller than the structural error and is rarely exceeded two trees with very different shapes are rarely encountered.<SCI_GEN>\n",
            "241 firstly it has been difficult to directly use standard treebanks of functional annotations in statistical parsing systems with the result that linguistic data sets of coarse grained statistical parsing systems have been relatively unexplored <BOS>firstly, using standard treebanks of functional annotations, statistical methods for analysing languages of coarse-grained statistical parsing systems have limited the direct use of such data.<SCI_GEN>\n",
            "72 how can this research help in the development of a real world nlp system <BOS>how can this research help to create a real world nlp system<SCI_GEN>\n",
            "48 such cases are filtered using an optional filter <BOS>an optional filter is used to filter such cases<SCI_GEN>\n",
            "105 the pattern of deletion was gradually evolving across the population and over the different lexical items <BOS>the pattern of deletion was gradually evolving across the population and over the different lexical items<SCI_GEN>\n",
            "54 variants are ranked according to increasing complexity <BOS>variants are ranked according to the increasing complexity<SCI_GEN>\n",
            "78 finally we reject transliterations which do not exist in the target vocabulary <BOS>in the final stage, we reject the transliterations that don't actually exist in the target vocabulary.<SCI_GEN>\n",
            "91 deciding which theory to use to decieve the stack is a critical issue in stacking decoders  <BOS>deciding which theory to use to decieve the stack is a key issue in stack decoders<SCI_GEN>\n",
            "205 on the other hand the two features have no coherent feature structure and their unification produces a cyclic feature structure which makes the definition of links and possible implementations more complex <BOS>on the other hand, the two features have no coherent structure, and their unification produces a cyclical feature structure that makes the definition of links and possible implementation more complex.<SCI_GEN>\n",
            "107 these results suggest that people may have distinct cognitive distinctions between two types of similarity  <BOS>the results suggest that people can discriminate between two types of similarity in certain cognitive processes.<SCI_GEN>\n",
            "74 the notation used in compiling transducers has been variously defined e.g. <BOS>there are various versions of the notation used in the compilation of transducers, e.g.<SCI_GEN>\n",
            "121  consistency among analysts is important because it can minimize the possibility of analyzing ambiguities among analysts  <BOS>analysts must be consistent to minimise the possibility of analysing differences among them.<SCI_GEN>\n",
            "94 in principle it is possible to use the ucg planning capabilities to perform the planning tasks <BOS>in principle, the planned activities can be used to carry out the tasks of the UCC.<SCI_GEN>\n",
            "110 as mentioned above words often share similar semantic contexts so we want to see if ppmvs are highly correlate <BOS>the same words often share similar semantic meanings so we want to see if ppmvs are highly correlate.<SCI_GEN>\n",
            "43 this behavior has been successfully modeled <BOS>this behavior was successfully adapted to a model.<SCI_GEN>\n",
            "104 several problems arise in comparing sentences produced by a sentence parser with those of a text planner <BOS>in comparing the sentences produced by a sentence parser with those of a text-formatter, several problems arise<SCI_GEN>\n",
            "95 the results indicate that the coarse granularity of the notion of sense may be further improved <BOS>the results indicate that the coarse granularity of the concept of'sense' can be further improved<SCI_GEN>\n",
            "58 the language model can incorporate the overall probability <BOS>the overall probability model can be incorporated into the language model<SCI_GEN>\n",
            "88 in practice static analysis can greatly reduce the complexity of resulting relationships <BOS>in practice, the complexity of the resulting relationships can greatly reduce the static analysis.<SCI_GEN>\n",
            "47 for example consider the japanese name koizumi  <BOS>for example think about the short japanese name kokizumi.<SCI_GEN>\n",
            "45 examples of translation of the first rule are <BOS>rule l - examples of translation of the first rule<SCI_GEN>\n",
            "48 the matching system works exactly as if w3 is w5 <BOS>the matching system will work exactly as if w3 is w5<SCI_GEN>\n",
            "94 finally sentence matching and rankingand the ranking system contained most relevant sentences  <BOS>the system was finally able to achieve the final sentence matching and ranking described in NUM and the ranking system contained the most relevant sentences<SCI_GEN>\n",
            "47 the training parameters are estimated from data <BOS>the training parameters are determined by the data collected<SCI_GEN>\n",
            "80 we then show how a simple and natural system of lexical rules can be implemented <BOS> and then we introduce a simple and natural system of lexical rules.<SCI_GEN>\n",
            "113 in ss5 we will show how loss computed in a common natural language task can be compared with other types of tasks <BOS>we'll show how loss calculation in a common natural language task can be compared with other types of tasks, such as those of ss5<SCI_GEN>\n",
            "110 the parser s mechanism for resolving search messages has also been restricted to prevent erroneous completions <BOS>the parser's mechanism for resolving search messages has also been limited to prevent erroneous completions in the search mechanism.<SCI_GEN>\n",
            "131 testing is not an option for all companies and for all institutions and all systems which rely heavily on high quality translation  <BOS>the company and all of the institutions and institutions which rely heavily on high-quality translation cannot be fully automated by testing, as shown by extensive testing.<SCI_GEN>\n",
            "79 this corpus has been the subject of research by the french electricity company  <BOS>the French electricity company has conducted research into this collection of documents.<SCI_GEN>\n",
            "54 the apsg core rules are a set of context free phrases  <BOS>the framework of the apsg core rules is a set of free phrases<SCI_GEN>\n",
            "53 the design of each method is compared in this section <BOS>in this section, the design of each method is compared.<SCI_GEN>\n",
            "143 lines can contain fragments which have loose syntactic relations to each other and to the main clause vocabulary false starts tag questions etc <BOS>a line can contain fragments that have loose syntactic relations to each other and to the main clause vocabulary, and false starts tag questions etc<SCI_GEN>\n",
            "48 the other mucsystems were not designed to learn  <BOS>the other mucosal systems were not designed to learn<SCI_GEN>\n",
            "16 go with the flow <BOS>go with the flow<SCI_GEN>\n",
            "238 this component integrates high quality transfer patterns automatically acquired from sentences in a bilingual corpus using an alignment grammar and algorithm described in section as well as the french and english versions of the mt system <BOS>high quality transfer patterns automatically acquired from sentences in a bilingual corpora using an alignment grammar and algorithm described in NUM (figure NUM), as well as the French and English versions of the mt system, are integrated into this component.<SCI_GEN>\n",
            "46 the intervention constitutes an element of the <BOS>the intervention is an element of the whole<SCI_GEN>\n",
            "71 the new data is not useful and can not be removed if the loss is small  <BOS>the new data is not useful and cannot be removed if the loss is small.<SCI_GEN>\n",
            "51 the structural limitation is precisely the same as  <BOS>the structural limitation is precisely the same as NUM's design.<SCI_GEN>\n",
            "122 non factored splits provide substantial accuracy improvements over the alternatives with relatively small efficiency gains <BOS>for relatively small efficiency improvements, non-factored splits provide significant accuracy improvements.<SCI_GEN>\n",
            "88 however strict independence assumptions are required in addition to the generative model <BOS>in addition, strict assumptions about the independence of the generative model are required.<SCI_GEN>\n",
            "211 thus far we have presented results indicating that kpca models outperform the other models and that on average accuracies in the election ensemble are significantly different from the results of the other models <BOS>therefore, the results of analysis of the kpca model of the other models and the results of their accuracy in the election ensemble are evaluated and found to be, on average, significantly different from the results of the other models.<SCI_GEN>\n",
            "83 nxt s data model every node may have multiple parents but only one set of children  <BOS>nxt s data model every node can have multiple parents but only one set of children<SCI_GEN>\n",
            "52 work only on automata with transitions such as that  <BOS>only automata with transitions like that work<SCI_GEN>\n",
            "88 the reusability of software in the lexicon modules of other languages is very important  <BOS>for other languages, the re-use of software in their lexicon modules is very important.<SCI_GEN>\n",
            "79 the introduction of non referential words is not possible with prepositions s2  <BOS>the preposition s2 can not be used to introduce non-reference words<SCI_GEN>\n",
            "85 this information is repeated several times in the text in the search for similar ones <BOS>in the search for similar ones, this information is repeated several times in the text.<SCI_GEN>\n",
            "118 the development of a high level data model for nlg systems is the aim of developing a general generation architecture  <BOS>the aim of developing a high-level data model for the nlg system is the development of a general generation architecture called Rags NUM<SCI_GEN>\n",
            "87 the lower bound is a simple algorithm that is computable and therefore can be automated <BOS>the lower bound is an algorithm that is simple, reasonable and can be automated.<SCI_GEN>\n",
            "81 this demonstrates that the ilc feature is not available in the absence of a frame <BOS>this shows that the ilc feature is not available in the absence of a frame.<SCI_GEN>\n",
            "113 the results for the first round are used as a reference score for the whole dossier in the context of all answers <BOS>in the context of the whole dossier, the results of individual answers to the first round are used as a reference score.<SCI_GEN>\n",
            "65 the translation probability was estimated by using a markov chain <BOS>the probability of guessing the translation of the word and document was estimated using a Markov chain.<SCI_GEN>\n",
            "121 the valency and informativeness principles have now made it possible to construct almost entirely hierarchical structures <BOS>the valency and transparency principles have now enabled an almost complete hierarchical structure<SCI_GEN>\n",
            "83 in order to extract each feature from a definition we introduce two separate steps  <BOS>to extract each feature from a definition, we introduce two separate steps.<SCI_GEN>\n",
            "47 this means that one structural relation is lost <BOS>that means the loss of one structural connection.<SCI_GEN>\n",
            "119 the text was fully annotated of the subjects were given a questionnaire in which the text was given explicit permission <BOS>the participants were given a questionnaire in which the text was fully approved<SCI_GEN>\n",
            "39 some of these errors are shown in table <BOS>table NUM shows some of these mistakes.<SCI_GEN>\n",
            "61 in the majority of cases users entered a code on the keyboard <BOS>in the majority of cases, users entered a code on the keyboard.<SCI_GEN>\n",
            "111 this paper describes a preliminary study of a knowledge engineering approach to natural language understanding  <BOS>the results of a preliminary study of a knowledge-based approach to natural language understanding are described in this paper<SCI_GEN>\n",
            "66 ambiguity is a problem for any natural language processing system  <BOS>ambiguity is a problem in any natural language processing system<SCI_GEN>\n",
            "89 the system then generates a directed graph with concepts as nodes and relations as edges  <BOS>the system then translates the domain model into a directed graph with concepts as nodes and relations as edges<SCI_GEN>\n",
            "84 the exact relation between phrasing and language use is a topic for further research <BOS>further research should examine the exact link between the phrasing and the language of the speech.<SCI_GEN>\n",
            "84 furthermore different types of contextual positions may occur in a particular n gram <BOS>in addition, different types of contextual positions may be found in a particular n gram.<SCI_GEN>\n",
            "48 we regularise these models using gaussian prior  <BOS>using Gaussian prior, we regularise these models.<SCI_GEN>\n",
            "78 additions and deletions of adjectives can modify other words in a context e.g. <BOS>for example, you can modify other words by adding or removing an adjective.<SCI_GEN>\n",
            "67 the evaluation of the translation problems involved five solutions  <BOS>evaluation of the translation problems involved five solutions<SCI_GEN>\n",
            "106 this is achieved by supporting as many different platforms as possible in order to achieve this objective  <BOS>the company is therefore supporting as many different platforms as possible, in order to achieve this goal.<SCI_GEN>\n",
            "167 the goal of our work is to obtain an improved probability distribution for event pairs that can be compared in terms of their likelihood of occurring in a given corpus <BOS>in order to achieve a more realistic distribution of event pairs, we aim to obtain an improved probability distribution for each possible class.<SCI_GEN>\n",
            "43 next we can take a logical cluster of facts <BOS>a logical cluster of facts can be taken next<SCI_GEN>\n",
            "106 delphi can also be used to demonstrate spoken language systems in an air force resource management domain  <BOS>an air force control system can also be used to demonstrate the spoken language of Delphi.<SCI_GEN>\n",
            "90 our human test results showed that difficulty indicators predict human performance on task <BOS>human test results showed that the difficulty indicators predict the ability to perform the tasks of the first interview.<SCI_GEN>\n",
            "127 although this approach is completely different from language modeling it has been used by groups working on speech recognition  <BOS>there are, however, groups working on speech recognition using this approach, which is completely different from the language model.<SCI_GEN>\n",
            "105 these messages have properties such as text compression which is due to constraints of time and durations <BOS>the message compression properties of text are due to the constraints of time and duration, which is why these messages have the characteristics of text compression.<SCI_GEN>\n",
            "95 victories in sports reports can be interpreted as referring to the head noun and its modifiers  <BOS>the head noun and its modifiers can be interpreted as victories in sports reports.<SCI_GEN>\n",
            "108 the test person communicates with the system and the dialogues are recorded and recorded using digital means <BOS>the test person is communicating with the system and the dialogues are recorded and recorded using digital means.<SCI_GEN>\n",
            "70 the results on the german development and test sets are shown in table <BOS>table NUM shows the results of the development and testing of the German development and test sets.<SCI_GEN>\n",
            "109 the initial slu model also has an application capability and can be used to determine the flow of application <BOS>the initial model of the slu model can also be used to determine the flow of applications.<SCI_GEN>\n",
            "56 auxiliary functions will be written in xml based on perl <BOS>the auxiliary services will be written in apl.<SCI_GEN>\n",
            "89 because they found audio clips that fit the time range therefore the song is a time warp  <BOS>because they found audio clips that fit the time range, so the song is a time-warp.<SCI_GEN>\n",
            "92 therefore the number of equivalence classes is the same as the number of elements in the set <BOS>therefore, the number of classes of equivalent elements is the same as the number of elements in the set<SCI_GEN>\n",
            "71 the second baseline was computed using the simple attraction algorithm  <BOS>the second baseline was calculated using a simple attraction algorithm<SCI_GEN>\n",
            "81 the use of pos tagging and chunk parsing is similar to that used in previous wcdg <BOS>using pos-tags and chunk-parsing is similar to the use of tags in the previous WCDG.<SCI_GEN>\n",
            "159 the syntactic trees generated using a statistical parser are built using compositional semantics and then the mrs are constructed using compositional semantics <BOS>syntactic trees generated using a statistical parser are built using compositional semantics and then the MRs are constructed using a compositional approach<SCI_GEN>\n",
            "125 the restructuring is accomplished by the pli program which is an interface between the lisp language and the restore library  <BOS>the restructuring is accomplished by the pli program, which is an interface between the Lisp language and the RESTORE library<SCI_GEN>\n",
            "30 see the full treatment of bpms <BOS>check out the full treatment of bpms<SCI_GEN>\n",
            "106 c requesting the commander to update a database containing biological weapons information would be unieldy <BOS>a biological weapons database should be updated for the purpose of the request of the commander<SCI_GEN>\n",
            "70 it is generally easy to see why some models are more similar to others <BOS>it's generally pretty easy to see why some models are more similar to others.<SCI_GEN>\n",
            "102 we are developing techniques that use a database of one million questions that can be parsed precisely <BOS>we're developing techniques that use a database of one million questions that can be processed precisely.<SCI_GEN>\n",
            "129 adjectives with noun modifiers can be identified by means of noun adjectives which have similar characteristics to those of nouns <BOS>in the case of modifiers, the subject of a particular adjective can be identified by means of these adjective-like elements<SCI_GEN>\n",
            "46 text and graphics corpora contain such schemas <BOS>these schemas are used for text and graphic design<SCI_GEN>\n",
            "105 data base extensions provide the means by which logical expressions can be specified in a declarative way <BOS>the specification of a logical representation is specified by specifying the extension of all the expressions in the data base.<SCI_GEN>\n",
            "101 even more problematic for a more complex ug grammar would be the elimination of even more constraints <BOS>in a more complex ug grammar, the restrictionors could delete even more.<SCI_GEN>\n",
            "196 this evaluation and subsequent observations were guided by an undulating process in which the system was examined and the users answered questions and provided comments on the system s development <BOS>the evaluation and its subsequent observations were guided by an undulating process, in which the system was examined and its users answered questions and provided comments on the system's development.<SCI_GEN>\n",
            "130 the exercise description does not include the basic information concerning the adverbials or conjunctive situations discussed here <BOS>the basic information concerning the adverbial or conjunctive situations mentioned in the exercise is not included in the description of the exercise.<SCI_GEN>\n",
            "118 their preliminary results are not comparable to ours in any sense because they do not precisely represent our features <BOS>in fact, their preliminary results are not comparable to ours, because they don't exactly match our characteristics.<SCI_GEN>\n",
            "62 the em algorithm was modified to estimate the parameters using <BOS>an estimate of the parameters was adjusted to the em algorithm.<SCI_GEN>\n",
            "84 in each case a randomly selected nn compound was substituted for the selected string <BOS>in each case, a randomly selected nn compound was substituted for the selected string<SCI_GEN>\n",
            "102 it seems that none of those kinds of language could today claim to be the main model for blog writing  <BOS>it seems that none of those kinds of language could today claim to be the main model for blog writing<SCI_GEN>\n",
            "102 uncts modify the logical form of a sentence but are not constituents of a verb subcategorization frame <BOS>uncts modify the logical form of the sentence but are not part of the sub-clause of the verb<SCI_GEN>\n",
            "69 this data is used to construct language models from the training data <BOS>this data is used to create a gram-based language model<SCI_GEN>\n",
            "34 crfs provide a way to exploit this <BOS>this can be done using crfs<SCI_GEN>\n",
            "39 the state change would be instantaneous <BOS>the change in one state would be instantaneously reversible<SCI_GEN>\n",
            "44 then a linear model is used to model the gap <BOS>then a linear model is used to model the gap<SCI_GEN>\n",
            "85 in this work we consider another situation in which the need for clustering may arise <BOS>in this context, we will consider another situation in which the need for a cluster of buildings may arise.<SCI_GEN>\n",
            "84 significant effort has been invested in defining the capability of mutable languages <BOS>a significant effort has been invested in defining the capability of mutable languages<SCI_GEN>\n",
            "61 consider for a second example the names of foreign countries  <BOS>for a second example, consider the names of foreign countries.<SCI_GEN>\n",
            "81 figureillustrates the illustrated alignments of the monotone hidden markov model  <BOS>the illustrated alignments of the monotone hidden markov model are shown in FIGURE NUMBER<SCI_GEN>\n",
            "84 the spelling correction and morphological analysis algorithms apply to unknown words <BOS>for unknown words, the spelling correction and morphological analysis algorithms apply<SCI_GEN>\n",
            "150 it follows from the fact that the indefinite quantifier in definite articles is interpreted as having non local scope in the case of definite articles <BOS>in the case of definite articles, the non-independence of the indefinite quantifier is interpreted as a condition of non-independence of the definite quantifier<SCI_GEN>\n",
            "68 the firstdocuments and their numerical features are listed in table  <BOS>table NUM contains a list of the first NUM documents and their numerical characteristics.<SCI_GEN>\n",
            "121 manually annotating these words was necessary since the relations were often not derived from real world knowledge bases  <BOS>since the relations were often not derived from real world knowledge bases, it was necessary to manually classify these words.<SCI_GEN>\n",
            "38 our argument has two main implications <BOS>our argument has two main implications:<SCI_GEN>\n",
            "97 this section presents the methodology and results of using the simulated environment described in <BOS>the methodology and results of using the simulation environment described in NUM shall be presented in this section.<SCI_GEN>\n",
            "103 to derive a content for an argument we introduce a binary classification of maximal entropy classifiers <BOS>to determine the contents of an argument, we introduce a binary classification of the maximum entropy classifiers.<SCI_GEN>\n",
            "126 thus combining statistical and linguistic methods can yield grammars that are both statistically and computationally effective <BOS>thus, grammars can be integrated into the combination of statistical and linguistic methods.<SCI_GEN>\n",
            "64 the translation may be done using either active or passive voice <BOS>active or passive voice may be used to translate the translation.<SCI_GEN>\n",
            "247 for example in the case of example productions and gazetteers which tend to introduce arbitrary categories it is easier to detect incorrect classes of statistics than to assign categories according to their precise nature which leads to low recall <BOS>in the case of example production and gas, which tends to introduce arbitrary categories, it is easier to detect incorrect classes of statistics than to assign categories according to their precise nature, which leads to a low recall.<SCI_GEN>\n",
            "149 our length constraint reduces the number of mislabeled training instances if we restrict our data to those instances that have been labeled correctly <BOS>if we limit our data to only those instances of mislabelled training, our length limitation is reduced<SCI_GEN>\n",
            "151 the construction of the matrix and the operation over suffix arrays clearly require more time and effort than the simpler and time consuming operations <BOS>the most complicated and time-consuming operations were clearly shown to be the construction of the matrix and the operation of the data structure over the suffix array.<SCI_GEN>\n",
            "141 although the basic processing method may be sufficient we expect that other nlp methods based on deeper processing may help us with this task <BOS>although the basic processing method may be sufficient, we expect that other nlp methods based on deeper processing may help us with this.<SCI_GEN>\n",
            "91 let us illustrate the learning algorithm by showing how it performs for the following words <BOS>let's see how the learning algorithm works for the following words<SCI_GEN>\n",
            "66 was used extensively in translation of source and target languages <BOS>in translation of source and target languages, WASM is used<SCI_GEN>\n",
            "106 in this section we compare nouns and verbs found in wordnet and roget s nes with those found in the corpus <BOS>in this section, we compare the synonyms of the nouns and verbs found in the wordnet and the rogetment.<SCI_GEN>\n",
            "62 a method that can be adapted or replaced with previous methods <BOS>an adaptable or replacement method for previous ones<SCI_GEN>\n",
            "65 this is because common substrings are only used once in a lattice <BOS>because common substrings are only used once in a lattice<SCI_GEN>\n",
            "37 the second set contained around words <BOS>there were around 1000 words in the second section.<SCI_GEN>\n",
            "142 in our first attempt we chose regular c graphs which are often used to represent the classes in which there is a string to represent the curve <BOS>as a first step, we chose regular c graphs, which are often used to represent the classes in which there is a string to represent the curve.<SCI_GEN>\n",
            "44 all information is considered to be positive <BOS>all information is considered to be positive<SCI_GEN>\n",
            "132 supervised learning algorithms although they have been used in supervised learning approaches are not applicable in other situations <BOS>in supervised learning algorithms, but in other cases, supervised learning algorithms are used, although they are more supervised than semi- supervised approaches<SCI_GEN>\n",
            "119 each of the three methods investigated in this paper make use of word classes to support argumentation in broad context <BOS>all three methods investigated in this study use the same word in broad context to support the argument of each method.<SCI_GEN>\n",
            "75 this could be either an addition or a constraint on the theory of tg itself <BOS>this could be either an addition or a restriction on the theory of tg itself.<SCI_GEN>\n",
            "59 a number of features determine these grammatical candidates <BOS>these grammatical candidates can be compared to several features, which will determine their content.<SCI_GEN>\n",
            "76 in this paper we discuss some problems of translation of russian into german <BOS>in this paper, we discuss some problems with respect to translations of Russian into German.<SCI_GEN>\n",
            "97 i am grateful to the nsf and the workshop participants for many helpful comments and discussions  <BOS>thank you for many helpful suggestions and many discussions about this project.<SCI_GEN>\n",
            "92 tablegives the result for linear inequalities with unit coefficients of the form p xi j xj q <BOS>the result for linear inequalities with unit coefficients of the form p xi j xj q is given in Table NUM.<SCI_GEN>\n",
            "54 to test our approach we used small sets of constraints <BOS>small sets of constraints were used to test our approach.<SCI_GEN>\n",
            "84 it is a blank canvas to be used as a pun intended to convey a non linguistic meaning <BOS>it's a blank canvas to be used as a pun.<SCI_GEN>\n",
            "108 the links in the resulting pair are preserved except for the selected link which is not mirrored in the pair <BOS>the links in the resulting pair are preserved, except for the selected link, which is not mirrored in the pair.<SCI_GEN>\n",
            "72 the nodes describe actions and arcs that describe relations between them <BOS>the nodes describe actions and arcades that describe relations between them.<SCI_GEN>\n",
            "76 this analysis represents aroundof the dependency relationships in the corpus <BOS>the dependency relationships represent around 100% of the dependency data in this analysis.<SCI_GEN>\n",
            "73 the quality of such a system may depend on the expectations of its users  <BOS>there may be differences in the quality of such systems between languages, depending on their expectations.<SCI_GEN>\n",
            "73 if the initial classifier is inaccurate the resulting classifier may fail <BOS>in the case of inaccurate initial classifiers, the resulting classifier may not be successful<SCI_GEN>\n",
            "51 audio news from the tdtcollection is also available <BOS>audio news from the tdt multilingual collection is also available<SCI_GEN>\n",
            "173 these results suggest that even in a computer mediated dialogue the speech segments are sufficiently strongly marked by pitch and or amplitude signals as in real monologues  <BOS> and these results suggest that even in a computer-mediated dialogue, the speech segment structure is sufficiently strongly marked by pitch and/or amplitude signals as in real monologues.<SCI_GEN>\n",
            "52 the ucp grammar formalism is integrated into the ucp <BOS>the ucp grammar formalism is integrated into the ucp<SCI_GEN>\n",
            "170 there is often no consensus on what the correct linguistic structure of a sentence should be because these algorithms can be evaluated in terms of their relative accuracy <BOS>there is often no consensus on what the correct grammatical structure of a sentence should be, because these algorithms can be compared.<SCI_GEN>\n",
            "72 these issues are not easy to address and have consequences on usability  <BOS>there is no doubt that these issues are difficult for users but can have serious consequences for the system.<SCI_GEN>\n",
            "37 they were incorrect about of the time <BOS>they got it wrong about a lot of times.<SCI_GEN>\n",
            "192 the result of np completeness is that the general case of id lp parsing algorithms is often difficult to understand so it is not surprising that the combinatorial explosion can sometimes occur <BOS>the result of the completeness of the np completeness test is that the general case of the id lp parsing algorithm is often difficult to understand, so it is not surprising that the combinatorial explosion can sometimes occur.<SCI_GEN>\n",
            "69 thus it may not exceed an unbounded number of rules in an application <BOS>so that the application of rules may not exceed an infinite number.<SCI_GEN>\n",
            "111 the pilot study did not have an adequate system for message processing and did not create an application system <BOS>the pilot study did not have an adequate system for message processing and did not create an application system.<SCI_GEN>\n",
            "126 the input string is translated to the same output string by path t which is the path from the initial state to the final state <BOS>output from the initial state of the path to the final state is translated into the same input string.<SCI_GEN>\n",
            "84 most of the data should be stored on disk since we have to trade off speed for space <BOS>since we have to trade off speed for space, most of the data should be stored on disk.<SCI_GEN>\n",
            "71 experiments were performed to create japanese equivalents for sentences <BOS>in Japan, experiments were carried out to create a japanese equivalent sentence.<SCI_GEN>\n",
            "45 dependency analysis is first of all effective <BOS>first of all, it seems to be effective to analyze dependent words.<SCI_GEN>\n",
            "76 this is complemented by the other improvements described in the next section <BOS>the other improvements described in the next section are complemented by this.<SCI_GEN>\n",
            "127 automated decisions may be made from the appropriately preprocessed corpus but they will always require the editor s judgement  <BOS>automated decisions may be made by properly preprocessing the corpora of speech, but they will always need to be judged by the editor.<SCI_GEN>\n",
            "42 the whole system is implemented in prolog  <BOS>the entire system is implemented using a logic programming language.<SCI_GEN>\n",
            "48 a and b were identical to the same test a and b  <BOS>a and b were identical to the same test a and b<SCI_GEN>\n",
            "85 in the examples below we consider only one entry to be a separate meaning of the verb <BOS>therefore, only a single entry in the examples given below can be considered to be a separate meaning of the verb.<SCI_GEN>\n",
            "96 the resulting thesaurus provides even more loosely related translations and many irrelevant ones <BOS>the resulting thesaurus will provide even more loosely related translations and many irrelevant ones.<SCI_GEN>\n",
            "127 the instantiated patterns for the concept nodes generated by autoslogare shown in the left column and in the following examples <BOS>in the left-hand column, the instantiated patterns for the concept nodes generated by the autoslog are shown in the following examples:<SCI_GEN>\n",
            "45 she told susan that she really liked the gift <BOS>she told susan that she really liked the gift.<SCI_GEN>\n",
            "124 in particular the constraints in the present case may entail the restrictionist treatment of discourse structure in some way <BOS>for example, the restrictionist theory of discourse structure in the present case may impose certain restrictions on the composition of the primitive composition.<SCI_GEN>\n",
            "118 the principle of consistency in the management of priorities is based on the notion of obeying selectional constraints <BOS>the principle of coherence in the management of the hierarchy of priorities is based on the idea of complying with selection criteria<SCI_GEN>\n",
            "77 hydel defines a set of document types corresponding to the specified language <BOS>hydel defines a set of document types corresponding to the specified language<SCI_GEN>\n",
            "134 the goal of this project is to develop the capability of speech translation systems to deliver applications in real world environments <BOS>the project aims at improving the capabilities of speech translation in real-world settings to deliver real-world applications of speech translation<SCI_GEN>\n",
            "60 automatic recognition of french expletive usage in sentences <BOS>an automatic recognition of the use of the French expletive in sentences<SCI_GEN>\n",
            "56 these features are intended to model binding constraints <BOS>these features are meant to be simulating the binding conditions.<SCI_GEN>\n",
            "91 a solution may be found in many branches that may be brought together in pursuit of a goal  <BOS>in the process of achieving a goal, many branches may be brought together to examine the implications of the solution.<SCI_GEN>\n",
            "60 the terminology is important to find relations between terms <BOS>to find relations between the terms, it is necessary to use the terminology.<SCI_GEN>\n",
            "72 the audio file created during the extraction would be played to the user <BOS>the audio file created during the extraction would be played to the user<SCI_GEN>\n",
            "81 our goal is not to evaluate student essays in comparison with previous approaches <BOS>our goal is not to grade student essays in comparison with previous approaches.<SCI_GEN>\n",
            "123 the original problem can be reframed as maximizing a minimization problem that does not depend on the original optimization <BOS>the original problem of optimal minima can be replaced by a new one that does not depend on the original assumptions.<SCI_GEN>\n",
            "36 in this example we generate the head <BOS>in this example, we create the head<SCI_GEN>\n",
            "117 furthermore the model should be adapted to handle more complex sentences because they were not adequately summarized  <BOS>in addition, the model should be adapted to handle more complex sentences because they were not properly summarised.<SCI_GEN>\n",
            "87 these three persons have different aspects of the discourse context in their utterances <BOS>these three persons have different aspects of the speech in the context of the discourse<SCI_GEN>\n",
            "50 we observed some interesting results after pruning <BOS>after pruning, we saw some interesting results<SCI_GEN>\n",
            "105 in the future we intend to try additional translation candidate methods and apply them to other languages <BOS>in the future, we will attempt to use other candidate translation methods and apply them to other languages.<SCI_GEN>\n",
            "41 here we will only examine the mode system <BOS>only the system of the mode system will be examined here.<SCI_GEN>\n",
            "136 this also makes words with the most powerful predictive power in a sentence seem to be the ones that tend to generate the least powerful <BOS>this also makes words with the most powerful predictive power in a sentence seem to be the ones that tend to generate the least powerful.<SCI_GEN>\n",
            "44 the annotation was performed by two students <BOS>two students performed the annotation.<SCI_GEN>\n",
            "110 the numbers on the list correspond to the values assigned in the computation and are used to derive the scores <BOS>the scores are obtained using a similar algorithm, and the numbers on the list correspond to the values assigned in the calculation.<SCI_GEN>\n",
            "76 statistical methods for lexicographic research in baltic and romanian states <BOS>statistical methods for lexicographical research in the Bulgarian and Romanian states<SCI_GEN>\n",
            "81 therefore it is possible to adjust this approach to a wider range of applications <BOS>therefore, the possibility to adjust this approach to a wider range of applications can be foreseen.<SCI_GEN>\n",
            "72 one of the most important developments is the addition of one innovation <BOS>one of the most important developments is the addition of one innovation.<SCI_GEN>\n",
            "68 to avoid this problem we have to reduce the dictionary size to words <BOS>we have to reduce the number of words in the dictionary to avoid this problem.<SCI_GEN>\n",
            "112 it is clear that the mechanism that selects relevant sentences in the source document context requires some work <BOS>in the context of the source document, it is necessary to create a mechanism that will select the relevant sentences.<SCI_GEN>\n",
            "98 this gives us a broad base to answer questions we posed earlier in the course of these experiments <BOS>we can answer the questions we have asked before in the whole course of these experiments.<SCI_GEN>\n",
            "105 equationdescribes in principle the description model i.e. language and quality properties as described in <BOS>in principle, the description model is described by language and quality properties as described in equation NUM<SCI_GEN>\n",
            "120 experiments show that discourse structure provides the most advantageous framework for integrating summarization methods <BOS>in the context of experiments, the most important factor is the structure of the discourse, which allows for a more complex integration of these different methods of summarizing<SCI_GEN>\n",
            "147 in these cases the user may be expecting a system response as soon as the signal is given indicating that the end of an operation has been reached  <BOS>if the signal indicates an end of an operation, the user may be expecting a sudden response from the system.<SCI_GEN>\n",
            "201 it is not yet clear what precise disjunction principles are needed to project disjunctive constituents onto unseen constituents and what types of features are sufficient to disjunct those constituents  <BOS>the definition of a possible daughter-compound is not yet sufficiently precise to allow a specific, possibly unappealing, projection of disjunction principles to the unseen components of the daughter<SCI_GEN>\n",
            "142 a more detailed analysis of the strengths and weaknesses of the approach is required in particular in those domains in which we are interested <BOS>in particular, there are detailed assessments of the strengths and weaknesses of the approach.<SCI_GEN>\n",
            "157 the parse tree representation of the short answer is transformed into a template which if the short answer is not an imperative and the answer is not a table <BOS>if the short answer is not an imperative and the answer is not a table, the input query's parse tree representation shall be transformed into a template corresponding to the short answer<SCI_GEN>\n",
            "114 the two types of lexical cohesion models can be classified intolexical cohesion models and content oriented models <BOS>two types of lexical model for NUM topics can be classified as NUM lexical cohesion models and NUM content oriented models<SCI_GEN>\n",
            "33 this case is discussed in section <BOS>in this case, the case is reviewed in section NUM<SCI_GEN>\n",
            "117 information extraction systems are designed to extract specific types of information from natural language documents  <BOS>information extraction systems are designed to extract specific types of information from natural language documents<SCI_GEN>\n",
            "95 lexical gaps are those where the language lacks words corresponding to the ones in the language <BOS>lexical gaps are where the language lacks words corresponding to the ones in the language<SCI_GEN>\n",
            "120 a compound feature may appear in more than one tree in a compound but each leaf node has a different value of confidence <BOS>the same feature can appear in more than one tree in a single compound, but each leaf node has a different value of confidence.<SCI_GEN>\n",
            "128 the labels in the log files indicate whether the wizard s call has been completed or whether the user s call has been terminated <BOS>the labels in the log files indicate whether the wizard has already taken over the call or if the user has hung up.<SCI_GEN>\n",
            "43 this theory of memory has two consequences  <BOS>two consequences of this theory of memory<SCI_GEN>\n",
            "65 this case is the information contained in the transfer dictionary <BOS>the information in the dictionary of transfer terms is contained in this case.<SCI_GEN>\n",
            "93 these results are better than those reported earlier which were based on different approaches <BOS>these results are better than the previous studies, which were based on different approaches.<SCI_GEN>\n",
            "165 whether a particular set of engines can be used in a given application depends crucially on the choice of an optimal cover which is the central problem in this paper <BOS> of the paper, a central problem is the selection of an optimal cover for each of the different engines described in the paper.<SCI_GEN>\n",
            "119 we apply regularization to the script based model and to the criterion for maximum likelihood estimation of the entropy <BOS>we apply a regularization of the script of linear models to the loglinear model, and to the criterion for the maximum likelihood estimation of the entropy.<SCI_GEN>\n",
            "62 the intention tag can be defined in the extended decision tree <BOS>the extended decision tree can define the intention tag.<SCI_GEN>\n",
            "136 we present here the system architecture of the proposed qa system and provide some brief descriptions of the components that underlie it <BOS>here we present the system architect's system architect's description of the components of the proposed qa system.<SCI_GEN>\n",
            "92 these errors are specific to french and can be classified into four typeserrorserrorserrors  <BOS>these errors are specific to the French language and can be classified into four types:<SCI_GEN>\n",
            "73 this does not imply that there is no instrument as this is not essential  <BOS>this does not mean that there is no instrument, as this is not essential.<SCI_GEN>\n",
            "101 the paraphrasing system is equivalent to the similarity between partial sentences of a candidate text <BOS>the system of phrasal paraphrase is equivalent to the similarity of the partial sentences of the candidate text<SCI_GEN>\n",
            "165 to explore what might be done to reach a desired result with the most space utilization in a production run we have experimented with various models on a large scale <BOS>for testing the effect of different approaches to solving the size limit in a production run, we have used a variety of models in order to explore what could be done to reach a desired result with the most possible use of the available space.<SCI_GEN>\n",
            "48 nouns in a class usually have similar properties <BOS>nouns in a class usually have the same properties<SCI_GEN>\n",
            "85 our research focuses on the development of a high quality statistical language model  <BOS>our research is mainly focused on the development of a high-quality statistical language model.<SCI_GEN>\n",
            "53 there is a single start and end state for all topics  <BOS>for all topics, there is a single start and end state.<SCI_GEN>\n",
            "33 so a camping domain may be chosen <BOS>so the camping area may be chosen.<SCI_GEN>\n",
            "78 also the segment with an exclamation point has the possibility of segmentation <BOS>the segment with an exclamation point also has the possibility of segmentation<SCI_GEN>\n",
            "153 one problem that must be resolved is the way to resolve the inconsistencies between stereotypes that are generated by the interaction with the individual <BOS>there must be a way to resolve the contradictions between the stereotypes that are generated by the interaction with the individual.<SCI_GEN>\n",
            "115 in particular we were impressed by the performance of wlm on the task of communicating with one another on the web  <BOS>we were particularly impressed by the results ofwlm's research on communicating with one another on the Internet.<SCI_GEN>\n",
            "120 tablereports performance on relation classification using svm and lp based classifiers with varying sizes of labled data <BOS>table NUM reports the performance of the classification of relations using svm and lp, depending on the size of the labled data<SCI_GEN>\n",
            "183 the availability of an unrestricted and freely available dialogue system will support the development of an open source toolkit that can be used to evaluate dialogue system conditions <BOS>the availability of a free and open source dialogue system will support the development of a modern open source toolkit that can be used for the evaluation of the conditions of the dialogue system<SCI_GEN>\n",
            "126 in these systems other features of a complete language system are not in place since the emphasis is on memory based modeling  <BOS>since the main focus is on the memory model, the other features of a complete language system are not yet in place in these systems<SCI_GEN>\n",
            "72 the following are the results after the above measures for the data set  <BOS>table NUM and NUM show the following data after the above measures:<SCI_GEN>\n",
            "61 regular count noun phrases are handled by the following rules <BOS>the following rules apply to regular count noun phrases<SCI_GEN>\n",
            "187 we have developed a methodology for solving the limitations of usual tools for multilingual document creation which originated in the tradition of constructive type theory and mathematics <BOS>- In this tradition, we have developed a methodology for solving the limitations of the usual tools for multilingual document creation, which originated from the constructive theory of type and mathematics of the type editor.<SCI_GEN>\n",
            "86 semantic classes have direct applicability in medical research and question answering  <BOS>in medical research,semantic classes can have direct practical application, which is in the area of information retrieval and question answering.<SCI_GEN>\n",
            "97 the number of mutually independent interpretations of lexical items is large and highly contested <BOS>in particular, lexical items tend to have a large number of mutually independent interpretations, and their lexical content is highly contested.<SCI_GEN>\n",
            "86 this sequence of operations typically requires several iterations of acoustic modeling <BOS>the acoustic model is usually refined several times in this sequence.<SCI_GEN>\n",
            "73 we find that our method outperforms the baseline in every precision range <BOS>in every precision range, we find that our method is superior to the baseline.<SCI_GEN>\n",
            "101 we hope that named entities and parts of speech provide useful information for capturing news stories <BOS>in order to capture the news, we hope that the named entities and parts of speech will be useful.<SCI_GEN>\n",
            "171 in addition to the knowledge base created offline the search was conducted in a context where the paraphrasing form of a phrase was identified and created a knowledge base <BOS>the search for a correct phrase was carried out offline and created a knowledge base about the phonetic form of the phrase.<SCI_GEN>\n",
            "93 the errors involve overgeneralization of the specific definition of the effectative adjective <BOS>the error relates to the over-generalization of the specific concept of the effectative adjective.<SCI_GEN>\n",
            "97 the length of a domination path is not directly dependent on the existence of a non finite set of <BOS>the existence of a non-exhaustive domination path does not directly affect the length of the domination path.<SCI_GEN>\n",
            "63 so far this has essentially been the work of the clerical staff <BOS>so far this has essentially been the work of the clerical staff.<SCI_GEN>\n",
            "102 proolving reference and anaphora is of great interest in computational linguistics and formm semantics <BOS>in the area of Computational Linguistics and Formm semantics, it is of great interest to solve reference and anaphora.<SCI_GEN>\n",
            "61 this is not to say that polysemy is not handled properly e.g. <BOS>for example, polysemy is not properly handled.<SCI_GEN>\n",
            "53 the system does not have to search the entire lexicon <BOS>the system does not have to search the entire lexicon.<SCI_GEN>\n",
            "53 simple classification and routing algorithms are used <BOS>classification and routing algorithms are simple<SCI_GEN>\n",
            "106 reliability of human subjects was not evaluated in our experiments and was not evaluated in the literature <BOS>the reliability of the human subjects was not assessed in our experiments and was not verified in the literature.<SCI_GEN>\n",
            "89 the grammar rule is a rule used in grammatical parsing of first order logical expressions <BOS>the grammar rule is a rule for grammatical use of the first order logical expressions (first-order logic)<SCI_GEN>\n",
            "37 the x axis is pa and the y axis is pb <BOS>the x axis is Pa and the y axis is Pb<SCI_GEN>\n",
            "58 in this paper we present a kernel based algorithm for wsd  <BOS>we present a system of our kernel based algorithms for WSD<SCI_GEN>\n",
            "67 cooperative behavior is not possible if there is a serious conflict <BOS>if there is a serious conflict, then cooperation will be impossible.<SCI_GEN>\n",
            "92 each sub topic in the sub veet s list is listed with the relevant sub topic s in the context <BOS>each sub-Topic in the sub-curve lists the relevant sub-topics<SCI_GEN>\n",
            "91 sumit et al have designed a test based on the answers to questions automatically generated  <BOS>sumit et al have designed a test based on the answers of the questions generated automatically.<SCI_GEN>\n",
            "63 has begun using a generative statistical model for name finding <BOS>he had begun using a generative statistical model for the name search.<SCI_GEN>\n",
            "48 this is discussed more fully in the next section <BOS>in the next section, we discuss this more thoroughly.<SCI_GEN>\n",
            "63 a search procedure is proposed based on dynamic programming dp  <BOS>based on dynamic programming, a search procedure is proposed for the source string.<SCI_GEN>\n",
            "117 any word with a fertility value of zero is deleted and any word with a fertility value greater than two is duplicated <BOS>any word with a fertility value of zero is deleted, and any word with a fertility value greater than two is duplicated.<SCI_GEN>\n",
            "99 such knowledge structures have proven useful in topic identification and other pre processing steps <BOS>such knowledge structures have proved useful in the area of identification of topics and other pre-processing steps<SCI_GEN>\n",
            "77 to build our sample lexicon we need to align words in several asian languages <BOS>words in several asian languages must be aligned so that our sample lexicon can be built<SCI_GEN>\n",
            "45 textdependent features can also be recognized <BOS>the recognition of text dependent features can also be performed<SCI_GEN>\n",
            "630 dimensional adjectives provide qualitative information about physical properties using the following linguistic termsadjectives can provide quantitative information about physical propertiesadjectives can provide qualitative information about physical propertiesadjectives can provide qualitative information about physical propertiesadjectives can provide quantitative information about physical propertiesadjectives can provide qualitative information about physical propertiesadjectives can provide quantitative information about physical propertiesadjectives can provide qualitative information about physical propertiesadject <BOS>dimensional adjectives can provide qualitative information about physical properties using the following grammatical terms:<SCI_GEN>\n",
            "105 in our generator there is a blackboard model of control which is implemented as an interface to the user  <BOS>there's a blackboard model of the control system in our generator.<SCI_GEN>\n",
            "103 ideally the correct meaning of a verb should be revealed at least partially by its use of the predicate <BOS>in principle, at least partial arguments should reveal the proper meaning of the word \"to\"<SCI_GEN>\n",
            "95 the following table lists the properties of the owl model that can be used for lexical analysis <BOS>the following table lists the properties of the owl model that can be used for lexical analysis<SCI_GEN>\n",
            "75 our observations have led to the classification at the nominalization level <BOS>at the level of nominalization, our observations have produced the classification.<SCI_GEN>\n",
            "141 to estimate how often each word appears with each component of speech we need to estimate how often it appears with each component of speech  <BOS>we need to estimate how often each word appears with each part of speech.<SCI_GEN>\n",
            "116 the advantage of this approach is also that it does not require any information about the correct number of clusters <BOS>the approach also has another advantage, which is that it does not require any information about the correct number of clusters.<SCI_GEN>\n",
            "90 the confusion matrix summarizing the resulting inter annotator agreement is shown in table <BOS>table NUM shows the confusion matrix summarizing the resulting interannotator agreement<SCI_GEN>\n",
            "44 in this rule there are at least two meanings <BOS>there are at least two meanings in this rule.<SCI_GEN>\n",
            "107 the difficulty is more marked in english because of the many syntactically ambiguous structures in japanese <BOS>in english, the difficulty is greater because of the many syntactically unclear structures in japanese.<SCI_GEN>\n",
            "78 the complete specification of the tag grammar for lr style parser is given in  <BOS>the complete specification of the tag grammar for lr style parser is listed.<SCI_GEN>\n",
            "105 vbn should behave similarly to that since these features are related to the transitive nature of features <BOS>since these features are related to the transitive nature of the features, vbn should behave similarly to that.<SCI_GEN>\n",
            "108 a probability based translation classification can still classify phrases not belonging to the training data <BOS>the classification of the phrases not belonging to the training data can still be classified according to a probability of translation.<SCI_GEN>\n",
            "106 a typical example involves a typist who entered a word text without noticing that the shift key was locked <BOS>a typical example is that the typist went on typing a few lines without noticing that the shift key was locked.<SCI_GEN>\n",
            "99 we also assumed that all contiguous entities we construct are similarly located on the target side  <BOS>we've also assumed that all the adjacent entities we're building are similarly located on the target side.<SCI_GEN>\n",
            "94 the addition of tags in both of these classes resulted inexamples being incorrectly classified <BOS>in both these classes, the addition of tags has led to a number of examples being incorrectly classified.<SCI_GEN>\n",
            "118 in other words the goal of the target function is irrelevant to the grammars or to the choice of a restrictive lexicon <BOS>this is the case, for example, if the restriction is taken into account by grammars or selecting a restrictive lexicon, the aim of the target function is irrelevant.<SCI_GEN>\n",
            "89 however there are some peculiarities of language that vary from one individual to another <BOS>however, there are some peculiarities in the language of individual countries.<SCI_GEN>\n",
            "64 verbal verbs are categorized into endings in the form ing or ed  <BOS> endings in the form ing or ed are called verbal verb types<SCI_GEN>\n",
            "53 furthermore the prepositions are language independent <BOS>in addition, the prepositions are language independent.<SCI_GEN>\n",
            "115 however one wonders about the relevance of many extracted concepts which are not even at all relevant to the domain <BOS>however one wonders about the relevance of many extracted concepts that are not even at all relevant to the field.<SCI_GEN>\n",
            "189 the narrative elements which can be used to represent the text s core grammatical structure constitute the narrative units that provide the structural units for the construction of the text <BOS>the core grammatical structure of the text is the narrative elements that can be used to represent the entire text.<SCI_GEN>\n",
            "119 whether or not a phenomenon is actually present is an empirical question which can be tested using linguistic resources <BOS>- if you use a particular language, then it is possible to test whether the phenomenon is actually present.<SCI_GEN>\n",
            "137 to obtain a more complete set of entity names we used wordnet and filtered out those that contained words that were not in the dictionary <BOS>using wordnet, we searched for entities using the words in the dictionary of the word \"entity\" and removed those that contained them.<SCI_GEN>\n",
            "71 the easiest word to recognize in our sample of english is collaboration <BOS>in the sample of English, the easiest word is cooperation<SCI_GEN>\n",
            "119 the issues that we are attempting to address have driven us on to the problems of what is appropriate and what is what  <BOS>the issues we are trying to solve have driven us on to the problems of what is appropriate and what is what.<SCI_GEN>\n",
            "204 the deterioration in accuracy is likely to be compounded by the tagging of pos tags according to the training scheme which is based on the pos tag set but which is not necessarily the set used in practice <BOS>according to the training scheme, which is based on the use of the POS tag, the accuracy deterioration is likely to be compounded by the splitting of the tag<SCI_GEN>\n",
            "66 these and other methods do not recover the extergrammatical status <BOS>the recovery of the extergrammatical status is not possible in these and other ways.<SCI_GEN>\n",
            "153 the count and information status of previous anaphora decisions are determined by the decision module and are entered into the dialogue management system <BOS>the decision-making module shall determine the count and information status of the previous anaphora decision.<SCI_GEN>\n",
            "109 the criteria used to evaluate the database should be adapted to the context of multilingual lexical resources <BOS>in the context of a multi-lingual lexical database, the criteria for evaluating the database should be adapted<SCI_GEN>\n",
            "63 it should be possible to do the job more efficiently with tran  <BOS>in the case of tran, it will be possible to do the job more efficiently than fortran<SCI_GEN>\n",
            "104 there is more evidence for a speaker s belief in the presence of pbcp1a than evidence for its initiation <BOS>the speaker's belief in the presence of pbcp1a could be supported by more than just the initiation of the topic.<SCI_GEN>\n",
            "44 but there is plenty of room for improvement  <BOS>but there is a lot of room for improvement.<SCI_GEN>\n",
            "81 smartnotesimplicit labeling of meeting data through user note taking and browsing <BOS>smartnotes implicit labeling of meeting data through user note taking and browsing<SCI_GEN>\n",
            "74  information may not be specified in an order that respects grammaticality <BOS>the order of information, for example grammatical codes, may not be specified<SCI_GEN>\n",
            "42 variants of the term and some phrases e.g. <BOS>variants of the term and some phrases e.g.<SCI_GEN>\n",
            "50 we can observe at least q observations in a sample <BOS>in a sample, we can observe at least q observations.<SCI_GEN>\n",
            "48 the system looks for these concepts to find text <BOS>the system is looking for these concepts to find the text<SCI_GEN>\n",
            "112 she must now decide which rhetorical effects she wants in the text and which will allow her to realize her goal  <BOS>she must now choose between the rhetorical effects she wants in the text and the ones that will allow her to realize her goal.<SCI_GEN>\n",
            "102 the overall coherence structure of a sentence is ranked according to the ranking of sentence coherence <BOS>the ranking of sentence coherence based on the overall coherence structure of the sentence<SCI_GEN>\n",
            "106 however this assumption is in the current implementation at least for now to ensure that it is always true <BOS>however, this assumption is applied in the present implementation period in order to ensure that it is always true.<SCI_GEN>\n",
            "137 in our case we are dealing with technical articles which are the result of the complex process of scientific inquiry that starts with the <BOS>in our case, we are dealing with technical articles which are the result of the complex process of scientific inquiry that starts with the<SCI_GEN>\n",
            "41 figureshows the difference in tagset data <BOS>the difference in the tag data is represented by NUM tags.<SCI_GEN>\n",
            "100 the model of local topic shifts in text can not capture the structure of the transitions in the text <BOS>the model of local changes in the text cannot capture the structure of the transition of the topic in the whole text.<SCI_GEN>\n",
            "86 attribute value pairs provide a means for identifying values in different applications <BOS>the application-specific attributes provide a way to identify values in different applications<SCI_GEN>\n",
            "118 furthermore students should be able to explore the formalism in order to understand themselves and their own judgments <BOS>in addition, students should be able to examine the formalism in order to understand themselves and their own judgments.<SCI_GEN>\n",
            "176 the task of automatically learning a method of merit for the purposes of decoding is therefore one of learning methods whose success is a function of the difficulty of the task <BOS>such a task is, for example, the task of automatically learning a method of merit for the purpose of deciphering.<SCI_GEN>\n",
            "127 the gradient of a function is a vector whose direction indicates the relative increase in brill value with increasing frequency <BOS>the gradients of the function are a vector that points in the direction in which the function is increasing fastest.<SCI_GEN>\n",
            "64 more details on these numbers are given in the relevant sections <BOS>the relevant sections shall provide more detailed information on these numbers.<SCI_GEN>\n",
            "65 the complete set of features considered in defining spanish table <BOS>the complete set of features considered in the definition of spanish table NUM<SCI_GEN>\n",
            "175 in contrast interlingua based systems rely on source string structure to determine constituent structure and thus thus the constituent structure of the resulting target string <BOS>in contrast, the interlingua-based systems rely on a source string to determine the structure of the target string, and thus the structure of the resulting target string.<SCI_GEN>\n",
            "54 the wizard s year old system sat in an open laboratory <BOS>the wizard sitting in an open lab listened to the wizard in the headphones<SCI_GEN>\n",
            "75 the general assumption is that the quantified formula is a four part object <BOS>the general assumption is that the quantitatively expressed formula is a 4-part object.<SCI_GEN>\n",
            "80 it is clear that embedded responses are typical during the interaction of users  <BOS>it is clear that the embedded responses are typical during the interaction of users.<SCI_GEN>\n",
            "54 our classification of grammars into four types yields  <BOS>there are four types of grammars in our classification.<SCI_GEN>\n",
            "127 instead i concentrate on parameter estimation which for attribute value grammars can not be accomplished by standard techniques <BOS>instead i concentrate on parameter estimation which for attribute value grammars cannot be accomplished by standard techniques<SCI_GEN>\n",
            "51 two different ways can express the same requirement <BOS>the same requirement can be expressed in two ways.<SCI_GEN>\n",
            "80 translation pairs with the translation tag will be added to the translation list <BOS>translations with the translation tag will be added to the translation list<SCI_GEN>\n",
            "112 to our knowledge this is the largest and most complete evaluation of subcategorization frames for english so far <BOS>we have the largest and most extensive evaluation of subcategorization categories in English so far.<SCI_GEN>\n",
            "69 a function is defined as a function of two states instead of just one <BOS>instead of just one state, a function is defined as a function of two states.<SCI_GEN>\n",
            "162 in other words it should be possible to detect pairs of words that are phonetically similar or phonetically similar by means of detecting cognate or similar words <BOS>in other words, it is possible to identify phonetically similar or phonetically similar words by means of detections of phonetic similarity or similar terms.<SCI_GEN>\n",
            "61 the experiments need to be replicated to verify these results <BOS>the results of the experiments need to be verified in order to draw conclusions from them.<SCI_GEN>\n",
            "85 these constraints can also depend on the domain model but can also be domain specific <BOS>depending on the domain model, these constraints can also depend on the specific constraints<SCI_GEN>\n",
            "155 in this case a text based system would guarantee good coveragewhile still requiring a smaller sample of the written text than a purely text based procedure <BOS>in this case, the text based system would guarantee good coverage, while still requiring a smaller sample of the written text than a purely text based procedure.<SCI_GEN>\n",
            "46 the strongest items are listed first and so on <BOS>the strongest ones are listed first, and so on.<SCI_GEN>\n",
            "107 the topics will be chaired by experts in different fields and they will introduce the topics in the meeting <BOS>the meetings will be chaired by experts from different fields and they will introduce the topics.<SCI_GEN>\n",
            "87 a new cluster is formed and the set of nodes that satisfy the condition are added to it <BOS>a new cluster is created and the selected set of nodes are inserted into it.<SCI_GEN>\n",
            "123 the effect is to require some part of the current clause to be consistent with some possibly different clause in the future <BOS>the effect is to require some part of the current clause to be consistent with some possibly different clause in the future.<SCI_GEN>\n",
            "92 however this phenomenon is much more widespread than previously recognized in the literature <BOS>however, the phenomenon is much wider than previously recognised in the literature.<SCI_GEN>\n",
            "109 it can be seen that dowty s treatment of the nonmonotonic nature of inference involves taking account of this <BOS>in the context of the intervening years, it can be seen that dowty is taking account of the non-monotonic nature of the conclusions involved.<SCI_GEN>\n",
            "96 in particular for small quantities of information the speed advantage of tts is less problematic <BOS>in particular, the speed advantage of tts is less problematic for small quantities of information.<SCI_GEN>\n",
            "84 prepositions have been described in various ways by different philosophical schools  <BOS>the prepositions were variously interpreted by different philosophical schools.<SCI_GEN>\n",
            "110 e.g. non parallel bitext maps which were created without the chain length parameter characters between points  <BOS>e.g. non parallel bitext maps, created without the chain length parameter, have on average NUM characters between points<SCI_GEN>\n",
            "64 the use of additional data to extend the coverage of the dataset <BOS>to extend the data to a more specific range, the use of<SCI_GEN>\n",
            "99 some of these recommendations are well known whereas others are specific to information extraction  <BOS>for example, some of these recommendations are well known, while others are specific to information extraction<SCI_GEN>\n",
            "154 two contrasting views are thus possiblemessages are thus an opportunity for two opposing views messages are thus an opportunity for two contrasting views  <BOS>sending messages is thus an opportunity for two opposing views<SCI_GEN>\n",
            "110 the first phase consists in establishing all possible projections from id rules and fcrs to the input document <BOS>in the first phase, all possible projections of the id rules and the corresponding FECA rules are established<SCI_GEN>\n",
            "56 what are we to conclude from these inconsistent results  <BOS>:)  What are we to conclude from these inconsistent results?<SCI_GEN>\n",
            "163 in this case the evaluation is done as if there are two reference sentences therefore a candidate sentence will receive the same score regardless of its politeness <BOS>in this case, the evaluation is done as if there are two reference sentences, therefore the same candidate sentence will receive the same score regardless of its politeness<SCI_GEN>\n",
            "128 he suggests that nlp procedures can be used to overcome traditional methods of dealing with individual terms and their relations <BOS>according to him, nlp procedures can be used to overcome traditional methods of dealing with individual terms and their relations.<SCI_GEN>\n",
            "165  increasing the potential for confusion increases the number of words in a vocabulary and also increases the number of new words that need to be added to the lexicon <BOS>words in a vocabulary increase the potential for confusion, as well as adding new words to the lexicon<SCI_GEN>\n",
            "98 initial skeletons are easily represented as language independent data structures and do not change <BOS>the initial skeletons are easily represented as language-specific data structures, which don't change.<SCI_GEN>\n",
            "110 the problem of solving a linear equation using simple linear methods can be solved if the system is consistent <BOS>if the system is consistent, it is possible to solve the problem of solving a linear equation using simple linear methods<SCI_GEN>\n",
            "116 more specifically we will demonstrate the ll config performance using a selection method specifically tailored to ll <BOS>in particular, a specific selection method will be used to demonstrate the performance of the model of the ll config.<SCI_GEN>\n",
            "90 whether a word can have both a dependent and an ordered meaning is a question of semantics <BOS> can a word have a dependent and an ordered meaning?<SCI_GEN>\n",
            "133 while the above distinctions are useful for describing the content of a text they are not useful for describing the content of a book <BOS> reading is a modification of the book, listening is not a modification of the book, and so on.<SCI_GEN>\n",
            "53 this inconsistency may be due to the word match error <BOS>the word match error may be a reason for this inconsistency<SCI_GEN>\n",
            "74 on the other hand these features will cause unwanted distinctions too e.g. <BOS>in the other hand, these characteristics will cause unwanted distinctions too e.g.<SCI_GEN>\n",
            "209 the two words in the discourse can be related in that they can be interpreted as implying a situation in which the height is excessively high or in the opposite meaning that the height is not sufficiently high <BOS>in the deeper linguistic analysis, the two words can be related in that they can be interpreted as implying a situation in which the height is excessively high, or, in the opposite, implying a situation in which the height is not sufficiently high.<SCI_GEN>\n",
            "122 the first step in the verification of form x t is to thoroughly test the decomposition rules for the initial constraint x  <BOS>in the first phase of the verification of the form x t, the criteria for applying the decomposition rules to the initial condition of x are thoroughly checked.<SCI_GEN>\n",
            "56 it is more difficult to track down too specific examples <BOS>if they are too specific, it will be harder to track down.<SCI_GEN>\n",
            "59 these alternatives may be required for updating file cards  <BOS>these alternatives may be required for the update of the file cards.<SCI_GEN>\n",
            "69 ppar is used to rewrite the output of the dependency analysis program <BOS>the output of the dependency analysis program is rewritten by ppar<SCI_GEN>\n",
            "133 this definition is quite similar to the definition of a cfqist in the sense of a freddy but the two differ in composition and ranking <BOS>in this definition, the criterion of a cfqist is quite similar to the criteria of a freddy, but the two differ in composition and ranking.<SCI_GEN>\n",
            "74 two different features and normalisations were used to test each parameter <BOS>each parameter was tested with two different features and normalisations<SCI_GEN>\n",
            "59 the words in a group correspond to components of the vector <BOS>the words selected for the group correspond to the components of the vector<SCI_GEN>\n",
            "72 but this is not the case when selecting a governor for a particular word <BOS>but this is not the case, when you select a governor for a particular word.<SCI_GEN>\n",
            "249 while a single system may use a language model to guide speech recognition while a formal language model may provide a means for controlling the parsing of sentences in the same way that language is used to provide instructions for a computer system <BOS> in the case of a single system of speech recognition and speech recognition, the language model may be used to guide speech recognition, while a formal language model may be used to control the processing of the same sentences<SCI_GEN>\n",
            "87 the nature of these primitive elements may vary with different levels of representation <BOS>in different levels of representation, the nature of these primitive elements may differ.<SCI_GEN>\n",
            "50 lists can be easily detected by these special tags <BOS>these special tags can be easily detected by the lists themselves.<SCI_GEN>\n",
            "118 we show that the model based on local information yields significant improvements over the baseline in our experiments <BOS>in our experiments, the use of local information results in significant improvements in the model, which is based on local information.<SCI_GEN>\n",
            "64 our results support high accuracy for our data set of senseval3  <BOS>the results of the data set of the SenseVal3 database support high accuracy of our analysis.<SCI_GEN>\n",
            "122 the combination approach did not improve the speech features approach significantly but was not significantly worse either <BOS>the combination approach did not improve the speech feature approach significantly, but was not significantly worse.<SCI_GEN>\n",
            "51 different rules apply to the same data in the chart <BOS>in the chart, different rules apply to the same data.<SCI_GEN>\n",
            "110 the virtual character was able to provide the user with the context in which to provide the answer or question <BOS>the virtual character was able to provide the user with the necessary context in which to provide the answer or question<SCI_GEN>\n",
            "112 the use of probability based language features is characteristic of our proposed use of the probability approach <BOS>the use of probability based on multiple levels of language features is characteristic of our proposed use of the probability approach.<SCI_GEN>\n",
            "100 we keep a single word that has a small number of neighbors if there are multiple words in a sentence <BOS>if there are multiple words in a sentence, we keep the one that has the fewest.<SCI_GEN>\n",
            "213 pragmatic linguists have long recognized the possibility of eliminating assumptions in the conditional interpretation of phrases and have used this to change the conditional interpretation of verbs and adjectives  <BOS>the change in the conditional interpretation of the phrase, which sets out the possibility of eliminating assumptions in the context of speech, allows pragmatists to depart from a conditional interpretation of the word<SCI_GEN>\n",
            "49 finally we plan to pursue related and future work <BOS>we shall conclude our work on the future and related projects.<SCI_GEN>\n",
            "133 the syntactic behavior of words is represented by probability values which are used to approximate the syntactic behavior of the text <BOS>the probability values of the words used in the text are set according to the syntactic behaviour of the word<SCI_GEN>\n",
            "96 the inefficiency of natural language processing is a major problem in computational linguistics  <BOS>the inefficiency of natural language processing is a major problem in computer science.<SCI_GEN>\n",
            "180 as levesque points out there are a lot of assumptions built into this approach not the least being that the knowledge in d must be complete in some non trivial sense and consistent <BOS>as levesque points out there are a lot of assumptions built into this approach not the least being that the knowledge in d must be complete in some non trivial sense and consistent.<SCI_GEN>\n",
            "91 this paper reports on work on designing simple language interfaces with limited interaction <BOS>the design of a simple language interface with limited interaction is reported in this paper.<SCI_GEN>\n",
            "72 this functionality could be directly incorporated into the editing tools <BOS>the functionality could be directly integrated into the editing tools.<SCI_GEN>\n",
            "301 the results of our experiments using reading time as an offline measure of comprehension appear to be consistent with those using reading time as an intrinsic measure of language understanding and suggest that there is a distinct pattern of acceptability for different types of referential expressions <BOS>indeed, using online language comprehension tests as an offline measure of comprehension, the results of experiments using reading time to assess the acceptability of different types of re-formulations of the referential expressions appear consistent with the results of experiments using online language comprehension tests.<SCI_GEN>\n",
            "98 psychological methods are needed to establish protocols that do not bias the interesting variables <BOS>in setting up protocols that do not bias the interesting variables, psychological methods are needed<SCI_GEN>\n",
            "109 links between start and end points are given a single entry in which the start and end points are interleaved <BOS>a single link is created in which the start and end points of the links are interlinked.<SCI_GEN>\n",
            "43 for example we will use the parser strategy <BOS>for an example, we will use the strategy of the Parser for CYK.<SCI_GEN>\n",
            "157 such a rule may also set up common features on the strings to which it applies such that it is easy to determine which strings are associated with each other <BOS>such a rule may also set up common rules on the use of a few strings, according to common features.<SCI_GEN>\n",
            "280 the linguistic statements are governed by the set of statements and their associated language structures as defined by the grammar and by the appropriate linguistics and the creation of the appropriate structures from the set of statements is the essence of language construction  <BOS>in order to achieve the necessary linguistics and the creation of the appropriate linguistic structure, the language is governed by the language-building statement and its associated language-structuring rules.<SCI_GEN>\n",
            "123 before we present our data set we begin by discussing some of the issues we consider relevant for evaluation and discussion <BOS>we'll start with the data set we use for our evaluation and discussion.<SCI_GEN>\n",
            "82 this is a very computationally complex task and in our project it is not realistic <BOS>in the context of our project, it is highly complicated and expensive, and is not realistic.<SCI_GEN>\n",
            "120 the number of occurrences of induced expressions is used as a metric for evaluating the resulting frame assignment rules <BOS>the results of the evaluation of the results of the resulting frame- assignment rules are used to determine the number of occurrences of induced expressions<SCI_GEN>\n",
            "80 sentence compression aims to retain the most salient information in the sentence <BOS>compression of the sentence to retain the most salient information<SCI_GEN>\n",
            "74 the language games are deliberately similar to those in language research  <BOS>the language games are deliberately similiar to the language of children's research.<SCI_GEN>\n",
            "102 the first property means that only one subtree may represent a single subpart of the larger structure  <BOS>the first property means that only one sub-part of the larger structure can be represented in a single subtree<SCI_GEN>\n",
            "62 this new information will be loaded into the system s database <BOS>the new information will be loaded into the site's database.<SCI_GEN>\n",
            "47 f i ck is a binary function and its value isor  <BOS>f i ck is a binary function and its value is NUM or NUM<SCI_GEN>\n",
            "89 the purpose of this study is to develop a method for disambiguating japanese conjugations <BOS>the purpose of the study is to develop a method for disambiguating Japanese conjugations<SCI_GEN>\n",
            "61 the different actions depend on the types of ingredients used <BOS>the different actions depend on the types of ingredients used.<SCI_GEN>\n",
            "137 the assignment of meaning by animals is based on classification of terms and the animal s behavior and pattern of the operator s behavior <BOS>the assignment of meaning by animals is based on the classification of the terms and the animal's behavior and the pattern of the operator's behaviour.<SCI_GEN>\n",
            "75 language models play an important role in modern speech recognition systems <BOS>one of the main components of modern speech recognition systems is the language model<SCI_GEN>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "456"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "filtered_outputs_model2_rewards = []\n",
        "filtered_inputs_model2_rewards = []\n",
        "unfiltered_outputs_model2_rewards = outputs_model2_rewards\n",
        "unfiltered_inputs_model2_rewards = inputs\n",
        "for i in range(len(outputs_model2_rewards)):\n",
        "  o = outputs_model2_rewards[i]\n",
        "  if len(o)>len(inputs[i])/2:\n",
        "    print(len(o), o, inputs[i])\n",
        "    filtered_outputs_model2_rewards.append(o)\n",
        "    filtered_inputs_model2_rewards.append(inputs[i])\n",
        "\n",
        "\n",
        "len(filtered_inputs_model2_rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2:"
      ],
      "metadata": {
        "id": "eqPc2dR33l2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3vfUntjWh6g"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Add tokens to sentences - REPLACE \"formal\" WITH THE INPUTS SENTENCES\n",
        "\n",
        "\n",
        "# Making data: taking the formal sentences and adding tokens, put it in a list\n",
        "inputs = []\n",
        "\n",
        "for i in total_model2_sample:\n",
        "  # sentence = \"<BOS>\" + i[0] + \"<SCI_GEN>\"\n",
        "  inputs.append(i[0])#sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01dda49a-b254-4bdc-8c84-2307b434dd39",
        "id": "P-IALE3wWh6g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8DBhyrkWh6h"
      },
      "outputs": [],
      "source": [
        "# STEP 2: Tokenize inputs for the models into their individual lists\n",
        "model_titles = [\"Model2_rewards\"]\n",
        "\n",
        "# Tokenizing the inputs for the PARANMT model (input_ids_P) and GYAFC model (input_ids_G)\n",
        "input_ids_2 = [] \n",
        "for sent in inputs:\n",
        "  input_ids_2.append(tokenizer_2_rewards.encode(sent, return_tensors='pt'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_all = [inputs]\n",
        "models = [model_2_rewards]\n",
        "tokenizers = [tokenizer_2_rewards]"
      ],
      "metadata": {
        "id": "1kr26D1aWh6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "e2aa56c5-b0c6-4852-ecf1-2fb7f05458b9",
        "id": "7XWJsIA0Wh6i"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a smoothing filter can be used to introduce new trends into temporally coherent frequencies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f69554cf0aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'processor' is not defined"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(model_titles))):\n",
        "\n",
        "  # STEP 3: Select model to generate with  --- !! CHANGE DECLARATION FOR DIFFERENT MODEL !!\n",
        "  title = model_titles[i]\n",
        "  input_ids = input_ids_all[i]\n",
        "  model = models[i]\n",
        "  tokenizer = tokenizers[i]\n",
        "\n",
        "  # STEP 4: Generate Outputs from model\n",
        "\n",
        "  # Generating for each in the list\n",
        "  outputs = []\n",
        "  input_prompt = \"\"\"<BOS>A classifier is further trained to ensure contextual consistency of the generated sentence.<SCI_GEN>\"\"\"\n",
        "  for inp in tqdm(input_ids):\n",
        "    # outputs.append(model.generate(\n",
        "    #     inp,\n",
        "    #     max_length=int(len(input_prompt)),\n",
        "    #     top_p=0.7,\n",
        "    #     temperature=0.9,\n",
        "    #     pad_token_id = 50256,\n",
        "    #     eos_token_id = 50256,\n",
        "    #     top_k=50,\n",
        "    #     do_sample=True,\n",
        "    #     early_stopping=True\n",
        "    # ))\n",
        "    print(inp)\n",
        "    output = processor(inp)\n",
        "    print(output)\n",
        "    outputs.append(output)\n",
        "\n",
        "  # # STEP 5: Print some of the outputs just to check them\n",
        "\n",
        "  # for i in range(10):\n",
        "  #   print(tokenizer.decode(outputs[500+i][0]))\n",
        "\n",
        "  # STEP 6: Save generated outputs using pickle --- MAKE SURE TO CHANGE VARIABLE NAME WITH NEW MODElS, DON'T OVERWRITE\n",
        "\n",
        "  gen_outputs = outputs\n",
        "  open_file = open(\"generated_outputs_\"+title+\".p\", \"wb\")\n",
        "  pickle.dump(gen_outputs, open_file)\n",
        "  open_file.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ7X4q0uWh6i"
      },
      "outputs": [],
      "source": [
        "  # STEP 7: Load using pickle --- BEWARE VARIABLE NAME\n",
        "\n",
        "  # gen_outputs_pk = pickle.load(open(\"generated_outputs.p\", \"rb\"))\n",
        "  # print(tokenizer.decode(gen_outputs_pk[0][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Output in Batches"
      ],
      "metadata": {
        "id": "mJHP14aKMd_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GYAFC Model 1"
      ],
      "metadata": {
        "id": "PX9blZVUUSYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, token_ids, attention_masks):\n",
        "    self.token_ids = token_ids\n",
        "    self.attention_masks = attention_masks\n",
        "    if len(self.token_ids) != len(self.attention_masks):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _token_ids = self.token_ids[index]\n",
        "    _attention_masks = self.attention_masks[index]\n",
        "    return _token_ids, _attention_masks\n",
        "\n",
        "def seperate_sents(sent):\n",
        "  rm_special = sent.replace(\"<BOS>\",\"\").replace(\"<PAD>\",\"\")\n",
        "  input = rm_special.split(\"<SCI_GEN>\")[0]\n",
        "  output = rm_special.split(\"<SCI_GEN>\")[1]\n",
        "  output = output.split(\"<EOS>\")[0]\n",
        "  return input, output\n",
        "\n",
        "# Tokenize batch before inference\n",
        "def generate_paraphrase(texts, batch_size):\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  texts =  [\"<BOS>\"+ t + \"<SCI_GEN>\" for t in texts]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  tokenizer_res = tokenizer(texts, padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=100, truncation=True).to(device)\n",
        "  loader = iter(DataLoader(CustomDataset(tokenizer_res[\"input_ids\"], tokenizer_res[\"attention_mask\"]), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    token_ids, attention_masks = loader.next()\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        min_length = 10,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return all_sents\n",
        "\n"
      ],
      "metadata": {
        "id": "jsBcqIZoVKvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag1 = \"<BOS>\"\n",
        "tag2 = \"<SCI_GEN>\"\n",
        "outputs = None\n",
        "model = model_GYAFC\n",
        "tokenizer = tokenizer_GYAFC\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = model.to(device)\n",
        "\n",
        "# Tokenize batch during inference\n",
        "def generate_paraphrase(texts, batch_size):\n",
        "  # Add special tokens and sort by len\n",
        "  texts =  [\"<BOS>\"+ t + \"<SCI_GEN>\" for t in texts]\n",
        "  # all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  # texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  loader = iter(DataLoader(CustomDataset(texts, [1]*len(texts)), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    texts, all_lens = loader.next()\n",
        "    t_res = tokenizer(list(texts), padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=200, truncation=True).to(device)\n",
        "    token_ids = t_res[\"input_ids\"]\n",
        "    attention_masks = t_res[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out"
      ],
      "metadata": {
        "id": "cI47kv8FMiq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.special_tokens_map\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3mtRIh72_-0",
        "outputId": "bdf8df05-fbff-4311-b02b-c02a15140e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'additional_special_tokens': ['<SCI_GEN>'],\n",
              " 'bos_token': '<BOS>',\n",
              " 'eos_token': '<EOS>',\n",
              " 'pad_token': '<PAD>',\n",
              " 'unk_token': '<|endoftext|>'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [x[0] for x in total_data_50_50[:100]]\n",
        "# reference_output = [x[1] for x in total_data_50_50[:100]]\n",
        "outputs = generate_paraphrase(inputs, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "YLp1jwFVONMG",
        "outputId": "7ad5eb33-17ef-4f55-ed52-58dd6edcf396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 1/13 [00:03<00:47,  3.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<BOS>Four suspected terrorists had been detained and were now undergoing interrogation.<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>You and Grandma want to stay in the room.<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>If you just send him an email, then it means you are frightened<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', \"<BOS>Dr. Garner's agreed to drop the kidnapping charges if you turn over the boy.<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\", '<BOS>Incoming breakers broke, spilling shatters of foam on the sand.<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>Enjoy your time going out Enjoy your freedom<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>Go into chat rooms that are in your peer group, and then introduce yourself<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>His distaste for America quailed before his hatred for the rulers of his own country.<SCI_GEN>He hated the people that rule in his own country and so did he hate America<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [00:07<00:43,  3.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<BOS>Ask him or have one of your girlfriends ask him<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>Darling, I was so excited when I got your message.<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>I would say, Havent you people ever heard of closing a door<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', \"<BOS>Anyway, I've got a huge pile of Latin translation to do.<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\", '<BOS>Put your greatest effort in staying close on an emotional level<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>Richard Hatch, Amber Brkich, Tina and Ethan are all probably going to the cookout<SCI_GEN>Richard Hatch, Amber Brkich, Tina and Ethan are all probably going to the cookout<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>The largest tree also has the longest period of growth.<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>', '<BOS>I know that we cant be graphic but consider an adult shop<SCI_GEN><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [00:11<01:03,  5.75s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-f81db73e07a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtotal_data_50_50\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# reference_output = [x[1] for x in total_data_50_50[:100]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_paraphrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-08b049f95ae1>\u001b[0m in \u001b[0;36mgenerate_paraphrase\u001b[0;34m(texts, batch_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m       )\n\u001b[1;32m     40\u001b[0m     \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m             )\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0;31m# pre-process distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_warper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m             \u001b[0;31m# Store scores, attentions and hidden_states when required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0msorted_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mcumulative_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[:10])\n",
        "print(reference_output[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7406vAAzwLu",
        "outputId": "b710fd2b-e336-45a1-d9f5-28aa61ed77da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Four suspected terrorists had been detained and were now undergoing interrogation.', 'You and Grandma want to stay in the room.', 'If you just send him an email, then it means you are frightened', \"Dr. Garner's agreed to drop the kidnapping charges if you turn over the boy.\", 'Incoming breakers broke, spilling shatters of foam on the sand.', 'Enjoy your time going out Enjoy your freedom', 'Go into chat rooms that are in your peer group, and then introduce yourself', 'His distaste for America quailed before his hatred for the rulers of his own country.', 'Ask him or have one of your girlfriends ask him', 'Darling, I was so excited when I got your message.']\n",
            "['they further were detained by the four suspects, who have now been subjected to questioning.', \"you'll be staying with your grandmother.\", 'If you just send him an email, then that means ur scared', 'when you give him the boy, Dr. Garner withdraws a kidnapping charge.', 'the waves crashed and splashed across the sand with showers of foam.', 'GO OUT AND HAVE A GOOD TIMEBE FREE', 'GO INTO CHAT ROOMS THAT ARE YOUR PEER GROUPINTRODUCE YOURSELF', \"Muhammadi's hostility to America was in awe of hatred for his country's rulers.\", 'ask him or have one of your girl friends ask him', 'oh, sweetie, your message has made me so happy.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(inputs[i], \" \", outputs[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOZQnkEbiVud",
        "outputId": "8fabd165-7d89-4888-bb3b-18012c855cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Four suspected terrorists had been detained and were now undergoing interrogation.   ('', '')\n",
            "You and Grandma want to stay in the room.   ('The dream was hilarious', '')\n",
            "If you just send him an email, then it means you are frightened   ('Hell tell you youre alike', '')\n",
            "Dr. Garner's agreed to drop the kidnapping charges if you turn over the boy.   ('Could you help me with my math', '')\n",
            "Incoming breakers broke, spilling shatters of foam on the sand.   ('He looks ridiculous when he does that', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mWCeCDjzic8",
        "outputId": "fe6acfae-12a7-4de0-d03c-1cd4247862a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('', ''), ('The dream was hilarious', ''), ('Hell tell you youre alike', ''), ('Could you help me with my math', ''), ('He looks ridiculous when he does that', ''), ('Rock is the worst in my opinion', ''), ('Would you agree that is somewhat unusual', ''), ('Enjoy your time going out Enjoy your freedom', 'Go out, go out, have fun'), ('Jed Allen, the soap opera actor', ''), ('Long time no saw something so romantic.', '')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_gyafc = outputs"
      ],
      "metadata": {
        "id": "iBfOLI2vWZIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(outputs_gyafc, open(\"new_gyafc_output.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "tCaDPZE3ZEpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARANMT Model 1"
      ],
      "metadata": {
        "id": "G4YUKkzgVqba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, token_ids, attention_masks):\n",
        "    self.token_ids = token_ids\n",
        "    self.attention_masks = attention_masks\n",
        "    if len(self.token_ids) != len(self.attention_masks):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _token_ids = self.token_ids[index]\n",
        "    _attention_masks = self.attention_masks[index]\n",
        "    return _token_ids, _attention_masks\n",
        "\n",
        "def seperate_sents(sent):\n",
        "  rm_special = sent.replace(\"<BOS>\",\"\").replace(\"<PAD>\",\"\")\n",
        "  input = rm_special.split(\"<SCI_GEN>\")[0]\n",
        "  output = rm_special.split(\"<SCI_GEN>\")[1]\n",
        "  output = output.split(\"<EOS>\")[0]\n",
        "  return input, output\n",
        "\n",
        "# Tokenize batch before inference\n",
        "def generate_paraphrase(texts, batch_size):\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  texts =  [\"<BOS>\"+ t + \"<SCI_GEN>\" for t in texts]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  tokenizer_res = tokenizer(texts, padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=100, truncation=True).to(device)\n",
        "  loader = iter(DataLoader(CustomDataset(tokenizer_res[\"input_ids\"], tokenizer_res[\"attention_mask\"]), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    token_ids, attention_masks = loader.next()\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        min_length = 10,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out\n",
        "\n"
      ],
      "metadata": {
        "id": "hczV4IrkVqbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag1 = \"<BOS>\"\n",
        "tag2 = \"<SCI_GEN>\"\n",
        "\n",
        "model = model_PARANMT\n",
        "tokenizer = tokenizer_PARANMT\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = model.to(device)\n",
        "\n",
        "# Tokenize batch during inference\n",
        "def generate_paraphrase(texts, batch_size=128):\n",
        "  # Add special tokens and sort by len\n",
        "  texts =  [tag1+ t + tag2 for t in texts]\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  loader = iter(DataLoader(CustomDataset(texts, [1]*len(texts)), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    texts, all_lens = loader.next()\n",
        "    t_res = tokenizer(list(texts), padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=200, truncation=True).to(device)\n",
        "    token_ids = t_res[\"input_ids\"]\n",
        "    attention_masks = t_res[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    #print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out"
      ],
      "metadata": {
        "id": "Z4uc2aFmVqbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [x[0] for x in total_data_50_50]\n",
        "outputs_paranmt = generate_paraphrase(inputs, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c725c92b-e731-460a-e849-3f765813463c",
        "id": "HMRX8yruVqbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [23:37<00:00, 17.72s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(outputs_paranmt, open(\"new_outputs_paranmt.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "Pas-Kt_mPvxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combi Model 1"
      ],
      "metadata": {
        "id": "pg8QIzb_7cdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, token_ids, attention_masks):\n",
        "    self.token_ids = token_ids\n",
        "    self.attention_masks = attention_masks\n",
        "    if len(self.token_ids) != len(self.attention_masks):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _token_ids = self.token_ids[index]\n",
        "    _attention_masks = self.attention_masks[index]\n",
        "    return _token_ids, _attention_masks\n",
        "\n",
        "def seperate_sents(sent):\n",
        "  rm_special = sent.replace(\"<BOS>\",\"\").replace(\"<PAD>\",\"\")\n",
        "  input = rm_special.split(\"<SCI_GEN>\")[0]\n",
        "  output = rm_special.split(\"<SCI_GEN>\")[1]\n",
        "  output = output.split(\"<EOS>\")[0]\n",
        "  return input, output\n",
        "\n",
        "# Tokenize batch before inference\n",
        "def generate_paraphrase(texts, batch_size):\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  texts =  [\"<BOS>\"+ t + \"<SCI_GEN>\" for t in texts]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  tokenizer_res = tokenizer(texts, padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=100, truncation=True).to(device)\n",
        "  loader = iter(DataLoader(CustomDataset(tokenizer_res[\"input_ids\"], tokenizer_res[\"attention_mask\"]), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    token_ids, attention_masks = loader.next()\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        min_length = 10,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out\n",
        "\n"
      ],
      "metadata": {
        "id": "p5WQEmE97cdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag1 = \"<BOS>\"\n",
        "tag2 = \"<SCI_GEN>\"\n",
        "\n",
        "model = model_combi\n",
        "tokenizer = tokenizer_combi\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = model.to(device)\n",
        "\n",
        "# Tokenize batch during inference\n",
        "def generate_paraphrase(texts, batch_size=128):\n",
        "  # Add special tokens and sort by len\n",
        "  texts =  [tag1+ t + tag2 for t in texts]\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  loader = iter(DataLoader(CustomDataset(texts, [1]*len(texts)), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    texts, all_lens = loader.next()\n",
        "    t_res = tokenizer(list(texts), padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=200, truncation=True).to(device)\n",
        "    token_ids = t_res[\"input_ids\"]\n",
        "    attention_masks = t_res[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    #print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out"
      ],
      "metadata": {
        "id": "iG9iuhj87cdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [x[0] for x in total_data_50_50]\n",
        "outputs = generate_paraphrase(inputs, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b44473-ecbc-409b-cd85-ba0080d3621b",
        "id": "Eb7Ap4xs7cdz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [04:44<00:00,  7.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_combi = outputs"
      ],
      "metadata": {
        "id": "ta4HN6yR7cdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(outputs_combi, open(\"new_combi_output.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "AWrt5Yj67cdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GmdTEsAfYLXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 Rewards"
      ],
      "metadata": {
        "id": "jNO4DTMAYMxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, token_ids, attention_masks):\n",
        "    self.token_ids = token_ids\n",
        "    self.attention_masks = attention_masks\n",
        "    if len(self.token_ids) != len(self.attention_masks):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _token_ids = self.token_ids[index]\n",
        "    _attention_masks = self.attention_masks[index]\n",
        "    return _token_ids, _attention_masks\n",
        "\n",
        "def seperate_sents(sent):\n",
        "  rm_special = sent.replace(\"<BOS>\",\"\").replace(\"<PAD>\",\"\")\n",
        "  input = rm_special.split(\"<SCI_GEN>\")[0]\n",
        "  output = rm_special.split(\"<SCI_GEN>\")[1]\n",
        "  output = output.split(\"<EOS>\")[0]\n",
        "  return input, output\n",
        "\n",
        "# Tokenize batch before inference\n",
        "def generate_paraphrase(texts, batch_size):\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  texts =  [\"<BOS>\"+ t + \"<SCI_GEN>\" for t in texts]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  tokenizer_res = tokenizer(texts, padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=100, truncation=True).to(device)\n",
        "  loader = iter(DataLoader(CustomDataset(tokenizer_res[\"input_ids\"], tokenizer_res[\"attention_mask\"]), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    token_ids, attention_masks = loader.next()\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        min_length = 10,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out\n",
        "\n"
      ],
      "metadata": {
        "id": "4-JSAJpRYMxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag1 = \"<BOS>\"\n",
        "tag2 = \"<SCI_GEN>\"\n",
        "\n",
        "model = model1_rewards\n",
        "tokenizer = tokenizer1_rewards\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = model.to(device)\n",
        "\n",
        "# Tokenize batch during inference\n",
        "def generate_paraphrase(texts, batch_size=128):\n",
        "  # Add special tokens and sort by len\n",
        "  texts =  [tag1+ t + tag2 for t in texts]\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  loader = iter(DataLoader(CustomDataset(texts, [1]*len(texts)), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    texts, all_lens = loader.next()\n",
        "    t_res = tokenizer(list(texts), padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=200, truncation=True).to(device)\n",
        "    token_ids = t_res[\"input_ids\"]\n",
        "    attention_masks = t_res[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    #print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out"
      ],
      "metadata": {
        "id": "d0-7b6daYMxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [x[0] for x in total_data_50_50]\n",
        "outputs = generate_paraphrase(inputs, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725723be-f6fc-4c8f-d00f-265178120130",
        "id": "kXi3FlJ-YMxR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [06:48<00:00, 10.21s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_model1_rewards = outputs"
      ],
      "metadata": {
        "id": "soLoBxElYMxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(outputs_model1_rewards, open(\"new_model1_rewards_output.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "JBLHYj6VYMxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2_2"
      ],
      "metadata": {
        "id": "wp6nlQ_8bcJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, token_ids, attention_masks):\n",
        "    self.token_ids = token_ids\n",
        "    self.attention_masks = attention_masks\n",
        "    if len(self.token_ids) != len(self.attention_masks):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _token_ids = self.token_ids[index]\n",
        "    _attention_masks = self.attention_masks[index]\n",
        "    return _token_ids, _attention_masks\n",
        "\n",
        "def seperate_sents(sent):\n",
        "  rm_special = sent.replace(\"<BOS>\",\"\").replace(\"<PAD>\",\"\")\n",
        "  input = rm_special.split(\"<SCI_GEN>\")[0]\n",
        "  output = rm_special.split(\"<SCI_GEN>\")[1]\n",
        "  output = output.split(\"<EOS>\")[0]\n",
        "  return input, output\n",
        "\n",
        "# Tokenize batch before inference\n",
        "def generate_paraphrase(texts, batch_size):\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  texts =  [\"<BOS>\"+ t + \"<SCI_GEN>\" for t in texts]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  tokenizer_res = tokenizer(texts, padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=100, truncation=True).to(device)\n",
        "  loader = iter(DataLoader(CustomDataset(tokenizer_res[\"input_ids\"], tokenizer_res[\"attention_mask\"]), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    token_ids, attention_masks = loader.next()\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        min_length = 10,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out\n",
        "\n"
      ],
      "metadata": {
        "id": "zUg8e56LbcJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag1 = \"<BOS>\"\n",
        "tag2 = \"<SCI_GEN>\"\n",
        "\n",
        "model = model_2\n",
        "tokenizer = tokenizer_2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = model.to(device)\n",
        "\n",
        "# Tokenize batch during inference\n",
        "def generate_paraphrase(texts, batch_size=128):\n",
        "  # Add special tokens and sort by len\n",
        "  texts =  [tag1+ t + tag2 for t in texts]\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  loader = iter(DataLoader(CustomDataset(texts, [1]*len(texts)), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    texts, all_lens = loader.next()\n",
        "    t_res = tokenizer(list(texts), padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=200, truncation=True).to(device)\n",
        "    token_ids = t_res[\"input_ids\"]\n",
        "    attention_masks = t_res[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    #print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out"
      ],
      "metadata": {
        "id": "FySInaHkbcJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [x[0] for x in total_model2_sample]\n",
        "outputs = generate_paraphrase(inputs, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb50bb7a-e195-44ca-e3db-117f942f9b80",
        "id": "GPK6tfg1bcJW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [02:07<00:00,  3.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_model2 = outputs"
      ],
      "metadata": {
        "id": "i9DV59vVbcJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(outputs_model2, open(\"new_model2_2outputs.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "-yuTgt0ybcJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2_1"
      ],
      "metadata": {
        "id": "OjSPp48Mc-4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, token_ids, attention_masks):\n",
        "    self.token_ids = token_ids\n",
        "    self.attention_masks = attention_masks\n",
        "    if len(self.token_ids) != len(self.attention_masks):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _token_ids = self.token_ids[index]\n",
        "    _attention_masks = self.attention_masks[index]\n",
        "    return _token_ids, _attention_masks\n",
        "\n",
        "def seperate_sents(sent):\n",
        "  rm_special = sent.replace(\"<BOS>\",\"\").replace(\"<PAD>\",\"\")\n",
        "  input = rm_special.split(\"<SCI_GEN>\")[0]\n",
        "  output = rm_special.split(\"<SCI_GEN>\")[1]\n",
        "  output = output.split(\"<EOS>\")[0]\n",
        "  return input, output\n",
        "\n",
        "# Tokenize batch before inference\n",
        "def generate_paraphrase(texts, batch_size):\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  texts =  [\"<BOS>\"+ t + \"<SCI_GEN>\" for t in texts]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  tokenizer_res = tokenizer(texts, padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=100, truncation=True).to(device)\n",
        "  loader = iter(DataLoader(CustomDataset(tokenizer_res[\"input_ids\"], tokenizer_res[\"attention_mask\"]), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    token_ids, attention_masks = loader.next()\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        min_length = 10,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out\n",
        "\n"
      ],
      "metadata": {
        "id": "1wHu97A4c-4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag1 = \"<BOS>\"\n",
        "tag2 = \"<SCI_GEN>\"\n",
        "\n",
        "model = model2_1\n",
        "tokenizer = tokenizer2_1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = model.to(device)\n",
        "\n",
        "# Tokenize batch during inference\n",
        "def generate_paraphrase(texts, batch_size=128):\n",
        "  # Add special tokens and sort by len\n",
        "  texts =  [tag1+ t + tag2 for t in texts]\n",
        "  all_lens = [len(tokenizer.tokenize(t))for t in texts]\n",
        "  texts = [t for len , t in sorted(zip(all_lens, texts)) if len < 50]\n",
        "  batch_size =  batch_size\n",
        "  num_batches = math.ceil(len(texts) / batch_size)\n",
        "  loader = iter(DataLoader(CustomDataset(texts, [1]*len(texts)), batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  all_sents = []\n",
        "  for i in tqdm(range(num_batches)):\n",
        "    torch.cuda.empty_cache()\n",
        "    texts, all_lens = loader.next()\n",
        "    t_res = tokenizer(list(texts), padding = True, return_attention_mask=True, return_tensors=\"pt\", max_length=200, truncation=True).to(device)\n",
        "    token_ids = t_res[\"input_ids\"]\n",
        "    attention_masks = t_res[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "        inputs = token_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        max_length=200,\n",
        "        pad_token_id= tokenizer.pad_token_id,\n",
        "        top_p=0.7,\n",
        "        temperature=0.9,\n",
        "        top_k=50,\n",
        "        do_sample=True,\n",
        "        early_stopping=True\n",
        "      )\n",
        "    sents = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
        "    #print(sents)\n",
        "    all_sents.extend(sents)\n",
        "    in_out = list(map(seperate_sents, all_sents))\n",
        "  return in_out"
      ],
      "metadata": {
        "id": "ZmqKdJE_c-4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [x[0] for x in total_model2_sample]\n",
        "outputs = generate_paraphrase(inputs, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dd0899-0776-4b14-e14b-bbb378f54ec5",
        "id": "ccksxTI9c-4U"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [04:14<00:00,  6.36s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_model2_1 = outputs"
      ],
      "metadata": {
        "id": "sCSP8t3_c-4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(outputs_model2_1, open(\"new_model2_1outputs.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "6P8DrqKEc-4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}